<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<search>
  
  <entry>
    <title>欢迎加入 VxWorks 俱乐部！</title>
    <url>/post/welcome-to-vxworks-club/</url>
    <categories><category>Announce</category>
    </categories>
    <tags>
      <tag>VxWorks</tag>
      <tag>WindRiver</tag>
    </tags>
    <content type="html"><![CDATA[欢迎来到 北南南北 文档站点！ 相关文章来源于 VxWorks 俱乐部  ，也可能发布于 AI 嵌入式开发  ，专注于技术分享和交流。
免责声明 所有资源均来自网络，版权归原作者，如有侵权，请联系删除！
欢迎投稿  欢迎广大网友投稿 欢迎加入网友微信群  ]]></content>
  </entry>
  
  <entry>
    <title>不理解EMC，画不好PCB</title>
    <url>/post/hardware/understand-emc-deeply-will-help-pcb-layout.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>EMC</tag>
      <tag>Layout</tag>
      <tag>PCB</tag>
    </tags>
    <content type="html"><![CDATA[本文将从PCB的分层策略、布局技巧和布线规则三个方面，介绍EMC的PCB设计技术。
除了元器件的选择和电路设计之外，良好的印制电路板（PCB）设计在电磁兼容性中也是一个非常重要的因素。PCB EMC设计的关键，是尽可能减小回流面积，让回流路径按照设计的方向流动。最常见返回电流问题来自于参考平面的裂缝、变换参考平面层、以及流经连接器的信号。跨接电容器或是去耦合电容器可能可以解决一些问题，但是必需要考虑到电容器、过孔、焊盘以及布线的总体阻抗。
PCB分层策略 电路板设计中厚度、过孔制程和电路板的层数不是解决问题的关键，优良的分层堆叠是保证电源汇流排的旁路和去耦、使电源层或接地层上的瞬态电压最小并将信号和电源的电磁场屏蔽起来的关键。从信号走线来看，好的分层策略应该是把所有的信号走线放在一层或若干层，这些层紧挨著电源层或接地层。对於电源，好的分层策略应该是电源层与接地层相邻，且电源层与接地层的距离尽可能小，这就是我们所讲的“分层”策略。下面我们将具体谈谈优良的PCB分层策略。
 布线层的投影平面应该在其回流平面层区域内。布线层如果不在其回流平面层地投影区域内，在布线时将会有信号线在投影区域外，导致“边缘辐射”问题，并且还会导致信号回路面积地增大，导致差模辐射增大。 尽量避免布线层相邻的设置。因为相邻布线层上的平行信号走线会导致信号串扰，所以如果无法避免布线层相邻，应该适当拉大两布线层之间的层间距，缩小布线层与其信号回路之间的层间距。 相邻平面层应避免其投影平面重叠。因为投影重叠时，层与层之间的耦合电容会导致各层之间的噪声互相耦合。  多层板设计 时钟频率超过5MHz，或信号上升时间小于5ns时，为了使信号回路面积能够得到很好的控制，一般需要使用多层板设计。在设计多层板时应注意如下几点原则：
 关键布线层（时钟线、总线、接口信号线、射频线、复位信号线、片选信号线以及各种控制信号线等所在层）应与完整地平面相邻，优选两地平面之间，如图1所示。关键信号线一般都是强辐射或极其敏感的信号线，靠近地平面布线能够使其信号回路面积减小，减小其辐射强度或提高抗干扰能力。  图1 关键布线层在两地平面之间
电源平面应相对于其相邻地平面内缩（建议值5H～20H）。电源平面相对于其回流地平面内缩可以有效抑制“边缘辐射”问题，如图2所示。  图2电源平面应相对于其相邻地平面内缩
此外，单板主工作电源平面（使用最广泛的电源平面）应与其地平面紧邻，以有效地减小电源电流的回路面积，如图3所示。
图3 电源平面应与其地平面紧邻
单板TOP、BOTTOM层是否无≥50MHz的信号线。如有，最好将高频信号走在两个平面层之间，以抑制其对空间的辐射。  单层板和双层板设计 对于单层板和双层板的设计，主要应注意关键信号线和电源线的设计。电源走线附近必须有地线与其紧邻、平行走线，以减小电源电流回路面积。
单层板的关键信号线两侧应该布“Guide Ground Line”，如图4所示。双层板的关键信号线地投影平面上应有大面积铺地，或者同单层板地处理办法，设计“Guide Ground Line”，如图5所示。关键信号线两侧地“保卫地线”一方面可以减小信号回路面积，另外，还可以防止信号线与其他信号线之间地串扰。
图4单层板的关键信号线两侧布“Guide Ground Line”
图5 双层板的关键信号线地投影平面上大面积铺地
总的来说，PCB板的分层可以依据下表来设计。
PCB布局技巧 PCB布局设计时，应充分遵守沿信号流向直线放置的设计原则，尽量避免来回环绕，如图6所示。这样可以避免信号直接耦合，影响信号质量。此外，为了防止电路之间、电子元器件之间的互相干扰和耦合，电路的放置和元器件的布局应遵从如下原则：
图6 电路模块沿信号流向直线放置
  单板上如果设计了接口“干净地”，则滤波、隔离器件应放置在“干净地”和工作地之间的隔离带上。这样可以避免滤波或隔离器件通过平面层互相耦合，削弱效果。此外，“干净地”上，除了滤波和防护器件之外，不能放置任何其他器件。
  多种模块电路在同一PCB上放置时，数字电路与模拟电路、高速与低速电路应分开布局，以避免数字电路、模拟电路、高速电路以及低速电路之间的互相干扰。另外，当线路板上同时存在高、中、低速电路时，为了避免高频电路噪声通过接口向外辐射，应该遵从图7中的布局原则。
  图7 高、中、低速电路布局原则
线路板电源输入口的滤波电路应应靠近接口放置，避免已经经过了滤波的线路被再次耦合。  图8 电源输入口的滤波电路应应靠近接口放置
接口电路的滤波、防护以及隔离器件靠近接口放置，如图9所示，可以有效的实现防护、滤波和隔离的效果。如果接口处既有滤波又有防护电路，应该遵从先防护后滤波的原则。因为防护电路是用来进行外来过压和过流抑制的，如果将防护电路放置在滤波电路之后，滤波电路会被过压和过流损坏。此外，由于电路的输入输出走线相互耦合时会削弱滤波、隔离或防护效果，布局时要保证滤波电路（滤波器）、隔离以及防护电路的输入输出线不要相互耦合。  图9接口电路的滤波、防护以及隔离器件靠近接口放置
敏感电路或器件（如复位电路等）远离单板各边缘特别是单板接口侧边缘至少1000mil。 存在较大电流变化的单元电路或器件（如电源模块的输入输出端、风扇及继电器）附近应放置储能和高频滤波电容，以减小大电流回路的回路面积。 滤波器件需并排放置，以防止滤波后的电路被再次干扰。 晶体、晶振、继电器、开关电源等强辐射器件远离单板接口连接器至少1000mil。这样可将干扰直接向外辐射或在外出电缆上耦合出电流来向外辐射。  PCB布线规则 除了元器件的选择和电路设计之外，良好的印制电路板（PCB）布线在电磁兼容性中也是一个非常重要的因素。既然PCB是系统的固有成分，在PCB布线中增强电磁兼容性不会给产品的最终完成带来附加费用。任何人都应记住一个拙劣的PCB布线能导致更多的电磁兼容问题，而不是消除这些问题，在很多例子中，就算加上滤波器和元器件也不能解决这些问题。到最后，不得不对整个板子重新布线。因此，在开始时养成良好的PCB布线习惯是最省钱的办法。下面将对PCB布线的一些普遍规则和电源线、地线及信号线的设计策略进行介绍，最后，根据这些规则，对空气调节器的典型印制电路板电路提出改进措施。
 布线分离  布线分离的作用是将PCB同一层内相邻线路之间的串扰和噪声耦合最小化。3W规范表明所有的信号（时钟，视频，音频，复位等等）都必须象图10所示那样，在线与线，边沿到边沿间予以隔离。为了进一步的减小磁耦合，将基准地布放在关键信号附近以隔离其他信号线上产生的耦合噪声。
图10 线迹隔离
保护与分流线路  设置分流和保护线路是对关键信号，比如对在一个充满噪声的环境中的系统时钟信号进行隔离和保护的非常有效的方法。在图21中，PCB内的并联或者保护线路是沿着关键信号的线路布放。保护线路不仅隔离了由其他信号线上产生的耦合磁通，而且也将关键信号从与其他信号线的耦合中隔离开来。分流线路和保护线路之间的不同之处在于分流线路不必被端接（与地连接），但是保护线路的两端都必须连接到地。为了进一步的减少耦合，多层PCB中的保护线路可以每隔一段就加上到地的通路。
图11 分流和保护线路
电源线设计  根据印制线路板电流的大小，尽量加粗电源线宽度，减少环路电阻。同时、使电源线、地线的走向和数据传递的方向一致，这样有助于增强抗噪声能力。在单面板或双面板中，如果电源线走线很长，应每隔3000mil对地加去耦合电容，电容取值为10uF＋1000pF。
地线设计  地线设计的原则是：
 数字地与模拟地分开。若线路板上既有逻辑电路又有线性电路，应使它们尽量分开。低频电路的地应尽量采用单点并联接地，实际布线有困难时可部分串联后再并联接地。高频电路宜采用多点串联接地，地线应短而租，高频元件周围尽量用栅格状大面积地箔。 接地线应尽量加粗。若接地线用很纫的线条，则接地电位随电流的变化而变化，使抗噪性能降低。因此应将接地线加粗，使它能通过三倍于印制板上的允许电流。如有可能，接地线应在2~3mm以上。 接地线构成闭环路。只由数字电路组成的印制板，其接地电路布成团环路大多能提高抗噪声能力。  信号线设计  对于关键信号线，如果单板有内部信号走线层，则时钟等关键信号线布在内层，优先考虑优选布线层。另外，关键信号线一定不能跨分割区走线，包括过孔、焊盘导致的参考平面间隙，否则会导致信号回路面积的增大。而且关键信号线应距参考平面边沿≥3H（H为线距离参考平面的高度），以抑制边缘辐射效应。
对于时钟线、总线、射频线等强辐射信号线和复位信号线、片选信号线、系统控制信号等敏感信号线，应远离接口外出信号线。从而避免强辐射信号线上的干扰耦合到外出信号线上，向外辐射；也避免接口外出信号线带进来的外来干扰耦合到敏感信号线上，导致系统误操作。
对于差分信号线应同层、等长、并行走线，保持阻抗一致，差分线间无其它走线。因为保证差分线对的共模阻抗相等，可以提高其抗干扰能力。
根据以上布线规则，对空气调节器的典型印制电路板电路进行改进优化，如图12所示。
图12 改进空气调节器的典型印制电路板电路
总体来说，PCB设计对EMC的改善是：在布线之前，先研究好回流路径的设计方案，就有最好的成功机会，可以达成降低EMI辐射的目标。而且在还没有动手实际布线之前，变更布线层等都不必花费任何钱，是改善EMC最便宜的做法。
]]></content>
  </entry>
  
  <entry>
    <title>什么是域控服务器</title>
    <url>/post/server/what-is-a-domain-control-server.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Domain Control</tag>
    </tags>
    <content type="html"><![CDATA[在当今信息技术领域，组织和管理大量用户、计算机和资源是一项庞大的任务。为了有效地实现这一目标，域控制服务器应运而生。域控制服务器是一种关键的网络服务，其核心功能是集中管理和分发安全策略、用户账户、组信息等，从而提高组织内部的整体安全性和协同工作效率。
域控制服务器的概念源于Microsoft的Active Directory（AD）服务，是一种分层、分布式的目录服务。通过域控制服务器，组织可以有效地组织和管理网络中的资源，并提供了一种集中式的身份验证机制，确保只有授权用户能够访问特定资源。
域控服务器在信息技术中扮演了多重角色，其核心功能和作用包括：
  用户身份验证 域控服务器负责验证用户的身份，确保只有合法用户能够访问组织内的资源。这通过用户账户和密码的验证实现。
  资源管理 通过域控服务器，管理员可以轻松管理和分配网络上的资源，包括文件夹、打印机、应用程序等。这为组织内的资源分配提供了灵活性和集中化管理。
  安全策略和权限控制 域控服务器允许管理员定义安全策略，包括访问控制、密码策略等，以确保网络的安全性。权限控制机制通过用户组的创建和管理来实现，使管理员能够轻松地控制用户对资源的访问权限。
  集中化管理 域控服务器提供了集中化的管理平台，管理员可以通过一个界面管理整个网络中的用户、计算机、服务器等。这种集中化管理简化了日常管理任务，提高了效率。
  基础概念 域（Domain） 在理解域控服务器之前，首先需要了解什么是“域”。域是一种在网络环境中组织和管理用户、计算机和其他网络资源的方式。它可以看作是一种逻辑上的划分，将网络划分为不同的管理单元，每个域都有自己的安全策略、用户账户和资源。
 域边界（Domain Boundary）： 域的边界定义了一个管理单元的范围，决定了哪些资源和用户属于特定的域。 域名（Domain Name）： 域名是用于唯一标识域的名称。在网络中，域名通常采用层级结构，例如example.com。域名不仅用于标识域，还在Internet上唯一标识计算机和服务。  目录服务（Directory Service） 目录服务是一种用于存储和组织信息的服务，提供了对这些信息进行检索和更新的机制。在域控制服务器的背后，最常见的目录服务是Microsoft的Active Directory（AD）服务。
 目录（Directory）： 目录是一个包含有关对象的信息的集合。对象可以是用户、计算机、打印机等网络中的实体。 架构（Schema）： 架构定义了目录中可以存储的对象类型和其属性。它规定了目录的结构。  域控制器（Domain Controller） 域控制器是运行域控制服务器软件的计算机，负责存储和管理域中的目录信息。一个域可以有多个域控制器，它们之间共享目录信息，并提供容错和负载均衡。
 目录复制（Directory Replication）： 多个域控制器之间会定期同步目录信息，确保它们保持最新。这种同步过程称为目录复制。 全局目录（Global Catalog）： 全局目录包含了域中所有对象的一部分信息，用于加速查询操作。至少有一个域控制器会充当全局目录服务器。  Active Directory（AD）服务 Active Directory（AD）是Microsoft开发的目录服务，为组织提供了一种层次化的方式来存储和组织网络中的资源。以下是一些关键概念：
Active Directory使用层次化的目录树结构，类似于文件系统。树的顶部是根域，下面是子域，形成了一个层次结构，使得资源可以有序地组织。
AD的架构定义了目录中可以存储的对象类型和属性。架构规定了整个目录树的结构，包括用户、组、计算机等对象类型，以及它们的属性。
每个对象在AD中都有一个唯一的名字，称为Distinguished Name（DN）。DN通过命名空间唯一标识了目录树中的对象，使其易于查找和引用。
AD的组织结构 域是AD中的基本组织单位，可以包含用户、计算机、组等对象。域的边界由域控制器定义，每个域都有唯一的域名。
OU是域内的一个子容器，用于组织和管理对象。OU提供了更灵活的管理层次，管理员可以根据组织的结构创建OU，将对象分类放置。
AD中的对象和属性  对象  在AD中，对象是指用户、计算机、组等实体。每个对象都有一个唯一的DN标识。
 属性  对象包含属性，描述了对象的特征。例如，用户对象的属性包括姓名、电子邮件地址、密码等。属性定义了对象的各个方面。
 构建Block  构建Block是AD中的逻辑组，它定义了一组常用的对象和属性。构建Block使得在创建新对象时更加简便，可以快速选择所需的属性。
AD服务的工作原理   身份验证 当用户尝试登录时，域控制器负责对用户进行身份验证。这通常涉及到使用Kerberos协议，确保用户是合法的域用户。
  目录查找 当用户需要访问某个资源时，客户端会向域控制器发送LDAP查询请求，域控制器负责查找并返回所需的目录信息。
  复制机制 AD使用复制机制保持域控制器之间的目录信息同步。这确保了在整个域中的所有域控制器都具有相同的目录信息。
  LDAP和AD的区别 LDAP（轻量级目录访问协议）和AD（Active Directory）是两个不同但相关的概念：
LDAP（Lightweight Directory Access Protocol）：  LDAP是一种协议，用于访问和维护分布式目录服务信息。 它是一个开放标准，可以在不同的操作系统和应用程序之间实现目录信息的共享和访问。 LDAP目录是一种分层、有组织的目录服务，可以存储和管理用户、计算机、应用程序等信息。 LDAP本身并不限制于特定的操作系统或应用程序，因此它是一个通用的目录服务协议。  AD（Active Directory）：  AD是Microsoft Windows操作系统中的目录服务。 它使用LDAP作为其核心协议，但AD不仅限于LDAP，还包括其他服务和功能。 AD提供了用于存储和组织网络中的对象（如用户、计算机、组）的目录服务。 AD还包括身份验证、授权、策略管理等功能，使其成为一个综合的目录和身份管理解决方案。 AD通常用于创建和管理Windows域，提供了一种集中化的管理方式。  区别：  LDAP是协议，而AD是基于LDAP的目录服务实现。 LDAP是一个开放标准，可以在各种系统中实现，而AD是Microsoft专门为Windows环境设计的目录服务。 LDAP本身并不提供身份验证、授权等功能，而AD在LDAP的基础上扩展，提供了更多的功能和服务。   LDAP是一个通用的协议，而AD是一个特定于Windows环境的目录服务。在Windows环境中，AD是主要的目录服务解决方案，而LDAP可以在其他环境中用于类似的目录服务需求。  域控服务器的部署与配置 选择适当的操作系统是域控服务器部署的第一步。常见的域控制器操作系统包括Windows Server系列。在选择操作系统时，考虑以下因素：
 版本选择： 不同版本的Windows Server提供了不同的功能，选择适合组织需求的版本。 硬件要求： 确保选定的操作系统符合组织的硬件规格，以确保系统性能。  在部署域控服务器之前，需要进行一些前期准备工作，包括：
 网络规划  定义域的网络结构，确定IP地址分配方案以及子网划分。良好的网络规划有助于提高网络性能和管理效率。
域名规划  选择适当的域名，确保域名能够清晰地反映组织结构。同时，考虑域名的唯一性和易记性。
硬件规划  评估组织的硬件需求，确保域控服务器有足够的计算资源来处理用户身份验证、目录查找等任务。
域控服务器的安装步骤 安装操作系统 在选定的硬件上安装选择的操作系统。确保按照操作系统的最佳实践进行配置，包括安装最新的更新和补丁。
添加域控制器角色 通过服务器管理工具添加域控制器角色。在此过程中，定义域的类型（新域、附加域）、设置域的管理员密码等。
Active Directory配置 完成域控服务器的安装后，进行Active Directory配置，包括指定域控制器的命名、选择目录服务复制选项、配置DNS服务等。
配置域控服务器的最佳实践  启用安全日志记录：配置域控服务器以记录安全事件，以便审计和监视安全性。 实施密码策略：定义强密码策略，包括密码长度、复杂性要求和定期更改密码等。 调整硬件资源：根据实际负载和需求，调整域控服务器的硬件资源，以保障性能。 监控性能指标：使用性能监控工具跟踪域控服务器的性能指标，及时发现并解决潜在问题。 定期备份：建立定期备份策略，确保在发生故障时能够快速恢复域控服务器。 日志分析：定期分析域控服务器的日志，及时发现并解决潜在问题。  用户和组管理 用户账户的创建与管理 使用Active Directory Users and Computers（ADUC）工具，管理员可以创建新用户账户。在创建用户时，需要指定用户名、密码、邮箱等信息，并分配适当的组成员身份。
管理员可以管理用户账户的属性，包括修改用户密码、设置账户过期时间、启用或禁用账户等。这些属性的合理管理有助于提高账户的安全性和可维护性。
组的概念与应用 组是一种将用户集合在一起的方式，简化对多个用户的权限管理。通过ADUC工具，管理员可以创建不同类型的组，如安全组和分发组。
将用户添加到组中，通过为组分配权限，可以有效地管理和控制用户对资源的访问。这种权限的集中管理使得安全性的维护变得更为简便。
用户和组的权限管理 通过ACL，管理员可以定义对资源的访问权限。ACL将用户和组与资源之间建立关系，控制用户是否可以读取、修改或删除特定资源。
RBAC是一种权限管理模型，通过将权限分配给角色，然后将用户分配到角色上，实现对用户访问权限的灵活控制。
用户和组的安全性最佳实践 遵循最小权限原则，即给予用户和组足够的权限来完成其工作，但不多于其实际需要的权限，以减小潜在的安全风险。
定期审计用户和组的权限，确保权限的分配和使用符合组织的安全策略。及时发现并纠正不当的权限配置。
安全性与身份验证 安全性策略  密码复杂性要求： 确保用户设置强密码，包括大小写字母、数字和特殊字符。 密码历史： 防止用户反复使用相同的密码，通过密码历史机制限制新密码与先前使用的密码相似度。 账户锁定阈值： 设置账户锁定的尝试次数，以防止暴力破解攻击。 账户锁定持续时间： 在账户锁定后，设定账户锁定持续的时间，以防止频繁尝试。  审计策略  安全审计： 启用安全审计，记录与身份验证和权限相关的事件，以便在发生安全事件时进行追踪和调查。  身份验证机制  票据传递： Kerberos使用票据传递机制，确保用户只需登录一次即可访问多个服务，提高便利性。 TGT（Ticket Granting Ticket）： 用户通过一次身份验证获得TGT，后续访问其他服务时使用TGT获取服务票据。 双因素认证： 引入双因素认证，通常包括密码和额外的身份验证方法，如手机短信、硬件令牌等。 智能卡： 使用智能卡进行身份验证，提高身份验证的安全性，防止密码被盗取。  安全性最佳实践  审计日志： 定期审查域控服务器的安全审计日志，以便发现异常活动。 实时监控： 使用实时监控工具，对身份验证事件进行实时监控，及时应对潜在威胁。 网络隔离： 将域控服务器置于安全的网络段，限制对其访问的网络流量，防止未授权的访问。 用户培训： 对用户进行定期的安全培训，教育其使用安全密码、避免点击恶意链接等。  通过采取这些安全性和身份验证最佳实践，组织可以有效地保护域控服务器，防止未授权访问和数据泄露，确保身份验证机制的安全可靠性。
故障排除与性能优化 身份验证问题  密码重置： 处理用户无法登录的情况，执行密码重置并通知用户。 账户锁定： 如用户账户被锁定，解锁账户并调整账户锁定策略。  目录同步问题  检查复制状态： 确保域控服务器之间的目录复制正常进行，及时发现并解决同步问题。  DNS配置问题  DNS解析： 检查域控服务器的DNS配置，确保域名解析正常，避免网络通信问题。   使用性能监控工具监测域控服务器的CPU和内存使用率，确保资源利用率在合理范围内。 检查磁盘I/O性能，确保磁盘读写操作不成为性能瓶颈。 移除不再需要的日志和临时文件，释放存储空间。 监测网络带宽利用率，确保域控服务器能够处理正常的网络流量。 处理网络延迟问题，确保域控服务器与其他服务器之间的通信畅通。 定期备份域控服务器的系统状态，以便在需要时进行快速恢复。 定期备份Active Directory数据库，确保目录数据的安全性。 定期分析域控服务器的审计日志，寻找潜在的故障迹象和安全事件。 制定灾难恢复计划，包括域控服务器故障时的快速恢复步骤。  总结 域控服务器是企业网络架构中至关重要的组件之一，其在网络安全、用户管理和资源控制方面发挥着关键作用。
下面瑞哥对重要的概念进行总结，大家可以回顾一下文章内容，看看自己到底掌握了多少。
 基础概念：   域的定义： 域是一种逻辑结构，用于组织和管理网络中的用户、计算机和资源。 目录服务： 通过LDAP协议，域控服务器提供分层次的目录服务，用于存储、组织和访问信息。  Active Directory服务：   目录结构： 基于树形结构，Active Directory提供层次化的组织，包括域、组织单元和对象。 对象与属性： 用户、计算机等都是对象，它们具有各种属性，如姓名、电子邮件等。  用户和组管理：   用户账户： 通过域控服务器创建和管理，包括密码策略、属性和隶属关系。 组的概念： 用于组织和管理用户，通过组实现权限分配和资源控制。  安全性与身份验证：   密码策略： 包括密码复杂性和密码历史，提高账户安全性。 Kerberos身份验证： 通过票据传递和TGT提高身份验证安全性。 多因素身份验证： 引入双因素认证和智能卡，增强身份验证层级。 ]]></content>
  </entry>
  
  <entry>
    <title>PCB上怎么画GND</title>
    <url>/post/hardware/how-to-draw-gnd-on-pcb.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>PCB</tag>
      <tag>GND</tag>
    </tags>
    <content type="html"><![CDATA[在电路原理设计阶段，为了降低电路之间的互相干扰，工程师一般会引入不同的GND地线，作为不同功能电路的0V参考点，形成不同的电流回路。
GND地线的分类 细究GND的原理 一个地线GND怎么会有这么多区分，简单的电路问题怎么弄得这么复杂？为什么需要引入这么多细分的GND地线功能呢？工程师一般针对这类GND地线设计问题，都简单的统一命名为GND，在原理图设计过程中没有加以区分，导致在PCB布线的时候很难有效识别不同电路功能的GND地线，直接简单地将所有GND地线连接在一起。虽然这样操作简便，但这将导致一系列问题：
 信号串扰: 假如将不同功能的地线GND直接连接在一起，大功率电路通过地线GND，会影响小功率电路的0V参考点GND，从而产生不同电路信号之间的串扰。 信号精度: 模拟电路的考核核心指标就是信号的精度。失去精度，模拟电路也就失去了原本的功能意义。交流电源的地线CGND由于是正弦波，是周期性的上下波动变化，它的电压也是上下波动，不是像直流地线GND一样始终维持在一个0V上不变。将不同电路的地线GND连接在一起，周期性变化的交流地线CGND会带动模拟电路的地线AGND变化，这样就影响了模拟信号的电压精度值了。 EMC实验: 信号越弱，对外的电磁辐射EMC也就越弱；信号越强，对外的电磁辐射EMC也就越强。假如将不同电路的地线GND连接在一起，信号强电路的地线GND，直接干扰了信号弱电路的地线GND，后果是原本信号弱的电磁辐射EMC，也成为了对外电磁辐射强的信号源，增加了电路处理EMC实验的难度。 电路可靠性: 电路系统之间，信号连接的部分越少，电路独立运行的能力越强；信号连接的部分越多，电路独立运行的能力就越弱。试想，如果两个电路系统A和电路系统B，没有任何的交集，电路系统A的功能好坏是不能影响电路系统B的正常工作，同样电路系统B的功能好坏也不能影响电路系统A的正常工作。假如在电路系统中，将不同功能的电路地线连接在一起，就相当于增加了电路之间干扰的一个联系纽带，也即降低了电路运行的可靠性。  手把手教你画“GND” “GND”在一块PCB板上的重要程度，不亚于水对人体的重要程度。怎么画好“GND”呢？只要注意下面这几点就可以了。
做好分区“GND” 在PCB板上，不同的模块功能会分布在不同的位置，而对应模块的“GND”要求也会不一样。下图是一个电源地与信号地冲突的画板，此电路中电源的GND实际作用是“电源负极”而不是“0V参考地”，而信号部分的GND实际作用是“0V参考地”。在这种情况下，电源地的不干净就导致了信号部分受干扰！这样的情况处理的方式分两种：1.将信号部分的地与电源部分的GND分开，不要直接连接；2.将信号部分的GND掏空，如果需要供电，就以走线的方式去供电。
不要跨步“GND” 还有一些受制于结构导致的，某一个模块本应完整的GND，被其他走线分割成多个区域的跨步GND。例如下图的PCB电路所示，电源输入的负极接上PCB板后直接变成“GND”也就是①位置，往电源模块过去的方向上，①与②之间被信号线隔断；②与③之间被5V输出隔断；而③与④之间被芯片的使能隔断。这样布局的GND虽然用万用表上测量是连通的，但是从原理图上的走线先后顺序，以及高频状态下的“地阻抗”来说都是不合理的。尤其是电源这个模块作为EMC问题的核心之一，地的布局一定要在同一层是完整的！
拒绝小蛮腰“GND” 在给PCB整个板子覆铜或者铺地时，经常会有一些地方因为其他位置的走线或者过孔导致“GND”与“GND”之间出现“小蛮腰”！例如下面两张图片里面，左边是“小蛮腰”类型的GND，右边是“猪尾巴”类型的GND，这两种样式的GND对于EMI和EMS来说，都不是一个好的layout！“小蛮腰”类型的GND可以对其进行加宽，或者过于狭小的区域直接禁止铺铜，而“猪尾巴”类型的GND最好不去铺铜切掉，如果是其他功能需要，就多增加过孔，确保接地OK。
PCB板上的“GND”需要工程师的反复检查，以及全局布局的考虑，不要图方便而敷衍了事，也不要为了接地而接地！在铺铜“GND”的时候，一定要注意区分各个部分的GND能否通铺，密密麻麻的走线之间是否有“不合理”的GND，以及“GND”在各个区域的实际作用！
原文地址： PCB上怎么画GND  
]]></content>
  </entry>
  
  <entry>
    <title>I2C总线基础知识分享</title>
    <url>/post/hardware/basic-knowledge-of-i2c-bus-sharing.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>I2C</tag>
    </tags>
    <content type="html"><![CDATA[很多电子工程师都应该从 EEPROM 通信了解到的I²C总线，其实，I²C总线远不止于 EEPROM 存储器，它也有类似485、SPI等应用场景。
EEPROM存储器系统架构图
位传输 I2C总线是由飞利浦(Philips)公司开发的一种双向二线制同步串行总线，实现有效的IC间的控制，它只需要两根线(SDA和SCL)即可在连接于总线上的器件之间传送信息。
I2C总线在传输数据都是按照bit来传送。SCL为时钟线，SDA为数据线；在SCL时钟线为高电平时，SDA数据线上的电平不允许被修改，SCL时钟线为低电平时，SDA数据线上的电平可为高/低。
I2C总线的位传输
起始条件：SCL为高电平时，SDA由高电平向低电平切换；表示开始传送数据。
停止条件：SCL为高电平时，SDA由低电平向高电平跳变；表示结束传送数据。
空闲条件：I2C总线的SDA和SCL两条信号线同时处于高电平时；表示空闲状态。
起始和停止条件
数据传输 字节传输 发送数据时，由主机先发送一个起始信号，再将SDA信号切换为输出模式，然后将8位数据依次由高到低发送出去；
发送完成后，主机将SDA信号切换为输入模式，等待丛机回应ACK或NAK；再发下一笔数据
I2C总线数据传输
丛机地址 在I2C总线系统中，每个设备都有它的固定地址，一般由芯片的A0,A1和A2决定。丛机地址字节由七位地址位(D7-D1位)和一位方向位(为D0位)组成。
器件地址的D7-D4一般都是被厂家固定了为1111，余下的D3，D2和D1连接到芯片的A2，A1和A0决定；D0为0x00表示写，D0为0x01表示读。大家看例程都是些0xA0和0xA1就是这个原因。
EEPROM的器件地址
读写过程 写数据过程  主机发送I2C总线停止信号，防止总线忙写数据失败 主机发送I2C总线复位信号，确保写数据之前总线处于空闲状态 主机发送I2C总线开始信号，启动一次数据的写入 主机发送I2C丛机地址和写模式(W/R=0)信号，并且等待一个丛机的应答信号 主机接收到ACK的应答信号后，开始多个字节的写入，每写完一个字节需要等待一个丛机的应答信号 主机接收到ACK的应答信号后，发送2IC总线停止信号，确保总线处于空闲状态  读数据过程  主机发送I2C总线停止信号，防止总线忙写数据失败 主机发送I2C总线复位信号，确保读数据之前总线处于空闲状态 主机发送I2C总线开始信号，启动一次数据读取 主机发送I2C丛机地址和读模式(W/R=1)信号，并且等待一个丛机的应答信号 主机接收到ACK的应答信号后，开始多个字节的读取，每读完一个字节需要给丛机发送一个ACK应答信号 主机接收到ACK的应答信号后，发送I2C总线停止信号，确保总线处于空闲状态  主机读/写数据过程
结语 I2C总线在嵌入式应用中非常广泛，基本上所有的电力电子设备都会用到这个总线。
]]></content>
  </entry>
  
  <entry>
    <title>AI PC的崛起，开启个人计算机的新纪元</title>
    <url>/post/hardware/the-rise-of-AI-PC-opens-a-new-era-of-personal-computers.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>AI</tag>
      <tag>PC</tag>
    </tags>
    <content type="html"><![CDATA[“AI”这个词汇相信大多数人都比较熟悉了。随着 人工智能（AI）  技术的不断发展，它变得越来越贴近我们的生活。
对于我们做BIOS的来讲，AI PC显得这么近却又那么远，说近是因为AI应用到PC上了，而说远则是几乎不用BIOS做什么事情。但是为了与时俱进，我还是花时间AI做了一些了解。
进入正题，伴随着强大的AI模型如OpenAI的ChatGPT、微软的Copilot和谷歌的Gemini，以及国内的文心一言、通义千问等的问世，人工智能已经从幕后研究走向日常应用的前台。这些大模型在语言理解、编程协作、数据处理和认知服务等多领域展现出强大的能力。
什么是AI PC AI PC是指在硬件层面集成了特定的AI处理单元，可以提供深度学习和机器学习等能力的个人计算机。这些计算机通常配备有高性能的中央处理器(CPU)，图形处理器(GPU)以及神经处理单元(NPU)等，以满足人工智能应用程序的特定需求。据trendforce报道，微软对AI PC定义的理想标准包括至少拥有40 TOPS的算力和至少16GB的DRAM。Intel于2023年12月推出的 Meteor Lake 的 CPU+GPU+NPU 综合算力为 34 TOPS，未达到微软的标准。然而，Intel即将推出的 Lunar Lake 可能会突破 40 TOPS 的门槛。
与普通PC相比，AI PC具备更强大的算力和高效的数据处理能力。它可以实时地执行复杂算法，如图像识别、自然语言处理和机器学习任务，引领用户享受到智能助理、自然交互和定制化服务的便捷。
软硬件厂商产品 行业巨头如Intel、AMD、高通不断推动AI PC的技术进步。Intel的Lunar Lake处理器，AMD的Strix Point，以及高通的Snapdragon X Elite，都是为AI和机器学习应用量身定制的芯片，它们的推出预示着AI将成为人们生活和工作的重要组成部分。
微软作为软件和操作系统的领导者，也在通过其Windows操作系统和Office套件主导AI的集成，计划将Copilot集成到下一代Windows中。它将允许用户享受到更加智能化和定制化的计算体验——一个对话式的计算环境，可以通过自然语言理解并执行用户的命令。
最后 AI PC的市场需求正在快速增长，其未来前景看起来同样光明。随着更多软硬件的整合和创新，AI PC预计将改变人们的工作方式，提高生产效率，推动教育革新，并在家庭娱乐中引入前所未有的交互形式。从企业到教育机构，再到家庭用户，AI PC的多样化用例将促使个人计算走向一个更加智慧和互联的未来。
]]></content>
  </entry>
  
  <entry>
    <title>展望2024：半导体行业收入将增长17%</title>
    <url>/post/server/outlook-2024-semiconductor-revenue-to-grow-17.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>NAND</tag>
      <tag>DRAM</tag>
    </tags>
    <content type="html"><![CDATA[根据 Gartner 公司的最新研究，全球半导体收入预计将在 2024 年取得巨大进步，达到 6240 亿美元，增长约 16.8%。
这与 2023 年市场下滑至 5340 亿美元，即同比下降 10.9% 的情况大相径庭。
Gartner 表示，2024 年的大幅增长将由存储器市场的两位数增长所推动，但这一年所有类型半导体的收入都将增长。
 内存反弹  过去几年，内存芯片市场一直处于严重供过于求的状态，导致价格下跌和需求疲软。这种下滑的趋势非常严重，Gartner 预测今年的降幅将达到创纪录的 38.8%，收入将降至 354 亿美元。
好消息是，NAND 领域的价格将触底反弹，供应商的处境将有所改善，Gartner 预测 2024 年所有内存类型的收入将增长高达 66.3%。特别是 NAND 将达到 530 亿美元，同比增长 49.6%。
供过于求也使 DRAM 厂商陷入困境，2023 年 DRAM 价格暴跌。不过，价格有望在 2024 年反弹，收入将增长 88%，达到 874 亿美元。
内存固然是 2023 年半导体业困境的一个重要原因，但其他因素也起到了推波助澜的作用：
智能手机需求减少；
个人电脑需求减少；
 数据中心  支出疲软。
]]></content>
  </entry>
  
  <entry>
    <title>2024-2025年TOP5新兴厂商：多站点文件协作解决方案</title>
    <url>/post/server/multi-site-file-collaboration-solution.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>CPU</tag>
      <tag>H100</tag>
      <tag>A100</tag>
      <tag>V100</tag>
    </tags>
    <content type="html"><![CDATA[众多企业仰仗有效的基于文件的协作来支持核心业务流程。当员工在连接到文件服务器或NAS的快速链路的办公室时，一切都运转良好。然而，如今的现代劳动力已经扩展到全局范围。
分布式办公环境中的文件协作挑战 众多企业仰仗有效的基于文件的协作来支持核心业务流程。当员工在连接到文件服务器或NAS的快速链路的办公室时，一切都运转良好。然而，如今的现代劳动力已经扩展到全局范围。
在新冠疫情前，估计有5.7%的美国工作人员在家远程办公。这个百分比在短短两年内增长了近18%。这并未包括在家或办公室工作的28%的混合型员工2，以及遍布全局的远程工作者。所有这些都意味着如今的现代劳动力分散在办公室、家庭、移动设备和国外。当这个分散的劳动力需要使用传统系统进行共同文件协作时，结果就是沮丧、时间和金钱的损失，以及企业面临的风险。考虑到任何企业面临的竞争压力，实施能够加速数字协作生产的解决方案将带来多重好处。
使用传统系统进行有效文件协作的挑战包括：
有限的可扩展性： 传统系统通常在文件协作方面缺乏可扩展性。随着远程团队规模的扩大，本地文件系统可能难以满足远程文件共享和协作的不断增长的需求。
版本控制： 在缺乏有效文件协作解决方案的分布式企业中，问题会出现。员工可能意识到他们正在处理错误版本的文件。更糟糕的是，他们可能在向客户发送不正确版本后才发现这一点。团队成员必须比较版本以找到和理解两个可能文档之间的差异，从而浪费时间。然后，用户必须花时间解决和合并不同版本以生成正确版本。
难以管理的文件数据增长： 信息技术部门面临着非结构化数据量的持续增加，其中包括协作文件。由于终端用户和IT员工通常不愿删除文件，担心会意外删除重要或必要的内容，这些动态因素导致文件混乱，并显著增加存储容量。由于企业必须保护存储的数据，备份和归档存储与其主动文件存储一起增长。
共享文件和文件夹： 为了进行协同工作，共享文件和文件夹带来了一系列问题。传统系统通常依赖于本地文件存储，这使得远程工作者难以访问文件。通过电子邮件发送文件存在安全风险、传送失败和过时文件的问题。如果团队使用电子邮件发送文档，他们必须花时间发送消息、进行更改，然后通过电子邮件发送文件。企业可以为外部合作伙伴创建VPN或其他共享方式，然而，这往往涉及手动操作和可能的错误。
数据安全和控制： 传统的文件共享方法通常缺乏安全性和合规性功能。当协作涉及敏感信息时，这种缺乏可能是一个重大问题。员工的疏忽、安全差或受损的端点和存储介质可能导致数据泄漏。一次违规或攻击可能摧毁企业及其声誉。因此，IT部门需要提供比许多传统系统更好的监控、控制和对文件数据的可见性。
处理大文件： 传统的本地NAS基础设施或许能够轻松应对大文件，但在广域网络（WAN）上共享大文件时，问题随之而来。在涉及分布式团队的情况下，文件共享可能变得缓慢，甚至变得几乎不可能。终端用户不得不完全舍弃通过电子邮件发送大文件的方式进行协作。这些挑战严重阻碍或甚至阻止数字协作团队所需的工作流程。
延迟： 无论是在本地还是云端，集中文件存储为多地点文件协作提供了可能性，但同时也存在一些障碍。广域网传输速度、移动访问以及在WAN链路上与其他应用程序竞争可能导致延迟问题，使协作工作变得沉闷和耗时。对于存储在本地的文件，除了那些位于托管文件本地的用户之外，用户体验通常较慢。
受阻、成本和风险： 企业失去了宝贵的时间和金钱。此外，传统方法缺乏企业范围的自动化，无法实现效率收益。这些问题降低了生产力，增加了成本，并提高了对数据安全、收入和品牌声誉的风险。
基于SDS的文件协作优势 随着向分布式劳动力的过渡，企业正积极将SDS解决方案融入其存储基础设施中，以获得这些软件产品提供的卓越灵活性、敏捷性和功能。许多基于SDS的文件存储解决方案包括强化多地点文件协作的功能，并带来多方面的好处。
可扩展性： 随着企业的扩张，这些文件存储解决方案允许IT部门轻松适应新增用户、容量和协作服务。最佳的软件产品在扩展的同时能够提供一贯的性能。
版本控制： 作为一个显著的功能，这些解决方案有助于在时间轴上管理、跟踪和保留文件的更改。用户可以在出错或更喜欢文件的早期版本时回滚到早期文件版本。这些解决方案通常提供审计跟踪，展示了文件的所有互动，以符合合规性和安全性的要求。
现代文件协作： 这些软件产品支持与企业外的内部和外部利益相关者共享文件和文件夹。根据需要，可以定制访问程度。对协作者文件的更改会自动更新到权威源，不管它们位于何处。为了加快同步，只有更改的文件部分通过网络传输。这些解决方案的一个常见特征是它们能够流畅处理大文件。
减少存储容量： 通过集中共享文件并实施有效的版本控制，公司可以节省文件存储成本。许多产品还利用压缩和去重技术以实现更高效的存储和减少数据传输。因此，企业可以节省文件存储成本并减少WAN带宽需求。
公有云集成： SDS解决方案通常与公有云服务集成。这为公有云或混合云部署提供了机会。企业可以利用公有云存储进行归档、备份或托管文件进行协作。此外，公有云提供商为保护数据免受网络攻击和不可预见事件提供了许多功能。
数据保护、安全和控制： 通过这些产品，IT管理员可以全面管理共享文件数据。IT部门通过在粒度级别分配文件权限属性而获得控制。企业可以利用数据安全功能来保护其数据免受未经授权的访问。
快速文件访问： 这些软件产品经常集成提供分布式团队和远程终端用户快速访问活动文件的技术。例如，尽管权威文件可能存储在私有或公有云中，但每个办公室或终端用户都在本地缓存活动数据。这提高了性能，并在用户或应用程序访问数据时克服了WAN延迟问题。文件更改在后端更新，对终端用户不可见。因此，所有用户都能够近乎立即查看文件更新，从而提升积极的终端用户体验。
自动化： 这些文件协作解决方案提供自动化功能，节省时间并加速数字制作。许多解决方案支持API，允许企业将文件工作流集成到其他软件应用程序中。企业可以自动化和编排复杂的协作过程，否则可能是容易出错的手动尝试。自动化可节省企业的时间和金钱，并通过加速工作流程提高收入。
总之，这些解决方案加速了文件协作，改善了终端用户体验，增强了安全性，并减少了企业的存储需求。最终，这些能力对于提高企业为其内部和外部利益相关者生产数字资产的质量和速度至关重要。
解决方案的突出特点 本报告是对文件存储的SDS市场的深入研究成果。在这次研究中，DCIG对大多数解决方案进行了评估，这反映了SDS解决方案的典型特性。更详细的调查揭示，其中一些解决方案体现了SDS的一部分特性，但并非全部。这些为数不多的解决方案提供了卓越的文件协作能力。总体而言，DCIG评估了18个符合其对崛起供应商的定义，并被归类为文件协作解决方案或文件存储协议的软件定义存储解决方案。
通过对来自公开来源、供应商以及DCIG自身经验的数据进行基于特性的分析和比较，本报告中的解决方案共享以下特点，使它们在DCIG评估的其他解决方案中脱颖而出。
多云支持： 所有五个解决方案明显支持多云部署和存储。它们均能在主要的云提供商，如亚马逊、Azure、IBM和Google，作为VM部署和存储目标进行支持。这种广泛的支持提供了将云提供商的能力与业务需求相匹配的灵活性。
S3支持： 除了支持流行的文件存储协议外，所有五个解决方案都支持S3协议用于对象存储。通过S3，企业可以将其文件协作解决方案与私有和公有云对象存储集成。
并发协议访问： 在企业内部，不同的团队可能有不同的协议需求。通过支持并发多协议访问，数据可以在各种环境中共享和访问。所有五个解决方案都支持对同一数据存储的并发协议访问（SMB、NFS和S3）。
广泛的应用场景支持： 所有五个解决方案都支持超出文件协作之外的各种应用场景。这意味着IT部门可以根据各种应用程序或部门的需求定制其文件存储解决方案。这种广泛的应用场景支持还使企业能够在业务需求发展的过程中充分利用这些存储解决方案。
解决方案的其他相似性 全局命名空间： 所有五个解决方案中的每一个都提供全局命名空间（或其等效物）。全局命名空间呈现了数据的统一视图，将分布式的异构存储资源呈现为单一的中央文件系统。由此产生的可见性使企业能够在其全局数据资产中实现一致的数据管理。
REST API： 企业寻找与其现有基础设施管理工具和应用程序良好集成的解决方案。REST API有助于将SDS数据存储与外部应用程序集成。所有五个解决方案中的每一个都提供REST API。这种接口的支持使得企业能够更加灵活地整合这些解决方案，实现更高水平的自动化和工作流程集成。
解决方案之间的差异 SMB和NFS支持： 对SMB和NFS的支持在大多数企业应用程序中是访问基于文件的存储的关键协议。五个解决方案在对SMB和NFS最新版本的支持上存在差异，新版本提供了新功能、改进的性能和增强的安全性。
加密支持： 解决方案在对加密技术的支持程度上存在差异。加密在存储中发挥着至关重要的作用，通过提高数据安全性、保护敏感信息并保持合规性来实现。一些解决方案依赖底层存储平台提供加密。
第三方阵列集成： 集成第三方存储阵列的能力将现有的传统存储引入统一的存储管理领域。五个解决方案中，许多但不是全部都支持第三方存储阵列的集成。
容量优化： 容量优化技术，如压缩和去重，通过减少存储非结构化数据所需的物理存储量，帮助企业在不断增长的存储成本上节省资金。五个解决方案在它们提供的容量优化方面存在差异。
文件锁定： 在防止多个用户协作一个文件时的机制上，五个解决方案存在差异。一些供应商内置自己的文件锁定机制，而其他人依赖文件存储协议提供文件锁定服务。
操作系统和虚拟化支持： 解决方案在对流行操作系统（OS）和虚拟化技术的支持上存在差异。IT企业重视广泛的OS和虚拟化支持，因为这确保了任何解决方案在整个IT环境中能够良好集成。
基于角色的访问控制（RBAC）： RBAC允许IT管理员分配具有预定义权限的特定角色，限制用户在工作角色中所需的访问和权限。这五家厂商对这一数据安全的附加层次有不同程度的支持。
技术支持： 在为其解决方案提供技术支持方面，DCIG TOP 5获胜者存在差异。这些差异包括客户如何报告问题、运营时间以及响应时间。
Hammerspace Hammerspace解决了在边缘、核心和云位置的孤立数据存储和数据服务之间管理和协调的关键挑战。通过抽象化企业底层的全部或部分存储基础设施，Hammerspace提供了一个并行的全局文件系统，使企业能够在任何地方提供高性能的数据读/写，并在不同的存储系统之间协调数据。Hammerspace与所有主要云提供商合作，因此企业可以跨多个云和不同的云区域以及来自任何供应商的本地和边缘数据存储管理数据。企业可以从其单一软件包开始，该软件包可安装在裸金属服务器、二型虚拟化器上，也可以本地在云中本地安装，然后逐步扩展Hammerspace以适应新的用例和位置。
全局数据管理： Hammerspace通过跨存储系统和云提供标准化的统一命名空间。由于这个统一的命名空间，基础设施管理人员可以管理、监视和分析他们整个本地和云数据生态系统的性能和健康状况。Hammerspace仪表板提供了优化存储资源、识别问题并主动解决问题的见解。使用Hammerspace，管理员可以通过其许多数据安全性和保护功能，如防病毒集成、审计、备份、灾难恢复、加密、不可变性、权限控制和快照，全面地保护和保护其企业文件数据。
全局数据协调： Hammerspace软件使文件元数据对于所有用户和应用程序都是通用的，无论文件实际存储在何处。将文件系统元数据和自定义元数据的力量结合到一个通用的层次元数据控制平面中，使企业能够以传统存储系统无法实现的方式全局协调其数据。使用Hammerspace，企业可以根据由一个或多个元数据变量触发的预定义策略在全局范围内透明地移动数据。Hammerspace使企业能够自动化涉及全局用户和应用程序的复杂工作流，从而扩大了可能性。这些能力为企业企业带来了灵活性、创新、成本降低和竞争优势。
全局文件协作： 无论文件存储协议如何，Hammerspace的编排引擎都允许经授权的用户访问和协作存储在不同位置的文件，就像它们是本地的一样。这种后台操作对用户和应用程序是透明的。Hammerspace实现了实时协作，即使不同的用户或应用程序正在处理同一文件。通过在元数据级别进行更新，以避免冲突。实时同步技术和文件协作功能确保每个用户和应用程序都拥有任何文件的最新版本。将Hammerspace的文件协作功能与其数据协调功能相结合，使企业能够大大缩短复杂项目的生产时间线。
LucidLink Filespaces LucidLink Filespaces将任何符合S3标准的对象存储呈现为本地文件系统，提供了一个专为创意协作需求而调整的高性能云原生文件服务。由于LucidLink文件服务连接并表现得像传统硬盘，几乎可以无限制地连接到云存储，使用任何桌面应用程序。这些功能使创意用户能够共同在共享数据集上工作，就像他们在同一位置一样。LucidLink提供基础、高级和定制许可层，与客户选择的几乎任何公共或私有云存储供应商兼容。
简单架构： 利用集线器和辐射拓扑结构，LucidLink Filespaces由三个主要组件组成：桌面客户端软件、元数据服务和对象存储。适用于Windows、MacOS和Linux的客户端软件为用户提供了无论他们位于何处都可以获得的本地存储体验。元数据服务向所有客户节点呈现文件系统元数据。第三个组件包括对象存储，所有文件内容都以安全的方式存储，并根据需要按需流式传输。LucidLink的架构使扩展容量和用户变得简单。
本地文件系统体验： LucidLink桌面客户端软件将云存储呈现为传统的挂载点，与任何本地硬盘没有区别。为了使远程地点的本地磁盘性能相等，LucidLink将文件存储为256KB块，使得可以在任何时刻仅流式传输桌面应用程序所需的最小文件内容。这种减少开销意味着即使在端点带宽不足的情况下，也可以实时从云中流式传输大型视频文件。LucidLink技术的其他元素，包括智能预取、本地缓存、元数据同步和将数据和元数据分割到完全不同的平面，都有助于性能和用户体验。LucidLink通过与流行的桌面创意工具集成，进一步推动了协作。
加密： LucidLink可以显著减轻远程工作的现代工作人员在彼此之间的安全担忧。LucidLink使用AES-256加密，在传输和静止时加密文件数据和元数据。每个文件和文件夹都有其自己的加密密钥，由客户的桌面实例进行管理。用户只能看到管理员已经授予他们访问权限的内容。作为LucidLink“零知识”加密模型的一部分，LucidLink和云提供商任何时候都不能查看客户数据。最后，LucidLink通过加密、不可变的快照保护客户免受勒索病毒攻击，允许企业将文件、文件夹或整个Filespace还原到勒索病毒攻击之前的最后一个快照。
Quobyte Quobyte使企业能够从单一存储基础设施提供性能、容量和可扩展性。Quobyte的SDS部署在x86硬件上，可以作为虚拟机（VM）、在云中或在Kubernetes环境中运行。企业还可以将基于本地和云的Quobyte部署组合成高效的混合云存储系统。即使在同一个集群中，基础设施管理人员也会发现Quobyte在其支持的硬件和驱动器配置方面非常灵活。通过Quobyte的管理控制台，基础设施管理人员可以设置数据存储和服务策略、监视实时性能和数据完整性、运行分析并配置重要的警报。Quobyte通过免费的社区版和包含24/7支持（通过电子邮件、电话或Zoom）的全包式许可证提供其软件。
高性能SDS： Quobyte基于并行分布式POSIX文件系统构建其存储软件。为了高性能计算，Quobyte体系结构可以向存储集群的所有节点发出并行读写。这种方法特别有利于大数据集、分析和机器学习工作负载。Quobyte的分布式架构避免依赖可能成为故障点的任何控制节点。随着更多节点加入集群，性能呈线性增长。节点数量翻倍，性能也翻倍。线性性能扩展提供了如何添加资源影响工作负载性能的清晰理解。
多协议文件协作： Quobyte在同一命名空间中提供统一的文件和对象存储。使用Quobyte，无论文件访问协议如何，用户和应用程序都可以从任何界面访问和协作数据，包括Linux、Windows、MacOS等。Quobyte用户可以通过S3在全局范围内共享其数据。在支持文件锁定的所有文件协议中，锁定（字节范围或文件级别）都会保持。Quobyte的高性能SDS解决方案使其适用于多样化的团队，无论是在小文件上工作还是协作于庞大的4k和8k视频文件。
自愈性SDS： Quobyte整合了许多功能，确保在组件故障、中断或灾难期间保持数据可用性。Quobyte会自动监视和检测有问题的连接和组件，然后根据预设的响应进行反应。这些操作可能是简单的，比如将网络路径从服务中移除，或者自动切换到冗余存储节点。其他自我恢复和自愈功能包括端到端的数据完整性检查、复制、纠删编码和卷镜像。将这些功能与Quobyte的安全功能（如加密、ACL、多租户和不可变性）结合起来，确保企业的数据对用户和应用程序既安全又可用。
Resilio Connect Resilio Connect提供了一种与传统的集线器和辐射文件协作工具不同的方法。基于点对点（P2P）架构，其分布式和多方向的解决方案可以同时在多个终端之间复制和同步文件。相较于传统方法，提供了明显更快的同步速度，使企业能够在相同或不同位置以及远程和混合团队中保持数据的实时性。当涉及到大量节点（3个或更多终端）和大量数据集时，这种更快的同步尤为明显。在远程和混合工作中，Resilio允许多个协作者在多个位置使用不同设备对相同文件进行几乎实时的更改。在后台，Resilio可靠地对变更进行哈希处理，并以多对多的完全网状复制方案将变更复制到其他连接的设备上。Resilio Connect在网络和系统中断时重新路由，增强了服务器和站点的可用性和弹性。
无限制同步： Resilio软件可以实时检测和同步数百万个文件的更改。企业可以根据需要设计文件同步，覆盖多个服务器、文件系统、存储设备、站点以及本地或离线用户。Resilio Connect可以处理小文件和大文件。同步可以是单向的、双向的、一对多的、多对多的和多对一的。对于实时同步，Resilio在文件发生更改时立即检测到并以压缩格式开始传输更改的数据块。虽然企业通常在本地部署Resilio Connect，但Resilio也可以在云中运行。例如，企业可以配置Resilio Connect将不活动的文件移至云端，以释放本地存储空间。
集中同步管理： Resilio Connect适用于任何类型的热门服务器（物理、虚拟、容器化）、存储（DAS、NAS、SAN，甚至是云文件和对象存储）和操作系统（Windows、Mac和移动设备）。Resilio Management Console可在Windows或Linux上运行。使用此控制台，管理人员可以集中管理所有文件同步服务，如添加、删除或更改共享、同步时间和优先级。所有功能都可以通过脚本或API自动化执行。此外，管理员可以监视性能并设置重要事件的通知。
快速WAN优化： Resilio Connect集成的Zero Gravity Transport（ZGT）提供了高速、低延迟的宽域网络同步优化技术。ZGT是端到端加密的，以可预测的速度在所有位置之间移动数据。因此，可以实现对WAN带宽的充分利用。ZGT克服了网络延迟和数据包丢失，并调整以最大化网络利用率，同时尊重业务优先级。所有这些功能确保关键任务数据在整个企业中无延迟地同步。
Tiger Technology Tiger Bridge Tiger Technology以“本地优先”的理念为基础，设计了其混合云解决方案的存储软件。该理念认识到在本地需要快速、低延迟的数据，并通过将本地存储与云存储和服务结合，实现了增强的好处。Tiger Bridge软件将企业的本地文件存储与云或多云存储整合成一个单一的、多层次的命名空间。通过这个单一的命名空间，企业能够通过利用云进行文件服务器扩展、持续数据保护、归档、灾难恢复、勒索病毒保护和文件协作等多方面的应用来优化本地存储。
灵活的文件扩展： Tiger Bridge成为将本地文件存储扩展到云端的理想解决方案。它与流行的云存储提供商（如Microsoft、Amazon、Google、Wasabi等）合作，支持S3兼容的对象存储。企业可以利用本地对象和文件存储进行存储扩展。管理员可通过Tiger Bridge分析现有数据存储和使用情况，决定政策以优化存储成本。Tiger Bridge可在后台基于文件大小和上次访问等标准自动将数据放置在热、冷和存档层中。它以原生格式存储文件，并通过使用现有的NTFS ACLs实现透明访问。
多站点数据同步： 通过在云中存储集中式副本，Tiger Bridge提供了远程文件协作和多站点同步的能力，无需VPN服务。管理员可以配置与协作需求相匹配的同步时间。启用文件锁定以防止文件冲突，同时允许用户在文件解锁后同步更新。若云提供商支持版本控制，企业可以使用此功能恢复以前的版本。这是一个通过云获取附加值的巧妙例子，同时优先考虑本地存储。
高性能文件协作： 除了数据同步功能外，Tiger Technology还提供了几个增强文件协作的附加产品。对于大型团队，Tiger Store可实现在SAN和NAS存储之间进行高性能协作工作流，处理高分辨率媒体等大型数据集。Tiger Spaces帮助企业在同一存储中为复杂项目分配虚拟工作空间，以管理用户、项目和工作流。最后，Spaces|MAM，也是Tiger Spaces软件套件的一部分，提供了有效的媒体资产管理工具。这些附加产品扩展并与Tiger Bridge的远程文件协作功能集成，同时为本地团队提供快速、高性能的文件协作和数字生产。
]]></content>
  </entry>
  
  <entry>
    <title>PCIe的发展史：从诞生到广泛应用</title>
    <url>/post/hardware/the-development-history-of-PCIe.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>PCIe</tag>
    </tags>
    <content type="html"><![CDATA[随着科技的不断发展，计算机硬件也在不断地更新换代。在这个过程中， PCIe  （Peripheral Component Interconnect Express，外围组件互联高速）作为一种全新的总线标准，逐渐取代了AGP和PCI，成为计算机系统中不可或缺的一部分。本文将为您详细介绍PCIe的发展史，带您了解这一技术从诞生到广泛应用的历程。
AGP和PCI的局限性 在PCIe出现之前，计算机系统中常用的总线标准主要有AGP和PCI。AGP（Accelerated Graphics Port，加速图形端口）是专门为图形卡设计的总线，它可以让图形卡与CPU之间的数据传输更加高效。然而，随着计算机硬件性能的不断提升，AGP逐渐暴露出了一些局限性，如带宽不足、扩展性差等问题。
与此同时，PCI（Peripheral Component Interconnect，外围组件互联）总线虽然可以连接各种扩展卡，但其带宽同样有限，无法满足高性能硬件的需求。因此，业界开始寻求一种全新的总线标准，以解决这些问题。
PCIe的诞生 2001年，英特尔公司提出了PCIe的概念，旨在为计算机系统提供更高的带宽、更好的扩展性和更高的可靠性。经过几年的研发，2004年，PCIe 1.0规范正式发布。PCIe 1.0采用了全新的数据传输方式，即点对点传输，每个设备独享带宽，从而大大提高了数据传输效率。
PCIe的发展 自PCIe 1.0规范发布以来，PCIe技术得到了快速发展。以下是PCIe各版本的主要特点：
 PCIe 1.0：2004年发布，提供了250MB/s的带宽。 PCIe 2.0：2007年发布，将带宽提高到了500MB/s。 PCIe 3.0：2010年发布，带宽进一步提高到了985MB/s。 PCIe 4.0：2017年发布，带宽达到了1969MB/s。 PCIe 5.0：2020年发布，带宽进一步提高到了3938MB/s。  随着PCIe版本的不断升级，其应用范围也越来越广泛。除了传统的显卡、网卡、声卡等设备外，SSD、USB控制器、Thunderbolt接口等设备也开始支持PCIe接口。
PCIe的广泛应用 如今，PCIe已经成为计算机系统中不可或缺的一部分。以下是PCIe在各个领域的应用：
 高性能计算：PCIe的高带宽和低延迟特性使其成为高性能计算领域的理想选择。许多高性能计算设备，如GPU、FPGA等，都采用PCIe接口与主板连接。 数据中心：在数据中心领域，PCIe技术被广泛应用于服务器、存储设备和网络设备。通过PCIe接口，可以实现高速数据传输，提高数据中心的性能和效率。 消费电子：随着PCIe技术的发展，越来越多的消费电子产品也开始支持PCIe接口。例如，许多高性能的笔记本电脑、平板电脑、智能手机等设备都采用了PCIe接口的SSD。  PCIe作为一种全新的总线标准，自诞生以来，其发展速度和应用范围不断扩大。未来，随着科技的不断进步，PCIe技术将继续发展，为计算机系统提供更高的性能和更好的用户体验。
]]></content>
  </entry>
  
  <entry>
    <title>华尔街：现在是时候投入量子计算了</title>
    <url>/post/news/analyst-panel-says-take-the-quantum-computing-plunge-now.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Quantum Computing</tag>
    </tags>
    <content type="html"><![CDATA[我们应该开始探索量子计算吗?去年年初，在Tabor Communications召开的华尔街高性能计算和人工智能会议上，一个分析师小组表示，答案是肯定的。
毫无疑问，量子计算的前景仍然不明朗。然而在过去的大约五年里，量子计算的各个方面几乎都在飞速发展。目前，至少有一个1000多量子比特的系统正在接近用户访问，另一个也很快完成。在 &ldquo;量子堆栈 &ldquo;的上下两端，软件产品也在不断涌现，尽管还很不完善。最令人欣喜的是，从最初的几项 POC 用例探索，到现在已发展成为许多领域的一起努力。
我们还在等什么？在取得惊人进步的同时，也存在着非常棘手的技术问题。其中，纠错/缓解问题居首位。另一个是有效的量子网络。需要选择的量子比特类型太多（至少目前是这样）。规模问题&ndash;预计实际量子计算可能需要数百万量子比特。这些都不是小挑战。为什么要费心解决呢？
也许最好的理由是别无选择。围绕实现实用量子计算的激烈地缘政治竞争——包括美国、英国、欧盟和中国的大手笔投资——就是具体证据。
Hyperion Research的首席量子观察员Bob Sorensen重点谈到了量子急于融入原本停滞不前的HPC（高性能计算（硬件））领域的问题。
“在HPC领域，性能提升的轨迹正在趋于平缓，这已经不是什么秘密了，我们已经到达了一些终点，摩尔定律的终点、在芯片上封装更多晶体管的能力、Dennard Scaling（你只能在芯片上投入这么多能量）、光刻能力耗尽的概念。Sorensen说：&ldquo;我们现在采用的是亚纳米线宽光刻技术，全世界只有一家公司生产先进的光刻组件，即荷兰的 ASML 公司，而这两家公司只能提供两家真正有实力的硅代工厂来生产高性能计算领域所需的先进芯片&ndash;台积电和三星。
“所以，HPC性能的提升轨迹正在下降，量子计算的出现恰逢其时。这意味着如果想继续先进计算之旅，就必须寻找下一件大事。量子的有趣之处在于，它的潜力是最有吸引力的，而且它的发展轨迹与经典 HPC 目前的发展轨迹不同。这才是真正的希望所在。因此，如果想入门，就必须做几件事。
&ldquo;我们认为，量子技术本身并不是一种新的计算能力。它更多地是为了加速高性能计算领域一直在处理的最复杂、最先进的工作负载。因此，我们将其视为 &ldquo;加速先进计算机遇 &ldquo;方面的又一个转折点。我们的出发点是研究最复杂、最棘手的计算问题。
这是一场引人入胜的讨论，Tabor已经存档了完整的视频。重点不是在奇异的量子技术上——虽然重要，但对我们大多数人来说不容易接触到——而是如何以及为什么开始探索它们。
小组成员包括：IDC首席量子分析师、IDC基础设施系统、平台和技术部研究经理Heather West；Hyperion研究部高级副总裁兼首席量子分析师Sorensen；Vizias首席执行官、戴尔科技公司前高管、德克萨斯高级计算中心创始人Jay Boisseau。HPCwire 编辑约翰-拉塞尔（John Russell）主持了会议。
West展示了几张幻灯片，很好地描绘了新兴的量子信息科学市场，然后小组讨论了为什么现在是合适的时机，并提供了如何做到这一点的建议。他们的核心观点是：量子技术正在快速发展；通过 AWS Braket 和 Strangeworks 等网络平台，获取工具和 QPU 相当容易，而且成本低廉；如果现在不参与其中，很可能会延缓以后的发展。
这里只是小组成员的一些评论。让我们从West展示的几张幻灯片开始，描绘了量子的发展。她在视频中展示了完整的幻灯片。
West指出，量子预测是动态的，条件可以迅速变化，而 IDC 会随着变化的影响变得更加清晰而将其纳入预测。例如，IDC 根据变化将总支出从 2027 年的 86 亿美元缩减到 76 亿美元。尽管有这些变化，但量子支出计划在 IT 预算中所占的比例仍在大幅增长。
“在过去的20年里，我们看到【量子计算】从学术成就转变为现在可以用于小规模实验的小规模系统。希望在未来几年内，我们能看到利用错误纠正和缓解技术，以及稍微扩展规模，以提供一些短期优势的系统，”West说。
IDC 对量子细分市场做了很好的分析。在谈到量子硬件开发商的激增时，她说：&ldquo;我们把它们分为两类，一类是硬件开发商，另一类是硬件供应商。两者之间的区别在于，硬件供应商已经发展到能够以溢价收费的方式提供系统和服务访问权的地步，这样像你们这样的组织就能够使用它们，利用它们进行一些实验、用例识别等。(见下文幻灯片）
回顾过去，Sorensen和Boisseau回忆起采用下一代HPC系统的高成本。
Sorensen说，“量子现在最神奇的地方在于低门槛。在以前，如果你想得到一个HPC，Jay知道这一点，你必须投入2500万美元来引进一台Cray。你必须雇佣25个人，他们住在地下室里。他们从不出门，一直在编写代码，他们说一种你不懂的语言，你必须支付他们很多钱来做这件事。进入HPC的门槛很高。
“量子的门槛是，你坐下来，进入AWS或Strangeworks。选择你选择的云访问模型，花几块钱注册，再找几个刚从量子化学或其他专业毕业的新员工，然后你就可以去玩了，然后你就会知道该如何运作。因此，进入量子领域的门槛非常高。我以前就说过，我还要再说一遍，如果不是因为有了云接入，我们所有人都不会坐在这里对量子隐约感兴趣；这才是真正的兴趣所在。”
Vizias的CEO Boisseau也有类似的看法。“你不必选择合作伙伴。你不必做出这样的决定。事实上，我认为现在做这个决定会很糟糕。你可以去找任何一家基于 CSP 的基础设施提供商（拥有量子网关），然后说我想在 D-Wave 系统上运行这个任务，我想在 IonQ 上运行这个任务，我想在 Rigetti Systems 上运行这个任务，而且可以做得相当无缝，&ldquo;他说。
“有趣的是，作为一个电气工程师，我倾向于非常务实地看待事情，现在运行的很多软件都是所谓的硬件不可知的，这意味着你可以在任何（量子）硬件上运行它。但现在，自由探索才是最重要的，”Boisseau说。
当然，广泛的小组讨论还有更多内容，包括选择正确问题的建议，以及对一篇论文的简要讨论，该论文是去年春天由微软的Matthias Troyer和他的同事们发表的（Disangling Hype from Practicality: On Realistically Achieving Quantum Advantage）。微软正在坚定地追逐量子！
West指出，“并不是每个人都那么乐观，有些人仍然因为成本、系统成熟度或不成熟以及它是否真的与他们愿意解决的问题相关而对采用量子计算持谨慎态度。然而，对于那些企业来说，他们确实应该开始注意了，因为量子时代正在迅速到来，其速度可能比想象的还要快。。我们仍然需要把它放在一个小背景中：快速接近并能够提供近期优势，这可能是五到七年后的事情。因此，&ldquo;快 &ldquo;不会是在未来六个月内。也不会是明年，而是比之前认为的十几年、几十年更快。”
]]></content>
  </entry>
  
  <entry>
    <title>C++ volatile</title>
    <url>/post/software/volatile-in-c-plus-plus.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>C++</tag>
      <tag>Volatile</tag>
    </tags>
    <content type="html"><![CDATA[volatile关键字在C++中解决了编译器优化可能带来的问题，确保程序能够正确地访问由外部因素改变的变量。下面是volatile解决的主要问题和使用场景的详细说明：
解决的问题 防止编译器优化: 编译器为了提高程序性能，会进行各种优化，比如通过将变量缓存在寄存器中而非每次都从内存读取来加速访问。这在大多数情况下是有效的，但在某些特殊情况下，变量的值可能由于硬件事件、其他线程或外部输入而改变，这些改变对编译器来说是不可预见的。使用volatile可以告诉编译器，该变量的值可能会突然改变，因此需要每次在使用时直接从其内存地址读取，禁止优化这些读写操作。
确保内存可见性: 在多线程环境中，volatile关键字确保当一个线程更新了某个变量的值时，这个新值对其他线程是可见的。这是通过防止编译器对这些变量的访问进行重排序或优化来实现的。
使用场景 硬件寄存器访问: 在嵌入式系统或底层硬件编程中，程序需要直接与硬件寄存器交互，这些寄存器的值可能会由硬件事件（如中断）改变。在这种情况下，使用volatile修饰符可以确保程序正确地从硬件寄存器读取最新的值。
中断服务程序中的变量: 在编写中断服务例程（ISR）时，变量可能会在中断服务程序和主程序之间共享。这些变量需要被声明为volatile，以确保主程序中的读取和写入操作能够看到由ISR所做的更改。
多线程共享的全局变量: 当多个线程需要访问和修改全局变量时，这些变量应该被声明为volatile，以确保一个线程对变量的更改对其他线程立即可见。然而，需要注意的是，volatile本身并不解决线程同步问题（如互斥和原子性问题），它仅确保变量访问的内存可见性。
注意  volatile并不意味着线程安全，它不会防止多线程环境中的竞态条件。对于需要原子操作或者线程间同步的场景，应该使用其他同步机制，如互斥锁（mutex）、条件变量（condition_variable）或原子操作（std::atomic）。 过度使用volatile可能会导致性能问题，因为它禁止编译器对这些变量的访问进行优化。因此，只有在确实需要防止编译器优化的情况下才使用volatile。  总的来说，volatile关键字在需要直接与硬件交互或者确保多线程程序中变量状态更新的实时性时非常重要，但它并不是解决所有并发问题的万能钥匙。正确地使用volatile需要对程序的运行环境和编译器优化策略有深入的理解。
为什么使用volatile 硬件寄存器映射: 在嵌入式系统编程中，硬件寄存器的值可能随时变化，而这些变化是由外部事件（如硬件中断）触发的，编译器无法预测。使用volatile可以确保每次访问都直接从寄存器读取值，而不是使用可能已经过时的缓存值。
多线程共享变量: 在多线程程序中，一个线程可能修改另一个线程可以访问的变量。通过将这些变量标记为volatile，可以确保每个线程都能看到最新的修改。
为了深入理解volatile关键字的重要性以及没有使用它所可能引发的问题，让我们通过对比具体例子来探讨。
硬件寄存器映射 有volatile的情况 // 假设这是一个映射到硬件状态寄存器的地址 volatile uint32_t* const statusRegister = (uint32_t*)0x40021000; void checkHardwareStatus() { if (*statusRegister &amp; 0x01) { // 处理硬件状态  } } 在这个例子中，statusRegister指向的硬件寄存器可以随时由外部硬件事件（如中断）改变。由于使用了volatile关键字，编译器会在每次checkHardwareStatus函数执行时，直接从statusRegister指向的内存地址读取值，确保获取的是最新的硬件状态。
没有volatile的情况 uint32_t* const statusRegister = (uint32_t*)0x40021000; void checkHardwareStatus() { if (*statusRegister &amp; 0x01) { // 处理硬件状态  } } 在没有使用volatile的情况下，编译器可能认为statusRegister指向的值在函数调用期间不会改变，因此可能只在第一次访问时从该地址读取值，之后可能使用寄存器中的缓存值。如果在两次checkHardwareStatus调用之间硬件状态发生了变化，程序可能无法检测到这一变化，从而导致错误的行为。
多线程共享变量 有volatile的情况 volatile bool keepRunning = true; void workerThread() { while (keepRunning) { // 执行任务  } } void stopWorkerThread() { keepRunning = false; } 在这个例子中，keepRunning变量被标记为volatile，这告诉编译器这个变量可能会被程序中的其他部分（如不同的线程）修改。这确保了workerThread函数在每次循环迭代时都会从内存中重新读取keepRunning的值，从而能及时响应stopWorkerThread函数的停止请求。
没有volatile的情况 bool keepRunning = true; void workerThread() { while (keepRunning) { // 执行任务  } } void stopWorkerThread() { keepRunning = false; } 如果keepRunning没有被声明为volatile，编译器可能会假设这个变量在workerThread的执行过程中不会被其他线程修改，因此可能将其值缓存起来。这样，即使stopWorkerThread被调用并将keepRunning设置为false，workerThread中的循环可能仍然继续执行，因为它使用的是缓存的true值，而不是最新的内存值。
结论 没有使用volatile关键字时，编译器的优化可能会导致程序无法检测到变量的改变，特别是在这些变量可能被外部事件或其他线程修改的场景中。这可以导致程序逻辑错误、数据不一致或难以调试的问题。因此，在需要确保变量的读写操作直接对应于内存操作，以响应外部变化或多线程间通信的场景中，使用volatile是非常关键的。
]]></content>
  </entry>
  
  <entry>
    <title>为什么DDR5要在一个dimm里面设计两个channel</title>
    <url>/post/hardware/why-does-DDR5-need-to-design-two-channels-in-one-DIMM.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>DDR5</tag>
      <tag>Channel</tag>
    </tags>
    <content type="html"><![CDATA[为什么 DDR5  要设计sub channel的概念，sub channel的设计初衷是什么？一个sub channel的带宽是32bit，要组成一个64bit的cache line岂不是还是需要两个channel同时工作？
首先引入2个概念:
 Burst Length: 突发(Burst) 是指在同一行中相邻的存储单元连续进行数据传输的方式。连续传输的周期数就是突发长度 (Burst Lengths，简称BL)。  对于DDR3和DDR4内存，其BL=8: 对于DDR5内存，其BL=16.
Cache line: 我们知道CPU是不能直接读取内存当中的数据，CPU要想读取内存当中的数据，首先要将数据从内存里加载到高速缓存cache中，然后再读取cache中的数据  我们将一个cache平均分成相等的很多块，每一个块大小我们称之为cache line。
例如: 一个32 Bytes大小的cache，如果我们将其平均分成32块，那么每一块cache line就是1Byte，总共有32行cache line。如果我们将其平均分成8块，那么cache line大小就是4 Bytes，总共8行cache line。
cache line是cache和内存之间数据传输的最小单位。什么是最小单位?
例: cache从Memory获取数据的最小单位是64Bytes，当cache要从内存里读取一个32 Bytes的数据时，不会只把这32 Bytes的数据读进来，而是会把64 Bytes的数据一起读进来
而对于X86架构的CPU来讲，它的Cache line大小正好就是64Bytes。
在我们DDR4时，数据位宽是64位的，就是我们一次读写64bit的数据，每次读写最高的BurstLength是8位，乘起来就是64bit*8=512bit=64Byte，也就是我们X86架构的CPU cache line 的大小。
那么到了DDR5的时候，每次读写最高的Burst Length变为了16位，如果我们的通道还是维持64bit的位宽，那么我们乘起来就是64bit*16=1024bit，1024bit超过了我们的cpu cache line%的传统大小。如果我们依然要这么做的话，那么我们的内存控制器的架构，从底层硬件到上层读写数据的软件配套都要去改，这样改动就非常大。所以在DDR5时，就引入了sub-channel的概念
每个sub-channel有效数据位是32位，32bit*16 (Burst Length) =512bit，这样就能够满足我们cpu cache line 的需求。所以就是DDR5引入sub-channel的原因。
]]></content>
  </entry>
  
  <entry>
    <title>英伟达GH200增加HBM3e内存</title>
    <url>/post/server/NVIDIA-GH200-adds-HBM3e-memory.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>NVIDIA</tag>
      <tag>GH200</tag>
      <tag>HBM3e</tag>
    </tags>
    <content type="html"><![CDATA[英伟达Grace-Hopper提供了一个紧密集成的CPU + GPU解决方案，针对生成式人工智能逐渐成为主导的市场环境。
为了提高性能，这家GPU制造商将HBM3e内存放入了名为GH200的新型芯片封装中，该封装包括一个Grace CPU和一个Hopper GPU。Hopper以前在芯片封装中使用HBM3存储器。
英伟达将把两个GH200芯片（每个都有一个72核CPU和一个Hopper GPU）连接到一个更大的芯片集群中，用于扩展数据中心。 HBM3e内存比HBM3快50%，总带宽为每秒10TB；CPU基于Neoverse V2设计。英伟达CEO黄仁勋表示:“这些芯片正在生产中，我们将在2023年年底左右进行样品测试。”
一个封装中的两个GH200芯片将具有282GB的HBM3e内存，这相比于之前GH100芯片的192GB HBM内存是一大改进。它还将拥有每秒8千万亿次的人工智能计算能力，以及每秒10 TB的HBM3e性能。
该芯片组可以接受任何大型语言模型，“可以疯狂地进行推理”。英伟达表示，这些芯片可以运行3.5倍大的模型，并通过更快的内存带宽获得性能提升。
该公司打算将256个GH200 GPU配置到一个名为Grace Hopper的超级计算机系统中，该系统将提供1百亿亿次的人工智能性能。黄仁勋将该系统称为“世界上最大的单一GPU”，所有256个GH200协同工作。
目前所有的大型学习模型都是在Grace Hopper超级计算机这样的系统上训练的。黄仁勋说，未来随着人工智能在设备之间的分布越来越广，每个应用程序都将使用一个大型语言模型。随着越来越多的公司探索人工智能来提高运营效率，Hopper GPU现在很受欢迎。该公司承认GPU供应短缺。
黄仁勋还描绘了如何分解其GPU路线图以满足分布式模型。Grace Hopper超级计算机位于顶部，然后可以将其分配到具有不同要求的服务器和桌面GPU上的不同GPU上。
]]></content>
  </entry>
  
  <entry>
    <title>英伟达不仅有NVLink、InfiniBand，还有以太网Spectrum-X方案</title>
    <url>/post/server/nvidia-also-has-the-Spectrum-X-network-solution.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Data center</tag>
      <tag>NVIDIA</tag>
      <tag>Spectrum-X</tag>
    </tags>
    <content type="html"><![CDATA[传统数据中心南北向网络和典型的AI东西向网络有非常明显的特征差异，总体来说AI属于分布式紧耦合业务的类型，对低延迟抖动、无阻塞以及可预期的网络性能有着明确的诉求。
AI训练的本质就是一堆GPU卡不停的“算算数”（梯度计算），为了让成百上千的GPU卡协同工作，就有了数量并行（把训练的数据拆分成不同的子集分给不同GPU计算）、模型并行（把模型中神经网络的不同层拆分给不同GPU计算）、张量并行（把同一层张量拆分成不同小块给不同GPU计算），不管是那种方式都需要GPU间的大量数据交互，对通信网络的需求就是：高速、低延迟、无拥塞、无丢包。
英伟达在AI网络通信方案方面的策略是All In：“小孩子才做选择，你要啥我有啥!”，不但有NVLink网络（主要应用于服务器内部的GPU通信以及小规模跨服务器节点间的数据传输）、InfiniBand网络（适用于中小规模且对价格不敏感的客户群体），还有推出了基于ROCE无损以太网的Spectrum X平台方案。
NVIDIA® Spectrum™-X 网络平台是第一个专为提高Ethernet-based AI云的性能和效率而设计的以太网平台。在类似LLM的大规模AI工作负载中，提升了1.7倍AI性能、能效，以及保证在多租户环境中的一致、可预测性。Spectrum-X基于Spectrum-4以太网交换机与NVIDIA BlueField®-3 DPU网卡构建，针对AI工作负载进行了端到端优化。
Spectrum-4以太网交换机 NVIDIA Spectrum-4 以太网交换机基于其自研的 51.2Tbps 的 Spectrum-4 ASIC 而构建，支持单个2U交换机中最多128个400G以太网端口或64个OSFP 800G接口，两级CLOS组网支持8K GPU节点。Spectrum-4 ASIC 采用了112G SerDes通道，Spectrum-X方案从交换机到DPU到GPU都采用了相同的SerDes技术，可以降低网络功耗，提高网络效率。
BlueField-3 DPU网卡： NVIDIA BlueField-3 DPU是第三代数据中心基础设施芯片，使组织能够构建从云到核心数据中心到边缘的软件定义的、硬件加速的IT基础设施。通过400Gb/s以太网网络连接，BlueField-3 DPU可以卸载、加速和隔离软件定义的网络、存储、安全和管理功能，从而显著提高数据中心的性能、效率和安全性。BlueField-3为由Spectrum-X驱动的云AI数据中心中的南北和东西流量，提供多租户、安全性能力。
RoCE自适应路由解决AI网络中低熵（流负载不均衡）问题 传统以太网ECMP流量负载均衡机制，由于不同流量的大小不一样，大象流（如：几个G的大文件），“老鼠流”（如：几K到几M的小流量）都按照哈希算法进行调度时，会导致网络整体利用率很低（通常达不达60%），业内解决办法就是把逐流负载改成逐包负载（包喷洒），但逐包负载的难题是流乱序问题，同一条流的不同数据包被负载到不同链路上转发，会出现数据包乱序的情况，需要有相应机制处理对错序的数据包进行重新排序。
RoCE 自适应路由是一种细粒度的负载均衡技术。它动态地重新路由 RDMA 数据以避免拥塞，并提供最佳负载均衡以实现最高的有效数据带宽。
它是一种端到端功能，包括 Spectrum-4 交换机和 BlueField-3 DPU 。Spectrum-4 交换机负责为每个数据包选择最不拥塞的端口进行数据传输。由于同一流的不同数据包通过网络的不同路径来传输，它们可能会无序到达目的地。BlueField-3 在 RoCE 传输层转换任何无序数据，透明地将有序数据传递给应用程序。
Spectrum-4 根据出口队列负载评估拥塞，确保所有端口都很好地均衡。对于每个网络数据包，交换机都会在其出口队列中选择负载最小的端口。Spectrum-4 还接收来自相邻交换机的状态通知，这会影响路由决策。所评估的队列与服务质量级别相匹配。
NVIDIA 是在DPU网卡侧处理乱序的数据包，业内处理数据包乱序到达的思路还有“信元”+交换机侧缓存排序的DDC方案、对普通以太网数据包进行编号（虚拟容器化）+交换机侧排序的智能调度方案，如果大家感兴趣可以直接点关键词看我的历史文章。
NVIDIA RoCE拥塞控制 INCAST引起的拥塞问题不是逐包负载均衡能解决的，这种拥塞的主要原因被称为多对一拥塞，即存在多个数据发送方和单一数据接收方。必须通过拥塞控制来解决，NVIDIA采用端网协同的拥塞控制机制来减少网络拥塞问题。
这种拥塞不能使用自适应路由来解决，并且实际上需要对每个端点的数据流进行计量。拥塞控制是一种端到端的技术，Spectrum-4 交换机提供代表实时拥塞数据的网络遥测信息。这些遥测信息由 BlueField DPU 处理，后者管理和控制数据发送方的数据注入速率，从而实现网络共享的最大效率。
如果没有拥塞控制，多对一的场景将导致网络背压和拥塞扩散，甚至出现丢包，从而极大地降低网络和应用程序的性能。
在拥塞控制过程中，BlueField-3 DPU 执行拥塞控制算法。它们以微秒的反应延迟每秒处理数百万个拥塞控制事件，并应用细粒度的速率决策。
Spectrum-4 交换机带内遥测既包含用于准确拥塞估计的排队信息，也包含用于快速恢复的端口利用率指示。NVIDIA RoCE 拥塞控制通过使遥测数据绕过拥塞流排队延迟，同时仍然提供准确和并发的遥测，从而显著改善了拥塞发现和反应时间。
RoCE 性能隔离 人工智能超大规模和云基础设施需要支持越来越多的用户（租户）和并行应用程序或工作流。这些用户和应用程序无意中竞争基础设施的共享资源（如网络），因此可能会影响性能。
NVIDIA Spectrum-X 平台包括一些机制，当它们结合在一起时，可以提供性能隔离。它确保一个工作负载不会影响另一个工作负荷的性能。这些机制确保任何工作负载都不会造成网络拥塞，从而影响另一个工作负载的数据移动。性能隔离机制包括服务质量隔离、用于数据路径扩展的 RoCE 自适应路由和 RoCE 拥塞控制。
NVIDIA Spectrum-X 平台具有软件和硬件的紧密集成功能，能够更深入地了解人工智能工作负载和流量模式。这样的基础设施提供了使用专用以太网 AI 集群进行大型工作负载测试的能力。通过利用来自 Spectrum 以太网交换机和 BlueField-3 DPU 的遥测技术，NVIDIA NetQ 可以主动检测网络问题并更快地解决网络问题，以优化网络容量的使用。
NVIDIA NetQ 网络验证和 ASIC 监控工具集提供了对网络健康状况和行为的可见性。NetQ 流遥测分析显示了数据流在穿越网络时所采用的路径，从而提供网络延迟和性能洞察
]]></content>
  </entry>
  
  <entry>
    <title>SSD固态硬盘适合做RAID阵列吗</title>
    <url>/post/server/could-ssd-be-used-for-raid.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>SSD</tag>
      <tag>Raid</tag>
    </tags>
    <content type="html"><![CDATA[SSD（Solid State Drive）固态硬盘，是一种使用闪存（Flash Memory）作为存储介质的硬盘。与传统的 HDD（Hard Disk Drive）机械硬盘不同，SSD 没有机械运动部件，数据存取速度快，抗震性强，而且功耗相对较低。这些特点使得 SSD 在许多应用场景中逐渐取代了 HDD。
RAID 阵列的定义和分类 RAID（Redundant Array of Independent Disks），即独立磁盘冗余阵列，是将多个硬盘组合起来，以提高数据存储的可靠性和性能的一种技术。常见的 RAID 级别包括：
 RAID 0（条带化）：提高性能，但不提供数据冗余。 RAID 1（镜像）：提供数据冗余，通过复制数据到多个硬盘来提高数据安全性。 RAID 5（带奇偶校验的条带化）：平衡性能和数据冗余，需要至少三个硬盘。 RAID 10（镜像+条带化）：结合了 RAID 0 和 RAID 1 的特点，提供高性能和数据冗余。  SSD 在 RAID 阵列中的应用考虑 性能提升 SSD 固态硬盘的读写速度远超 HDD，因此在 RAID 0 配置中，使用 SSD 可以获得极高的数据传输速度。这在需要高速读写的应用场景（如大型数据库、高速缓存系统）中非常有用。
数据冗余和安全性 在 RAID 1、RAID 5 或 RAID 10 配置中，SSD 的使用可以提供更快的数据恢复速度和更好的抗震性。这对于数据安全性有着重要意义。
写入耐久性问题 SSD 的一个缺点是写入耐久性。SSD 的每个存储单元只能承受有限次数的写入。在高负载的 RAID 环境中，这可能导致 SSD 的寿命缩短。因此，在选择 SSD 作为 RAID 配置的一部分时，需要考虑到这个因素。
成本考量 与 HDD 相比，SSD 的成本通常更高。在构建 RAID 阵列时，这一成本因素需要被考虑。特别是在需要大量存储空间的情况下，成本可能成为限制因素。
SSD 固态硬盘用于 RAID 阵列的适用场景  高性能要求的场景：例如，需要高速数据处理和读写的服务器和存储系统。 数据安全重要的场景：利用 SSD 的高可靠性和快速恢复特性，可以在关键数据存储中提供更好的保护。 小型或中型企业应用：对于那些需要平衡成本和性能的企业，使用 SSD 构建 RAID 1 或 RAID 10 阵列是一个不错的选择。  结论 综上所述，SSD 固态硬盘用于 RAID 阵列是可行的，但是否适合取决于具体的应用场景和需求。在高性能、高数据安全性的场景下，SSD 构建的 RAID 阵列具有明显优势。然而，成本和写入耐久性是在考虑使用 SSD 时必须要考虑的因素。总的来说，SSD 和 RAID 技术的结合为数据存储提供了更多的灵活性和选择，但选择时应根据具体需求谨慎决策。
]]></content>
  </entry>
  
  <entry>
    <title>SSD固态硬盘阵列有什么优缺点</title>
    <url>/post/server/advantages-and-disadvantages-of-SSD-solid-state-drive-raid.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>SSD</tag>
      <tag>Raid</tag>
      <tag>Array</tag>
    </tags>
    <content type="html"><![CDATA[SSD（固态硬盘）已经成为许多计算环境中的首选存储介质，尤其是在构建硬盘阵列方面。 SSD   阵列是一种使用多个 SSD 以提高性能和可靠性的存储解决方案。本文泪雪网将详细探讨 SSD 阵列的优缺点，帮助您更好地理解这项技术并做出明智的选择。
SSD 阵列的优点 高速读写性能：SSD 没有机械部件，数据传输速度远高于传统机械硬盘（HDD）。在阵列配置中，多个 SSD 可以并行工作，极大地提升了数据的读写速度。
更低的延迟：SSD 在数据存取上的延迟远低于 HDD。这对于需要快速访问数据的应用程序来说是一个重要优势，如数据库管理和高频交易。
更好的可靠性和耐用性：由于没有移动部件，SSD 对物理震动的敏感度低，更耐用、更可靠。在阵列配置中，即便某个 SSD 发生故障，其他 SSD 仍然可以继续工作，保证数据的安全。
节能和环境友好：SSD 消耗的电力远低于 HDD。在大型数据中心，这意味着显著的能源节省和较低的散热需求。
易于管理和维护：由于 SSD 的可靠性高，它们需要的维护和更换频率较低，从而减少了管理成本和时间。
SSD 阵列的缺点 高成本：相较于 HDD，SSD 的价格更高。尽管价格随着技术的发展在下降，但在构建大容量存储阵列时，成本依然是一个重要因素。
有限的写入寿命：SSD 使用闪存单元存储数据，这些单元有限的写入次数。虽然现代 SSD 的耐用性已大幅提升，但在极端的高写入环境中，寿命仍可能成为问题。
数据恢复难度大：一旦 SSD 损坏，数据恢复比 HDD 更加困难。这是因为 SSD 内部的数据存储方式与 HDD 不同，且各厂商的 SSD 构造和管理方式各异。
性能随时间降低：SSD 在长期使用过程中可能会出现性能下降的情况，尤其是在高强度写入的应用场景中。
容量限制：虽然 SSD 的存储容量在不断提升，但相比于 HDD，目前仍然存在一定的容量限制，特别是在成本和容量之间需要权衡时。
适用场景 鉴于 SSD 阵列的优缺点，它们特别适用于以下几类应用场景：
高性能计算：如大数据分析、科学计算等场景，需要极快的数据读写速度。
关键业务应用：如金融行业的交易系统，需要低延迟和高可靠性。
动态内容交付：如视频流媒体服务，需要快速连续的数据交付。
结论 综上所述，SSD 阵列在性能、可靠性和能效方面具有显著优势，但成本和寿命限制是其主要劣势。选择是否使用 SSD 阵列，应基于具体的应用需求、预算和长期维护能力来决定。随着技术的不断进步，我们可以期待 SSD 在未来将成为更加经济高效的存储解决方案。
]]></content>
  </entry>
  
  <entry>
    <title>2024年存储和基础设施领域的三个预测</title>
    <url>/post/server/2023-facts-and-2024-predictions-for-storage.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Storage</tag>
      <tag>AI</tag>
      <tag>ML</tag>
    </tags>
    <content type="html"><![CDATA[本文针对2024年存储和基础设施领域进行了三个预测。
主-备高可用性实践演进 - 主-主模式迎来其时 没有持续的可用性和实时数据访问，企业可能面临失去竞争对手、基于不准确信息做出决策等风险。因此，不足为奇的是，CIO们开始对他们的数据中心提出更高的要求。在未来的12个月里，许多IT领导人可能会开始采用主-主的能力，通过在多个节点之间分配工作负载来提高性能，从而允许访问所有服务器的资源。
通过摆脱那些并未充分利用可用服务器的主-备技术，通常在故障期间需要手动干预，CIO们将确保数据在任何位置都是可操作的，尽可能接近最终用户以提高性能，并且数据处理的负荷分散在所有计算和存储节点上，无论是在边缘、数据中心还是云中。
存储行业将启动人工智能（AI）和机器学习（ML）的产品化进程 虽然人工智能和机器学习具有巨大的潜力，但是它们的导入速度并没有像行业内人士所期待的那样迅速。其中一个显而易见的原因是，用户不知道如何充分发挥这些技术的潜力。目前，除了易于使用且备受欢迎的ChatGPT等产品外，对于企业存储客户而言，尚未出现真正的开箱即用产品。因此，除非组织内有数据科学家能够协助他们理解人工智能和机器学习的复杂性，否则在实施任何解决方案时，他们很可能会采取观望态度。
存储行业面临着巨大的机遇，一些具有远见卓识的公司已经开始探索这一领域。到2024年，我们将见证人工智能和机器学习产品化的起步。届时将推出完善的解决方案，使用户能够轻松了解这些技术如何助力他们实现目标，同时设置和运行也将变得简单易懂。随着人工智能和机器学习产品的普及，我们将看到越来越多的企业开始应用这些技术。
虚拟桌面基础设施（VDI）势不可挡，但许多公司正考虑将其迁回本地 在新冠疫情爆发时，VDI成为许多人能够继续工作的关键因素。它为用户提供了灵活且一致的体验，无论他们从何处登录，在封锁期间为组织提供了重要的支持。然而，问题出现了：硬件难以获取。在疫情期间，由于我们习惯了紧急情况，没有时间等待供应链自行调整，因此CIO们纷纷转向云端。
请不要误会，云端具有明显的优势。它易于实施，具有弹性，并且能够迅速响应和满足我们的需求。然而，由于云服务商通常按交易量收费，因此成本可能相当高且难以预测。
随着供应链可用性的改善，高负载事务可能会重新迁回本地。
]]></content>
  </entry>
  
  <entry>
    <title>美机构：立即停止使用C和C++</title>
    <url>/post/software/US-organizations-warn-stop-using-C-and-C-plus-plus.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>C</tag>
      <tag>C++</tag>
    </tags>
    <content type="html"><![CDATA[对于嵌入式软件工程师来说，C/C++语言是最常用的编程语言之一，它是一种高效、简洁、灵活的编程语言，尤其在嵌入式、单片机领域，它创造了许多奇迹，包括智能手机、家用电器、汽车或是医疗设备。
但每每提及“安全”问题时，大部分人便将C/C++划在围城之外。12月6日，美国网络安全和基础设施局 （CISA）联合美国国家安全局（NSA）、美国联邦调查局 （FBI）及澳大利亚、加拿大、英国和新西兰的网络安全机构发布《内存安全路线图指南》，点名C/C++存在内存安全漏洞，软件开发商应放弃使用，改用C#、Rust、Go、Java、Python和Swift等内存安全的编程语言 (MSL)。
那么，这究竟是什么情况，我们还能安心使用C/C++吗？
C/C++的黑暗面 内存安全漏洞（CWE-1399:综合分类:内存安全）是一类影响在编程语言中以意外方式访问、写入、分配或释放内存的漏洞。
透过漏洞，恶意行为者能够非法访问数据、损坏数据或运行任意恶意代码。例如，恶意行为者可能会向应用程序发送精心制作的有效载荷，从而破坏应用程序的内存，然后使其运行恶意软件。或者，恶意参与者可以发送包含恶意软件的格式错误的映像文件，以在受害者系统上创建交互式外壳。如果参与者可以以这种方式执行任意代码，参与者可以获得对运行该软件的帐户的控制权。
事实上，早在去年9月，微软CTO Mark Russinovichi就在其社交账号上发布动态称，开发人员是时候停止使用C/C++来启动新项目，建议在使用non-GC语言的场景中使用Rust。
2022年底，NSA也曾在报告《Software Memory Safety》中呼吁过放弃C/C++，彼时他们表示，C/C++已被证实是内存安全漏洞的温床，它们在内存管理方面提供了很大自由度和灵活性，用这种语言开发的应用程序安全性很大程度上需要依赖程序员的测试、检测环节，与此同时，他们还鼓励各组织将编程语言从C/C++转向C#、Rust、Go、Java或Ruby等编程语言。
今年1月，C/C++的问题甚至引起了拥有87年历史的《消费者报告》的关注，表明了对这个问题的认识，彼时报告中称，内存安全是复杂的话题，据估计，至少有65%的安全漏洞是内存错误的结果。
此次报告中则指出，这个几十年前就首次发现的缺陷仍然是当前恶意行为者经常利用的常见漏洞，以破坏应用程序和系统。比如说：
 微软在2019年一次会议上表示，自2006年至2018年，70%的漏洞是由内存安全问题引起的； 在GoogleChromium项目中发现的漏洞中，约70%是内存安全漏洞； 在对Mozilla漏洞的分析中，34个严重/高度错误中有32个是内存安全漏洞； 根据Google Project Zero团队的分析，2021年有67%的零日漏洞是内存安全漏洞。  其实C/C++的这种漏洞并非不可控的，许多软件制造商投资于开发人员的培训计划。许多这些培训计划包括旨在减少由这些语言产生的内存不安全漏洞的流行率的策略。此外，还有许多商业和工业贸易协会的培训计划。此外，各种组织和大学提供培训和专业证书，以证明在C和C++安全编码实践的知识。
虽然培训可以减少编码员可能引入的漏洞数量，但考虑到内存安全缺陷的普遍性内存安全漏洞仍然会出现，这几乎是不可避免的。即使是最有经验的开发人员编写的bug也会引入显著的漏洞。培训应该是一个组织实现更健壮的技术控制(如内存安全语言)的桥梁。
许多公司针对这种漏洞，进行了许多优化。很多科技公司引入了代码覆盖测试、安全编码准则、Fuzzing 测试软件及开发者使用了静态应用程序安全测试（SAST）和动态应用程序安全测试（DAST）工具来查找各种软件的内存安全漏洞。比如说，C++社区一直在考虑向后兼容性、内存安全默认值和基础语言的其他优先级之间的平衡；苹果修改了iBoot system中使用的C编译器工具链，以缓解内存和键入安全问题；微软早些年还开源了一个更安全的C语言版本Checked C，在C中添加静态和动态检查，以检测或防止常见的编程错误；Google打造了一款 C++ 的继任者Carbon，针对现有代码的C++内存安全采取了改进措施。
硬件厂商，也在积极开发使用硬件支持内存保护。比如说，美国SRI International和剑桥大学的联合研究CHERI项目，为现有的芯片架构增加了新的功能；英国政府的数字安全设计（DSBD）计划汇集7000万英镑的政府资金和1.17亿英镑的工业联合投资开发技术；2022年，Arm公司探讨了其实验性Morello Program及CHERI架构实现原理，希望借此解决系统攻击中常被利用的一系列内存访问漏洞；而后，微软也参与了CHERI研发的相关工作。
当然，即便厂商已经投入大量心力避免漏洞，但结果依然不容乐观，而这正是CISA、NSA、FBI反驳使用C/C++的根本原因，而报告中，则推荐了C#、Rust、Go、Java、Python和Swift等几个编程语言。
安全性不等于内存安全 面对市场传言，C++之父Bjarne Stroustrup并没有选择沉默，而是在今年多次回击。
其中，最具代表性的就是其在2月发布的《Think seriously about“safety”;then do something sensible about it》（认真考虑“安全”，然后采取一些明智的措施”）一篇文章。
文章中，Bjarne表示，很多人的焦点都放在C/C++的弱点上，但实际这些缺陷是完全可以避免的。首先，要声明的是，C和C++根本就是天壤之别的两种语言，请不要混为一谈。C++能更加直接的表达程序员的想法，NSA完全忽略了C++在30年依赖的进步，并将C与C++混为一谈，这让人深表遗憾。
C++正引入更多特性，变得越来越安全，合格的C++程序员可以写出安全性可以与Rust媲美的程序。忽视安全问题会伤害C++社区的大部分成员，并破坏我们为改进C++所做的许多其他工作。专注于安全也是如此。
除此之外，“安全”的定义并不只有一个，我们可以通过编程风格、库的组合以及静态分析来实现各种各样的安全。NSA对“安全”的概念仅限于内存安全，而忽略了一门语言可能被用来违反某种形式的安全保障和十几种其他方式。
不是每个人都把“安全”看得高于一切。比如，在性能是主要关注点的应用程序域中，规则中允许仅在需要应用时保证安全，并在需要时使用最喜欢的调优技术。
目前世界上有数百万C++程序员与数十亿行C++代码，被应用在包括航空航天、医疗仪器、人工智能/机器学习、知识图谱、生物医学及高能物理等领域。据我所知，在发布报告前，没有一位专家向C++标准委员会进行过咨询，所谓“明智的做法”是什么，建议列出一个明确的清单。
1月中旬，官方C++“指导小组”发布了一份声明，解决了人们对C++安全性的担忧。虽然许多语言现在都支持“基本类型安全”，即确保变量只访问由其数据类型明确定义的内存部分，但C++一直难以提供类似的保证。
工程师怎么看 大佬们吵翻天，工程师其实都早已看在眼里。“菜刀可能会导致剁掉手掌，请所有支持C++不安全观点的人，以后不要吃饭。”一位工程师发出这样的灵魂拷问，他把C++比喻成一把锋利的刀，高效好用，而CISA的说法，就像是说刀太快，不安全，要包上棉花使用。
“美国就是喜欢揪着小尾巴不放，但不用C/C++，操作系统、编译器、执行器、甚至虚拟机，都会完全无法工作？虽然C/C++的指针使用不当会导致一系列问题，但指针对内存的精确控制，也能从一定程度上节省内存消耗，这难道不是一个程序员更应该考虑的吗？”
C接近汇编，执行效率高是优点，但确实对技术架构和编程质量有较高要求，因为很容易实现底层控制。那时也少有分层分级管理的概念，不像现在，伴随着黑客的门槛下降，动不动就零信任。
有工程师表示，大家都对内存安全嗤之以鼻，但还有多少人对C++停留在98版本，还有多少人在使用int *p=new int这种语法？还在使用说明根本不了解现代C++，iterator 、智能指针都能代替传统的指针，很多问题诸如用户用自己定义的函数操纵了类受保护的变量，是编程语言也处理不了的，只能依靠程序员自己。明明是程序员自己编程犯的错，为什么要把责任推到C++语言头上？为什么不从积极的角度把C++的这种特性看成是灵活运用指针自由使用内存数据的语言能力呢？
“没有绝对安全的编程语言，更没有能写出绝对安全代码的程序员。我们总是要平衡利弊，找到那个平衡点。这也是计算机领域发展至今的铁律。”一位程序员这样总结道。
当然，也有程序员认为，编程语言的代谢速度到了一个临界点，迎接新的挑战才是常态。编写糟糕的代码是开发人员的过错，但令人惊讶的是，过了这么久才指出这一点，大多数人都不擅长编写良好的代码，或者说，因为能安全使用C和C++的年轻人越来越少了。所以，我们从使用的语言中得到的帮助越多越好。
作为IT行业的晴雨表，TIOBE编程语言排行榜向来最能反映当前编程语言的热度和变化趋势。2023年，12月份的TIOBE编程语言排行榜中显示，C与C++依然位列第二和第三，但从趋势上来看，C#的表现强劲，有着威胁C与C++的能力。作为竞争者，C#在1年内上涨了2.38%，C#相比Java，最大的优势在于可以非常高效用在工业界，对接大量已存在的C/C++代码，但Java就不行。
“新的语言通常需要多年的时间和重大的努力，才能在其广泛的应用领域中与成熟的语言相媲美。发烧友们很少看到这一点，他们的评论往往是相当片面的。”Bjarne曾经在与Azure CTO一次隔空辩论中如是说。
]]></content>
  </entry>
  
  <entry>
    <title>在日本之后，中国也发布新型光刻机</title>
    <url>/post/news/china-also-releases-new-lithography-machine.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>ASML</tag>
      <tag>DUV</tag>
      <tag>EVU</tag>
    </tags>
    <content type="html"><![CDATA[由于美国的影响，ASML对中国出售光刻机一直都在摇摆之中，不过2022年底至少有三家中国芯片企业获得ASML的光刻机，显示出ASML的态度再次发生变化，导致如此结果或许在于中国近期宣布的新型光刻机。
开辟芯片制造新技术 说到绕开ASML的光刻机开发芯片制造新技术，当然得说日本，日本最先研发成功绕开光刻机的芯片制造工艺，日本研发的芯片制造工艺被称为NIL技术，该项技术已被日本的存储芯片企业铠侠采用，据称日本已将该技术发展到10nm工艺，预计可以进一步拓展到5nm工艺。
相比起采用ASML的光刻机生产的芯片制造工艺，NIL技术的成本更低，毕竟一台EUV光刻机的价格高达1.2亿美元，而第二代EUV光刻机价格更将高达近4亿美元，昂贵的成本让全球都非常关注日本的NIL工艺。
中国开发新型光刻机，则在于ASML对中国的光刻机供应总是在改变，受美国的影响，ASML至今都未向中国企业供应EUV光刻机；2022年下半年在美国的要求下，ASML又暂停供应14nm以下的DUV光刻机。
面对ASML的态度，中国一直都在力求研发新型光刻机，日前中科院光电所就研发了名为超分辨率光刻机，可以实现22nm工艺，目前该项技术还在提升之中，还花时间进一步改进以取得经济性生产成本，不过这一消息对ASML无疑是巨大的刺激。
ASML的态度发生变化 ASML曾扬言，即使给中国图纸也生产不出光刻机，因为光刻机是一个高精密的机器，需要全球产业链的配合，DUV光刻机需要数万个零部件，而EUV光刻机更要近10万个零部件，需要全球5000家厂商共同参与。
中国作为后来者，具有光刻机生产能力的企业有上海微电子等企业，上海微电子一直都在力推14nm光刻机，不过由于光刻机需要国内产业链的配合，仅是靠上海微电子自己的技术是不可能生产出来的，因此这几年中国一直都在推进光刻机产业链的完善。
除了研发传统的光刻机技术之外，开发新的技术也是中国芯片行业努力的方向，毕竟日本已研发的NIL工艺已证明了这是一条可行的道路，而超分辨率光刻机的研发成功就代表着中国在研发芯片制造工艺方面取得了进展。
中科院光电所的成果让ASML转变了态度，ASML高管早前就表示只要给予时间，中国迟早能研发成功先进的光刻机；同时ASML表示它是一家欧洲企业，不应该受美国的影响，荷兰外贸大臣也表示支持ASML争取自由出货的权利。
促使ASML转变态度的原因还有全球芯片市场的变化，从2022年下半年以来全球芯片行业出现过剩，连最大芯片代工厂台积电都关停了几台EUV光刻机降低生产成本，如此情况下中国以外的市场对光刻机的需求大减，中国这个在继续推进芯片产能扩张的市场对ASML来说可谓雪中送炭，ASML自然希望从中国市场获取更多收入。
如此也就不奇怪ASML在2022年底突然加快对中国出售光刻机了，毕竟它担忧中国的新型光刻机很快量产，到那时候就不需要ASML的光刻机，如今加紧出货能赚一分是一分，还能帮助它过冬。
ASML的态度变化说明了中国芯片行业还是需要自立自强，只要我们取得技术突破，那么海外高科技产品对中国市场就会迅速放松，乃至降价销售，不过即使如此我们还是应该推进光刻机技术，正如知名院士倪光南所说，先进技术是买不来的、求不来的，只有我们自己取得进展，将核心技术掌控在手里，才不会处处受制于人。
]]></content>
  </entry>
  
  <entry>
    <title>STM32芯片的内部架构</title>
    <url>/post/hardware/the-internal-architecture-of-STM32-chip.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>STM32</tag>
    </tags>
    <content type="html"><![CDATA[STM32芯片主要由内核和片上外设组成，STM32F103采用的是Cortex-M3内核，内核由ARM公司设计。
STM32的芯片生产厂商ST，负责在内核之外设计部件并生产整个芯片。这些内核之外的部件被称为核外外设或片上外设，如 GPIO、USART（串口）、I2C、SPI 等。
Image
芯片内部架构示意图
芯片内核与外设之间通过各种总线连接，其中驱动单元有 4 个，被动单元也有 4 个，具体如上图所示。可以把驱动单元理解成是内核部分，被动单元都理解成外设。
ICode 总线 ICode总线是专门用来取指令的，其中的I表示Instruction（指令），指令的意思。写好的程序编译之后都是一条条指令，存放在 FLASH中，内核通过ICode总线读取这些指令来执行程序。
DCode总线 DCode这条总线是用来取数的，其中的D表示Data（数据）。在写程序的时候，数据有常量和变量两种。常量就是固定不变的，用C语言中的const关键字修饰，放到内部FLASH当中。变量是可变的，不管是全局变量还是局部变量都放在内部的SRAM。
系统System总线 我们通常说的寄存器编程，即读写寄存器都是通过系统总线来完成的，系统总线主要是用来访问外设的寄存器。
DMA总线 DMA总线也主要是用来传输数据，这个数据可以是在某个外设的数据寄存器，可以在SRAM，可以在内部FLASH。
因为数据可以被Dcode总线，也可以被DMA总线访问，为了避免访问冲突，在取数的时候需要经过一个总线矩阵来仲裁，决定哪个总线在取数。
内部的闪存存储器Flash 内部的闪存存储器即FLASH，编写好的程序就放在这个地方。内核通过ICode总线来取里面的指令。
内部的SRAM 内部的SRAM，是通常所说的内存，程序中的变量、堆栈等的开销都是基于内部SRAM，内核通过DCode总线来访问它。
FSMC FSMC的英文全称是Flexible static memory controller（灵活的静态的存储器控制器）。通过FSMC可以扩展内存，如外部的SRAM、NAND-FLASH和NORFLASH。但FSMC只能扩展静态的内存，不能是动态的内存，比如就不能用来扩展SDRAM。
AHB 从AHB总线延伸出来的两条APB2和APB1总线是最常见的总线，GPIO、串口、I2C、SPI 这些外设就挂载在这两条总线上。这个是学习STM32的重点，要学会对这些外设编程，去驱动外部的各种设备。
]]></content>
  </entry>
  
  <entry>
    <title>文件服务器到底是选Windows还是选Linux比较好</title>
    <url>/post/linux/selection-of-linux-or-windows-for-file-server.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>fil server</tag>
    </tags>
    <content type="html"><![CDATA[文件服务器是一种用于存储和共享文件的网络设备，它可以提高数据的安全性和可用性。文件服务器的选择取决于多种因素，如成本、性能、兼容性、易用性等。本文将从这些方面对比Windows和 Linux  两种文件服务器的优缺点。
成本方面 Windows文件服务器的软件费用通常高于Linux文件服务器，因为Windows需要购买操作系统和相关的许可证，而Linux是开源的，可以免费使用。但是，Windows文件服务器的硬件费用可能低于Linux文件服务器，因为Windows对硬件的要求较低，而Linux需要更高的配置。此外，Windows文件服务器的维护费用也可能低于Linux文件服务器，因为Windows有更多的技术支持和用户社区，而Linux需要更多的专业知识和技能。
性能方面 Linux文件服务器通常优于Windows文件服务器，因为Linux更稳定、更安全、更灵活。Linux可以运行在各种硬件平台上，支持多种文件系统和协议，可以根据需要进行定制和优化。而Windows文件服务器可能受到病毒、恶意软件、黑客攻击等威胁，需要经常更新和重启，导致性能下降和数据丢失。
兼容性方面 Windows文件服务器和Linux文件服务器各有优劣。Windows文件服务器更适合与其他Windows设备和应用程序进行交互，如Active Directory、Exchange Server、SQL Server、Office等。而Linux文件服务器更适合与其他Linux或Unix设备和应用程序进行交互，如Apache、MySQL、PHP等。如果需要在不同平台之间共享文件，可以使用一些通用的协议和工具，如SMB、NFS、FTP等。
易用性方面 Windows文件服务器通常比Linux文件服务器更容易使用和管理，因为Windows有更友好的图形界面和操作方式，而Linux需要更多的命令行和配置文件。但是，这也取决于用户的习惯和偏好，有些用户可能更喜欢Linux的灵活性和自由度。
综上所述 Windows和Linux两种文件服务器都有各自的优缺点，没有绝对的好坏之分。选择哪种文件服务器要根据具体的需求和场景进行权衡和评估。  根据个人经验，给出一些建议仅供参考：
 如果需要一个低成本、高性能、高安全性的文件服务器，可以选择Linux文件服务器。例如，在互联网行业中，很多网站和应用程序都使用Linux作为后端的存储平台。 如果需要一个与Windows环境高度集成、易于使用和管理的文件服务器和打印机，可以选择Windows文件服务器。例如，在企业内部网络中，很多办公文档和数据都使用Windows作为共享平台，而且Windows服务器操作界面更友好，易于上手。 如果需要一个既能与Windows又能与Linux交互的文件服务器，可以选择使用SMB或NFS等协议来实现跨平台的共享。例如，在教育或科研机构中，很多学生和教师都使用不同的操作系统来进行学习和研究。 ]]></content>
  </entry>
  
  <entry>
    <title>数据中心到底是如何工作</title>
    <url>/post/server/how-does-data-center-operate.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Data center</tag>
    </tags>
    <content type="html"><![CDATA[数字时代的 数据中心  ，就如同网络世界的心脏，它的鼓动关系到整个网络生态的运转。但这个复杂而庞大的数据枢纽背后隐藏着怎样的精密机制，是许多人颇感好奇的谜。
今天，我们将深入解析数据中心的内部运作，揭示其高科技元素是如何协同工作，从高可用性系统到人工智能的应用，一一呈现数据中心如何无懈可击地保持运转。
高可用性系统和冗余: 数据中心的运作如同一台巨大的机器，而高可用性系统则是其默契的舞台指挥。这些系统保障了数据中心在任何时候都能保持操作状态，就如同精准的交响乐团。故障转移和冗余系统则是数据中心的安全防线，降低了单点故障的风险，确保了系统的不间断运行。这种高效率的运作，正是数据中心在数字化时代稳定运行的关键。
网络运营中心: 在数据中心中，网络运营中心犹如指挥官的指挥部，负责监控、管理和维护计算机资源。通过网络可视化，这个指挥中心能够一览数据中心的全局，随时调度资源以应对各种挑战。其在数据中心运作中的重要性不可低估，正如一位船长需要一个舰桥一样，数据中心需要一个网络运营中心来确保一切井然有序。
不间断电源: 数据中心的生命线无疑是电源，而不间断电源则是其保持生命力的关键。托管设备和服务器倚赖着专用电源，确保其持续运行。电源备份的重要性无法忽视，为数据中心提供了稳定的能量，维持了整体服务的可用性。在数字时代，数据中心如同一座不停运转的城市，而电源则是这座城市的灯塔。
物理安全措施: 安全是数据中心的底线，而物理安全措施则是构筑这座底线的砖石。多因素身份识别、整个建筑的监控、金属探测器和生物识别系统，这些措施形成了数据中心的坚实墙垣。数据中心如同一座金库，物理安全人员则是守护者，确保这个数字世界的财富得到最完善的保护。
强大的冷却系统: 电源和冷却，如同数据中心的两翼。主机托管设备和服务器的运行需要足够的冷却，以防过热。数据中心的建设要保证有足够的气流，使整个系统保持凉爽。这种对温度的严格掌控，让数据中心得以在高负荷运转下依然保持冷静。
备用电源系统: 数据中心如同一艘巨大的航母，而备用电源系统则是其动力系统的备胎。不间断电源和发电机在电力中断期间发挥着至关重要的作用。发电机能够自动启动，为数据中心提供持续运行的能源，而UPS系统的冗余性则是确保整个系统在关键时刻不失效的关键。
数据中心计算机化维护管理系统: CMMS如同数据中心的智囊团，通过监控、测量和增强维护计划，为数据中心提供了最有效的运作方式。这个计划不仅能够追踪维护工作的进度和成本，还能够通过人工智能的运用，实现最小的人为干预，提高内部效率。数据中心的未来，离不开这个智能化的维护管理系统的引领。
在数字时代，这些关键元素的协同工作使得数据中心得以高效运行。高科技的应用和智能系统的运用，让数据中心不仅仅是一个简单的服务器堆叠，更是一个复杂而庞大的数字生态系统，为我们的数字化生活提供了强大的支持。这也是我们期待数字时代数据中心持续演进的原因，因为它们不仅仅是科技的堆砌，更是未来的数字社会的中枢。
]]></content>
  </entry>
  
  <entry>
    <title>英特尔又裁员了！这冬至不太好过</title>
    <url>/post/news/intel-lay-off-employees-again.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Intel</tag>
      <tag>Lay off</tag>
      <tag>Windows Phone</tag>
    </tags>
    <content type="html"><![CDATA[裁员雪球，越滚越大，Intel这是要进一步开源节流阿!
裁员雪球，越滚越大 “一半欢喜一半忧”。英特尔今年自家的汤圆怕是多了些许苦涩。
今日老相好 ASML 起了个大早，给英特尔送了份大礼。早先预定的高数值孔径光刻设备成功交付至俄勒冈州。
据外媒透露，这台光刻设备为用于3nm工艺生产的TWINSCAN EXE:5000系列。
得知老板年底签收新设备的消息，估计员工们这会悬着的心都安稳了不少。（既然有钱买设备，那裁员浪潮也该停一停了吧）
结果转眼间，英特尔便痛下决心，启动了第五轮裁员计划。
美国加州就业发展部今日宣称，英特尔已向自己打了“预防针”：计划在年末掀起裁员浪潮，“毕业”人数高达311名员工。
其中圣克拉拉总部76名，而今年刚优化近500人的福尔松研发中心，也没能幸免，“开源节流”的幅度进一步扩增至235人。
对此，英特尔发言人Addy Burr解释道，英特尔此举是延续CEO 盖尔辛格在一年前所制定的降本计划，而“人事行动”本就是该计划的一部分。
至于30亿美元成本削减的目标是否达成，他则没有正面回答，而是强调加州员工仍有上万名，未来也将持续投资智能制造业，不过优先选址于亚利桑那、新墨西哥和俄勒冈等地。
从今年这五轮的裁员方向来看，加州是一大“重灾区”。
外媒 Market Watch 在1月份时，就曾报道 Intel 将接连裁撤硅谷的数百个岗位，而今年8月份再度传出的140人裁员消息，依然是坐落于加州的福尔松。
业绩回暖乏力 虽然英特尔总裁 Pat Gelsinger 曾表示降本计划是以工厂效率的提升为主，人力流动为辅，但多达5次的裁员风波，还是无法掩饰英特尔急于重现荣光的野心，特别是在业绩下滑的压力下。
据英特尔公布的Q3财报显示，虽然营收超出市场预期，高达142亿美元，但同比去年同期却下滑了8%。
值得一提的是，这已经是英特尔连续第七个季度营收未见回暖了，而净利润的增长态势也未见好转，同比下滑的比例扩大至71%。
具体来看，PC业务逐渐回暖，下跌幅度收缩至3%。晶圆代工业务也是迎来了春天，不仅跻身全球晶圆代工厂的营收前十榜单，同比增长幅度更是高达299%。
不过豪赌 AI  的英特尔在Q3却吃了“闭门羹”，营收同比下降了10%，而自身归结的原因是服务器市场需求的缩减和竞争对手的博弈。
不难猜测，英特尔所意指的便是在AI芯片上一骑绝尘的英伟达了。乘着AI东风的英伟达，市值一路窜升至万亿美元，不但近乎是两个台积电的总和，与 Intel 更是有着近7倍的鸿沟。
有趣的是，眼红英伟达的英特尔 CEO 帕特，还在近日坦言道，“英伟达的成功不过是机缘巧合，如果当时Intel坚持开发Larabee项目，英伟达不可能有今天的成绩。”（Emmm&hellip;. 好酸Image）
结语 Intel 这个“事后诸葛亮”的迷惑发言，让人不禁联想起隔壁家“巨硬”，微软此前也表示过，关停Windows Phone是个战略错误，如果时光能够倒流，与苹果掰掰手指头压根不是问题。
不过好在 Intel 只是入局较晚，有着OpenVINO的起点，虽说与老黄分庭抗礼还为时尚早，但迎头赶上的曙光还是清晰可见的。
]]></content>
  </entry>
  
  <entry>
    <title>以太网（Ethernet）技术小解</title>
    <url>/post/server/a-brief-explanation-of-Ethernet-technology.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Ethernet</tag>
      <tag>LAN</tag>
    </tags>
    <content type="html"><![CDATA[以太网（Ethernet）是一种常见的局域网（LAN）技术，它使用多种协议来实现数据通信。Ethernet的协议分为多层，其中二层协议主要涉及数据链路层。在Ethernet中，数据链路层使用帧（frame）来传输数据，而帧的结构由多个字段组成。
以下是Ethernet二层协议解码中可能涉及的一些重要字段：
 Preamble（前导码）：Preamble是一系列重复的模式，用于同步接收方的时钟。它通常是 8 字节的模式，以帮助接收方正确解析后续的数据。 Start Frame Delimiter（起始帧定界符）：紧随Preamble之后的一个特殊模式，指示帧的开始。 目标MAC地址（Destination MAC Address）：6字节，指示帧要发送到哪个设备。 源MAC地址（Source MAC Address）：6字节，指示帧的发送者。 EtherType/Length字段：指示上层协议的类型或者数据帧的长度。如果该字段的值小于等于 1500（0x05DC），则表示长度字段；如果大于 1500，则表示 EtherType 字段，标识上层协议类型。 数据（Payload）：包含传输的实际数据。上层协议的格式和内容由EtherType字段决定。 Frame Check Sequence (FCS)：4字节，用于检测在传输过程中是否发生了错误。 VLAN标签（802.1Q）：当使用虚拟局域网（VLAN）时，帧的头部可能包含一个4字节的VLAN标签。这个标签包括VLAN标识符、优先级和标准的EtherType字段。 802.1Qad（QinQ）：在QinQ配置中，两个VLAN标签可能会被嵌套在一起，提供更高层次的VLAN隔离。 MAC控制：这是一个3字节的字段，用于指定帧的控制信息，例如是否是一个帧的开始或结束。 流控制（Flow Control）：Ethernet帧中的一些字段可能用于实现流控制，以防止网络拥塞。 冗余检测（STP - Spanning Tree Protocol）：Ethernet网络中可能会使用STP来防止网络环路，STP帧包含用于构建网络拓扑的信息。 LACP（Link Aggregation Control Protocol）：用于组合多个物理连接成为一个逻辑连接，提高带宽和冗余性。 LLDP（Link Layer Discovery Protocol）：用于发现和描述直接连接的设备和它们的能力。 广播和多播地址：Ethernet支持广播和多播通信，所以目标MAC地址中可能包含广播地址（全1）或多播地址（最低有效位为1）。 物理层信息：Ethernet帧并不涉及具体的物理层传输细节，但理解底层物理层的特性（如速率、半双工/全双工）对于完全理解以太网帧的传输环境是有帮助的。 Jumbo Frames：除了标准的以太网帧大小（最大1518字节），一些网络设备和标准支持更大的Jumbo Frames，通常可以达到9000字节。使用Jumbo Frames可以提高数据传输效率，但需要确保所有网络设备都支持。 以太网类型（EtherType）：除了IPv4和IPv6之外，还有其他以太网类型，例如ARP（Address Resolution Protocol）、IPv6的ICMPv6、PPPoE（Point-to-Point Protocol over Ethernet）等。解码时需要根据EtherType字段来确定上层协议。 MAC地址的学习和过滤：在交换机等设备中，有关MAC地址的学习和过滤是重要的。交换机通过学习源MAC地址来建立MAC地址表，并使用该表来转发数据帧。 MAC地址欺骗（MAC Spoofing）：攻击者可能尝试欺骗网络，发送带有伪造源MAC地址的帧。网络安全中需要考虑如何防范和检测这种类型的攻击。 以太网帧的生命周期：了解以太网帧在网络中的传播和处理过程，包括交换机、路由器、网桥等设备的作用。 QoS（Quality of Service）：以太网帧头部的优先级字段用于指定帧的服务质量，有助于实现流量的优先级和管理。 MAC层的广播和多播协议：了解广播和多播的概念，以及在MAC层如何处理这些帧。 截断MAC地址：有时在显示中可能会看到截断的MAC地址，这是为了简化而只显示前面几个字节，通常是前三个字节表示厂商标识符。 Link Layer Discovery Protocol (LLDP)：LLDP是一种用于发现直接连接的设备及其能力的协议。LLDP帧包含有关设备的信息，如设备类型、设备标识符、端口标识符等。 Link Aggregation Control Protocol (LACP)：LACP用于在两个设备之间协调和管理链路聚合（Link Aggregation）。LACP帧用于协商和验证链路聚合的成员关系。 802.1X认证：802.1X是一种网络访问控制协议，用于对接入网络的用户进行身份验证。相关的EAPOL（Extensible Authentication Protocol over LAN）帧用于在认证过程中传输信息。 ARP（Address Resolution Protocol）：ARP帧用于在IPv4网络中解析IP地址和MAC地址之间的映射关系。它是一种解析层协议，用于确定目标设备的MAC地址。 IPv6在以太网中的表示：IPv6帧与IPv4帧有所不同，包括更大的地址空间和去除了校验和字段。IPv6的EtherType值为0x86DD。 MPLS（Multiprotocol Label Switching）标签：在一些网络中，以太网帧可能携带MPLS标签，用于进行流量工程和服务提供商的标记。 EtherChannel和Port Aggregation：类似于LACP，一些厂商使用EtherChannel或Port Aggregation的术语来描述将多个物理链路组合成一个逻辑链路以提高带宽和冗余性的过程。 Frame Priority and VLAN Priority：除了VLAN标签外，帧头部可能包含用于QoS的优先级字段，这有助于实现流量的优先级和管理。 错误检测和处理：了解以太网帧中的FCS字段如何用于检测传输错误，以及在发现错误时的处理方式。 网络分析工具：Wireshark等网络分析工具可以用于捕获和分析以太网帧，帮助诊断网络问题和了解网络流量。 QoS和DiffServ标记：在以太网帧头部，可能包含用于服务质量（QoS）和不同服务（DiffServ）的标记，用于实现流量的优先级和区分。 帧序号和流量控制：一些以太网标准支持帧序号和流控制机制，以确保数据的可靠传输。 VXLAN和NVGRE：用于实现虚拟局域网（VLAN）扩展的封装协议，它们在以太网帧中添加了虚拟网络标识。 SDN（Software-Defined Networking）：SDN引入了控制平面和数据平面的分离，以太网帧在SDN环境中可能会包含与SDN控制器的通信信息。 MACsec（MAC Security）：用于在以太网帧层实现加密和完整性保护。802.1X认证扩展：在802.1X认证的基础上，可能会使用EAP（Extensible Authentication Protocol）进行更灵活的身份验证。 PTP（Precision Time Protocol）：用于在网络中同步时钟，以太网帧可能包含PTP消息。 802.11帧：在无线局域网（WLAN）中，以太网帧的格式与有线以太网有所不同，需要考虑无线特定的字段，如信道、信号强度等。 sFlow和NetFlow：这些是用于网络监控和分析的流量采样协议，可以在以太网帧中包含有关流量的信息。 PROFINET、EtherCAT等：在工业控制系统中，有一些特定的以太网协议和帧格式，用于实时通信和控制。 IPv6 over IPv4 Tunneling：为了支持IPv6的过渡，以太网帧中可能包含IPv6数据报通过IPv4网络的隧道。 6LoWPAN（IPv6 over Low-power Wireless Personal Area Networks）：在物联网中，以太网帧可能在低功耗、有限带宽的网络中传输，需要考虑这些特定环境的协议和机制。 ]]></content>
  </entry>
  
  <entry>
    <title>将 CPU 与 FPGA Fabrics 结合使用的案例</title>
    <url>/post/fpga/example-of-using-cpu-and-fpga.html</url>
    <categories><category>FPGA</category>
    </categories>
    <tags>
      <tag>FPGA</tag>
      <tag>eFPGA</tag>
      <tag>CPU</tag>
      <tag>Fabric</tag>
    </tags>
    <content type="html"><![CDATA[如何在规模效益下降时继续推动性能提升，本文就介绍一个将 CPU 与 FPGA Fabrics 结合使用的案例。
鉴于半导体行业通过进一步缩小工艺几何尺寸在物理和经济上所能实现的目标已开始达到极限，缩小特征尺寸和增加晶体管数量已不再能达到以往的效果。取而代之的是，整个行业都在关注全新的系统架构，并通过重新思考如何在每个设备中完成任务来更好地利用现有硅片。当我们进入这个新的技术时代时，以 嵌入式   FPGA 的形式将 FPGA   结构与 CPU 集成成为一种极具吸引力的解决方案。
虽然 FPGA 和 CPU 都使用内存和逻辑组合来保存和处理数据和指令，但两者之间存在重要的根本区别。中央处理器针对快速上下文切换进行了优化，而 FPGA 的配置速度较慢，但能以类似于硬连线电路的速度模拟数字逻辑。因此，CPU 擅长执行各种任务，而 FPGA 则擅长执行重复性（尤其是高度并行化）任务，这些任务重复执行数千次，偶尔才会重新定义。
市场指标 有明显的证据表明，CPU 和 FPGA 技术的结合可以通过更紧密的集成带来真正的价值。这方面的第一个例子是英特尔公司斥资 167 亿美元收购 Altera 公司，用于加速数据中心功能。第二个例子是微软的 Catapult 计划，该计划表明，通过在每台服务器中集成 FPGA 来加速必应搜索、Azure 和 Microsoft 365，可以将数据中心服务器的计算能力提高一倍。这些例子表明，业界已经开始认识到 CPU 和 FPGA 异构架构的优势。这些类型的异构架构将不可避免地转移到同一设备上，FPGA 结构将作为 IP 块集成到 ASIC 中。
迈入 eFPGA 时代 Achronix 现在是这一领域的主要推动者，它已经推出了嵌入式 FPGA IP，这些 IP 源自其早期以高性能和复杂路由架构著称的独立 FPGA 系列。Speedcore™ eFPGA IP 展示了将 FPGA 结构集成到 CPU/SoC 中的许多可能优势。下图显示了如何将 Speedcore IP 集成到 SoC 子系统中。
图 1：SoC 子系统中的速核 eFPGA
由于 eFPGA 位于同一设备上，信号无需经过 SerDes 和 PCIe 等协议编码。因此，延迟时间要低一个数量级。此外，由于片上互连的带宽更高，采用 eFPGA 结构的 SoC 比采用独立 FPGA 的 SoC 性能更高。
集成 FPGA 结构还大大降低了功耗。由于在片上集成了 FPGA 结构，去除了时钟发生器、无源元件等一些辅助元件，因此这种功耗节省还延伸到了系统层面。
分立 FPGA 的尺寸和性能范围是固定的，而 eFPGA IP 块中逻辑门和存储器之间的组合则不同，可以由客户自行定义，这样就能获得适当数量的 FPGA，以加速相应的功能。这种功能可确保在 SoC 中实现最佳的 CPU 大小与 FPGA 资源比，从而优化硅面积、功耗和成本。
总之，毫无疑问，eFPGA 将成为未来几年的主要架构趋势。其优势实在是太引人注目了。
]]></content>
  </entry>
  
  <entry>
    <title>Linux常用命令TOP 10超详细汇总</title>
    <url>/post/linux/linux-top-10-commands.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Command</tag>
    </tags>
    <content type="html"><![CDATA[大家应该都知道 Linux  操作系统，就算不熟悉至少也听说过吧，由于它是开放性的，也是免费的，且安全性比较高等，近些年受到越来越多人的喜欢，不少公司也都是使用Linux系统办公。
Linux中最要的一部分就是Linux命令，因为Linux很多功能是需要命令来实现的，而且使用命令简单方便。
另外，在Linux系统管理方面，有时候用命令确实会比图形界面方便很多，所以学习Linux命令是必须要学的。
但是有一个问题是，Linux命令很多，一一记住着实比较困难，而且也没必要，有的命令使用概率比较低，就无需专门记下，因为时间久了用不到会忘记，最好的方法就是边用边记忆，特别是对于使用频率较高的命令就需要格外用心了。
那使用频率较高的命令，也就是热门命令有哪些呢，作用又是什么呢？接下来我就罗列一些Linux热门命令，并作功能简要概述，大家可以参考下。
ls命令： ls是 list 的缩写，可列出指定目录下的内容及其相关属性信息，是使用频率较高的Linux命令之一。
ls命令功能有不少，可以用来查看Linux文件夹里的文件，也可以查看包括目录、文件夹等一些文件权限和对目录信息的查看等等。语法格式:ls [选项] [文件]。
cat命令: cat是concatenate的简写，cat也是比较常用的Linux命令，主要是用于查看内容较少的纯文本文件的。
简要概述的话主要有三大功能吧，
第一个功能就是可以一次显示整个文件，表示就是：cat filename;
第二个功能是可以合并文件，和dos下面的type命令比较相似，表示就是：cat file1 file2 &gt; file;
第三个功能是可以从键盘创建一个文件，表示就是：cat &gt; filename.
语法格式：cat [参数] [文件] cp命令: cp是copy的缩写，主要用于复制文件或目录，可以合并文件复制，即多个文件复制到一个文件或目录下。
语法格式：cp [参数] [文件] 举例一个简单的语法，即复制文件转移至不同的文件夹：# cp [options&hellip; .] source(s) destination
mkdir命令: mkdir是make directories的缩写，它主要是用来创建目录的，可以创建一个或多个目录。但是它只会创建不存在的目录，如果文件名已经有就不会再创建，所以我们在创建目录时要检查一下，确保要创建的文件的名字是新的。
语法格式:mkdir [参数] [目录] 比如在某个目录下，要创建名为 A 的子目录：[root@vxbus~]# mkdir A
echo命令: 是Linux比较常用的命令之一，主要用于字符串的输出，另外它可以用来提示用户，即在屏幕或显示器上输出一段字符串。
语法格式：echo [参数] [字符串] 举个例子，输出一段字符串的写法：[root@vxbus~] echo “LinuxCool.com” LinuxCool.com
mv命令： mv是move的缩写，大家都知道move的意思是移动，那在这里意思差不多，是移动文件或对文件进行改名。mv命令是文件管理类的命令，使用频率比较高。
语法格式：mv [参数] 如果要将文件A移动到目录B中就可以这样表示：[root@vxbus~]# mv A / B
rm命令: rm是remove 的缩写，是常用的用于删除的命令，可以用来删除整个目录，也可以只删除某个目录下的某一个文件或多个文件，看个人需求来定。但是操作时要看好了再下手哦，要不然可能会出现误删的情况。
它的语法格式是：rm [参数] [文件] 举个例子，如果要删除某个目录下所有文件，可以如下写：[root@vxbus~]# rm -rf*
df命令: df是Disk Free的缩写，是有关磁盘空间的命令，可以查看我们的磁盘空间已经使用了多少，磁盘分区使用情况等。
语法格式为：df [参数] [指定文件]。 例如，如果想要查看某个文件系统磁盘空间的使用情况，可以用 $ df来表示。
find命令： 也是很常用的一个命令，并且功能强大，不加参数的话可用于查找目前所在路径的文件和目录，加参数的话，不同的参数会有不同的功能，并且支持正则。
语法格式为：find [参数] [路径] [查找和搜索范围]。 举个使用例子，当使用-name参数查看/usr目录下面所有的.txt结尾的配置文件时，可以这样表示：[root@vxbus~find /usr-name ”*.txt
rpm命令: rpm是Red-Hat Package Manager的缩写，是管理软件包常用的命令。它具有安装、卸载、升级、查询和验证等五种基本的功能，如果想要安装、卸载或者管理软件等都可以用此命令。
它的语法格式为：rpm [参数] [软件包]。 想要直接安装软件包的话就输入[root@vxbus ~]#rpm -ivh packge.rpm
以上就是10种使用比较多的命令。
]]></content>
  </entry>
  
  <entry>
    <title>详解交换机与防火墙的关系</title>
    <url>/post/server/detailed-explanation-of-the-relationship-between-switches-and-firewalls.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Switches</tag>
      <tag>Firewall</tag>
    </tags>
    <content type="html"><![CDATA[在 网络  的巨大森林中，有三位关键角色，它们分别是交换机、路由器和防火墙。这三者几乎是每个网络的基石，但很多人对它们的使用却容易产生混淆。今天，我们将深入剖析这三种设备的应用与区别.
首先，让我们聚焦于交换机。它就像城市中的立交桥，连接着各种网络设备，包括路由器、防火墙以及无线接入点。在局域网中，交换机的功能是桥接不同的网络设备，并为计算机、服务器、网络摄像机以及IP打印机等提供一个中心连接点。简而言之，它是网络的黏合剂，让各设备畅通无阻。
而防火墙则是网络安全的守护者，位于内部网络和外部网络之间，形成一道坚不可摧的防线。它能够隔离内外网络，保护内部/私有局域网免受外部攻击，并有效防止敏感数据泄露。防火墙的功能堪称多重，包括反病毒、入侵防御、URL过滤、文件过滤、内容过滤、应用行为控制、邮件过滤，甚至能防范各类常见DDoS攻击和传统的单包攻击。这些强大的安全特性，三层交换机可望望尘莫及。
那么，交换机和防火墙的区别究竟在哪里呢？它们在网络配置中如何各显神通？
交换机：网络的黏合剂 在局域网（LAN）中，交换机连接了路由器、防火墙、无线接入点以及众多客户端设备，如计算机、服务器、网络摄像机和IP打印机。这种连接方式使得交换机成为网络中的中心，为各种不同的设备提供了一个高效的交流平台。
防火墙：网络的安全卫士 接下来，我们聚焦防火墙，这位网络的安全卫士。防火墙位于内部网络和外部网络之间，属于网络安全系统的一部分。其主要功能在于隔离内部网络和外部网络，形成一道坚固的安全屏障。
防火墙的存在至关重要，尤其是在防范网络攻击和保护重要数据方面。相比之下，没有防火墙的情况下，路由器在内部网络和外部网络之间盲目传递流量，没有有效的过滤机制。而防火墙则能够监控流量，阻止未经授权的流量进入内部网络。
总体而言，防火墙的作用不仅仅限于网络的基本连接，更涉及到网络的安全和隐私保护。它能够进行反病毒防御、入侵检测、URL过滤、文件过滤、内容过滤、应用行为控制、邮件过滤，还能有效防范各种网络攻击。这些强大的安全功能，是三层交换机所不具备的。
交换机与防火墙的区别与配置 既然我们了解了它们各自的功能，接下来看看它们之间的区别和如何配置上网。
交换机与防火墙的区别 在网络配置中，人们经常会产生两个疑问：交换机有没有防火墙的功能，能不能当防火墙使用？反之，防火墙有没有路由功能，能不能当路由器使用？
首先，一般的交换机是不具备防火墙功能的。防火墙的功能主要在三层以上进行，因此至少需要三层交换机才可能支持防火墙功能。例如，某些三层交换机可以配置ACL（访问控制规则），通过设定条件对接口上的数据包进行过滤，实现部分防火墙功能。但在网络安全要求不高的情况下，交换机可以完全忽略防火墙的存在。
其次，防火墙已经具备路由器的功能。因此，很多情况下可以用防火墙直接替换路由器，新建网络时也可以直接使用防火墙作为出口。防火墙的三种工作模式——路由模式、透明模式和旁路模式，分别适用于不同的网络部署情境。
防火墙的工作模式解析 路由模式（网关模式）： 多用于出口部署，配置NAT、路由、端口映射等功能。在此模式下，防火墙所有功能均能正常使用。当防火墙位于内部网络和外部网络之间时，需要将防火墙与内部网络、外部网络以及DMZ（隔离区域）相连的接口分别配置成不同网段的IP地址，重新规划原有的网络拓扑。
透明模式： 主要用于串连网络，对两个不同安全域进行边界防护。在透明模式下，端口映射、NAT和VPN等功能将无法使用。这种模式常用于需要保持原有IP地址和拓扑结构的网络环境。
混合模式： 如果防火墙同时存在于工作在路由模式和透明模式的接口，那么它将工作在混合模式下。混合模式主要应用于透明模式作双机备份的场景，但使用场景相对较少。
交换机与防火墙的结合，构建了一个既高效又安全的网络环境。通过明确它们的功能和区别，我们可以更好地配置和管理网络设备，确保网络的畅通和安全。
在网络配置中，我们解答了关于交换机和防火墙功能的疑惑，让复杂的网络设备变得清晰明了。尽管普通交换机缺乏防火墙的强大功能，但通过合理配置，三层交换机也能发挥一部分防火墙的作用。而防火墙不仅具备路由功能，更以其三种灵活的工作模式，适应不同网络部署的需求。
网络的安全与畅通，需要交换机与防火墙的密切合作。路由模式、透明模式、混合模式，它们共同构筑了一个安全高效的网络环境。
]]></content>
  </entry>
  
  <entry>
    <title>一文读懂C++如何实现多返回值</title>
    <url>/post/software/how-to-implement-multiple-return-values-in-C-plus.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>C++</tag>
    </tags>
    <content type="html"><![CDATA[在C++编程的旅程中，我们时常会遇到需要一次性返回多个值的情况。传统的C++中，我们可能会通过引用、指针或结构体等方式来实现这个目标。然而，随着C++11的引入，元组的出现为多返回值带来了一种全新的解决方案。
结构体或类：传统而稳定 在C++中，结构体或类是一种传统且经典的实现多返回值的方式。通过将多个需要返回的值封装在结构体或类的成员中，我们可以以一种清晰、有序的方式返回多个值。
struct MultipleValues { int value1; double value2; char value3; }; MultipleValues functionWithMultipleReturnValues() { MultipleValues result; result.value1 = 42; result.value2 = 3.14; result.value3 = &#39;A&#39;; return result; } 这种方式的优势在于代码结构清晰，易于维护和理解。同时，结构体或类可以提供更多的封装性，更好地组织相关数据。然而，对于一些简单的情况，可能显得有些繁琐。
引用或指针参数：直截了当的交互 另一种常见的方式是通过引用或指针参数传递需要返回的值。这样，函数可以直接修改调用者传递的变量，达到多返回值的效果。
void functionWithMultipleReturnValues(int &amp;value1, double &amp;value2, char &amp;value3) { value1 = 42; value2 = 3.14; value3 = &#39;A&#39;; } // 调用函数 int main() { int result1; double result2; char result3; functionWithMultipleReturnValues(result1, result2, result3); // 现在，result1、result2、result3 包含了函数返回的多个值  return 0; } 这种方法的直接性很受一些程序员的喜爱，同时也适用于需要在函数内修改变量的场景。然而，对于不熟悉该函数的人来说，可能不够直观，而且容易出现潜在的错误。
元祖 现代C++的精巧之选，随着C++11的到来，引入了std::tuple，为多返回值问题提供了一种更为现代、简洁的解决方案。
#include &lt;tuple&gt;std::tuple&lt;int, double, char&gt; functionWithMultipleReturnValues() { return std::make_tuple(42, 3.14, &#39;A&#39;); } // 调用函数 int main() { auto result = functionWithMultipleReturnValues(); int result1 = std::get&lt;0&gt;(result); double result2 = std::get&lt;1&gt;(result); char result3 = std::get&lt;2&gt;(result); // 现在，result1、result2、result3 包含了函数返回的多个值  return 0; } std::tuple的优势在于简洁明了，对于返回多个值的场景非常合适。通过std::get函数可以轻松地获取元组中的各个值。而且，std::tuple支持自动类型推导，代码更为简洁。
比较与选择 在实际编码过程中，我们应该根据具体的情况选择合适的方式。如果需要返回的值之间具有一定的逻辑关系，结构体或类是一个不错的选择。如果函数需要在内部修改调用者的变量，引用或指针参数会更为直观。而在简单、独立的场景下，元组可能是最为优雅的解决方案。
当然，也可以根据实际情况灵活运用这些方式。在C++17之后，更进一步的结构化绑定也为处理多返回值提供了更加方便的语法糖。
结语 在C++中，实现多返回值并没有唯一的正确方式，而是根据实际情况选择适合的方法。结构体、引用或指针参数以及元组都是可行的方案，各自有着优劣之处。在实际项目中，根据代码的可读性、维护性以及性能需求等方面进行权衡，选择最为合适的方式。
]]></content>
  </entry>
  
  <entry>
    <title>上市 74 年，百年巨头东芝今日正式退市</title>
    <url>/post/news/century-old-giant-toshiba-officially-delisted-today.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Toshiba</tag>
    </tags>
    <content type="html"><![CDATA[12月20日消息，日本东芝公司（以下简称“东芝”）将于今日正式退市，结束自1949年以来74年的上市企业历史。
东芝公司创立于1875年，至今已有近150年历史，作为日本制造业的代表之一，东芝打造了横跨家电、电气、半导体、能源、基建等领域的庞大帝国。
据悉，日本的第一个灯泡、第一台洗衣机、第一台冰箱、第一个雷达、第一台电视机、第一个微波炉、第一个电饭煲、第一个可视电话，都来自于东芝；甚至全球第一台笔记本电脑，也来自东芝。全盛时期，东芝是全球前三的医疗器械厂商，还是日本第二大综合电机制造商、日本四大核能厂商之一。
此外，东芝曾是日本的重要半导体制造商，曾发明NAND闪存芯片。2000年东芝半导体的销售额仅次于美国芯片巨头英特尔，位列全球第二；2008年东芝排名第三，仅次于英特尔和三星。但近年全球芯片领域竞争不断加剧，台积电、三星等企业的实力不断提升，东芝芯片已经远远落后。
2018年，身陷多重困境的东芝将半导体业务剥离，以大约2万亿日元的价格出售给了包括美国贝恩资本在内的企业联盟，由此成为了独立运作公司铠侠。其中贝恩资本持有铠侠49.9%的股份，东芝则持有40.2%股份。
今年8月起，以日本国内基金“日本产业合作伙伴”（JIP）为主的财团正式向东芝发起总额约2万亿日元的要约收购。东芝官网发布文件称，JIP财团将从普通股东手中收购剩余股份，将东芝收购为全资子公司。
东芝日前表示，公司私有化完成后，现任总裁岛田太郎将留任，JIP将任命包括一名副总裁在内的四名高管。
东芝目前约有 10.6 万名员工。麦格理资本证券日本研究主管Damian Thong表示：“东芝困境归根结底是糟糕的战略决策和坏运气共同造成的。我希望资产剥离可以让东芝的资产和人才找到新的归宿，充分发挥他们的潜力。”
有网友对于东芝退市一事评价道：
“东芝属于典型的不能再典型的日企衰落路线了，不可逆的那种。以重工起家，横跨家电，半导体等一大堆行业。在泡沫经济时代，全球日货横行，东芝快速崛起，然后紧跟美国的制裁，首先倒下的就是被美国扔给韩国的半导体，东芝的存储虽然多扛了几年，可惜现在已经掉队了，卖掉了。然后就是家电，随着中国国产家电的崛起，日系家电现在也就剩下信仰去支撑了，东芝家电业务及品牌也归美的了，至于需要更高技术支撑的消费电子也早卖了。最后这一波，也属于典型日式all in 思维定式，赌国运，消费业务一塌糊涂东芝压上所有去all in 核电，可惜天不随人愿，加上日式救援，福岛核事故来了，东芝直接玩完，能坚持到现在才私有化，不容易了。”
]]></content>
  </entry>
  
  <entry>
    <title>AMD Zen5实物首曝：192核心、512MB三级缓存遥遥领先</title>
    <url>/post/server/AMD-Zen5-Turin-is-on-the-way.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>AMD</tag>
      <tag>Turin</tag>
      <tag>Zen5</tag>
    </tags>
    <content type="html"><![CDATA[ AMD   Zen4架构的EPYC 9004/8004系列已经全员齐备，下一代Zen5架构的产品也越来越近了，今天就第一次看到了实物，还有部分规格信息。
Zen5架构的EPYC代号为“Turin”(都灵)，分为Zen5标准版的Turin Classic、Zen5c精简版的Turin Dense，一如现在Zen4、Zen4c的划分。
当然，Zen c系列算不上小核心，因为只是精简了三级缓存、提高了能效，其他几乎都不变，IPC性能、ISA指令集均保持一致。
经常曝料Intel/AMD服务器新品的YuuKi_AnS给出了Zen5 EPYC的第一张实物照，可以看到外形和现在完全相同，接口继续使用SP5 LGA6096。
同时曝出的还有两张内核布局图，一个是Zen5 Turin Classic，1颗IOD搭配16颗CCD。
IOD内集成PCIe 5.0控制器(通道数量不详)、CXL 2.0控制器、12通道的DDR5-6000内存控制器(现在是DDR5-4800)、第三代Infinity Fabric互连控制器，以及一颗新加入的安全协处理器。
CCD内还是每颗8个核心、32MB三级缓存，但是从12颗增加到16颗之后，总计达到128核心256线程、512MB三级缓存。
另一个是Zen5c Turin Dense，变成了1颗IOD搭配12颗CCD。
其中，IOD部分完全相同，但是每颗CCD内部拥有多达16个核心，因此总计有192核心384线程、384MB三级缓存。
再往后的Zen6 Venice EPYC，预计会升级到每CCD 32核心、16通道内存，总计可达256核心，但需要换新的SP7、SP8接口了。
]]></content>
  </entry>
  
  <entry>
    <title>这些技巧会帮助你更好地设计电路</title>
    <url>/post/hardware/these-skills-will-help-you-design-the-circuit-better.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>Circuit Design</tag>
    </tags>
    <content type="html"><![CDATA[读大学时，出现在教科书中的电路图与我们每天工作中完成的真实电路大相径庭。 电路设计并非易事，因为它需要对构成电路部分的每个元件都有充分了解，且实现“完美”设计需要大量实践。  但是，当你在 电路设计  中牢记并应用以下技巧时，它们将有助于使你的电路看起来更专业、能以最佳效率工作、并提高你的专业素养。
使用框图 本技巧似乎显而易见，但往往被过分自信的人忽视，他们认为自己已经把要做的活都弄明白了。完全按照你的需要表述电路的方框图对电路的成功设计至关重要。在你开始工作之前，方框图为你提供了一个大纲，它还为将要查看和检查你电路的任何人提供了极好的参考资料。  各个击破 在很多情况下，在设计电路时你可能不会单打独斗，所以花时间将设计划分为各功能块，每个块都有定义的接口，就可以实现各个击破的策略；参与电路设计的设计师可以专注于各个块。这些块可以独立地用于你目前正着手的项目，也可以在将来重复用于不同的电路设计。通过这种方法，你可以在事情不顺利的时候轻松排除故障，因为你将能够识别你遇到的麻烦是哪个块引起的。  为电路网络命名 的确，对这一步可能会有疑惑，但确保对PCB上的每个网络进行命名并标注每个网络的用途，可在紧要关头，为你提供诸多帮助。当你必须调试或运行模拟时，它也很有用。网络命名可让你在出问题时，知道该在哪下手。请记住：使命名易于识别；使命名对其要传载的意义一目了然。3．为电路网络命名  记笔记 谈到电子设计，你的笔记就是你的灵丹妙药。重要的是记录研发过程的每一步，你遇到的每个坑、找到的每个解决方案、以及与你的设计相关的任何其它内容。请务必记下为什么为你的设计选用某些组件、逻辑表的式样、以及设计电路时的任何特殊注意事项。你的笔记有多种用途：   通过清楚地记录每一步，你可以“回放”并查看哪里可能出问题、或你可在哪里进行修改以得到更高效的设计。 可以使用和交叉引用以前项目的注释，以便更好地理解、实现更好的方案以及激发出与当前工作相关的更多灵感。 你可以帮助其他人解决其设计问题，并在以后需要时阅读他们的笔记。  文本放置保持一致 如果你指定某些名称或在图表上进行注释，你会发现，再次查看时很难弄清这些文字到底是什么意思。在原理图上放置符号和名称时，请确保与命名过程保持一致。写注释时，不要在电路的一部分横着写，而在所有其它部分竖着写。尽量确保名称之间有一些空白，这样包括你在内的读者就不会感到困惑。注释间不要害怕有空白。实际上，空白有助于减少将图示与书写混在一起引发的混乱。这同样适用于速记命名。如果你要以缩写表述任何内容，请尝试在下面添加解释的“段子”，或确保它们易于识别。  流程化 不要削足适履试图将你的示意图(plan)和注释压缩进特定数量的页面。占页多少并不重要；不要苟且你原理图的质量。确保电路设计始终如一。这有助于提高可读性和更好的应用。在电子电路设计方面没有捷径；这完全取决于付出的努力和努力的结果。  保留标题 为原理图的每页制作标题、进而提供了每页的更多信息，这会使你受益。除可读性更高外，这样做还可以更轻松地为你的原理图页编制索引。这在调试时会带来益处：当你需要引用电路的某个部分、但又太忙无暇翻遍每一页、只得救助大脑记忆试图找出所需图表的位置时——页索引会帮大忙。  使连接器可见 你需要能立即区分所有连接器。最好的选择是在原理图中使用引脚表述连接器。通过简单的连接器识别，你将能够正确地追溯电路，且不会迷失在连接中。选用引脚之所以方便，是因为它将“坚守”其位置。与贴纸(sticker)或颜色不同，引脚能更突出引人注目，而不会在图表和笔记中占用太多空间。  结论 上面提到的技巧肯定会帮助你更好地设计电路。它们将有助于调试、模拟、注释参考等等。如果你记住这些技巧并在设计的所有阶段应用它们，那么你会发现自己正在从应届小白转变成电子电路设计的专业人士。 ]]></content>
  </entry>
  
  <entry>
    <title>嵌入式开发，究竟何时需要用RTOS</title>
    <url>/post/vxworks/when-to-use-real-time-operating-system.html</url>
    <categories><category>VxWorks</category>
    </categories>
    <tags>
      <tag>RTOS</tag>
    </tags>
    <content type="html"><![CDATA[最近好多朋友在问，嵌入式开发为什么要学 RTOS  ，日常开发过程中什么时候需要用到RTOS？这篇文章可以给出一些解释和启发。下面进入主题
如今，高性能处理器和通用操作系统实时升级的速度，似乎再次引发了嵌入式系统是否仍需要RTOS的讨论。答案没有改变：在相对低端的处理器上只有真正的RTOS能提供一些保障，也就意味着，这些OS可以留在嵌入式环境中。
究竟何时需要实时操作系统？ 大多数嵌入式项目是否仍需要实时操作系统？考虑到当今高性能处理器的速度以及适用于 Linux  ，Windows和其他通用操作系统（GPOS）的实时补丁的可用性，这是一个很好的问题。
答案在于嵌入式设备的本质。这些设备通常以数千，甚至数百万桃这种规模下生产，即使每套硬件成本降低1美元，也能为制造商节省一笔小财富。换言之，这些设备无法负担数百万赫兹处理器的成本（更不用说散热了）。
例如，在汽车远程信息处理市场，典型的32位处理器的运行频率约为600兆赫，远低于台式机和服务器中常见的处理器。在这样的环境中，设计用于从低端硬件中提取极其快速、可预测的响应时间的实时操作系统有巨大的经济优势。
除了节省成本外，实时操作系统提供的服务使许多计算问题更容易解决，特别是当多个活动竞争一个系统的资源时。例如，考虑一个用户期望（或需要）立即响应输入的系统。使用实时操作系统，开发人员可以保证由用户发起的操作将优先于其他系统活动执行，除非必须首先执行更重要的活动（例如，有助于保护用户安全的操作）。
还要考虑一个必须满足服务质量（QoS）要求的系统，例如显示实时视频的设备。如果设备的内容交付的任何部分都依赖于软件，那么它会以用户认为不可接受的速度体验掉帧，设备是不可靠的。然而，通过实时操作系统，开发人员可以精确地控制软件进程的执行顺序，并确保以适当和一致的速率进行回放。
实时操作系统不公平 在嵌入式行业中，对实时“硬”时间的需求仍然很普遍。问题是:实时操作系统有什么是GPOS没有的?而且，对于某些GPOS来说，现在的实时扩展有多有用?他们能提供一个合理的实时操作系统性能吗？
让我们从任务调度开始。在GPOS中，调度程序通常使用“公平”策略将线程和进程分派到CPU。这样的策略可以实现桌面和服务器应用程序所需的高整体吞吐量，但不能保证高优先级、时间紧迫的线程优先于低优先级的线程执行。
例如，GPOS可能会降低分配给高优先级线程的优先级，或者为了保证系统中其他线程的公平性而动态调整线程的优先级。因此，高优先级线程可能被低优先级线程抢占。此外大多数GPOS具有无界的调度延迟:系统中的线程越多，GPOS调度一个执行线程所需的时间就越长，这些因素中的任何一个都可能导致高优先级线程错过最后期限，即使是在高速CPU上。
此外，高优先级线程可以不间断地运行，直到它完成它需要做的事情，当然，除非它被一个更高优先级的线程抢占。这种方法被称为基于优先级的抢占式调度，允许高优先级线程满足其最后期限，即使许多其他线程正在争夺CPU时间。
抢占式内核 在大多数GPOS中，os内核是不可抢占的。因此，高优先级用户线程永远不能抢占内核调用，而是必须等待整个调用完成—即使调用是由系统中优先级最低的进程调用的。此外，当驱动程序或其他系统服务（通常在内核调用中执行）代表客户端线程执行exe剪切时，所有优先级信息通常都会丢失。这种行为会导致不可预知的延迟，并阻止关键活动按时完成。
另一方面，在实时操作系统中，内核操作是可抢占的。与在GPOS中一样，在时间窗口中可能不会发生抢占，在设计良好的实时操作系统中，这些窗口非常短，通常是数百纳秒的顺序。此外，实时操作系统对抢占延迟和中断禁用的时间设置了一个上限；这个上限允许开发人员确定最坏情况下的延迟。
为了实现一致的可预测性和关键活动的及时完成这一目标，实时操作系统内核必须尽可能简单优雅。实现这种简单性的最佳方法是设计一个内核，该内核只包含具有短执行路径的服务。通过从内核中排除工作密集型操作（例如进程加载）并将其分配给外部进程或线程，实时操作系统设计器可以帮助确保通过内核的最长不可抢占代码路径上存在上限。
在一些GPOS中，内核增加了一定程度的抢占性。然而，不可能发生抢占的时间间隔仍然比典型实时操作系统中的时间间隔长得多；任何此类抢占时间间隔的长度将取决于GPOS内核中任何模块（例如，网络）的最长关键部分。此外，一个可抢占的GPOS内核不会处理其他可能造成无限延迟的条件，例如，当客户端调用驱动程序或其他系统服务时发生的优先级信息丢失。
避免优先级反转 在GPOS中，甚至在实时操作系统中，低优先级线程可能无意中阻止高优先级线程访问cpu，这种情况称为优先级反转。当发生无限优先级反转时，可能会错过关键的最后期限，从而导致从异常系统行为到彻底失败的结果。不幸的是，在系统设计过程中，优先级反转常常被忽略。优先级反转的例子很多，其中包括1997年7月火星探险者项目。
一般来说，当两个不同优先级的任务共享一个资源，而高优先级的任务无法从低优先级的任务获得资源时，就会发生优先级反转。为了防止这种情况超过有限的时间间隔，实时操作系统可以提供GPOS中不可用的机制选择，包括优先级继承和优先级上限模拟。我们不可能公正地对待这两种机制，所以让我们关注一个优先级继承的例子。.
首先，我们必须考虑任务同步如何导致阻塞，以及阻塞如何反过来导致优先级反转。假设两个任务正在运行，任务1和任务2，并且任务1具有更高的优先级。如果任务1已准备好执行，但必须等待任务2完成活动，则会阻塞。此阻塞可能是由于同步造成的；例如，任务1和任务2共享由锁或信号量控制的资源，而任务1正在等待任务2解锁该资源。或者，可能是因为任务1正在请求任务2当前使用的服务。
阻塞允许任务2运行，直到发生任务1正在等待的条件（例如，任务2解锁两个任务共享的资源）。此时，任务1开始执行。任务1必须等待的总时间称为阻塞因子。如果任务1要满足其任何时间限制，则此阻塞因子不能随任何参数（例如线程数或系统输入）而变化。换句话说，阻塞因子必须是有界的。
现在让我们介绍第三个任务，任务 3，它的优先级高于任务 2，但低于任务 1（参见图1）。如果任务3在任务2执行时准备好运行，则它将抢占任务2，并且任务2将无法再次运行，直到任务3阻塞或完成。当然，这个新任务会增加任务1的阻塞因子；也就是说，它会进一步延迟任务1的执行。抢占引入的总延迟是一个优先级反转。
图1 任务1正在等待任务2完成一个活动，这时任务3抢占了任务2。此新任务进一步延迟任务1的执行
实际上，多个任务可以通过这种方式抢占任务2，从而产生一种称为链阻塞的效果在这种情况下，任务2可能会被无限期抢占，从而产生无限的优先级反转，并导致任务1无法满足其任何最后期限。
这就是优先级继承的来源。如果我们返回到我们的场景，并使任务2在同步期间以任务1的优先级运行，那么任务3将无法抢占任务2，从而避免产生优先级反转（参见图2）。
图2 任务2继承任务1的较高优先级，从而防止任务3抢占任务2。任务3不再延迟任务1的执行。
分区调度器 对于许多系统，保证资源可用性是至关重要的。如果一个关键的子系统被剥夺了，比如说，CPU周期，那么这个子系统提供的服务对于用户来说就变得不可用了。例如，在拒绝服务(DoS)攻击中，恶意用户可以用需要高优先级进程处理的请求轰炸系统。这个进程可能会使CPU超载，使其他进程的CPU周期中断，从而使系统对用户不可用。
安全漏洞并不是进程饥饿的唯一原因。在许多情况下，向系统添加软件功能会将系统推向“崩溃的边缘”，并使现有的应用程序占用大量CPU时间。及时运行的应用程序或服务不再按预期或要求作出响应。从历史上看，解决这个问题的唯一办法要么是改造硬件，要么是重新编码(或重新设计)软件——两者都是不受欢迎的选择。为了解决这些问题，系统设计人员需要一个分区方案，通过硬件或软件强制执行CPU运算，以防止进程或线程独占其他进程或线程所需的CPU周期。由于实时操作系统已经提供了对CPU、内存和其他计算资源的集中访问，所以实时操作系统是执行CPU分区运算的最佳选择。
有些实时操作系统提供一个固定的分区调度器。使用此调度器，系统设计人员可以将任务划分为组或分区，并为每个分区分配一定百分比的CPU时间。使用这种方法，任何给定分区中的任务消耗的CPU时间都不会超过分区静态定义的百分比。例如，假设一个分区分配了30%的CPU。如果该分区中的进程随后成为拒绝服务攻击的目标，那么它消耗的CPU时间将不超过30%。这个分配的限制允许其他分区保持其可用性;例如，它可以确保用户界面(例如远程终端)保持可访问性。因此，操作员可以访问系统并解决问题，而不必按下复位开关。
然而，这种方法有一个问题。因为调度算法是固定的，所以一个分区永远不能使用分配给其他分区的CPU周期，即使这些分区没有使用它们分配的周期。这种方法会浪费CPU周期，并阻止系统处理峰值需求。因此，系统设计者必须使用更昂贵的处理器，容忍更慢的系统，或者限制系统能够支持的功能数量。
自适应分区 另一种分区方案称为自适应分区，它通过提供更动态的调度算法来解决静态分区的缺点。与静态分区一样，自适应分区允许系统设计人员为一个进程或一组进程保留CPU周期。因此，设计人员可以保证一个子系统或分区上的负载不会影响其他子系统的可用性。但是，与静态方法不同，自适应分区可以动态地将CPU周期从不繁忙的分区重新分配给可以从额外处理时间分区预算中受益的分区，只有在CPU完全加载时才强制执行。因此，系统可以处理峰值调度应用程序不需要改变它们的调度行为。此外，设计人员可以动态地重新配置分区，以优化系统的性能。参加牛喀学城汽车操作系统技术培训，学习更多实用技术。扫描文末二维码报名。
“双重”内核 包括Linux、Windows和各种风格的unix在内的GPOS通常缺乏迄今为止讨论的实时机制。为了填补这个空白，GPOS供应商开发了大量的实时扩展和补丁。例如，有一种双内核方法，在这种方法中，GPOS作为一个任务运行在一个专用的实时内核之上(参见图4)。因此，这些任务可以在GPOS需要执行时抢占它们，并且仅在GPOS完成工作时才将CPU交给它们。
不幸的是，在实时内核中运行的任务只能有限地使用GPOS中的现有系统服务——文件系统、网络等等。事实上，如果某个实时任务向GPOS请求任何服务，那么该任务将受到相同的优先处理要求并实现100%的利用率，同时享受资源保障的好处。
同样重要的是，自适应分区可以覆盖在现有系统之上，而无需重新设计或修改代码。系统设计人员可以简单地在分区中启动现有的基于POSIX的应用程序，而实时操作系统调度器可以确保每个分区都收到分配的预算。在每个分区中，每个任务都根据基于优先级的抢占规则进行调度。
图3 自适应分区可以防止高优先级任务消耗超过分配的CPU百分比，除非系统包含未使用的CPU周期。例如，任务A和D可以在分配给分区3的时间内运行，因为任务E和F不需要剩余的预算CPU周期。
阻止GPOS进程确定性行为的问题。因此，必须专门为实时内核创建新的驱动程序和系统服务，即使GPOS已经有了类似的服务。而且，实时内核中运行的任务无法从大多数GPOS为常规，非实时流程提供的受MMU保护的强大环境中受益。相反，它们在内核空间中不受保护地运行。因此，包含常见编码错误（例如损坏的C指针）的实时任务很容易导致致命的内核错误。这是一个问题，因为大多数需要实时的系统也需要很高的可靠性。更复杂的是，双内核方法的不同实现使用不同的api。在大多数情况下，为GPOS编写的服务不能轻松地移植到实时内核，为一个供应商的实时扩展编写的任务可能不能在另一个供应商的扩展上运行。
图4 在典型的双内核实现中，GPOS作为单独的实时内核中优先级最低的任务运行。
这些解决方案指出了使GPOS能够支持实时行为的真正困难和巨大范围。这并不是“实时操作系统好，GPOS坏”的问题。诸如Linux、Windows和各种unix等GPOS都可以很好地作为桌面或服务器操作系统使用。然而，当它们被迫进入非为环境而设计的确定性环境时，如车载远程信息处理单元、医疗器械、实时控制系统和连续媒体应用程序，它们就不能满足要求。
扩展操作系统 特定于应用程序的需求 无论它们在确定性环境中的缺点是什么，使用它们都是有好处的。
这些优点包括对广泛使用的api的支持，以及对Linux的开放源码模型的支持。使用开放源码，开发人员可以根据特定于应用程序的需求定制操作系统组件，从而节省大量的故障排除时间。实时操作系统供应商不能忽视这些好处。对POSIX api (Linux和各种风格的unix使用的相同api)的广泛支持是重要的第一步。提供文档良好的源代码和定制工具包，以满足嵌入式开发人员的特定需求和设计挑战，也是如此。
实时操作系统的架构也起了作用。例如，基于微内核设计的实时操作系统可以使操作系统定制的工作从根本上比其他体系结构更容易实现。在微内核实时操作系统中，只有一小部分基本操作系统服务(例如，信号、计时器、调度)驻留在内核本身中。所有其他组件——驱动程序、文件系统、协议栈、应用程序——作为独立的、受内存保护的进程在内核之外运行(参见图5)。事实上，作为用户空间程序，这样的扩展变得和标准应用程序一样容易开发，因为它们可以用标准的源代码级工具和技术进行调试。
图5 在微内核实时操作系统中，系统服务作为标准的用户空间进程运行，从而简化了操作系统自定义的任务。
例如，如果设备驱动程序试图访问其进程容器之外的内存，操作系统可以识别负责的进程，指示错误的位置，并创建一个可以用源代码级调试工具查看的进程转储文件。转储文件可以包含调试器识别导致问题的源代码所需的所有信息，以及诸如数据项的内容和函数调用历史等诊断信息。
这种体系结构还提供了更好的故障隔离和恢复:如果驱动程序、协议栈或其他系统服务出现故障，它可以在不破坏其他服务或操作系统内核的情况下进行故障隔离和恢复。事实上，“软件监督”可以持续监视此类事件，并动态地重新启动违规服务，而无需重新设置整个系统或以任何方式涉及用户。类似地，可以动态地停止、启动或升级驱动程序和其他服务，而无需关闭系统。
这些好处不应该被忽视——对实时性能的最大破坏是计划外的系统重新启动!即使计划重新启动以合并软件升级也会干扰操作，尽管是以一种受控的方式。为了确保最后期限总是能够满足，开发人员必须使用能够持续可用的操作系统，即使在软件故障或服务升级的情况下也是如此。
一个战略决策  实时操作系统  有助于使复杂的应用程序既可预测又可靠；事实上，实时操作系统对时间的精确控制增加了GPOS无法实现的可靠性。（如果基于GPOS的系统由于不正确的计时行为而不能正确工作，那么我们可以合理地说该系统是不可靠的。）然而，选择正确的rtos本身可能是一项复杂的任务。实时操作系统的底层架构是一个重要的标准，但其他因素也是如此。其中包括：
 灵活选择调度算法-实时操作系统是否支持选择调度算法（FIFO，循环调度，零星调度等？）开发人员可以按线程分配算法，还是实时操作系统强迫他为系统中的所有线程分配一种算法？ 时间分区-实时操作系统是否支持时间分区，以便为进程提供一定百分比的CPU周期？这样的保证简化了从多个开发团队或供应商集成子系统的工作。它们还可以确保关键任务仍然可用并满足其最后期限，即使系统受到拒绝服务（DoS）攻击和其他恶意攻击。 支持多核处理器——迁移到多核处理器的能力已经成为各种高性能设计的基础。实时操作系统是否支持多处理模型(对称多处理、非对称多处理、绑定多处理)的选择，以帮助开发人员充分利用多核硬件?系统跟踪工具是否支持实时操作系统，以便开发人员诊断和优化多核系统的性能?如果没有能够突出资源争用、过度的线程迁移和多核设计中常见的其他问题的工具，优化多核系统很快就会成为一项繁重、耗时的任务。 用于远程诊断的工具-由于许多嵌入式系统无法容忍停机，因此实时操作系统供应商应提供诊断工具，可以分析系统的行为而不会中断系统提供的服务。寻找一个提供用于系统分析，应用程序分析和内存分析的运行时分析工具的供应商。 开放式开发平台-实时操作系统供应商是否提供基于开放式平台（如Eclipse）的开发环境，从而允许开发人员“插入”他们喜欢的第三方工具来进行建模，版本控制等？还是开发环境基于专有技术？ 图形用户界面-实时操作系统是使用原始图形库，还是支持多种人机界面技术（HTML5、Qt、OpenGL ES等），并提供高级图形功能，如多层界面、多头显示、加速3D渲染和真正的窗口系统？gui的外观和感觉可以很容易地定制吗？guis能同时显示和输入多种语言（汉语、韩语、日语、英语、俄语等）吗？二维和三维应用程序可以轻松地共享同一屏幕吗？标准api-实时操作系统是将开发人员锁定到专有api中，还是为posix和opengl es等标准api提供经认证的支持，从而使代码更易于在其他环境之间进行移植？此外，实时操作系统是否提供了对api的全面支持，或者它只支持定义接口的一小部分？ 标准api-实时操作系统是将开发人员锁定到专有api中，还是为posix和opengl es等标准api提供经认证的支持，从而使代码更易于在其他环境之间进行移植？此外，实时操作系统是否提供了对api的全面支持，或者它只支持定义接口的一小部分？ 针对数字媒体的中间件——对数字媒体的灵活支持正在成为一系列嵌入式系统的设计要求，包括汽车收音机、医疗设备、工业控制系统、媒体服务器，当然还有消费电子产品。一个系统可能需要处理多个媒体源（设备、流等），理解多个数据格式，并支持多种drm方案。通过为数字媒体提供设计良好的中间件，实时操作系统供应商可以消除连接到多个媒体源、组织数据和启动适当的数据处理路径所需的大量软件工作此外，一个设计良好的中间件解决方案将有灵活性来支持新的数据源，如下一代iPod，而不需要修改用户界面或其他软件组件。  对于任何项目团队来说，选择实时操作系统都是一项战略决策。实时操作系统供应商为上述问题提供清晰的答案后，您将可以选择现在和将来最适合的。
]]></content>
  </entry>
  
  <entry>
    <title>RDMA网络趋势</title>
    <url>/post/server/RDMA-network-trends.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>RDMA</tag>
    </tags>
    <content type="html"><![CDATA[本文深入探讨了RDMA传输协议，重点介绍了ROCEv2协议，这是 数据中心  、HPC和企业网络中领先的RDMA传输协议。
简介 人工智能（AI）的崛起极大地提高了对强大、高效和可扩展的网络传输协议的需求。本文深入探讨了RDMA传输协议，重点介绍了ROCEv2协议，这是数据中心、HPC和企业网络中领先的RDMA传输协议。基于ROCEv2的RDMA（远程直接内存访问）已经在超大规模数据中心的某些部分取代了TCP。RDMA可以在网络中的远程主机之间实现低延迟和高吞吐量的通信。在最近的一次NDSI-23-Talk中，微软强调Azure云的70%的网络流量（主要是存储网络流量）在以太网上运行的ROCEv2 RDMA上，只有很小一部分流量在基于TCP/IP的网络上运行。这一显著转变在甲骨文、阿里巴巴和Meta等其他超大规模云服务提供商中也很明显，它们都广泛利用ROCEv2 RDMA协议。这一趋势表明，随着云端、人工智能/机器学习工作负载的不断增长，行业对于优化网络性能的RDMA技术的使用正在发生更广泛的转变。
RDMA的现状 RDMA通过直接将“内存映射”数据传输到远程内存位置来进行操作，提供了两个关键优势：
 CPU效率：与消耗多个CPU核心的TCP/IP不同，RDMA通过注册内存并将数据传输委托给RDMA网络适配器来释放CPU资源，这对于希望利用这些空闲CPU核心获利的云服务提供商来说是一大福音。 低延迟和内存效率：RDMA绕过Linux内核，直接将数据传输到应用程序缓冲区，这种特性称为零拷贝。这消除了发送端和接收端节点的内存复制需求。内核绕过和零拷贝特性最大程度地减小了延迟和抖动。  RoCEv2 RDMA起源于高性能计算（HPC），并包含了IB Transport协议。
RoCEv2和InfiniBand协议栈，来源于附录6，InfiniBand架构规范第1卷。RoCEv2保留了InfiniBand Verbs语义以及它的IB Transport传输，并用UDP/IP替换了InfiniBand网络层，并用以太网的链路和物理层替换了InfiniBand。
因此，ROCEv2 RDMA已成为数据中心后端网络的标准，提供高吞吐量、微秒级低延迟和完全的CPU卸载。
注意：前端网络通常运行TCP/IP或其他协议，如QUIC。RDMA、InfiniBand和其他协议作为后端网络，通常被称为东西流量，占现代数据中心流量的70-80%。
以太网ROCEv2的挑战 InfiniBand架构 InfiniBand被设计为一种无丢包网络，注重服务质量（QoS）和传输层端到端的credit。IB协议栈在HPC和AI/ML网络中运作良好。然而，InfiniBand网络通常比以
太网更昂贵且扩展性较差。
注意：无丢包意味着底层网络被配置为消除由于网络拥塞导致的数据包丢失；由于错误条件，数据包可能会偶尔被损坏或丢失，此时传输协议中包含了一个端到端的传递机制，带有内置的数据包重传逻辑，通常是在硬件中实现的，并且在丢包时会触发以恢复丢失的数据包，而不需要软件堆栈的干预。
ROCEv2架构 ROCEv2数据包格式，来源于附录6.3，InfiniBand架构规范第1卷：
RoCEv2在以太网链路上通过UDP/IP运行。UDP是一种不可靠的数据报服务，以太网并不是设计成无丢包的。由于ROCEv2期望底层网络是无丢包的，以太网部署在将以太网配置为无丢包网络方面面临着几个挑战，如下所述：
 头阻塞（HOL阻塞）：由于优先级流量控制（PFC）。不同流中的数据包可能被拥塞的流量阻塞。在跨多个交换机的大型网络上进行扩展成为一项挑战。 拥塞管理：通常由软件以带外的方式处理。现有的技术速度慢且复杂。一些供应商正在借鉴InfiniBand的硬件技术，但这些技术是定制的，不是以太网标准的一部分。 吞吐量降低：以太网不是无丢包网络。由于拥塞丢包，可能会导致整个数据包窗口的重传（称为Go-back-to-N），这降低了网络的“好吞吐量”。  尽管存在这些挑战，大规模的ROCEv2网络已经成功部署，但需要仔细的调优和监控。大多数超大规模云服务提供商已经采取了定制的非标准ROCEv2解决方案，并在针对每个特定工作负载进行了RDMA栈的精细调优方面投入了大量资金。
在某些情况下，组织已经采取措施为特定应用程序（如AI/ML或存储）设置单独的基于ROCEv2 RDMA的数据中心，从而增加了运营成本。让我们深入研究三个不同的案例研究，以更细致地了解情况。
微软的经验 微软在超大规模数据中心部署RoCEv2已经超过十年，并发表了具有洞察力的Microsoft-RDMA-Challenges研究论文。这次讨论的主要负载是分离式存储，即基于网络的存储。在这些微软的部署中，面临PFC死锁问题、RDMA传输活锁问题和其他与NIC相关的问题。
微软认为，单纯的协议理论在真实世界的部署中不足够；需要在大规模上进行严格的测试、分阶段的推出和与NIC供应商的合作，以便找到最初设计协议时隐藏的大规模错误。微软开发了自定义的ROCEv2协议扩展，如基于DSCP的PFC，受到一些NIC/交换机供应商的支持。
此外，微软还实施了用于健康跟踪和故障排除的遥测系统，这对于识别这些隐藏复杂性至关重要。
甲骨文的方法 OCI（甲骨文云基础设施）是一个公共云，可以在同一个RDMA网络上运行多个不同的应用程序，例如AI、HPC、数据库和存储。
甲骨文通过多方面的方法解决ROCEv2挑战：
 限制优先级流量控制（PFC）：在三层Clos网络中限制在网络边缘。 网络本地亲和性：甲骨文根据网络亲和性将工作负载放置在本地，以保持大多数流量本地化。 精细调节的拥塞控制：利用显式拥塞通知（ECN）和DC-QCN，每个针对特定RDMA工作负载进行了精细调节，以平衡延迟和吞吐量。  有关更多见解，请参阅Oracle SuperClusters Blog
Meta的创新 Meta主要专注于ROCEv2 RDMA部署，主要用于AI/ML工作负载，如在Meta @Scale 2023活动视频AI Training &amp; Inference at Meta.中讨论的。主要工作负载包括推荐引擎、内容理解和大型语言模型（LLM）。这些集群从数百个GPU扩展到数万个GPU（用于LLM）。
有趣的是，Meta没有遇到与微软相同的挑战。例如，PFC HOL阻塞不是一个问题，因为其spine交换机具有深的缓冲区。Meta还成功使用了DC-QCN进行拥塞控制，并且没有遇到扩展性问题，这要归功于具有更大缓存的现代NIC。Meta可能由于多个原因没有遇到相同的问题-使用了具有先进功能的新硬件，以及拓扑结构、工作负载和软件策略的差异。
 Meta主要的挑战集中在负载均衡上，通过依赖SDN控制器来编程路由来解决。这些路由在网络事件发生之前不会更新。Meta在多个队列对（QP）之间复用流来增加熵的同时，通过自定义的ECMP哈希方案来增加熵。 Meta使用PCIe点对点（P2P）DMA技术来提高应用程序性能，通过实现跨GPU的直接数据传输。 Meta还在spine层收敛了流量，因为AI/ML流量模式不需要完全非阻塞的spine连接。这降低了数据中心的成本。  与其他许多公司一样，Meta正在探索数据包喷洒、基于分离式VOQ的交换机和可以容忍乱序传递的定制传输协议。
一篇有趣的MIT + Meta研究论文Optimized Network Architecture for LLMs提出了一种新的面向LLM的流量模式的网络架构，可以将网络成本降低37% - 75%。该架构为具有高通信需求的GPU定义了一个高带宽（HB）域。在HB中，GPU之间通过任意互连进行连接。在Meta的部署中，跨HB的网络流量是稀疏的，可以消除HB域之间的连接和交换机，从而降低网络成本。
RDMA的未来 超大规模云服务提供商和供应商都已经以定制的方式解决了ROCEv2的问题，但ROCEv2网络仍然需要针对每个工作负载进行定制和精细调优。
1RMA Scaling Framework 需要大规模扩展到数百万个节点和数亿个流的公共云。由于ROCEv2的面向连接的特性，工作队列条目（WQE）通常在硬件中实现，这限制了流的扩展。跨多个租户的安全性和线速加密对RoCEv2提出了额外的挑战。
对于云数据中心而言，一个有希望的替代方案是在1RMA论文中提到的1次远程内存访问（1RMA）方法，该方法提出了一种以软件为中心的新架构方法。
这种软件中心的方法变得更可行是因为带有SOC（System-on-Chip）处理器核心现在可以在DPU/IPU为基础的网络适配器上运行软件。其主要思想是：
 软件：将一些传统的NIC硬件数据结构，如排队、数据包排序、数据包调节和拥塞控制，转移到软件中。 硬件：将NIC硬件集中在主数据路径上，即DMA传输、连续传输控制、延迟测量、身份验证和加密。硬件是无连接的，并为软件提供细粒度的延迟测量和故障通知。  1RMA方法提倡将连接和大部分状态转移到软件中，以实现更好的可扩展性。这简化了硬件并支持公共云所需的大规模扩展，而且重要的是支持灵活性和可扩展性。需要注意的是，采用1RMA方法可能需要从头开始进行重构架构**，涉及新的协议和NIC硬件。
还要注意，1RMA研究集中于云数据中心的需求；AI/ML和HPC网络可能需要不同的权衡。
UEC联盟 UEC联盟提出用基于UDP/IP的新开放协议替代ROCEv2。UEC的重点是AI/ML和HPC网络。
ROCEv2替代协议的关键特性包括：
 多路径和数据包喷洒 灵活的传递顺序和选择性重传 响应式拥塞控制机制 更大的规模、稳定性和可靠性  可能需要在整个堆栈的所有层面进行更改。有关详细信息，请阅读UEC-Consortium-Whitepaper。一些白皮书的主题与1RMA论文和EDQS论文（由Broadcom收购的Correct Networks编写）
UltraEthernet联盟在Open Compute Global Summit做了技术更新。
未来的开放标准 目前，还没有ROCEv3标准出现在视野中。针对这些挑战的可扩展、通用和开放的解决方案仍然很难找到。
可能AI/ML、HPC和云数据中心工作负载的需求有足够的差异，以至于我们需要多个解决方案。例如，
 宪章：UltraEthernet联盟仅关注规模化的AI和HPC。 工作负载特性：HPC要求超低延迟，而AI/ML训练则优先考虑高吞吐量和低尾延迟。 各种拓扑：公共云通常使用2层或3层Clos网络，而AI/HPC网络可能使用dragon-fly、3D-torus或hypercube拓扑。这些拓扑结构在不断发展。 不断变化的需求：AI/ML算法不断演进，云数据中心工作负载也在不断演化，这可能导致将来进一步的差异化 开放与闭合：云数据中心可以继续使用定制解决方案或在OCP等上合作制定开放标准。  如果出现多个开放解决方案，跨领域的合作可能有助于建立一个统一的基础架构。
结论 尽管有许多定制和独特的方法来解决ROCEv2的挑战，但行业正在积极探索基于开放标准的ROCEv2 RDMA的替代方案。未来的RDMA协议必须发展成为一种对各种工作负载都像TCP一样“即插即用”的解决方案。最后，DPU/IPU技术内置的SOC正在改变我们对网络的理解。它们允许我们重新定义硬件和软件的边界，直接在网络硬件上运行关键软件，使我们的系统具有灵活性和可扩展性。
附录  Broadcom ROCE介绍 介绍Falcon：一种可靠的低延迟硬件传输 Meta Networking@Scale 2023活动 Meta公司用于AI集群的Next-Platform以太网 甲骨文RDMA博客 InfiniBand规范，包括ROCEv2的附录17，可以在InfiniBand协会网站上找到。  术语表  1RMA：1次远程内存访问。以软件为中心的RDMA架构。 AI：人工智能-能够学习和执行通常需要智力的任务的软件系统。 Clos：一种为非阻塞高吞吐量连接设计的网络交换机架构。 DC-QCN：数据中心量化拥塞通知-用于ROCEv2数据中心网络的端到端拥塞控制协议。 分离的VOQ：一种在网络交换机架构中使用的虚拟输出队列技术，与将所有流量保留在单个队列中的传统方法不同，为每个可能的输出位置维护单独的队列。它解决了一种称为头阻塞的常见问题。 DPU：数据处理单元是一种紧密集成了通用CPU和网络接口硬件的可编程计算机处理器，通常与IPU可以互换使用。 ECMP：等成本多路径-一种网络路由策略，允许在成本相等的多条路径上转发数据包，基于某些第3层参数。 ECN：明确拥塞通知-用于减少网络拥塞的网络协议功能。 端点：在网络中，端点是参与网络的个体设备。节点可以是计算机、服务器、交换机或任何可以处理、存储或转发数据的设备。 流：是从特定源到特定目的地发送的“相关”数据包的序列，表示单向数据流。一个例子是5元组流，包括源IP地址、目标IP地址、源端口、目标端口和传输层协议标识符。流可以根据工作负载上下文使用其他属性。 好吞吐量：有效的数据传输速率，不包括协议开销和重传。 GPU：图形处理单元-专用处理器，用于加速图像和视频的处理。GPU是并行处理机器，因此用于AI/ML训练和推断工作负载。 HOL阻塞：在网络交换机中的一种现象，由于处理延迟，一个数据包阻塞了属于其他流的后续数据包。 HPC：高性能计算-将计算能力聚合起来解决复杂问题的实践。 Incast：一种网络拥塞情况，多个发送方同时向单个接收方传输数据，通常导致数据包丢失。 IPU：基础设施处理单元是一种紧密集成了通用CPU和网络接口硬件的可编程计算机处理器，通常与DPU可以互换使用。 LLM：大型语言模型是一种执行各种自然语言处理（NLP）任务的深度学习模型。LLM使用变压器模型，并使用大规模数据集进行训练-因此是大模型。 NIC：网络接口卡-将计算机连接到网络的硬件组件。 节点：在网络中，节点是参与网络的个体设备。节点可以是计算机、服务器、交换机或任何可以处理、存储或转发数据的设备。 NVLink：NVIDIA的高速互连-一种高带宽、低延迟的内存映射互连。 OCI：Oracle Cloud Infrastructure-甲骨文的云计算服务。 数据包喷洒：一种在网络中将数据包分布到多个路径以优化资源利用和降低延迟的技术 PFC：优先级流量控制-由IEEE 802.1Qbb标准定义，PFC是一种链路级流量控制机制，用于防止由于拥塞而导致的帧丢失。与传统的流量控制不同，PFC在特定的优先级队列上操作，允许更精细的控制。 Queue-Pair：或QP包括发送队列和接收队列。发送队列发送请求RDMA操作的出站消息。接收队列接收传入消息或即时数据。 RDMA：远程直接内存访问-一种在不涉及操作系统的情况下实现两台计算机之间的内存访问的技术。 ROCEv2：RDMA over Converged Ethernet v2-是RDMA在以太网网络上的扩展。在InfiniBand架构规范的附录17中定义。 SoC：片上系统-集成了计算机系统的所有组件的集成处理器。 尾延迟：在分布的99th百分位延迟中经历的延迟，常用于衡量系统在峰值负载下的性能。 TCP/IP：传输控制协议/因特网协议是一套用于互联网上的网络设备之间进行连接的通信协议。 遥测：用于监控的测量和自动化的收集。 VOQ：一种在网络交换机架构中使用的技术，不同于将所有流量保留在单个队列中的传统方法，而是为每个可能的输出位置保留单独的队列。它解决了一种称为头阻塞的常见问题。 WQE：工作队列条目-用于管理RDMA技术中的工作请求的数据结构。 ]]></content>
  </entry>
  
  <entry>
    <title>2024年HDD展望：技术与趋势</title>
    <url>/post/server/HDD-Outlook-2024.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>HDD</tag>
      <tag>2024 Trend</tag>
    </tags>
    <content type="html"><![CDATA[机械硬盘是一种经过时间考验的可靠存储技术，具有出色的可靠性。其高容量和每单位容量低成本等关键优势，使其成为 数据中心  、监控、游戏和云计算等各个行业和应用领域中数据存储战略的重要基石。
HDD在未来将如何引领变革？在与其它存储解决方案的竞争中，HDD能否继续保持其重要地位？
在容量和成本间探寻平衡点 近期，东芝推出了22TB MG10F，此款HDD采用了传统的磁记录技术，采用10盘氦密封设计，为3.5英寸尺寸规格的MG10系列增加了10%的容量。更为重要的是，工程师们成功地在相同的尺寸规格和功耗下，以大致相同的成本实现了更多的容量。这一环节至关重要。目前，HDD与闪存存储的每单位容量成本差距约为7倍，这一优势仍是HDD的生存之道。如果成本呈指数级增长，增加容量就变得毫无意义。实际上，通过这些努力，HDD的容量可能会达到40甚至50TB，而成本仍与闪存存储相当。
此外，我们还需要考虑以下两个因素。首先，必须要对更高容量的HDD有需求，否则产品开发将失去意义。这个市场驱动因素是明确的。即使HDD的容量达到100TB，在数据驱动的大趋势下，我们也会在很短的时间内就将其填满。其次，从技术的角度讲，这必须是可行的。我们会不断地投资以推动相关技术的进步。目前，这项工作还在进行中，只要市场对更高容量的HDD有需求，我们就会继续前进。
满足数据中心运营商的可持续发展需求 数据中心依然将HDD视为云服务大规模设施中的主要存储设备。前文提及的22TB容量增长标志着显著的进步，因为在相同尺寸规格下实现更高容量为城市区域空间有限的问题提供了实质性的机架空间优势。越来越多的数据中心运用RAID技术将单个HDD组合起来，以构建更大、更快速的存储解决方案。常见的情况是将24个HDD集成到一个机箱中，而这一数字有可能会进一步增加，有可能达到60到120的范围。
数据中心的第二个重要趋势是可持续性，而HDD在两个方面能够为这一目标发挥作用。首先，在能源效率方面，存储盘在特定速度旋转和以特定速率访问时，不可避免地受到物理定律的限制，通常需要大约10瓦每单位。几年前推出的氦技术将这一数值降低到了7-8瓦左右。但要想更进一步节能，唯一的方法就是为这10瓦引入更多的容量，而近期的技术进展已经为实现这一目标提供了助力。此外，数据中心工程师正在思考如何在空闲或关机模式下以更为功耗优化的方式使用HDD。
另一个明显的可持续性趋势是回收利用。云数据中心首批部署的HDD是在6或7年前，这些组件现在已经接近使用寿命的终点，并将被报废。由于HDD主要由铝和铜制成，使其比其它组件和材料（如PCB、芯片和塑料）更易于回收。因此，我们预计HDD将成为循环经济中的一个重要组成部分，基于回收和重复利用等服务。
为终端用户提供存储解决方案建议 大多数HDD广泛应用于云和企业领域，这些领域的终端用户越来越希望HDD供应商能够成为他们的合作伙伴，协助他们构建最适合其特定部署的技术和配置。为了满足这一需求，我们的HDD实验室可以将多个HDD组合在一起，进行功能和性能测试。最近，他们安装了一个高容量的顶装JBOD机箱，其中包含78个18TB的HDD，总容量达到1.4PB，并与一台服务器相连。此基础设施可以通过测试单个HDD来确定其每秒MB的性能率。随后，可以切换到78个HDD的任何组合，并逐步添加它们以精确测量总输出。当所有78个HDD同时运行时，性能可达到近17GB/s。
这个基础设施还可以用于进行详细的权衡计算，协助终端用户确定如何正确配置手头的任务。如果没有这个基础设施，他们可能不得不投资于测试端口和HDD作为样本，这并不总是经济实惠的选择。在我们的实验室最新的工作中，已经测试了多个HDD组合，这些组合足够快速地进行数据归档、在线导航系统的视频流传输以及运营网络商店。这种紧密的合作对于那些在大规模应用中部署HDD的企业至关重要，最终延长了这一不断发展的技术的寿命。
保持写入密集型监控应用的相关性 监控领域对数据存储的需求仍然较高，趋势是向着更高质量、全天候视频流的方向发展。为了支持这一趋势，硬件需要具备价格合理且足够可靠的特点，以确保正常运行。以往，如果摄像头本身需要存储组件，通常会选择闪存，而中央录像机通常由一个或多个HDD组成。在某些地区，由于GDPR规定只能保留少量记录一段时间，因此系统供应商可能会考虑在中央存储中使用低容量SSD。因为在特定情况下，这种小容量可以实现与HDD相当的成本。但是，这种设置无法应对写入密集型操作的挑战。数据只能保存几天的高覆盖写周期会迅速使闪存组件受损。而对于HDD来说，则不存在这样的问题。
其它优势也逐渐凸显出来。监控系统一直涉及到顺序写入操作，也就是数据按照顺序连续写入。HDD在顺序写入性能上表现出色，因此它成为持续和顺序性视频录制的优选解决方案。此外，HDD还是一种非易失性存储设备，即使在断电的情况下也能保留数据。这对于监控系统来说至关重要，因为在断电或意外系统关闭的情况下，需要保持数据的完整性和可保存性。因此，HDD在监控领域仍将发挥重要作用。
]]></content>
  </entry>
  
  <entry>
    <title>CPU缓存简介</title>
    <url>/post/hardware/brief-introduction-to-cpu-cache.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>CPU Cache</tag>
    </tags>
    <content type="html"><![CDATA[　CPU的核心功能包括数据运算和指令控制。CPU运算的数据和执行的指令全部存储在CPU的寄存器中，这些数据和指令又都来自于CPU高速缓存。
最早的计算机系统存储由主存储和外部存储两部分组成，主存储即是插在主板上的内存，外部存储是内存以外的所有存储设备。早期的计算机“系统”内置在主板的ROM（一种断电后数据不会丢失的内存）中，而不是存储在硬盘里，数据处理的方式也是将数据都加载到主存中进行处理。所以硬盘驱动器与软盘驱动器、光盘驱动器等一样都是外部存储设备。主存是CPU和外部存储之间的一个缓冲区，为高效的运算处理提供了保障。
　随着CPU性能的提升，CPU的处理速度与内存的传输速度逐渐拉开了差距。于是CPU中开始内置更高速的内存，缓解二者之间的性能差距，CPU中的内存被称作CPU缓存。
　CPU缓存分为L1（一级缓存）、L2（二级缓存）、L3（三级缓存），也是随着CPU的演进逐渐发展出来。
　L1缓存是针对CPU内核中寄存器存储的数据进行缓存。L1d缓存指令数据，例如变量和数组；L1i缓存二进制的指令。两个L1缓存可同时被CPU访问，避免了资源冲突，而且封装在CPU内部有很高的执行效率。
　L2缓存是CPU单个核心中的“通用”缓存，存储的数据与内存中的数据一致，主要功能就是为内存提速。早期L2缓存集成在CPU的电路板或主板之上，现在与每个CPU核心独立集成在一起。L2缓存速度比内存要快很多，是提升性能的重要部件。
　L3缓存是为了解决L2级别缓存容量问题而扩充的缓存。L3缓存的集成方式也是从CPU外部逐渐转移到CPU内部。到了多核CPU时代，L3缓存主要作用是实现多个核心之间的数据交换，但对CPU性能提升的帮助不大。
CPU中缓存示意图
　随着技术的发展，存储器的性能越来越高，通用型的存储都逐渐统一为内存型存储设备。软盘基本已经消声灭迹（日本银行的老旧系统仍然在使用），光盘通常出现在播放器和游戏机中，个人计算机和服务器也逐渐采用固态硬盘，磁盘介质的硬盘驱动器只能应用在低成本大数据量的存储场景和备份场景。但是，速度又快、容量又大的存储永远都要付出高昂的成本。我们只能在整个系统中增加少量的高速缓存，缓解这个矛盾。
 CPU缓存简介  
]]></content>
  </entry>
  
  <entry>
    <title>解惑I2C总线的几个问题</title>
    <url>/post/hardware/some-questions-and-answers-about-i2c.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>I2C</tag>
    </tags>
    <content type="html"><![CDATA[本文解惑I2C总线的几个问题!
问题1：为什么I2C线上需要​330 Ω的串阻? 回答：330 Ω的串阻用来提高对I2C射频(RF)噪声的抗干扰能力。
串阻配合管脚电容组成了低通滤波器，用来滤除耦合到I2C总线的高频噪声。
问题2：I2C总线上的上拉电阻范围是多少？ 回答: 总线电容是走线部分、连接部分、管脚部分的电容的总和。总线电容限制了上拉电阻(Rp) 的最大值，因为I2C规定了上升时间（SDA和SCL信号的上升时间）。
而供电电压限制了上拉电阻的最小值，因为I2C规定了标准和快速模式下的最小3 mA、超快速模式下的最小20 mA的灌电流。以下列出了最大和最小上拉电阻的计算公式：
 Rp(最大) = t­­r / 0.8473 ×Cb Rp(最小)最大)) = (VDD – VOL(最大)) / IOL tr – I2C规范规定的SDA和SCL的上升时间 Cb – 经过检测的总线电容 VDD – I2C总线供电电压 IOL – I2C规范规定的最小总线灌电流 VOL(最大) – I2C规范规定的低电平输出电压。  问题3：3.3 V供电时I2C总线的最大通信速率是多少? 我能够在3.3 V供电时使I2C运行在400 kHz的速率吗? 回答：I2C的时钟参数选项指定I2C接口运行所需的时钟速率。三个时钟速度可以选择：50 kHz 标准\100 kHz 标准\400 kHz 快速
I2C的400 kHz速率，只有在内部主时钟(IMO)或者说系统时钟(SysClk)为24 MHz时可以正常使用。
I2C的最高通信速率和电压设置无关，和SysClk有关。
所以，如果SysClk在全局资源中设置为了24 MHz，您可以将I2C运行在400 kHz的最大速率。I2C的用户模块的时钟速率选项假设了SysClk为24 MHz。
如果SysClk在全局资源中设置为慢速内部时钟(SLIMO，6 MHz SysClk)，用户模块中的I2C速率设置数值也会成倍降低。
比如，如果SysClk是6 MHz，I2C时钟速率选项则为12.5 kHz，24 kHz和100 kHz。SysClk从中央处理器单元（CPU）时钟分出来。
问题4: I2C时钟是怎样影响I2C从机的时钟延展宽度的？ 回答：时钟延展是一种I2C从机在每次数据传输过程时，从第9个时钟起，即从应答（ACK）信号发出的时钟起，将SCL电平拉低的现象。
时钟被拉低的时间取决于CPU处理中断的时间，因此改时间取决于CPU速率而不是I2C时钟速率。
问题5: 时钟延展的最长时间是多少？ 回答: 时钟延展是一种I2C从机在每次数据传输过程时，从第9个时钟起，即从应答（ACK）信号发出的时钟起，将SCL电平拉低的现象。
当PSoC配置为I2C从机时，收到一组I2C数据后，会立即拉低SCL电平。伴随该事件会产生一个中断，在该中断中，CPU会准备写入ACK/NAK到I2C的控制寄存器中，以释放时钟线。
时钟延展的最长时间可以根据以下公式计算得到：
假设：程序中已使能的中断数量为N（包括I2C中断）
时钟延展时间 = (25 Cycles × N) × CPU_CLK + (N个中断处理时间之和)
注意：一个中断的处理时间可以通过该中断中CPU时钟运行的周期数乘以CPU时钟计算得到。
问题 6: PSoC对I2C通信时的SCL和SDA的上升和下降时间是怎样规定的？ 回答: 下表列出了在超快速、快速和标准模式的速率运行时，SCL和SDA的上升及下降时间规范。
]]></content>
  </entry>
  
  <entry>
    <title>RTX 40 SUPER发布时间定了</title>
    <url>/post/news/NVIDIA-RTX-40-SUPER-announce-plan-in-place.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Nvidia</tag>
      <tag>RTX 8040</tag>
      <tag>RTX 4070</tag>
      <tag>RTX 4090D</tag>
    </tags>
    <content type="html"><![CDATA[NVIDIA RTX 40 SUPER系列显卡基本确定将在2024年1月8日正式发布，也就是CES 2024大展期间，随后在1月中下旬陆续解禁上市。
RTX 4070 SUPER 1月16日解禁公版/原价丐版，1月17日解禁高价高配版，上市开卖，起价599-649美元左右。
AD104-350或者AD103-175核心，CUDA核心数量从5888个增至7168个，二级缓存从36MB增加到48MB，显存还是12GB，整卡功耗从200W略微增至220W。
性能提升幅度推测14％左右，可接近现在的RTX 4070 Ti。
RTX 4070 Ti SUPER 1月23日解禁公版/原价丐版，1月14日解禁高价高配版，上市开卖，起价799-849美元左右。
AD103-275或者AD102-175核心，CUDA核心数量从7680个增加到8448个，二级缓存48MB。
显存位宽从192-bit升至256-bit，容量也从12GB增至16GB，但频率不会太高，保持总带宽低于RTX 4080 SUPER。
功耗不变还是285W。
性能提升幅度推测15％左右。
RTX 4080 SUPER 1月30日解禁公版/原价丐版，1月31日解禁高价高配版，上市开卖，起价999-1099美元左右。
AD13-400核心，二级缓存64MB，CUDA核心数量从9728个增加到10240个，显存还是16GB，功耗还是320W。
性能提升幅度将会是最小的，估计只有5％左右。
PS：中国特供的RTX 4090D将在1月底发布。
]]></content>
  </entry>
  
  <entry>
    <title>闪存又要涨价了</title>
    <url>/post/news/flash-memory-prices-are-going-up-again.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Flash Memory</tag>
    </tags>
    <content type="html"><![CDATA[据悉，上游 存储  原厂三星、美光、SK海力士减产后，整体供货资源顺序出现动态调整，优先供货自家品牌产品，对外NAND销售比例下降。
由于存储涨价预期持续发酵，下游系统厂商采购渐趋积极，部分产品出现缺货。
据悉，上游存储原厂三星、美光、SK海力士减产后，整体供货资源顺序出现动态调整，优先供货自家品牌产品，对外NAND销售比例下降。
供应链称，目前已有部分产品缺货，客户敲定第一波预订单后，想再增加拉货却已买不到。
上周，全球第四大NAND闪存供应商西部数据对客户发出涨价通知信称，公司会每周审查硬盘产品定价，预计明年上半年价格将上涨。
此外，NAND闪存芯片方面，西部数据预期未来几季价格会周期性上涨，累计涨幅可能较当前报价高五成以上，达55%。
另外，SSD主控芯片厂商群联公布了11月的业绩，再次确认了存储行业也大涨价的事实。
按照群联的说法，11月SSD控制芯片总出货量持续回温，其中，PCIe SSD控制芯片总出货量年成长将近40%，创历史同期新高纪录。
展望第四季度，TrendForce预计，NAND闪存产品将迎来量价齐涨，预估全产品平均销售单价涨幅将达13%，NAND Flash产业营收将环比增长逾两成。
另外，群联电子将在CES 2024上展示两款新的PCIe 5.0 SSD主控方案，一个定位旗舰，一个面向主流。
PCIe 5.0 SSD诞生已经差不多一年了，但是受限于群联E26主控的先天不足，以及闪存技术的配合不到位，无论性能还是功耗都难以令人满意，普遍只能最高跑到12GB/s，而且大多数都离不开主动风扇。
新的旗舰主控叫做“PS5026-E26 Max14um”(诡异的名字)，其实就是现有E26的增强版，支持PCIe 5.0 x4、I/O+技术，加上深度调校的新固件，在搭配2400MT/s高速闪存的时候，顺序读取速度最高可达14.7GB/s，已经吃满PCIe 5.0 x4的全部带宽。
但是顺序写入速度相对有点慢，还是只能跑到12GB/s。
同时，随机性能也有了明显提高，尤其是写入，读写分别可达150万IOPS、160万IOPS。
作为对比，现有的E26一般最高可以跑到10GB/s、10GB/s、150万IOPS、125万IOPS。
另外，新主控在PCMark 10、3DMark存储测试中的成绩都可以超过1000MB/s，在消费级SSD中还是首次。
遗憾的是，E26 Max14um因为还是台积电12nm工艺，加上性能提升，功耗和发热可能更加不容乐观，官方演示都用了MEMS风扇。
不知道为什么群联非得守着落后工艺，就是不肯升级，那样既能提升性能，也可以控制功耗和发热，不香吗？
慧荣的SM2508方案就用了台积电6nm，号称顺序读写都可达满血14GB/s，随机读写分别高达250万IOPS、240万IOPS，甚至可以用于笔记本，但商用速度实在是太慢了。
面向主流市场，群联的PCIe 5.0 SSD主控方案是“PS5031-E31T”，仅支持四通道闪存，无缓存，最高速度为10.8GB/s，最大容量8TB。
PS5027-E27T：低功耗、高性能的PCIe 4.0 SSD主控，主打M.2 2230小尺寸规格，可用于ROG Ally、Steam Deck等掌机。
PS2251-21(U21)：全球首款单芯片USB4主控方案，最高速度4GB/s，可用于轻薄笔记本等设备。
]]></content>
  </entry>
  
  <entry>
    <title>Serial NOR flash 能 XIP 吗</title>
    <url>/post/hardware/can-serial-nor-flash-xip.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>Serial Nor Flash</tag>
      <tag>XIP</tag>
    </tags>
    <content type="html"><![CDATA[在小型 嵌入式系统  中，曾经比较流行用 Parallel NOR Flash。而目前绝大多数外挂 Flash 采用 Serial NOR flash 而不是 Parallel NOR Flash，这样能节省 PIN 脚的数目，有利于减小 PCB 的面积。
我们知道，Parallel NOR Flash 具有 XIP 特性。
XIP：eXecute In Place，即就地执行，也称片内执行，指存放在存储设备中的代码，被 CPU 执行前无需提前搬运到 RAM 中。比方说，Mask ROM，当编译后的程序指令掩膜到 ROM 中后，CPU 就可以直接从 ROM 中取指执行，而无需将 ROM 中的程序提前拷贝到 RAM 中。
类似的，Parallel NOR Flash 的 XIP， 就是指存储在 Flash 闪存中的程序指令，可以被 CPU 直接取指后执行，而不用提前拷贝到 RAM 中。
这个特性对于小型嵌入式系统是非常重要的，因为小型嵌入式系统对成本敏感，一般只会内置少量的 SRAM。如果存储程序指令的设备没有 XIP 能力，那么就必须要求外挂更大的容量的 RAM，用来加载程序。这无疑会增加成本。况且不少主控芯片本身也出于成本控制并不支持外挂 RAM。
Parallel NOR Flash 之所以能 XIP，就是因为它的 IO 接口类似于 SRAM，能满足 CPU 取指的条件。如下图所示，它具有并行的地址线和数据线。
Serial NOR flash，它并没有并行的地址线和数据线，那么它能 XIP 吗？
由于 Serial NOR flash 并没有并行的地址线和数据线，只能通过 Serial 接口比如 SPI 来与主控通信， CPU   显然不能直接读取存放在其中的程序指令。如果要实现 CPU 从 Serial NOR flash 取指的功能，必须借助额外的硬件部件，完成 Flash 串行总线到 CPU 并行总线的转换。
幸运地是，目前很多嵌入式主控芯片都支持了这个功能，在芯片内部实现了针对串行 Flash 的控制器。不同的芯片厂商，可能叫法不一样，比如 FlexSPI、SFC 等。
CPU 的取指操作会反映到 AHB 总线上，中间经过 Serial Flash 的控制器，转换成Serial Flash 支持的通信协议，并且会有适当的缓存，以提升性能。
另外，XIP 相当于实时地读取 Flash 中的代码指令，所以对于 Flash 的传输带宽是有要求的。传统的 SPI 模式无法满足 XIP 的要求，需要 Serial Flash 支持高性能的 Dual/Quad SPI 模式，在此模式下，有 2/4 根 IO 线用作 DATA 传输。
]]></content>
  </entry>
  
  <entry>
    <title>NVIDIA特殊新卡首曝：命名5880</title>
    <url>/post/news/NVIDIA-may-launch-RTX-5880-ADA.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>NVIDIA</tag>
      <tag>GPU</tag>
      <tag>RTX5880 ADA</tag>
    </tags>
    <content type="html"><![CDATA[ NVIDIA   RTX企业版驱动中，最近出现了一款面向工作站的新卡“RTX 5880 ADA”。
如此命名非常奇怪，让人高度怀疑它是针对中国市场特供的。
根据美国政府的规定，除了计算加速卡，RTX 6000 ADA工作站显卡、RTX 4090游戏显卡也都被禁止在中国内地和港澳地区生产、销售。
为了绕过限制，NVIDIA为中国定制了各种特供型号，比如A800、H800、RTX 4090D。
RTX 5880 ADA无论出现的时机，还是命名的方式，都非常符合特供特色。
具体规格参数不详，但估计和RTX 4090D/4090的关系差不多，也是在RTX 6000 ADA的基础上精简。
比如CUDA核心数量少于18176个、张量核心少于568个、FP32浮点算力低于91.1TFlops，但显存容量有可能维持384-bit 48GB GDDR6。
其实对于这种中国特供版产品，美国政府也盯得很紧，甚至明确警告NVIDIA，它们也可能会被禁售。
虽然受到美政府的严格约束，甚至被直接点名，但是NVIDIA仍将坚持在中国市场上推出特供版本的RTX 4090D，具体时间很可能会在2024年1月底。
RTX 4090D仍将基于AD102 GPU  核心，但是编号从AD102-300变为AD102-250，对应着规格的降级。
300变250
具体的CUDA核心数量仍然不详，但肯定少于RTX 4090 16384个。
意外的是，核心基准频率将从2235MHz小幅提高到2280MHz，但加速频率维持在2520MHz，TGP整卡功耗从450W小幅下调到425W。
如果你打算通过超频恢复一部分实力，那恐怕要失望了，RTX 4090D会锁定频率，不开放任何超频设定，当然更不可能“开核”。
至于价格，暂无更新说法，之前传闻将维持12999元起。
据了解，NVIDIA将在本周内向各家AIC品牌发送AD102-250核心的样品进行测试，相信很快就会看到更多曝料。
]]></content>
  </entry>
  
  <entry>
    <title>几种高效的电路分析方法</title>
    <url>/post/hardware/several-efficient-circuit-analysis-methods.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>Circuit Analysis</tag>
    </tags>
    <content type="html"><![CDATA[对电路进行分析的方法很多，如叠加定理、支路分析法、网孔分析法、结点分析法、戴维南和诺顿定理等。根据具体电路及相关条件灵活运用这些方法，对基本电路的分析有重要的意义。现就具体电路采用不同方法进行如下比较。
支路电流法 支路电流法是以支路电流为待求量，利用基尔霍夫两定律列出电路的方程式，从而解出支路电流的一种方法。
一支路电流分析步骤
 假定各支路电流的参考方向，对选定的回路标出回路绕行方向。若有n个节点，根据基尔霍夫电流定律列（n一1）个独立的节点电流方程。 若有m条支路，根据基尔霍夫电压定律列（m-n+1）个的独立回路电压方程。为了计算方便，通常选网孔作为回路（网孔就是平面电路内不再存在其他支路的回路）。对于平面电路，独立的基尔霍夫电压方程数等于网孔数。 解方程组，求出支路电流。  【例1】如上图所示电路是汽车上的发电机（US1）、蓄电池（US2）和负载（R3）并联的原理图。已知US1=12V，US2=6V，R1=R2=1Ω，R3=5Ω，求各支路电流。
分析：支路数m＝3；节点数n＝2；网孔数＝2。各支路电流的参考方向如图，回路绕行方向顺时针。电路三条支路，需要求解三个电流未知数，因此需要三个方程式。
解：根据KCL，列节点电流方程（列（n-1）个独立方程）：
a节点：I1+I2=I3
根据KVL，列回路电压方程：
网孔1：I1R1-I2R2=Us1- Us2
网孔2：I2R2+I3R3=Us2
解得：I1=3.8A I2=-2.2A I3=1.6A
叠加定理 在线性电路中，所有独立电源共同作用产生的响应（电压或电流），等于各个电源单独作用所产生的响应的叠加。
在应用叠加定理时，应注意以下几点：
 在考虑某一电源单独作用时，要假设其它独立电源为零值。电压源用短路替代，电动势为零；电流源开路，电流为零。但是电源有内阻的则都应保留在原处。其它元件的联结方式不变。 在考虑某一电源单独作用时，其参考方向应选择与原电路中对应响应的参考方向相同，在叠加时用响应的代数值代入。或以原电路中电压和电流的参考方向为准，分电压和分电流的参考方向与其一致时取正号，不一致时取负号。 叠加定理只能用于计算线性电路的电压和电流，而不能计算功率等与电压或电流之间不是线性关系的参数。 受控源不属于独立电源，必须全部保留在各自的支路中。  【例2】在如下电路中，用叠加定理求电路中的电流I3。
解：根据叠加定理可把图a中的电路图看成图b和图c中电路的叠加
 us1单独作用  us2单独作用  有叠加定理可得  #3 网孔分析法
网孔电流为待求变量，按KVL建立方程求解电路的方法称为网孔分析法。其网孔电流方程也称为网孔方程。
在应用网孔分析法应注意以下几点：
  根据网孔自电阻、互电阻、等效电压源的含义和计算方法，可以直接列写网孔分析方程的最终形式，称为视察法。
  对含受控电压源的电路，先将受控源视为独立电源，依照视察法的规律列写网孔方程，然后将受控源的控制量用网孔电流表示出来。
  【例3】如图所示电路列写网孔方程。
解：假定网孔电流分别在网孔1、2、3中流动，网孔电流的参考方向如图所示。
解：以支路电流为变量，列写各网孔的KVL方程为
为得到以网孔电流为未知变量的电路方程，用网孔电流表示各支路电流，即有：
将上述各式代入KVL方程，可得网孔电流方程
即为该电路的网孔方程，显然，由此三个方程，可求解网孔电流。
结点分析法 在有n个结点的电路中，任选一个结点为参考结点，其余各结点至参考结点的电压称为该结点的结点电位。以结点电位为待求变量，将各支路电流用结点电位表示，列写除了参考结点以外其他所有结点的KCL方程，求得结点电位后再确定其他变量的电路分析方法，称为结点分析法。
结点分析方程的列写步骤：
 选取参考结点，假定其余n-1个独立结点的结点电位； 列写n-1个独立结点的KCL方程，方程中的各支路电流用结点电位表示； 求解方程，得到结点电位； 通过结点电位确定其他变量。  【例4】对如图所示电路列写结点方程。
解：设结点④为参考结点，并令独立结点①、②、③电压分别设为。分别列写结点①、②、③的KCL方程如下。
为得到以结点电位为未知变量的电路方程，用结点电位表示各支路电流，即有：
将上述各式代入KCL方程，得到结点方程整理整理得：
戴维宁定理与诺顿定理 戴维宁定理与诺顿定理常用来获得一个复杂网络的最简单等效电路，特别适用于计算某一条支路的电压或电流，或者分析某一个元件参数变动对该元件所在支路的电压或电流的影响等情况。
应用的一般步骤：
 把代求支路以外的电路作为有源一端口网络； 考虑戴维宁等效电路时，计算该有源一端口网络的开路电压 考虑诺顿等效电路时，计算该有源一端口网络的短路电流isc; 计算有源一端口网络的入端电阻 Req; 将戴维宁或诺顿等效电路代替原有源一端口网络，然后求解电路。  【例5】如图所示电路的电流I=2A，试确定电阻R的值。
解：先确定电阻R以外电路的戴维宁等效电路，如图（b）所示，再由电流I=2A确定阻2R。
选择直接计算图a的和。根据叠加定理，R断开时
（电流源单独作用U&rsquo;ab＋U'&lsquo;ab电压源单独用）将独立电源置零，不难得到等效电阻。
由图（b）得
因此：
各种方法比较 以上通过几个例子说明了电路分析方法的合理选择。有些问题，需要几种方法综合应用，这里不再举例。总之，解题方法选择得当，可以使解题过程简捷，提高解题效率。每种电路的分析方法，一般都有其适用范围。应用霍夫定律求解适用于求多支路的电流，但电路不能太复杂；电源法等效变换法适用于电源较多的电路；节点电位法适用于支路多、节点少的电路；网孔分析法使适用于支路多、节点多、但网孔少的电路；戴维南定理和迭加定理适用于求某一支路的电流或某段电路两端电压。上面例题的电路比较简单，可选择任意一种方法求解，对于一些比较复杂但有一定特点的电路，必须选择合适的方法，才能使解题过程简单，容易正确求解。
 叠加定理仅适用于线性电路，应用叠加定理分析含受控源电路时，通常不把受控源单独作用于电路，而把受控源作为电阻元件一样对待。当某一独立电源单独作用于电路时，受控源保留在电路中。叠加时应注意各响应分量的参考方向与原来的响应变量方向是否一致，方向一致则响应分量前应取“+”号，不一致则响应分量前应取“-”号。叠加定理不可滥用，通常用于电源单独作用时电路容易求解的情况，也常用于电路结构或者参数不详的情况。 对于支路电流法，方程数等于支路数，利用计算机易于求解，但如果未知量较少，如三个时，无论代入消元法或行列式法，计算量都太大。如果减少未知量，则方程数减少。包括网孔电流法、回路电流法、节点电压法多事减少未知量，减少方程而提出的。 结点分析法的实质结点分析法的实质是以结点电位为待求变量，列写n-1个独立的KCL方程，对结点数少的电路尤为适用。一旦选定了参考结点，则其余结点相对于参考结点的电压即为结点电位，未知量非常容易确认，因此在电路计算机辅助分析中多采用结点分析法。 戴维宁与诺顿定理常用以简化一个复杂网络，特别适用于计算某一条支路的电压或电流，或者分析某一个元件参数变动对所在支路的影响等情况。应用步骤：把待求支路以外的电路作为有源一端口网络，计算该网络的开路电压、短路电流、输入端电阻3个参数中的任意两个。 在线性电路中，所有独立电源共同作用产生的响应（电压或电流），等于各个电源单独作用所产生的响应的叠加。 ]]></content>
  </entry>
  
  <entry>
    <title>如何搞定嵌入式 C 语言中的全局变量问题</title>
    <url>/post/software/global-variables-in-embedded-C-language.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>Embedded</tag>
      <tag>C programming language</tag>
      <tag>Global Variables</tag>
    </tags>
    <content type="html"><![CDATA[今天分享一篇关于嵌入式C编程中全局变量问题的文章。希望对大家有所启发。
嵌入式特别是单片机os-less的程序，最易范的错误是全局变量满天飞。
这个现象在早期汇编转型过来的程序员以及初学者中常见，这帮家伙几乎把全局变量当作函数形参来用。
在.h文档里面定义许多杂乱的结构体，extern一堆令人头皮发麻的全局变量，然后再这个模块里边赋值123，那个模块里边判断123分支决定做什么。
每当看到这种程序，我总要戚眉变脸而后拍桌怒喝。
没错，就是怒喝。我不否认全局变量的重要性，但我认为要十分谨慎地使用它，滥用全局变量会引申带来其它更为严重的结构性系统问题。
诸位看官，且听我细细道来  它会造成不必要的常量频繁使用，特别当这个常量没有用宏定义“正名”时，代码阅读起来将万分吃力。 它会导致软件分层的不合理，全局变量相当于一条快捷通道，它容易使程序员模糊了“设备层”和“应用层”之间的边界。写出来的底层程序容易自作多情地关注起上层的应用。这在软件系统的构建初期的确效率很高，功能调试进度一日千里，但到了后期往往bug一堆，处处“补丁”，雷区遍布。说是度日如年举步维艰也不为过。 由于软件的分层不合理，到了后期维护，哪怕仅是增加修改删除小功能，往往要从上到下掘地三尺地修改，涉及大多数模块，而原有的代码注释却忘了更新修改，这个时候，交给后来维护者的系统会越来越像一个“泥潭”，注释的唯一作用只是使泥潭上方再加一些迷烟瘴气。 全局变量大量使用，少不了有些变量流连忘返于中断与主回圈程序之间。这个时候如果处理不当，系统的bug就是随机出现的，无规律的，这时候初步显示出病入膏肓的特征来了，没有大牛来力挽狂澜，注定慢性死亡。  无需多言，您已经成功得到一个畸形的系统，它处于一个神秘的稳定状态！你看着这台机器，机器也看着你，相对无言，心中发毛。你不确定它什么时候会崩溃，也不晓得下一次投诉什么时候道理。
现实层面的后果是什么  “老人”气昂昂，因为系统离不开他，所有“雷区”只有他了然于心。当出现紧急的bug时，只有他能够搞定。你不但不能辞退他，还要给他加薪。 新人见光死，但凡招聘来维护这个系统的，除了改出更多的bug外，基本上一个月内就走人，到了外面还宣扬这个公司的软件质量有够差够烂。 随着产品的后续升级，几个月没有接触这个系统的原创者会发现，很多雷区他本人也忘记了，于是每次的产品升级维护周期越来越长，因为修改一个功能会冒出很多bug，而按下一个bug，会弹出其他更多的bug。在这期间，又会产生更多的全局变量。终于有一天他告诉老板，不行啦不行啦，资源不够了，ram或者flash空间太小了，升级升级。 客户投诉不断，售后也快崩溃了，业务员也不敢推荐此产品了，市场份额越来越小，公司形象越来越糟糕。  要说对策，只有两个原则  能不用全局变量尽量不用，我想除了系统状态和控制参数、通信处理和一些需要效率的模块，其他的基本可以靠合理的软件分层和编程技巧来解决。 如果不可避免需要用到，那能藏多深就藏多深。   如果只有某.c文件用，就static到该文件中，顺便把结构体定义也收进来； 如果只有一个函数用，那就static到函数里面去； 如果非要开放出去让人读取，那就用函数return出去，这样就是只读属性了； 如果非要遭人蹂躏赋值，好吧，我开放函数接口让你传参赋值；5)实在非要extern强奸我，我还可以严格控制包含我.h档的对象，而不是放到公共的includes.h中被人围观，丢人现眼。  如此，你可明白我对全局变量的感悟有多深刻。悲催的我，已经把当年那些“老人”交给我维护的那些案子加班全部重新翻写了。你能明白吗，不要让人背后唾弃你哦。
最后补充一下意见  全局变量是不可避免要用到的，每一个设备底层几乎都需要它来记录当前状态，控制时序，起承转合。但是尽量不要用来传递参数，这个很忌讳的。 尽量把变量的作用范围控制在使用它的模块里面，如果其他模块要访问，就开个读或写函数接口出来，严格控制访问范围。这一点，C++的private属性就是这么干的。这对将来程序的调试也很有好处。C语言之所以有++版本，很大原因就是为了控制它的灵活性，要说面向对象的思想，C语言早已有之，亦可实现。 当一个模块里面的全局变量超过3个(含)时，就用结构体包起来吧。要归0便一起归0，省得丢三落四的。 在函数里面开个静态的全局变量，全局数组，是不占用栈空间的。只是有些编译器对于大块的全局数组，会放到和一般变量不同的地址区。若是在keil C51，因为是静态编译，栈爆掉了会报警，所以大可以尽情驰骋，注意交通规则就是了。 单片机的os-less系统中，只有栈没有堆的用法，那些默认对堆分配空间的“startup.s”，可以大胆的把堆空间干掉。 程序模型？如何分析抽象出来呢，从哪个角度进行模型构建呢？很愿意聆听网友的意见。本人一直以来都是从两个角度分析系统，事件&ndash;状态机迁移图 和 数据流图，前者分析控制流向，完善UI，后者可知晓系统数据的缘起缘灭。这些理论，院校的《软件工程》教材都有，大家不妨借鉴下。只不过那些理论，终究是起源于大型系统软件管理的，牛刀杀鸡，还是要裁剪一下的。 ]]></content>
  </entry>
  
  <entry>
    <title>英伟达黄仁勋：领先中国芯片公司10年</title>
    <url>/post/news/NVIDIA-Jensen-Huang-Leading-Chinese-chip-companies-for-10-years.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>NVIDIA</tag>
      <tag>GPU</tag>
      <tag>AI</tag>
      <tag>Jensen Huang</tag>
      <tag>OpenAI</tag>
    </tags>
    <content type="html"><![CDATA[ 英伟达  公司首席执行官黄仁勋（Jensen Huang）经营着半导体行业最有价值的公司，他表示，美国距离打破对海外芯片制造的依赖还有长达 20 年的时间。
黄在纽约举行的《纽约时报》DealBook 会议上发表上述讲话，他同时还解释了他的公司的产品如何依赖来自世界各地的无数组件，而不仅仅是台湾，因为最重要的组件是在台湾制造的。
“我们距离供应链独立还有十年到二十年的时间，”他说。“对于一两年来说，这并不是一件真正实用的事情。”
黄在纽约时报 DealBook 会议上露面时表示：“我们绝对应该走下去。”他指的是拜登政府试图将中国与美国芯片供应脱钩。“但供应链的完全独立在一两年内还不是真正可行的事情。
前景表明，拜登政府的一个关键目标——将更多的芯片制造行业带到美国——还有很长的路要走。总统支持两党立法，支持在这里建设制造设施。许多最大的公司正计划扩大其在美国的业务。其中包括英伟达的顶级制造合作伙伴台积电以及三星电子和英特尔公司。
欧洲也在推动在本地建立更多的制造业。这是逆转几十年来全球化的努力的一部分，全球化已将生产分散到世界各地，但也导致了台湾和韩国等地区的瓶颈。
另外，黄仁勋重申了公司对中国的承诺——中国仍然是最大的芯片市场。
在被问及英伟达是否应该继续与中国开展业务时，黄仁勋表示：“我们是一家为商业而生的公司，因此我们尽力与所有人开展业务。另一方面，我们的国家安全和国家竞争力至关重要。”很重要。”
英伟达在11月21日的第三季度财报中警告称，预计第四季度将受到美国出口管制的负面影响
英伟达受到越来越严格的出口管制，限制了其向中国出口用于 人工智能  的最高性能 GPU 的能力。黄表示：“我们开发的最关键的技术，其领先优势并未提供给中国。”
但黄仁勋还指出，中国可以找到一种方法来获得该技术或“激励”国内芯片制造商。黄在特别提到受到制裁的中国制造商华为时表示，英伟达仍然领先这些公司十年。（原文：But Huang also noted that China can find a way to obtain that technology or “inspire” domestic chipmakers. Nvidia is still a decade ahead of those companies, Huang said in specific reference to sanctioned Chinese manufacturer Huawei.）
拜登政府优先考虑限制中国获取金融和智力资源。除了先进芯片的出口之外，美国政府还对美国风险投资公司在中国投资的行业实施了限制。
黄仁勋还对人工智能发展的快速发展发表了看法。Nvidia 通过其日益强大的 GPU 在该行业的发展中发挥了关键作用。黄说，五年内将实现与人类智力相当的人工智能。
在美国政府实施出口限制后，该公司失去了向该国出售其最强大的人工智能处理器的能力，并于上个月进一步收紧了出口限制。华盛顿认为，需要采取此类措施来保护国家安全。
黄说，在最新规定公布后，英伟达正在为中国开发不会引发限制的产品。
“我们必须拿出符合规定的新芯片，一旦符合规定，我们就会回到中国，”他说。
他还警告此类规则可能会带来意想不到的后果。他说，中国目前有多达 50 家公司正在开发可与 Nvidia 的产品竞争的技术。
并不担心人工智能行业竞争加剧 自从 OpenAI 以其广受欢迎的 ChatGPT 聊天机器人引发人工智能热潮以来，初创企业和科技巨头一直在竞相开发半导体来为这项热门技术提供动力，希望能够巩固 Nvidia 的市场主导地位。
但英伟达首席执行官黄仁勋周三表示，他并不担心竞争加剧。他说，他的公司已经领先了十年，于 2012 年开始生产第一台超级计算机。五年后交付的这台机器改变了计算机的工作方式，使它们能够生成句子、图像和视频。
“我们意识到深度学习和人工智能不是芯片问题。这是一个计算问题的重新发明，”黄先生在纽约 DealBook 峰会上发表讲话时说道。“你无法仅通过设计芯片来解决这种新的计算方式。计算机的各个方面都发生了根本性的变化。”
黄先生表示，竞争对手需要很长时间才能赶上。该公司目前超级计算机的售价为 25 万美元。他说，它们有 35,000 个零件，并与电动汽车等机器人组装在一起。
今年，对 Nvidia 机器的需求推动该公司股价上涨了近 240%，使 Nvidia 成为全球市值最高的上市半导体制造商。黄先生创立了这家公司，并把赌注押在了人工智能上，他的个人资产约为 400 亿美元。
黄先生表示，人工智能公司还需要十年时间才能实现所谓的通用人工智能（AGI），即机器可以像人脑一样分解任务的状态。在那之前，他预测企业将开发定制人工智能功能来实现特定目标，例如药物研究或设计半导体。他表示，英伟达的核心业务已经依赖人工智能。
“如果没有人工智能，我们今天的芯片就不可能实现，”他说。
黄的管理风格相当不寻常。与许多拥有十几名直接下属的首席执行官不同，他有 50 名下属向他汇报。他说，这种结构是更可取的，因为它的层数更少，可以更有效地传递信息。
“向首席执行官汇报的人应该需要最少的纵容，”他说。“他们应该处于比赛的顶端，并且技艺精湛。他们应该需要很少的管理。”
高管不需要职业指导 黄仁勋 (Jensen Huang) 在接受 CNBC 安德鲁·罗斯·索金 (Andrew Ross Sorkin) 采访时，一睹其不同寻常的管理风格，包括拥有“50 名直接下属”。
黄仁勋于 1993 年与人共同创立了 Nvidia，随着这家芯片制造商的股价今年因其在人工智能热潮中的核心作用而飙升，他的领导风格正在像苹果公司的史蒂夫·乔布斯或Meta 公司等其他技术创始人兼运营商的传统一样被研究和效仿。
黄说，他有这么多直接下属——大多数高管只有 10 名左右——因为这可以防止 Nvidia 建立不必要的管理层。
“CEO 的直接汇报越多，公司的层级就越少。它使我们能够保持信息流畅。”黄说，并补充说，它使 Nvidia 表现更好。
黄说，高级管理人员应该能够独立运作，并且需要“很少的管理”。
“向首席执行官汇报的人应该需要最少的溺爱，所以我认为他们不需要生活建议。我认为他们不需要职业指导，”黄说。“他们应该处于比赛的顶端，并且非常擅长他们的技艺。”
根据《纽约客》最近的一份简介，黄没有采用严格的管理层次结构，而是喜欢通过每周接收简短的电子邮件来直接从普通员工那里获取信息，其中列出了任何特定员工正在处理的五件最重要的事情。
据资料显示，黄还喜欢每天给他的员工写数百封简短的电子邮件，其中许多只有几个字长。
今年迄今为止，Nvidia 的股价已上涨超过 228%，原因是对该公司高端图形处理器 (GPU) 的需求旺盛，这些处理器用于训练和操作 OpenAI 的 ChatGPT 等人工智能模型。
Nvidia 今年在 AI GPU 领域的成功是过去几十年来多次押注的结果，这些赌注旨在开发软件和工具，将以前为 3D 游戏设计的芯片转变为 AI 引擎，这使其领先于AMD等其他芯片制造商。
该公司仍然预计人工智能芯片的销售额将大幅增长，但面临中国的出口限制，这可能会阻碍这个主要增长市场。
每天早上醒来都担心公司可能会失败 在 2023 年《纽约时报》DealBook 峰会上，该报的安德鲁·索尔金 (Andrew Sorkin) 请黄详细解释为什么他一直说他会尽一切努力让公司不倒闭。
“那是什么事？” 索尔金在接受采访时向黄问道。
对此，黄仁勋表示，鉴于英伟达过去经历过的挑战，他无法摆脱公司可能无法继续生存的感觉。该公司在 20 世纪 90 年代中期几乎破产。
黄说：“我认为，当你从头开始建立一家公司，经历过真正的逆境，并且确实经历过几次差点倒闭的经历时，这种感觉就会一直伴随着你。”
黄承认，他每天早上醒来时都会担心自己的芯片帝国陷入困境。
“我醒来时并不感到自豪和自信。我醒来时感到担忧和担忧，”黄说，观众礼貌地笑了。“这取决于你从床的哪一侧起床。”
索尔金所描述的黄的“偏执”部分可能来自英伟达面临来自台湾台积电等其他半导体公司的竞争。
“我不认为人们试图让我破产——我可能知道他们正在这样做，所以这是不同的，”黄说。“我生活在这样的环境中，我们一半绝望，一半渴望。”
然而，黄仁勋对失败的焦虑似乎促使他保持英伟达的生存下去。
“我认为在逆境中你会更加专注，”黄说。“当你更加专注时，你就能表现得更好。
“我喜欢生活在那种我们即将灭亡的状态，所以我喜欢这种状态，”他继续说道。“在这种情况下我会尽力而为。”
这次峰会并不是黄第一次坦诚地讨论困难是如何激励他经营自己的企业的。
“我的心率实际上下降了，”首席执行官最近说道告诉《纽约客》在谈论他如何在逆境中表现出色时。“任何在餐馆里经历过高峰时段的人都知道我在说什么。”
事实上，黄在 10 月份的一次讲话中表示播客剧集创办英伟达“比我预想的要困难一百万倍”，如果重来一次，他就不会再这样做了。
首席执行官的雄心壮志可能会给他的生活带来一些快乐。
“我喜欢回家告诉我的妻子我今天拯救了公司，”黄在 DealBook 峰会上说道。“也许这不是真的，但我想是这样。”
]]></content>
  </entry>
  
  <entry>
    <title>数据中心变革：构建可持续AI基础设施</title>
    <url>/post/server/data-center-transformation-building-a-sustainable-ai-infrastructure.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Data Center</tag>
      <tag>AI</tag>
    </tags>
    <content type="html"><![CDATA[ AI  时代的到来在各行各业引发了持续的热情，像ChatGPT这样的新工具承诺为企业带来竞争优势。然而，随着企业感受到将AI融入运营的推动力，它们的支撑基础设施可能未能为成功奠定基础。
许多企业缺乏应对高性能数据需求和能耗要求的必要基础设施，这是最大程度发挥AI优势所不可或缺的。实际上，传统系统通常无法满足实现机器学习模型所需的庞大AI数据管道。尽管AI带来了巨大的潜力，但其对能耗需求的影响可能出乎意料。
这些AI的潜在成本对于成功实施公司的关键计划构成了挑战，尤其是那些旨在实现环境目标的倡议。随着AI继续迅速普及，IT团队需要制定富有前瞻的数据战略，以确保他们能够通过适当的基础设施高效且有效地运营AI。
研究发现 对于IT负责人而言，挑战不仅在于构建持久的AI架构，还在于以符合其ESG（环境、社会、治理）优先目标的方式拥抱AI。为了帮助准确定位AI导入过程中与企业可持续发展目标相平行的障碍，我们在美国、英国、法国和德国等四个主要全球市场对500名以上员工的公司进行了调查。调查发现，对于88%已经实施AI的公司，对计算能力的需求急剧增长。实际上，近一半（47%）的公司自实施AI以来不得不将其计算能力提高一倍或更多。此外，近四分之三（73%）的IT负责人反馈，在其公司实施AI的过程中，并未充分准备好应对能耗需求的挑战。
未为AI对基础设施的影响做好准备，将使持续运营面临风险。
在没有适当的IT基础设施的情况下部署AI的主要后果，包括对IT部门增加解决数据团队问题的压力（51%）、需要更多投资来升级基础设施（49%）以及无法有效使用AI（48%）。
能耗需求仅仅是推动AI部署引发基础设施升级的一种手段。
值得注意的是，在这方面，数据管理工具（48%）、数据管理流程（46%）以及数据存储基础设施（46%）都发挥着关键作用。其它所需的IT基础设施升级包括网络基础设施（44%）、安全与隐私工具/流程（44%）以及计算基础设施（43%）。
这些挑战也对企业的可持续发展目标构成了阻碍。
几乎所有的IT负责人（超过99%）表示，他们面临着对致力于通过其产品和解决方案实现可持续性的供应商的压力。这种压力也反映在员工（51%）、客户（49%）、领导层（49%）和投资者（49%）的观感中。
IT负责人发现，无论如何，都无法回避与AI相关的电力、能耗和空间需求。事实上，88%的人认为，要实现ESG目标，必须在充分准备IT基础设施以支持AI计划的前提下才有可能。因此，几乎所有受访者（96%）已经或计划更新他们的IT基础设施，其中有29%表示已经或将需要进行彻底的全面改造。然而，实施AI意味着与企业领导层合作，克服他们对基础设施忽视的误解，也就是弄清楚他们为何忽视基础设施的确切原因。IT负责人认为，领导层在投资AI时忽视IT基础设施的首要原因是期望AI工作在云中完成（51%）。其它原因包括对AI影响的狭隘看法（50%）以及急于采纳AI（48%）。此外，超过四分之一的人（41%）表示这是因为领导层不完全了解他们当前的IT基础设施。
理想情况下，企业在部署AI之前应该提前准备好基础设施升级。
根据调查，89%的受访者在部署AI后升级IT基础设施时面临了实现ESG目标的困难。为了应对这一挑战，已经部署了AI技术或计划在未来12个月内部署的60%的人表示，他们投资了或将投资更节能高效的硬件，以实现ESG目标。
可持续AI部署的基础设施要点 在企业的流程和运营中实施AI可以极大地增强竞争优势，使组织能够实现更大的灵活性、提高客户满意度、改善运营卓越性，并加速创新。然而，随着ESG导入达到临界点，组织面临的挑战是在平衡环境影响与以业务为驱动的目标之间，以利用指数级数据增长的价值。因此，成功部署AI和其它数据密集型技术将越来越受到组织对规模和效率的基础设施能力所赋予的深思熟虑的定义。
当前，数据中心中超过80%的数据仍然被困在机械硬盘上。转向闪存优化系统是组织可以采取的初步步骤，可以减少5倍至10倍的功耗。除了帮助减少排放，闪存存储系统还能够处理AI工作负载的不断变化的数据需求，并设计用于适应不断增长的数据量而不影响性能。
]]></content>
  </entry>
  
  <entry>
    <title>博通裁撤VMware部分员工,逾1000名在华员工等待去留</title>
    <url>/post/news/broadcom-lays-off-some-VMware-employees.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Broadcom</tag>
      <tag>VMware</tag>
    </tags>
    <content type="html"><![CDATA[集微网消息，博通于11月22日宣布完成对VMware的690亿美元收购，据媒体最新报道，部分VMware员工11月27日得知，他们的职位将被取消。
博通于2022年5月首次宣布，将以610亿美元收购VMware，并承担其80亿美元的净债务。该公司宣布，在获得中国监管部门的批准后不久，于11月22日完成了这笔交易。
据悉，VMware被裁掉的员工11月27日收到了一封电子邮件，其中指出：“博通最近完成了对VMware的收购。作为集成计划的一部分，并遵循组织需求评估，我们确定了合并后公司所需的前进角色。我们很遗憾地通知你，你的职位将被取消，你的雇佣关系也将终止。我们要感谢您的奉献精神和服务。我们希望使这一过渡尽可能顺利，包括为您提供慷慨的遣散费，并为您提供一段不用工作的带薪通知期。”
目前尚不清楚VMware有多少员工会受到裁员的影响。截至今年2月，VMware拥有超过3.8万名员工。有消息称VMware在被博通收购完成前就已裁员，今年9月，VMware给员工发了一封信，称博通将为他们提供一份工作或一个过渡性职位，或者获得一笔遣散费。
另外近日有消息称VMware驻北京分公司已经在进行商标更换、人员调整。VMware CEO Raghu Raghuram在一封11月22日的信中表示，确保交易获得批准的“漫长旅程”充满不确定性和压力，尤其是在确认收购前的最后几周。如今收购已经获批，博通计划从11月27日起与员工沟通。
目前博通公司已在多个地区翻新办公室，位于北京中关村的VMware办公室已经换上博通公司的标识，不过1000多名在华员工仍在等待关于去留的更多消息，一部分人将面临工作变动。
博通公司11月27日没有立即回应置评请求。根据往年财报，博通公司2021和2022财年约有35%的收入来自中国。
VMware中国公司的一名员工透露，该公司的私有云业务正面临来自本土企业的激烈竞争，这些企业都在寻求使用国内产品替代国外产品，
2023年3月，VMware曾警告投资者，中美两国不同的法律规定可能导致法律冲突。该公司表示，中国有关数据存储和处理的法律法规可能会使其业务受到影响。
据一位匿名VMware员工称，博通将为现有员工提供两种选项：一份新合同或者给予离职补偿金。
]]></content>
  </entry>
  
  <entry>
    <title>git 解决push报错：[rejected] master -> master (fetch first) error: failed to push some refs to</title>
    <url>/post/github/git-push-error-failed-to-push-some-refs-to.html</url>
    <categories><category>Git</category>
    </categories>
    <tags>
      <tag>github</tag>
      <tag>error</tag>
    </tags>
    <content type="html"><![CDATA[今天对代码进行了修改优化，然后往往远程push，但push后报错了
git操作 git add . git commit -m&#34;fix&#34; git push origin master:dev-gaochao 报错信息 To https://amc-msra.visualstudio.com/trading-algo/_git/real-trading ! [rejected] master -&gt; dev-gaochao (fetch first) error: failed to push some refs to &#39;https://amc-msra.visualstudio.com/trading-algo/_git/real-trading&#39; hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., &#39;git pull ...&#39;) before pushing again. hint: See the &#39;Note about fast-forwards&#39; in &#39;git push --help&#39; for details. 原因 之所以出现这个原因，是因为我在线上生成、编辑了README.md文件，而本地代码文件中不包含它，所以线上线下就对不上了。
解决 将线上、线下代码进行合并
git pull --rebase origin dev-gaochao 然后再进行push
git push origin master:dev-gaochao 成功：
Enumerating objects: 11, done. Counting objects: 100% (11/11), done. Delta compression using up to 4 threads Compressing objects: 100% (7/7), done. Writing objects: 100% (7/7), 1.90 KiB | 487.00 KiB/s, done. Total 7 (delta 4), reused 0 (delta 0) remote: Analyzing objects... (7/7) (13 ms) remote: Checking for credentials and other secrets... (1/1) done (1008 ms) remote: Storing packfile... done (157 ms) remote: Storing index... done (87 ms) To https://amc-msra.visualstudio.com/trading-algo/_git/real-trading 1919525..6f3asa4dd6 master -&gt; dev-gaochao ]]></content>
  </entry>
  
  <entry>
    <title>Git：软件开发的黄金标配</title>
    <url>/post/software/git-for-software-development.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>Git</tag>
      <tag>Software development</tag>
    </tags>
    <content type="html"><![CDATA[ Git  ，它为软件开发提供了无与伦比的版本管理体验。
前言 在上一篇文章中，我们讨论了为何使用版本管理工具是一个比手动拷贝更好的选择。
今天，我们将了解其中的佼佼者——Git，它为软件开发提供了无与伦比的版本管理体验。
为何选择Git？  分布式特性  Git是一种分布式版本控制系统，每个开发者都有一个完整的本地仓库。这使得即使在没有网络连接的情况下，开发者也能够独立工作，不受限制。   强大的分支管理  Git的分支管理是其最大的亮点之一。开发者可以轻松创建、合并、删除分支，使得并行开发变得十分简单。   版本回滚和恢复  Git允许你轻松地回滚到之前的任何一个提交，甚至可以创建一个新的分支来实验性地进行修改，而不影响主分支。   高效的合并机制  Git的合并机制非常智能，能够自动解决大部分合并冲突，减轻了开发者的工作负担。   轻量级和高速  Git的设计注重性能，使得大型项目也能够在相对较短的时间内进行版本控制操作。  基本概念 在介绍Git之前，让我们回顾一下版本管理的基本概念。Git是一种分布式版本控制系统，它通过记录文件的变更历史，帮助团队协同工作，追踪项目的演变。以下是Git的基本概念：
 仓库（Repository）：存放项目所有文件及变更历史的地方。 提交（Commit）：保存项目在某一时刻的状态，每次提交都有一个唯一的标识。 分支（Branch）：是项目的一个独立线路，可以用于独立开发某个功能，然后合并回主线。 远程仓库（Remote）：位于网络服务器上的Git仓库，用于团队协作。 推送（Push）和拉取（Pull）：将本地的提交推送到远程仓库，或者将远程仓库的变更拉取到本地。   工作区域 在 Git 中的文件有三种状态：
 已提交：表示数据已经安全的保存在本地数据库中； 已修改：表示修改了文件，但还没保存到数据库中； 已暂存：表示对一个已修改文件的当前版本做了标记，使之包含在下次提交的快照中。  因此也引入了Git项目的三个工作区域的概念：
 工作区：就是项目文件所在的目录，目前可以看到的文件信息 暂存区：stage 或 index。一般存放在 .git/index 文件中，所以我们把暂存区有时也叫作索引 版本库：工作区下隐藏目录 .git，这里记录着仓库的版本信息和历史记录  基本使用 大致的使用流程：
 克隆仓库：使用git clone命令可以将远程仓库复制到本地，形成一个完整的本地仓库。 创建分支：使用git branch命令可以创建一个新的分支，开发者可以在不影响主干的情况下进行工作。 提交变更：使用git add和git commit命令可以将修改保存到本地仓库。 推送与拉取：使用git push命令可以将本地的修改推送到远程仓库，而使用git pull命令可以将远程仓库的变化拉取到本地。 合并分支：使用git merge命令可以将一个分支的变化合并到另一个分支，保持代码的一致性。  看提交效果，可以清楚地知道每次提交都改动了什么东西
实际应用  团队协作：Git使得多人协作变得更加流畅，每个成员都能够独立工作并将工作整合到项目中。 版本发布：通过创建标签（tag），可以轻松管理项目的版本发布，确保发布的版本是经过测试和稳定的。 持续集成（CI）：Git与持续集成工具结合使用，可以自动触发构建和测试，加速开发周期。 开源社区：Git是许多开源项目的首选版本管理工具，如GitHub、GitLab和Gitee等平台提供了强大的协作和贡献机制。  总结 在现代软件开发中，Git已经成为了不可或缺的利器。它不仅提供了高效的版本管理，还为团队协作和项目维护提供了强大的支持。如果你还没有尝试过使用Git，现在是时候踏上这个版本管理的征程，让你的软件开发变得更加流畅、高效！告别手动拷贝，迎接Git的便捷和强大！
]]></content>
  </entry>
  
  <entry>
    <title>为什么有时候会选择使用三层交换机而不是路由器</title>
    <url>/post/server/why-do-you-sometimes-choose-to-user-layer-3-switch-instead-of-router.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Layer 3 Switch</tag>
      <tag>Router</tag>
    </tags>
    <content type="html"><![CDATA[在 网络  设计中，选择使用三层交换机而不是路由器通常涉及到一系列因素，包括性能、成本、灵活性和管理需求。
以下是一些常见的原因：
性能 三层交换机通常在硬件上实现路由功能，能够提供更快的数据包转发速度。由于三层交换机专注于数据链路层和网络层的功能，其硬件设计通常更加专一，能够在高负载下提供更高的性能。
低延迟 由于三层交换机在 硬件  层面上实现路由，数据包在交换机内部的转发过程更加迅速，从而能够降低网络的延迟。这对于要求低延迟的应用，如实时音视频传输和在线游戏，非常重要。
灵活性 三层交换机通常支持更灵活的网络设计，包括VLAN（虚拟局域网）的配置、负载均衡、流量控制等功能。这使得网络管理员能够更好地适应不同的业务需求。
成本 通常情况下，三层交换机的价格相对较低，尤其是对于一些小型到中型规模的网络。相比之下，路由器通常需要更高的成本。
管理 三层交换机的管理通常更简单，因为它主要专注于局域网内的路由功能。对于一些相对简单的网络拓扑，使用三层交换机可能更为方便。
局域网内路由需求 如果主要的路由需求仅限于同一个局域网内的设备通信，而不需要连接到不同的物理网络或广域网，那么使用三层交换机通常足够满足需求。
尽管有这些优点，需要注意的是，路由器在连接不同网络和进行广域网通信方面仍然是不可替代的。因此，在设计网络时，需要根据具体的需求和网络拓扑来选择使用三层交换机还是路由器，有时也可能两者结合使用以实现更全面的网络架构。
]]></content>
  </entry>
  
  <entry>
    <title>如何将BootLoader与APP合并成一个固件</title>
    <url>/post/software/how-to-combine-bootloader-and-app-to-a-firmware.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>Embedded</tag>
      <tag>Bootloader</tag>
      <tag>Firmware</tag>
    </tags>
    <content type="html"><![CDATA[嵌入式固件一般分为 BootLoader  和App，BootLoader用于启动校验、App升级、App版本回滚等功能，BootLoader在cpu上电第一阶段中运行，之后跳转至App地址执行应用程序。
前言 因此，在发布固件的时候，会存在BootLoader固件和App固件；此时我们期望是将BootLoader固件和App固件合并成为一个固件，这样在量产时只需烧录一次即可。
传统方式 一些传统的方法都是“土办法”，没什么毛病，但比较繁琐。
项目种类增加，或者版本发布频繁时更加体现出繁琐性，且易出错，操作稍微失误可能导致固件不完整；烧录不完整的固件，机子变“砖头”。
 烧录两次，分别烧录BootLoader和App固件 烧录固件到芯片后，再从芯片读取固件，另存为hex文件 手动复制、合并固件 BootLoader支持App固件传输功能的，只烧录BootLoader，后期再升级App  高效方式 我们目标是通过自动化脚本合并生成一个发布固件，提高效率和确保固件的完整性。
合并文件 Linux下的脚本我们用得很多，其实Windows的脚本也非常优秀，利用Windows的脚本可以快速实现增、删、查、改文件。常用Windows脚本命令如下。
 合并两个文件：copy /b 重命名文件：ren &lt;source_file&gt; &lt;dect_file&gt; 删除文件：del  很显然，我们利用其合并命令，只需一条指令即可将BootLoader和App文件合并。
例子：
假设当前目录存在Boot.bin和App.bin文件，合并后文件命名为Firmware.bin。
copy /b .\Boot.bin + .\App.bin Firmware.bin 注：Windows的目录路径为反斜杠，与Linux不同。
bin转hex 我们知道，二进制（bin）文件是不存在地址信息的，cpu上电执行并不一定是从地址0开始执行代码，如STM32芯片起始执行地址为0x8000000。
因此不能通过串口工具烧录bin文件，只能通过J-link或者ST-link烧录，并且在烧录前指定存储起始地址。因此，将bin文件转换为hex文件是有必要的。
bin转hex方式：  使用jflash工具，把合并后的bin文件，使用jflash打开，另存为hex格式文件 将bin文件烧录置芯片，读取出来，另存为hex文件 自己动手写一个bin转hex工具 借助第三方bin转hex工具  前两者太繁琐，效率低下；第三个比较灵活，但需要花点时间；如果使用优秀的现成工具是最快捷的办法。推荐使用“srec_cat.exe”工具，可以结合Windows脚本一起使用。
srec_cat工具 srec_cat一个功能非常强大的文件合并、转换工具，支持功能众多，包括：
 文件合并 文件分割 bin转hex hex转bin 数据填充 CRC校验  此外，还存在srec的系列工具，文件比较工具 srec_cmp.exe和文件信息查看工具 srec_info.exe，可以从文章后面官方网站下载使用。
文件合并 命令格式：
srec_cat.exe &lt;源文件0&gt; &lt;文件类型&gt; &lt;源文件1&gt; &lt;文件类型&gt; &lt;目标文件&gt; &lt;文件类型&gt; 例子：
srec_cat.exe source0.bin -Binary source1.bin -Binary -o merge.bin -Binary srec_cat.exe source0.hex -Intel source1.hex -Intel -o merge.hex -Intel 如果BootLoader和App生产的文件为hex格式，可以直接使用该命令合并为一个hex文件，注意地址的连续性。
bin转hex 命令格式：
srec_cat.exe &lt;bin源文件&gt; &lt;-Binary&gt; &lt;-offset&gt; &lt;偏移地址&gt; &lt;-Output&gt; &lt;hex目标文件&gt; &lt;-Intel&gt; 例子：
将Boot.bin和App.bin合并的Firmware.bin转换为hex格式文件。
srec_cat.exe Firmware.bin -Binary -offset 0x8000000 -o Firmware.hex -Intel 0x8000000，是STM32的起始执行地址
更多的srec应用和工具下载详见官方网站：http://srecord.sourceforge.net/download.html
完整示例 第一步，在需要生成固件目录新建一个txt文件
第二步，键入如下内容(Boot固件和App固件可以指定目录)
copy /b .\Boot.bin + .\App.bin Firmware.bin srec_cat.exe Firmware.bin -Binary -offset 0x8000000 -o Firmware.hex -Intel del Firmware.bin 第三步，重命名txt文件为&quot;.bat&quot;后缀文件，即是Windows可执行脚本的文件类型 第四步，双击运行脚本，即可生成目标文件 出现任何目标文件生成失败的情况，检查相关源文件是否存在，路径是否正确。
举一反三 以此类比，存在多个App文件的情况，可以通过该方式分别进行合并出一个固件。
另外，实际项目中，经常会使用内部flash空闲扇区保存一些设备参数信息，如校准系数、设备地址、序列号等信息，我们可以将参数信息保存为一个bin文件，通过该方式和固件合并，这样量产时将参数和固件一并写入，提高生产效率！
]]></content>
  </entry>
  
  <entry>
    <title>嵌入式设备OTA升级的大致过程</title>
    <url>/post/software/OTA-update-process-for-embedded-device.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>Embedded</tag>
      <tag>OTA</tag>
    </tags>
    <content type="html"><![CDATA[大家都把我的这个旅游过程叫做 OTA  ，也就是在线升级。
OTA概述 大家好，我是一个软件升级包。这几天呢，我将会进行一次神奇的网络之旅，从开发者的电脑中，一直跑到终端嵌入式设备中。
大家都把我的这个旅游过程叫做 OTA，也就是在线升级。
那么啥叫 OTA 呢？全称是：Over the Air Technology，其实就是通过网络来把一个新的软件包从服务器上下载下来，更新到设备上。
首先有一个问题：为什么叫软件升级包，而不叫固件升级包呢？
其实在本质上，固件也是属于软件，大家都是用代码写出来的嘛！
虽然这两个说法很近似，但是有一部分小伙伴还是在狭义上对它们进行了一些区分。
既然如此，我们也就暂且把它俩进行一下区别：
 固件：是指一些没有文件系统的嵌入式设备中，把 Flash 分成不同的功能分区。可执行程序需要放在某个固定的起始位置，才能被 bootloader 进行启动。 软件：是指具有文件系统的嵌入式设备，可执行程序直接放在文件系统中。当设备启动之后，操作系统会启动文件系统中的可执行程序。   没有文件系统的嵌入式设备：
带有文件系统的设备:
我知道以上这样的区分方式不是很严谨，但是谁又说得清楚严谨的定义是什么呢？
暂且先这么来区分，只要不影响对文章的理解就可以了！
一个嵌入式设备在进行软件升级的时候，从宏观的角度看，可以分为2 个阶段：
 下载升级包; 解压升级包，写入 flash 或文件系统;   今天呢，主要以第 1 阶段为主，带你看一下我是如何从开发者的电脑里，一步一步的被嵌入式设备下载到本地的。
下面是一个完整的过程，让您先睹为快！
上传升级包 为了便于描述，我们来假设一个场景：运行在设备中的软件一共有 3 个文件：
 main 文件：可执行程序; config.ini：配置文件; mylib.so：一个动态库文件，里面包含一个算法，被 main 文件调用;   目前呢，设备中运行的版本是 V1.0，现在开发人员对 mylib.so 库中的算法进行了优化，升级为 V2.0 版本，现在需要把这个新版本升级到嵌入式设备中。
首先第一步需要做的事情，咱们用脚后跟都能想得到，那就是把 V2.0 版本的程序软件上传到文件服务器中。
有一点提醒一下：很多云平台都会把应用服务器和文件服务器进行区分。当然，如果仅仅是测试的话，它俩可以在同一台物理服务器上共存。
比如：亚马逊的 AWS 平台，就是把升级包上传到 S3 服务器中。
现在要对 V2.0 版本的程序进行打包了，在这里，除了 main、config.ini、mylib.so 这 3 个文件之外，我们还把另一个脚本文件 upgrade.sh 也放进打包文件中。
这个文件的作用暂且不说，到后面会为您揭晓答案。
Bingo - V2.0 版本的升级包诞生了：app_v2_0.tgz，上传到文件服务器上之后，地址为：http://fileserve/app_v2_0.tgz。
上传升级包描述文件 现在，V2.0 版本的升级包已经上传到文件服务器中了，是否现在就可以命令嵌入设备去下载、升级了呢？
我们知道，在一个物联网系统中，一般都是存在着很多个终端设备的。
这些设备可能处于正在运行状态、也可能处于断电状态，而且咱们也不能假设所有的设备都在同一个时间点进行升级。
再而且，一个设备进行升级之后，就变成了最新的 V2.0 版本，那么这个设备就应该有能力知道服务器上的最新版本是 V2.0 版本，这样它就不需要升级了。
因此，还需要一个新的文件来描述文件服务器中的 V2.0 版本的升级包，就叫它：升级包描述文件 app_desc.json，它的内容是 json 格式的字符串：
version 字段描述了文件服务器上升级包的版本，这样的话，设备就可以知道到服务器中的最新版本。
url 字段描述了升级包的下载地址，设备如果发现自己的版本低于 version 字段中的版本，就可以从这个地址下载新的升级包。
md5 字段描述了服务器中最新升级包的指纹信息，当设备把服务器上的升级包下载之后，需要计算一下升级包的 MD5 值，然后与这里的 md5 字段进行比较，如果相同的话，说明下载的升级包没有问题，没有被恶意的家伙掉包。
了解了升级包描述文件 app_desc.json 的作用之后，这个文件就被上传到应用服务器中了。
下载升级包描述文件 此时，作为升级包的我，已经静静的躺在文件服务器中了，我的兄弟升级包描述文件 app_desc.json 呢，也在应用服务器中准备就绪了，现在就等着嵌入式设备开始升级。
万事俱备，只欠东风了！应该说只欠一个触发嵌入式设备进行升级的动作了！
那么，应该在什么时候？由谁？来告诉设备：你正在运行的软件太旧了，服务器上现在有最新的版本，你去升级一下吧！
这个问题的答案就是：八仙过海，各显神通了！
比如：
 亚马逊的 AWS 平台，是通过在云平台中部署一个 job，来通知每一个需要升级的设备; 也可以通过一个手机 APP，向某一个嵌入式设备主动发起一个指令：嘿，老兄，请升级一下你的软件;   当终端设备收到升级命令之后，第一步就是下载升级包描述信息。
下载之后，解析这个 json 格式的文本内容，提取出 version 信息之后，与当前正在运行的软件版本进行比较。
如果服务器中的版本比较新，那么就继续提取 url 字段中的升级包下载地址，然后开始从文件服务器中下载新的升级包。
如果当前运行的版本已经是最新的了，那就到此结束！
下载升级包 到了下载升级包的过程就简单了，你可以直接用 wget 等工具来下载，也可以利用 curl 库来手写下载代码。
总之，你可以有一万种方式把我下载到设备中。
下载完成之后，有一件很重要的事情千万别忘记了，那就是：检查下载的升级包是否正确！
还记得升级包描述文件中的 md5 字段吗？那就是我的指纹信息。
你需要首先计算一下下载的升级包的 md5 值，然后与升级包描述文件中的 md5 字段中的值进行比对，如果完全一致，那就放心大胆的开始解压、升级吧！
]]></content>
  </entry>
  
  <entry>
    <title>嵌入式程序设计中的4种常用模式</title>
    <url>/post/software/4-common-patterns-in-embedded-programming.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>Embedded</tag>
    </tags>
    <content type="html"><![CDATA[模板方法模式是框架中最常用的设计模式。
模板方法模式 其根本的思路是将算法由框架固定，而将算法中具体的操作交给二次开发者实现。
例如一个设备初始化的逻辑，框架代码如下：
TBool CBaseDevice::Init() { if ( DownloadFPGA() != KErrNone ) { LOG(LOG_ERROR,_L(“Download FPGA fail”)); return EFalse; } if ( InitKeyPad() != KerrNone ) { LOG(LOG_ERROR,_L(“Initialize keypad fail”)); return EFalse; } return ETrue; } DownloadFPGA和InitKeyPad都是CBaseDevice定义的虚函数，二次开发者创建一个继承于CBaseDevice的子类，具体来实现这两个接口。
框架定义了调用的次序和错误的处理方式，二次开发者无须关心，也无权决定。
创建型模式 由于框架通常都涉及到各种不同子类对象的创建，创建型模式是经常使用的。
例如一个绘图软件的框架，有一个基类定义了图形对象的接口，基于它可以派生出椭圆，矩形，直线各种子类。
当用户绘制一个图形时，框架就要实例化该子类。这时候可以用工厂方法，原型方法等等。
class CDrawObj { public: virtual int DrawObjTypeID()=0; virtual Icon GetToolBarIcon()=0; virtual void Draw(Rect rect)=0; virtual CDrawObj* Clone()=0; }; 消息订阅模式 消息订阅模式是最常用的分离数据和界面的方式。界面开发者只需要注册需要的数据，当数据变化时框架就会将数据“推”到界面。界面开发者可以无须关注数据的来源和内部组织形式。
消息订阅模式最常见的问题是同步模式下如何处理重入和超时。作为框架设计者，一定要考虑好这个问题。
所谓重入，是二次开发者在消息的回调函数中执行订阅/取消订阅的操作，这会破坏消息订阅的机制。
所谓超时是指二次开发者的消息回调函数处理时间过长，导致其他消息无法响应。最简单的办法是使用异步模式，让订阅者和数据发布者在独立进程/线程中运行。
如果不具备此条件，则必须作为框架的重要约定，禁止二次开发者产生此类问题。
装饰器模式 装饰器模式赋予了框架在后期增加功能的能力。框架定义装饰器的抽象基类，而由具体的实现者实现，动态地添加到框架中。
举一个游戏中的例子，图形绘制引擎是一个独立的模块，比如可以绘制人物的静止，跑动等图像。
如果策划决定在游戏中增加一种叫“隐身衣”的道具，要求穿着此道具的玩家在屏幕上显示的是若有若无的半透明图像。应
该如何设计图像引擎来适应后期的游戏升级呢？
当隐身衣被装备后，就向图像引擎添加一个过滤器。这是个极度简化的例子，实际的游戏引擎要比这个复杂。装饰器模式还常见用于数据的前置和后置处理上。
]]></content>
  </entry>
  
  <entry>
    <title>可持续性难题：推动HPC和AI极限扩展</title>
    <url>/post/server/pushing-the-limits-of-hpc-and-ai-is-becoming-a-sustainability-headache.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>AI</tag>
      <tag>HPC</tag>
    </tags>
    <content type="html"><![CDATA[随着摩尔定律的减缓，构建更强大的HPC和 AI  集群意味着要建造更大、更耗电的设施。
“如果你追求高性能，需要购买更多硬件，导致更大系统，进而导致更多的能量消耗和冷却需求，”犹他大学教授Daniel Reed在最近在丹佛举行的SC23超级计算大会上解释道。
如今，Top500上最大的超级计算集群消耗超过20兆瓦，而许多数据中心园区，特别是为了支持AI训练和推理需求而建造的园区，甚至更为庞大。有预测指出，到2027年，一套能力级超级计算机所需的电力将高达120兆瓦。
在关于高性能计算的碳中和和可持续性的专题讨论中，来自芝加哥大学、施耐德电气、洛斯阿拉莫斯国家实验室、HPE和芬兰科学信息中心的专家们纷纷发表看法，并提供了关于未来规划、部署、报告和运营这些设施的洞察。
卓越的功耗效率，但不应以水资源为代价 讨论的一个核心主题是电能利用效率（PUE）。作为参考，该行业标准通过比较计算、存储或网络设备使用的电量与总利用率来度量数据中心的效率。PUE越接近1.0，设施的效率就越高。
虽然PUE是优化数据中心运营电力消耗的有效工具，但HPE的Nicolas Dubé指出，它导致一些超大规模和其它大型数据中心运营商养成了一些不良习惯。
“一些超大规模企业，我点到为止，在亚利桑那、新墨西哥等一些非常干燥的地区建造了大型数据中心。在那里建造数据中心，如果使用蒸发冷却，将会有惊人的PUE。但是，这将消耗一种对当地社区来说比单纯优化少数能源消耗更为重要的资源。”他说。“我认为这是犯罪行为，他们应该因此受到惩罚。”
对于那些不熟悉的人来说，蒸发冷却 - 有时被称为沼泽冷却器 - 是在功耗方面效率最高的冷却技术之一。这些系统在干燥和干旱环境中特别有效，但需要大量水来实现。
洛斯阿拉莫斯的Genna Waldvogel指出，对于已经采用蒸发冷却的设施，比如国家实验室的设施，有方法减轻这些系统的影响。
“我们的数据中心几乎100%使用回收水，”她说。“我们有一个非常先进的系统…从废水处理厂获取废水，进行处理，然后将其泵送回我们的超级计算机。”
根据Reed的介绍，蒸发冷却所消耗的大量水正在迫使运营商考虑系统的选址。
选址和规划至关重要 Dubé强调了在选址过程中位置的重要性。他认为，通过在拥有丰富绿色能源供应的地方部署数据中心，可以在一定程度上减轻生成式AI的环境影响。
以QScale在魁北克开发的一个100兆瓦数据中心设施为例，其中近乎100%的电力来自水力和风力等可再生能源。他说：“推理和一些其它工作负载对延迟非常敏感，它们需要与人口共同驻地，而且有点难以移动，但大规模的训练任务不需要。”“当你考虑这一点时，这些大规模的工作负载实际上应该被重新安置或推到计算它们最可持续的地方。”
除了在可再生能源附近部署数据中心的明显优势之外，Dubé认为，还有一个机会可以利用这些设施产生的热量，而不仅仅是将其排放到大气中。
Dubé提到的QScale设施将与农业温室共同设置，并将利用设施捕获的废热在加拿大漫长的冬季为它们供暖。
为了说明这个机会，Dubé提出了一个相当幽默的问题：通过一次对GPT-3的训练，你能种植多少番茄。根据他的计算，这是一个不足为奇的数量。
假设每个500平方米温室每年需要1000吉焦耳的供暖，以及用于训练GPT-3的1,287兆瓦时，这相当于4.6个温室。以每年每平方米75千克的番茄和85%的温室可用于生产，Dubé得出了147677千克或略多于一百万个番茄。这是很多酱料！
热能再利用在HPC或AI领域绝非新概念。欧洲最大的超级计算机LUMI系统就是一个典型例子。“我们位于如此北方，我们的气候足够寒冷，全年都可以使用干冷却器运行。”芬兰科学信息中心的Esa Heiskanen说。除了免费冷却外，该设施还使用热量捕获系统，为卡亚尼市提供20%的区域供热需求。
如果我们有时关闭系统会怎样？ 除了更高效的技术和选址，芝加哥大学不可阻挡计算CERES中心的Andrew Chien认为，通过以更加动态的方式运行数据中心，有机会提高其可持续性。
这里的思路是，与其一直以来以不变的容量运行HPC集群或数据中心，运营商可以根据某个特定时间内电网上的电力量或电力混合情况，调整系统的利用率。
例如，在一天中的某些时段，你可能会看到来自风能或太阳能的更高产出，这可能使设施能够以更高的容量运行，同时还减少其碳足迹。
将这些技术应用于日本理研实验室的“Fugaku Next”项目，该项目预计将在2030年至2040年之间投入使用。Chien预测，在此期间，除了电网改进外，有可能实现电力成本的90%降低和碳排放的40%减少。
“大家都认为电力是问题，但在我看来，碳更像是一个更为严格的约束条件，”他解释道，这暗示了未来能源电网可能会看到更多可持续能源的混合。
需要更好、更一致的报告 正如你所预料的，降低越来越大的HPC和AI集群的碳影响将需要更好、更一致的报告，这一事实被施耐德电气首席技术官办公室的创新产品负责人Robert Bunger强调。
“我的提议是，HPC社区应该努力成为领导者。他们在性能的所有其它方面都是领导者，我认为可持续性报告和测量应该是其中之一，”Bunger说道。
Bunger解释说，其中一个问题是数据中心运营商在报告可持续性指标方面存在很大差异。这可能并未得到帮助，因为超大规模运营商不喜欢详细讨论诸如电力或水消耗之类的事务。
为了解决这个问题，施耐德提出了他们认为数据中心运营商应该追踪的28个指标。这些包括常见因素，如总电力消耗、PUE、总可再生能源消耗、总水消耗、水利用效率。然而，该清单还建议追踪其它因素，如可再生能源因子、能量重复利用、服务利用率，甚至包括噪音和土地利用。
Bunger承认，对许多设施来说，试图跟踪所有28个指标可能是令人望而却步的，但他建议数据中心运营商从其中的六个开始，然后逐步增加。
]]></content>
  </entry>
  
  <entry>
    <title>为什么GPU比CPU更快</title>
    <url>/post/server/why-gpu-is-faster-than-cpu.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>CPU</tag>
      <tag>GPU</tag>
    </tags>
    <content type="html"><![CDATA[在过去几十年里， GPU  变得越来越流行，尤其是最近ChatGPT大火，背后训练大模型的硬件设备GPU达到了一片难求的地步。
你有没有好奇：为什么必须要用GPU？CPU被淘汰了吗？
大家好，我是老猫，猫头鹰的猫。
今天我们就来一起聊一下，为什么GPU比CPU更快！
GPU比CPU快，并不准确？ 单纯的来说是GPU快还是CPU快，其实并不公平。二者的设计理念并不一样。
CPU被称为计算机的&quot;大脑&quot;，主要来承担计算的处理功能，操作系统和应用程序运行等操作都必须依赖它来进行，CPU 还决定着计算机的整体速度。
GPU的作用则更具有专业性，其最初的设计是用于辅助3D渲染，能同时并行更多指令，其非常适合现在比较热门的动漫渲染、图像处理、人工智能等工作负载。
简单来说，CPU是为延迟优化的，而GPU则是带宽优化的。CPU更善于一次处理一项任务，而且GPU则可以同时处理多项任务。就好比有些人善于按顺序一项项执行任务，有些人可同时进行多项任务。
为演示 CPU 与 GPU 的不同，英伟达曾经邀请亚当·萨维奇 (Adam Savage) 和杰米·海尼曼 (Jamie Hyneman) 利用机器人技术和彩弹再现了一幅广为人知的艺术作品&ndash;蒙娜丽莎的微笑。这个视频充分展示了CPU和GPU工作的过程。
我们通过打比方来通俗的解释二者的区别。CPU就好比一辆法拉利，而GPU则相当于一辆货运卡车，二者的任务都是从A位置将100 Packages运送到B位置，CPU（法拉利）可以在RAM中快速获取一些内存数据（货物），而GPU（货运卡车）执行速度较慢（延迟更高）。但是CPU（法拉利）每次只能运送2 Packages，需要50次才能运送完成。
然而GPU（货运卡车）则可以一次获取更多内存数据进行运输。
换句话说，CPU更倾向于快速处理少量数据（例如算术运算：567），GPU更擅长处理大量重复数据（例如矩阵运算：（A*B）*C）。因此，虽然CPU单次运送的时间更快，但是在处理图像处理、动漫渲染、深度学习这些需要大量重复工作负载时，GPU优势就越显著。
但是，GPU最大的问题在于延迟对性能的影响，但对于深度学习的典型任务场景，数据一般占用大块连续的内存空间，GPU可以提供最佳的内存带宽，并且线程并行带来的延迟几乎不会造成影响。
那么是什么导致CPU和GPU工作的方式不同呢？那还要从二者设计结构来说。
为什么GPU和CPU工作方式不同？  架构核心不同  通过下面两张图可以有助于我们理解CPU和GPU工作方式的不同。上文中我们提到，CPU是为顺序的串行处理而设计的，GPU则是为数据的并行而设计的，GPU有成百上千个更小、更简单的内容，而CPU则是有几个大而复杂的内核。
GPU内核经过优化，可以同时对多个数据元素进行类似的简单处理操作。而且CPU则针对顺序指令处理进行了优化，这也导致二者的核心处理能力的不同。
网上有一个比喻用来比较 GPU 和 CPU 核心的区别，我觉得非常贴切，CPU的核心像学识渊博的教授，GPU的核心更像一堆小学生，只会简单的算数运算，可即使教授再神通广大，也不能一秒钟内计算出500次加减法，因此对简单重复的计算来说单单一个教授敌不过数量众多的小学生，在进行简单的算数运算这件事上，500个小学生(并发)可以轻而易举打败教授。
内存架构不同  除了计算差异之外，GPU还利用专门的高带宽内存架构将数据送到所有核心，目前GPU通常用的是GDDR或HBM内存，它们提供的带宽比CPU中的标准DDR 内存带宽的带宽更高。
GPU处理的数据被传输到这个专门的内存中，以最大限度地减少并行计算期间的访问延迟。GPU的内存是分段的，因此可以执行来自不同内核的并发访问以获得最大吞吐量。
相比之下，CPU内存系统对缓存数据的低延迟访问进行了高度优化。对总带宽的重视程度较低，这会降低数据并行工作负载的效率。
并行性  专用内核和内存的结合使GPU能够比CPU更大程度地利用数据并行性。对于像图形、渲染这样的任务，相同的着色器程序可以在许多顶点或像素上并行运行。
现代GPU包含数千个核心，而高端CPU最多只有不到100个核心。通过更多的核，GPU可以以更高的算术强度在更宽的并行范围内处理数据。对于并行工作负载，GPU核心可以实现比CPU高100倍或更高的吞吐量。
相比之下，阿姆达尔定律意味着CPU对一个算法所能获得的并行加速是有限的。即使有100个内部核心，由于串行部分和通信，实际速度也限制在10倍或更低。由于其大规模并行架构，GPU可以实现几乎完美的并行加速。
即时（JIT）编译  GPU的另一个优点是即时(JIT)编译，它减少了调度并行工作负载的开销。GPU驱动程序和运行时具有JIT编译功能，可以在执行之前将高级着色器代码转换为优化的设备指令。
这为程序员提供了灵活性，同时避免了CPU所需的传统离线编译步骤。JIT还支持基于运行时信息的优化，综合效果将GPU开销降低到几乎为零。
相比之下，CPU必须坚持预编译的机器码，不能根据运行时行为自适应地重新编译，因此CPU的调度开销更高，灵活性也更差。
编程模型  与CPU相比，GPU还提供了一个更加出色的并行编程模型CUDA，开发人员可以更快速编写并行代码，而不必担心低级别的线程、同步和通信等问题。
CUDA和OpenCL提供C/ C++编程语言，其中代码专注于跨抽象线程的并行计算，凌乱的协调细节在幕后被无形地处理。
相反，CPU并行性要求使用OpenMP等库直接处理线程。在线程管理、锁和避免竞争条件方面，存在明显的额外复杂性。这使得从高层考虑并行性变得更加困难。
响应方式不同  CPU基本上是实时响应，对单任务的速度要求很高，所以就要用很多层缓存的办法来保证单任务的速度。
GPU往往采用的是批处理的机制，即：任务先排好队，挨个处理。
应用方向不同  CPU所擅长的像操作系统这一类应用，需要快速响应实时信息，需要针对延迟优化，所以晶体管数量和能耗都需要用在分支预测、乱序执行、低延迟缓存等控制部分。
GPU适合对于具有极高的可预测性和大量相似的运算以及高延迟、高吞吐的架构运算。目前广泛应用于三大应用市场：游戏、虚拟现实和深度学习。
一、游戏市场
游戏是GPU最早应用的领域之一。由于GPU在图像处理和物理效果方面具有天然优势，因此在游戏开发中，GPU被广泛用于游戏引擎和游戏渲染。在游戏中，GPU可以快速运算出大量的几何体、纹理、光影等数据，从而实现更加真实的画面效果。
二、虚拟现实市场
虚拟现实技术是一种将计算机生成的三维图像与真实世界相结合的技术。GPU在虚拟现实应用中，可以实现对虚拟世界的逼真渲染和物体运动控制。随着虚拟现实技术的不断发展，GPU在虚拟现实市场中的应用越来越广泛，尤其是在头戴式设备和沉浸式体验方面。
三、深度学习
深度学习是一种基于人工神经网络的机器学习算法。GPU在深度学习中，可以高效地训练神经网络，并通过大规模并行计算来加速训练过程。目前，随着GPU在深度学习中的应用不断扩展，它已成为训练深度学习模型的主要加速器。
另外，GPU还可以应用于自动驾驶、医疗影像分析、金融风控等领域。不过，由于不同应用场景对GPU性能的要求不同，因此在选择GPU时需要考虑其计算能力、功耗和应用领域等因素。需要根据任务类型选择最合适的GPU，并进行优化以发挥其性能优势。
国产GPU发展情况 国产GPU的发展落后于国产CPU，直到2014年4月，景嘉微才成功研发出国内首款国产高性能、低功耗GPU芯片-JM5400。
在国产GPU的开发中，GPU对CPU的依赖性和GPU的高研发难度，阻碍了该产业的快速发展。首先，GPU对CPU有依赖性。GPU结构没有控制器，必须由CPU进行控制调用才能工作，否则GPU无法单独工作。所以国产CPU较国产GPU先行一步是符合芯片产业发展逻辑的。
再者，GPU技术难度很高。Moor Insights &amp; Strategy首席分析师莫海德曾表示：&ldquo;相比CPU，开发GPU要更加困难，而GPU设计师、工程师和驱动程序的开发者都要更少。&ldquo;国内人才缺口也是国产GPU发展缓慢的重要原因之一。
目前，中国的GPU芯片虽然在市场份额上仍然占据较小的比例，但国产GPU芯片的入局者也越来越多，越来越多的国内企业向图形处理领域转型，比如芯动科技、景嘉微等，国产GPU芯片也有了更好的发展机遇。
如今，随着一系列美国政策的实施，不少人看到了国产GPU芯片代替进口芯片的未来，并将开始多角度支持国内GPU芯片企业。根据最新统计数据，三家国产GPU企业壁仞科技、摩尔线程、沐曦仅仅获得的投资就已经超过100亿元，这说明着确实正在付出极大的努力投入到技术研发中。
目前看来，随着美国实施更多的出口管制措施，或将为&quot;中国芯&quot;崛起制造机会窗口，这可能导致英伟达在中国市场面临更大的竞争压力。
]]></content>
  </entry>
  
  <entry>
    <title>PCIe Gen 6的演进与洞察</title>
    <url>/post/server/PCIe-gen-6-evolution-and-insights.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>PCI Express</tag>
      <tag>PCIe Gen 6</tag>
    </tags>
    <content type="html"><![CDATA[ PCle协议  (外围组件互连Express)于2003年推出第一代，在串行计算机扩展总线中每通道允许高达2.5 GT/s的速度,成为业界的一项巨大突破。
此后,该协议已经发展了多次，与上一代相比，其传输速率始终翻倍，并在需要时引入新功能和优化。最新版本于2022年发布，其中引入了PCle 6.0，每通道速度高达64.0 GT/s。正如2023年在圣何塞举行的PCI-SIG开发者大会上宣布的那样，PCle 6.0不仅再次将速度提高了一倍，而且为未来的许多代产品奠定了基础。此次修改是考虑到对现有规则的许多必要优化，考虑到20年的行业使用和经验。引入了新的概念和技术,例如1b/1b编码、PAM4调制和Flit模式操作。
PCle 6.0规范中所有功能的更改都是考虑到需要进行优化以跟上更高的吞吐率。因此，遵循以下准则：
 减少损失:通过避免不必要的编码; 做出假设:基于既定模式; 避免传输不必要的信息：可能被对方推断出来; 避免重新配置：如果之前已经配置过。  PCle 6.0中引入的新编码是通过避免不必要的编码来减少损失的最大例子。以前，实例在以8.0GT/s或更高速度运行时使用128b/130b编码。这意味着每128位数据需要2个额外位才能被另一方正确解码。这导致串行链路效率低下，仅由于编码就损失了1.54%的比特级带宽。
1b/1b通过保证传输的每一位都可以被另一方用作实际信息来解决这个问题。这是通过在预期数据类型的每一侧实施内部计数器来完成的。只要正确验证设计以遵守这些计数器，就可以保证它们能够进行通信，而无需在链接中发送任何额外的不必要的信息。
fit序列号是PCle6.0中引入的新概念，与fit操作模式一起添加。它取代了事务层数据包(TLP)中存在的旧序列号及其确认或重播机制。以前，序列号总是附加到每个传输的TLP上。尽管它增加了链接的稳健性，但考虑到TLP具有连续的序列号，这被证明是一种资源浪费。因此，知道一个TLP的序列号意味着知道它旁边的TLP的编号，依此类推。
fit 序列号协议通过实现隐式序列号对此进行了优化，其中序列号由另一方推断。不仅如此，序列号也处于fit级别，可以同时容纳很多TLP。因此，先前用于始终发送的序列号信息的空间可用于增加有用信息的带宽。
以前,在连接后更改链路宽度的过程对于设备来说成本高昂，因为他需要检查链路训练和状态机制 （LTSSM)的所有配置状态。这意味着重新配置通道的所有细节，尽管唯一需要更改的 变量是所使用的链路密度。
PCie 6.0中通过引入仅在Fiit 模式中存在的LO部分(LOp)功能进行了增强。执行LOp序列可以在活动数据传输期间更改链路密度,而无需关闭链路。这意味着通过更改链路密度来实现节能更加有效 ,而且设备可以轻松保持较小的宽度，以防出現热节流问题。
综上所述，PCle 6.0带来了很多变化，这些变化都是为了保证PCle协议的各个层都能跟上更高的传输速率而进行的优化。目前正在进行的PCle7.0在所有这些变化的基础上，继续了对PCle的支持和优化。因此，验证设备是否遵循所有这些功能的功能行为非常重要,以确保它们能够从新一代协议以及尚未发布的版本提供的优势中受益。
]]></content>
  </entry>
  
  <entry>
    <title>新手必看的RTOS基础知识</title>
    <url>/post/software/basis-of-rtos.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>Embedded</tag>
      <tag>RTOS</tag>
    </tags>
    <content type="html"><![CDATA[实时操作系统（ RTOS  ）是一种操作系统（OS），旨在提供实时应用进程数据，通常没有缓冲延迟。
RTOS基础知识 RTOS 实时操作系统（ RTOS  ）是一种操作系统（OS），旨在提供实时应用进程数据，通常没有缓冲延迟。
RTOS中的关键因素是最小的中断延迟和最小的线程切换延迟。RTOS的价值在于它的响应速度或可预测性，而不是它在给定时间段内可以执行的工作量。
对于嵌入式设备，一般规则是当应用进程需要执行多个简单操作时使用RTOS。
实时操作系统具有以下目标：
 低延迟。 决定论：需要知道处理事情需要多长时间才能确保满足最后期限。 结构化软件：使用RTOS，可以以结构化的方式分而治之。直接向应用进程添加其他组件。 可扩展性：RTOS必须能够从简单的应用进程扩展到具有堆栈、驱动进程、文档系统等的复杂应用进程。 卸载开发：RTOS管理系统的许多方面，例如，RTOS与调度一起，通常处理电源管理，中断表管理，内存管理，异常处理等。  线程 基于RTOS的应用进程中的典型线程：
 中断服务例程（ISR）：由硬件中断启动的线程。ISR运行直至完成。ISR都共享同一堆栈。 任务：在等待事件发生时可以阻塞的线程。传统上，任务是长寿命线程（与运行直至完成的ISR相反）。每个任务都有自己的堆栈，可以让它长寿。 Idle：优先级最低的线程，仅在没有其他线程准备好执行时运行。通常，空闲只是具有尽可能低优先级的特殊任务。  调度进程 每个RTOS的核心都有一个调度进程。调度进程负责管理系统中线程的执行。调度进程有两种主要管理方式：抢占式调度和时间片调度。
抢占式调度是最常见的RTOS调度进程类型。TI-RTOS和FreeRTOS都有抢占式调度进程。使用抢占式调度进程，正在运行的线程将一直持续到
 完成（例如，ISR完成）。 较高优先级的线程准备就绪（在这种情况下，优先级较高的线程会抢占优先级较低的线程）。 线程在等待资源时放弃处理器（例如，任务调用sleep()）。  时间片调度保证每个线程都有一个要执行的槽。这种类型的调度通常不利于实时应用。如果需要，TI-RTOS内核支持使用任务进行时间切片调度。
其他关键术语 线程安全：如果一段代码以保证多个线程同时正确访问（读取、写入）的方式操作共享数据结构，则该代码段是线程安全的。
Blocked：如果任务正在等待资源且未消耗任何CPU，则阻止该任务。例如，如果任务调用Task_sleep()或Semaphore_pend()（非零超时且信号量不可用），则该任务将被阻止，并允许另一个线程运行。
裸机：不适用RTOS的应用进程的公用名。
裸机与实时操作系统 典型的裸机应用进程通常可分为三个关键部分：
 初始化：初始化main()中的硬件和软件组件。 超级循环状态机：用于管理应用进程的代码。这些操作基于中断（例如，收到SPI数据包或计时器过期）或轮询的结果。 ISR：由外围设备（例如UART）、定时器或其他特定于设备的项目（例如异常或多核通信）的中断执行的代码。  裸机应用进程有其一席之地。它们通常很小，速度快，并且通过简单的应用进程相对容易理解。一旦需要更复杂的逻辑，RTOS就开始大放异彩。
实时操作系统组件
 计划进程：保证最高优先级线程正在运行的抢占式计划进程。 通信机制：信号量、消息队列、队列等。 关键区域机制：互斥体、门、锁等。 计时服务：时钟、定时器等。 电源管理：对于低功耗设备，电源管理通常是RTOS的一部分，因为它知道设备的状态。 内存管理：可变大小的堆、固定大小的堆等。 外设驱动器：UART、SPI、I2C等。 协议栈：蓝牙、无线网络等。 文档系统：FatFs等。 设备管理：异常处理、启动等。  POSIX POSIX（Portable Operating System Interface）：可移植操作系统接口
SimpleLink SDK在TI-RTOS和FreeRTOS之上提供POSIX支持。这允许应用进程独立于底层RTOS。
POSIX API是底层实时操作系统之上的一个小填充码。创建POSIX线程时，将创建基础TI-RTOS（或FreeRTOS）任务。同样，在创建POSIX线程信号量时，将创建TI-RTOS（或FreeRTOS）信号量。
POSIX支持的一个很好的功能是能够从网络上获取基于POSIX的代码并快速使其正常工作。
POSIX不是实时操作系统。它是一个操作系统兼容性层，允许应用进程在操作系统之间轻松移植。
RTOS线程通信 所有RTOS都提供标准的通信机制，如信号量、互斥锁、消息队列、链表等。
信号量 信号量允许资源管理。任务可以在sem_wait()上阻塞，直到资源变得可用（通过sem_post()）。一个常见的用例是Hwi接收数据并发布信号量，以便任务可以处理它。这是可取的，因为它可以最大限度地减少中断的持续时间。大多数RTOS都支持二进制和计数信号量。
消息队列 消息队列对于在线程之间发送数据非常有用。消息队列可以配置为发送/接收任何大小的用户定义的消息。在这里，一个任务正在向另一个任务发送消息：
当希望将特定功能集中到单个任务中时，消息队列非常有用。所有其他线程都可以将消息发送到集中式任务进行处理。消息队列以线程安全的方式处理消息。
POSIX支持层中的消息队列是创建在TI-RTOS中的Mailboxes和FreeRTOS中的队列之上的。
执行 一个抢占式的调度进程在运行。假设以下线程是在main()中创建的：
ISRX：中断服务例程
MidA：在main()中创建第一个优先级为4
MidB：在main()中创建第二个优先级为4
High：在main()中创建最后一个优先级为8
一旦内核的调度进程启动（在本例中为main()中的BIOS_start()），所有任务都已准备好运行，首先运行的是High，因为它具有最高优先级。
  ISRX断言，因为它会抢占所有任务。High现在处于抢占状态。
  ISRX完成后，High将再次开始运行，直到它在Task_sleep()（或某些阻塞API）上阻塞。现在，MidA可以运行了。
  MidA一直运行，直到它遇到阻塞调用（比如Semaphore_pend()）。现在，MidB可以运行了。
  MidB一直运行到High取消阻塞（假设Task_sleep()已过期）。MidB现在被抢占了。
  High将一直运行，直到ISRX被断言并抢占High。注意：现在有两个任务被抢占。
  MidA准备就绪（假设ISRX发布了它被阻止的信号量）。MidA不会运行，因为有更高优先级的线程正在运行。
  ISRX完成，因此High再次运行，然后再次阻塞，因此MidB再次运行，直到它阻塞。现在MidA可以运行，因为没有更高优先级的任务正在运行。注意：MidA必须等到MidB完成后，因为当MidA准备就绪时，MidB正在运行。
  MidA阻塞，现在没有线程正在运行或准备运行，因此Idle运行。
  MidB取消阻塞并运行。
 ]]></content>
  </entry>
  
  <entry>
    <title>传三星斩获AMD部分订单</title>
    <url>/post/news/samsung-is-rumored-to-have-won-some-orders-from-AMD.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>AMD</tag>
      <tag>Samsung</tag>
      <tag>Zen5c</tag>
    </tags>
    <content type="html"><![CDATA[据报道，三星已获得 AMD  的订单，将使用其的4nm工艺技术，为AMD生产基于Zen 5c架构的处理器。目前，这一消息在多个渠道得到了证实。
如果这笔交易最终达成，这标志着AMD对其制造战略进行了调整，以实现多元化供应。其中，AMD的考量已经从工艺节点、生产良率、成本等因素，扩展到产能、生态链等多个角度。
据悉，AMD的“Prometheus”处理器将由三星和台积电共同生产。其中，三星将使用其先进的4nm工艺技术制造基础版本的“Prometheus”处理器，而台积电则将使用更先进的3nm工艺技术来生产更高级别的“Prometheus”处理器。
如今，三星正在积极扩展其4nm工艺，以能够从台积电那里获得更多订单。在关键的良率方面，业内人士普遍认为，台积电的4nm工艺良率达到了80%，而三星的4nm工艺已经从年初的50%提升到75%，与台积电相当。对此，外界猜测高通、英伟达等大客户可能会回流采用三星工艺。
据此前曝出的苹果高层会议纪录显示，台积电3nm制程的良率接近63%，报价比4nm高出一倍。因此，随着三星今年较大幅度改善良率和产能，再加上台积电今年决定涨价，很多大客户可能会从成本等角度考量，寻找第二供应商以分散外包生产订单。
]]></content>
  </entry>
  
  <entry>
    <title>AMD能否借助MI300加速器再次加速</title>
    <url>/post/server/can-AMD-accelerate-again-with-the-MI300-accelerator.html</url>
    <categories><category>server</category>
    </categories>
    <tags>
      <tag>AMD</tag>
      <tag>MI300</tag>
    </tags>
    <content type="html"><![CDATA[ AMD  宣布将于 2023 年 12 月 6 日举办“ Advancing AI ”现场直播活动，AMD董事会主席兼首席执行官苏姿丰博士（Dr. Lisa Su）将携手其他AMD高管、AI生态系统合作伙伴和客户共同探讨AMD产品和软件将如何重塑AI和自适应高性能计算领域。
基本上板上钉钉的是，这场活动中的“聚焦点”，是AMD将推出下一代 AMD Instinct MI300 数据中心 GPU 加速器系列。
总结：
 AMD的 MI300 AI 加速器可能成为该公司未来几年的主要增长动力，使其能够与NVIDIA等公司竞争。 MI300A以及MI300X加速器预计将明显增强AMD的数据中心业务，并有可能产生10亿美元的销售额。 AMD 在数据中心人工智能市场的强势地位，加上对 ROCm 软件生态系统的投资，将进一步支持其增长潜力。  MI300加速器预计成为AMD最快达成10亿美元销售额产品 在2023 财年第三季度财报电话会议上，AMD 管理层预计第四季度数据中心 GPU 收入约为 4 亿美元，2024 年将超过 20 亿美元，全年收入将持续增长。
22财年，AMD在数据中心业务上创造了60亿美元的收入，占集团总收入的25.6%。MI300A和MI300X加速器的出货极大地促进了他们的数据中心业务。Lisa Su表示，MI300 预计将成为公司历史上销售额最快达到 10 亿美元的产品。
MI300A是一款由1460亿个晶体管组成的CPU+GPU加速器，而MI300X则是一款专为数据中心市场设计的纯GPU产品。据透露，AMD有望在未来几周内开始向领先的云和 OEM 客户生产 Instinct MI300X GPU 加速器。此外，Instinct MI300A APU 于 10 月初开始生产发货，以支持 El Capitan Exascale 超级计算机。
MI300系列和NVIDIA H100的AI争夺战 MI300A 和 MI300X 都将成为 AMD 未来几年的重要增长动力。首先，尽管 AMD 的 GPU 产品比 NVIDIA更晚进入市场，但 MI300X 将8个加速器集成到一个平台上，并具有1.5TB HBM3 内存。凭借如此强大的计算能力，MI300X非常适合AI机器学习中的大型语言模型。
业界谈论到AI加速器，NVIDIA是绕不开的话题。
AMD 的 MI300X 使该公司能够与NVIDIA的 H100 GPU 产品竞争。Lisa Su声称MI300X提供5.2TBps的内存带宽，比NVIDIA H100 GPU好1.6倍。
值得注意的是，Lisa Su指的是NVIDIA H100 SXM版本，但NVIDIA同样具有高版本的H100 NVL——通过NVLink桥接2个GPU，提供7.8 TBps的内存带宽——仍然略高于AMD的MI300X。
不过，AMD MI300X的强大，足以满足大型语言模型的计算需求。
数据中心人工智能市场规模巨大，AMD预计今年的潜在市场总额将达到300亿美元，预计到2027年将增长至1500亿美元。
这些都给AMD在此领域留下足够想象的扩展空间。
ROCm 软件生态系统 成功的软件对于人工智能加速器的重要性不可低估。
NVIDIA 的 CUDA 软件已经成功建立了其生态系统，涵盖硬件、软件和外部合作伙伴。同样，AMD 也一直在投资其 ROCm 软件。最新的 ROCm 软件套件完全支持 AMD 的 MI300 加速器。
由于 CUDA 的先发优势，GitHub 上的许多现有代码主要基于 CUDA，为弥补这一差距，AMD 一直在为 AMD GPU 开发 PyTorch/TensorFlow 代码环境。该环境可与 AMD GPU 上基于 CUDA 的代码存储库兼容，从而促进 AMD 生态系统的扩展，并帮助客户更高效地构建机器学习应用程序。
顺应AI计算的浪潮。新推出的 MI300 AI 加速器预计将维持收入增长的高速势头。许多企业优先考虑云和人工智能投资，极大地推动了对加速器的需求。
研究和市场预测 GPU 市场的复合年增长率将达到 29.57%，将从 2021 年的 310 亿美元增至 2028 年的 1900 亿美元。
]]></content>
  </entry>
  
  <entry>
    <title>GH200，来自英伟达的AI超级计算机</title>
    <url>/post/news/gh200-from-nvidia.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Nvidia</tag>
      <tag>GH200</tag>
    </tags>
    <content type="html"><![CDATA[Nvidia的GH200 AI超级计算机是一款巨大的进步，相比于之前的 H100  ，其在使用TB级数据训练和部署AI模型方面的性能提升了3-7倍。
GH200拥有144TB的共享内存和141GB HBM3e内存，这个共享内存比标准的A100多出了500倍。
每一个GH200 GPU都能够访问其他GPU的内存，以及所有NVIDIA Grace CPU的扩展GPU内存，速度高达每秒900GB。这大大加快了大型语言模型（LLM）的训练速度，并显著降低了LLM推理的成本。有了这些超级计算机，就不再需要成千上万的机器来训练和运行LLM的推理。
有了GH200，就不再需要成千上万台机器来训练LLM和进行推理，这对初创公司和大型企业都是一个变革性的时刻。特别是对那些旨在训练、微调和部署LLM的初创公司来说，GH200为它们提供了以前只有大公司才能拥有的计算能力。
随着时间的推移，硬件将变得更加强大和便宜，不久的将来，我们甚至可能在我们的笔记本电脑上运行我们自己的强大的个人LLM。
]]></content>
  </entry>
  
  <entry>
    <title>英伟达发布H200, 高性价比全面升级</title>
    <url>/post/news/nvidia-launch-h200-gpu.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Nvidia</tag>
      <tag>H200</tag>
      <tag>H100</tag>
    </tags>
    <content type="html"><![CDATA[在11月13日的S23大会上， NVIDIA  宣布推出NVIDIA HGX H200，为生成式人工智能和高性能计算（HPC）工作负载提供强大支持。
根据介绍，新的H200 GPU是当前H100的升级产品，作为第一款搭载 HBM3e 的 GPU，H200 集成了141GB的内存，更大更快的内存推动生成式人工智能和大型语言模型（LLM）的加速，同时推进科学计算在 HPC 工作负载中的发展，在用于推理或生成问题答案时，性能较H100提高60%至90%。
H200主要在内存带宽和内存容量上进行提升 为了最大化计算性能，H200 是全球首款搭载 HBM3e 内存的 GPU，拥有4.8TB/s的内存带宽，较 H100 增加了1.4倍。H200 还将 GPU 的内存容量扩展到141GB，几乎是 H100 的80GB 的两倍。更快速和更大容量的 HBM 内存的结合，加速了计算密集型的生成式人工智能和高性能计算应用的性能，同时满足了不断增长的模型大小的需求。对比 H100 和 H200 的性能参数，在算力指标上H200和H100完全一样。H200 的所有改进都集中在更快速和更高容量的141GB HBM3e 的引入。
H200相较于H100在推理性能上最高提高至2倍 H200的推理表现相较于H100在各大不同的模型都具有明显的提升。与处理类似 Llama2（一个 700 亿参数的 LLM）的LLMs时相比，相较于 H100 GPU，H200 在推理速度上提高了最多 2 倍。
高内存带宽激发高性能计算表现 内存带宽对于高性能计算应用至关重要，因为它能够实现更快的数据传输，减少复杂的问题处理。对于内存密集型的高性能计算场景，如仿真、科学研究和AI，H200 的更高内存带宽确保数据可以被高效地访问和操作，从而在与 CPU 相比，实现高达 110 倍更快的生成结果时间。
降低能耗和总拥有成本（TCO） H200 的引入使得AI数据中心能源效率和TCO进一步提升。H200在性能相较H100具有明显提升的背景下，保持了与 H100 相同的功耗。以Llama2 70B这样的模型去推理衡量看，H200的性能是H100的两倍，在功耗相同的情况下，成本是原来单位成本的一半。
]]></content>
  </entry>
  
  <entry>
    <title>GPT4.0 终于可以免费使用了</title>
    <url>/post/news/gpt-4.0-is-finally-free-to-use.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>GPT 4.0</tag>
      <tag>Copilot</tag>
      <tag>Microsoft Ignite</tag>
    </tags>
    <content type="html"><![CDATA[2023年末将至，今年几乎每个产业都在经历着集体转型， AI  技术的发展为工作方式带来了新的变革。在最近的Microsoft Ignite技术大会上，微软展示了他们最新的技术和产品进展，让每个人都能体验到科技创新的力量。
Microsoft Ignite是一年一度针对开发者和IT专业人士举办的大会。AIGC无疑是本届大会的最大的热点。而最重磅的莫过于微软宣布，Bing Chat更名为Copilot，面向所有用户免费开启GPT-4功能。
Bing Chat正式更名为Copilot，品牌升级意味着Copilot正在成为一个独立的新产品，用户无需先导航到Bing就可以访问。Copilot现在可以通过Bing和Windows使用，与ChatGPT一样，微软Copilot也有了自己的独立域名：copilot.microsoft.com，但与ChatGPT不同，Copilot上像GPT-4、DALL-E 3等功能全部免费开放！你只需登录微软账户即可使用（而ChatGPT需要订阅会员，每月20刀）。
就连OpenAI上周发布的GPT自定义版本，微软也开始免费提供，命名为Copilot Studio。
此前，微软内部曾有十几种产品共享“Copilot”品牌，Copilot品牌起源于2021年的 GitHub Copilot，今年微软又推出了Dynamics 365 Copilot、Windows Copilot、Microsoft Security Copilot和Microsoft 365 Copilot等，似乎每项业务都有自己的“Copilot”。
那为什么要在Copilot家族中再添两名新成员？微软表示是为了给消费者和企业客户带来统一的Copilot体验。
现在，Bing Chat成为了微软的第六个Copilot，也可以视作是最通用的一个Copilot。未来，Bing将为其提供支持。另外，Copilot基于最新OpenAI模型，包括GPT-4和DALL-E 3，提供统一的文本和图像生成功能。
有分析认为，Bing Chat本身并未为Bing带来太多效益，所以微软将其从搜索引擎中剥离出来。此举颇为讽刺，因为微软此前大力利用AI产品来提升自家搜索引擎，意图从谷歌手中夺取市场份额。今年初，微软CEO纳德拉甚至称“谷歌是搜索领域800磅重的大猩猩”，微软将让它“跳舞”。但谷歌并未像微软那样急于在搜索中加入生成式AI。从现在看来，这种“不变”并未对谷歌造成什么不良影响：在Bing Chat推出近10个月后，谷歌搜索引擎的市场份额仍超过91%。
微软特别提到，从12月1日起，使用Microsoft Entra登录时，在Bing、Edge和Windows中使用Copilot的用户将享有商业数据保护功能。Copilot不会保存用户的prompt和回复，微软无法直接访问这些数据，也不会用于模型训练。
此外，微软还推出了其他Copilot产品：Microsoft Copilot Studio、Copilot for Azure、Copilot for Service和Copilot in Dynamics 365 Guides。
其中，Microsoft Copilot Studio对应OpenAI上周发布的GPTs产品。该新平台提供将微软AI应用与第三方数据连接的工具，企业可以用它创建定制的Copilot或集成自定义的ChatGPT对话机器人。该产品已向现有Copilot for Microsoft 365订阅用户开放公测版。
现在，无论是Edge、Chrome、Safari，还是移动端，都可以使用Copilot。需要注意的是，虽然Copilot仅需要登录微软账户就可免费使用，但Microsoft 365等其他Copilot产品仍需付费。
与OpenAI GPTs相比，微软Copilot Studio还有些不同。它的主要设计目的是扩展Microsoft 365 Copilot。用户可以利用该应用自定义集成不同数据集和自动化流程的Copilot。
除了将Bing Chat改名Copilot，微软还发布了期待已久的自研芯片。这是为云基础设施设计的两款高端定制芯片，分别是Azure Maia 100 AI芯片和Cobalt 100 CPU。两款芯片均由微软内部构建，深度针对整个云服务器堆栈进行了优化，在性能、功耗和成本方面具有竞争优势，计划2024年推出。
]]></content>
  </entry>
  
  <entry>
    <title>聊聊GPU产品选型那些事</title>
    <url>/post/server/how-to-select-gpu.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>CPU</tag>
      <tag>H100</tag>
      <tag>A100</tag>
      <tag>V100</tag>
    </tags>
    <content type="html"><![CDATA[本篇讲述了A100、V100、H100该如何选择？
作者 | 范雪莹
随着 人工智能  的飞速崛起，随之而来的是算力需求的指数级增加，CPU已经不足以满足深度学习、大模型计算等场景的海量数据处理需求。GPU作为一种强大的计算工具，无论是高性能计算、图形渲染还是机器学习领域，在各个领域展现出了巨大的潜力和应用前景。
说起GPU，绕不过的当然是NVIDIA这个公司了，现在市面上火热的A100/A800、H100等GPU全是他家的产品。但当你有业务需求或者个人需求，想要采购GPU的时候，你会发现各个型号的GPU令你眼花缭乱。这次我们就来聊聊NVIDIA的GPU产品，让你对各个型号的GPU有个深入的了解。
GPU应用场景 在选择GPU产品之前，首要任务是明确自己的应用需求。不同的应用领域对GPU的需求存在差异，因此了解自己的需求是做出明智决策的关键。接下来我们了解下常见的GPU应用场景。
游戏和图形渲染 我把游戏和图形渲染这个应用场景放在了第一位，并不是说它是GPU最常用的应用场景，而是很多小伙伴在学生时代就已经接触了“显卡”。
GPU不等于显卡，它是显卡的核心，就像CPU是主板上的一块芯片。GPU刚被发明出来的初衷是用于图形渲染，这从它的名字Graphic Processing Unit（图形处理单元）就可以看出来。在游戏和图形渲染中，GPU能够处理复杂的图形渲染任务，使游戏画面更加逼真和流畅。
游戏开发人员使用GPU来创建游戏的视觉效果、光照和物理模拟等。NVIDIA产品的GeForce系列，主要就是面向游戏娱乐领域，我们常说的RTX 4090，其中在框架中采用了第三代RT core，光线追踪性能最高可提升2倍，主要用于游戏开发、电影制作和虚拟现实等需要实时渲染的领域。当然，GeForce系列的显卡也可以用于AI推理等，只是在计算能力上没有像企业级GPU那么强悍。
大模型计算 大模型训练通常涉及处理海量数据和复杂的计算任务，例如深度神经网络的训练。大模型通常需要大量的显存来存储模型参数、梯度和中间计算结果。较大的显存容量可以提供更高的批处理大小和更复杂的模型结构，有助于提升模型的性能和准确度。
同时，大模型训练需要进行大量的矩阵计算、张量操作和梯度更新等复杂的计算任务。GPU具备强大的计算能力和优化的张量计算指令集，能够加速大规模模型的训练过程，减少训练时间。
通常而言，大模型训练会将训练数据分成多个批次，分配给不同的GPU进行并行处理，这就需要GPU具备高效的并行计算能力和快速的数据传输能力，以支持并行训练的效率和可扩展性。而在计算精度方面，通常会使用混合精度计算，即采用较低精度的浮点数进行计算，在关键位置使用较高精度的浮点数进行修正。这也是大模型计算和高性能计算区别较大的地方。
AI推理 AI推理是指在已经训练好的模型上进行实时推断和预测，通常要求在较短的时间内处理大量的数据，例如实时图像识别和语音识别。
GPU具备较低的计算延迟和高吞吐量，能够迅速处理输入数据并输出推理结果，满足实时性要求、AI推理任务主要涉及张量计算，包括矩阵乘法、卷积操作等。NVIDIA在Volta架构及其后续架构（如Ampere架构）中引入了Tensor Core，专门用于深度学习任务重的张量计算，如矩阵乘法和卷积运算。
Tensor Core核心特别大，通常与深度学习框架（如TensorFlow和PyTorch）相结合使用，它可以把整个矩阵都载入寄存器中批量运算，实现十几倍的效率提升。此外，AI推理对于功耗和散热也有一定要求。
性能计算 高性能计算涉及科学计算、数值模拟、天气预报等需要大规模并行计算的领域。在这种场景下，GPU需要具备大量的CUDA核心和高内存带宽，以实现高效的并行计算。此外，高性能计算还需要GPU具备良好的双精度浮点性能和高速的数据传输能力，以应对复杂的计算任务。
GPU系列及参数解读 NVIDIA GPU系列 在了解了GPU基本的应用场景后，我们来看下NVIDIA的显卡主要有哪些？NVIDIA三大主要产品线包括：
 GeForce系列：GeForce系列是NVIDIA面向个人计算和游戏市场推出的产品线。GeForce显卡是用于游戏、图形处理和多媒体应用的高性能图形处理器。GeForce显卡以其强大的图形渲染能力、高帧率和流畅的游戏体验而受到广大游戏爱好者的青睐。 Quadro系列：Quadro系列是NVIDIA专为专业工作站和专业图形应用开发的产品线。Quadro显卡具备专业级的图形渲染和计算能力，适用于CAD、动画制作、电影后期制作等领域。Quadro显卡提供高度可靠性、精确度和稳定性，满足专业用户对精确图形处理和计算的需求。 Tesla系列：Tesla系列是NVIDIA针对高性能计算和人工智能领域推出的产品线。Tesla显卡采用GPU加速计算，具备强大的并行计算能力和高性能计算效率。它们被广泛应用于科学计算、深度学习、大规模数据分析等领域，加速计算任务的执行和模型训练。我们常说的A100、V100都是属于Tesla系列的显卡。  GPU参数解读 我们结合下面这个表格，来看看GPU选型时需要关注哪些参数。
计算能力 计算能力是GPU进行并行计算的指标之一，也是GPU的核心能力。较高的计算能力意味着GPU具备更强大的计算能力和支持更高级的计算功能。具体这些计算参数有什么区别，在应用上有哪些不同呢？我们来一一了解下。
 FP64：双精度浮点数具有较高的精度和范围，可以表示更广泛的数值范围和更精确的小数值。在科学计算、工程模拟和需要高精度计算的应用中常常使用双精度浮点数。 FP32：单精度，作为训练场景的数据格式的标准值。相对于双精度浮点数，单精度浮点数具有较低的精度但更高的计算速度和较小的存储需求。在许多机器学习和深度学习任务中，单精度浮点数已经足够满足计算需求，并且能够加速计算过程。 TF32：从A100开始NVIDIA提出的数据格式。它比FP32精度低，比FP16精度高，主要用于深度学习训练，理论上比FP32+FP16混合精度效果更优； BF16：Intel x86、Arm采用的，主要用于机器学习和深度学习领域。作为一种低精度浮点数格式，可以在一定程度上平衡计算精度和计算效率。它在模型训练和推理中被广泛使用，可以减少存储需求和计算开销，同时仍能保持较高的计算准确性。 FP16：半精度浮点数具有较低的精度但更高的计算速度和较小的存储需求，主要用于推理。 INT8：INT8是一种使用8位（1字节）内存来表示整数的数据类型。相对于浮点数，整数计算通常具有更高的计算效率和较小的存储需求，主要用于推理。  可能光这样看文字，大家不是很好理解，我们拿FP32来做个具体的举例。
FP32长度有32位，其中指数位占8位，精度尾数占23位，最前面是标志位。指数位越大，代表数值越大，精度的长度越多，表示小数点后的精度越高。
显存容量（GPU Memory） 显存是GPU用于存储模型参数、计算中间结果和图像数据等的内存。显存容量的大小直接影响着能否加载和处理大规模的数据和模型。
CUDA Core CUDA Core是NVIDIA GPU上的计算核心单元，用于执行通用的并行计算任务，是最常看到的核心类型。NVIDIA通常用最小的运算单元表示自己的运算能力，CUDA Core指的是一个执行基础运算的处理元件，我们所说的CUDA Core数量，通常对应的是FP32计算单元的数量。
Tensor core Tensor Core是NVIDIA Volta架构及其后续架构（如Ampere架构）中引入的一种特殊计算单元。它们专门用于深度学习任务中的张量计算，如矩阵乘法和卷积运算。Tensor Core核心特别大，通常与深度学习框架（如TensorFlow和PyTorch）相结合使用，它可以把整个矩阵都载入寄存器中批量运算，实现十几倍的效率提升。
接口形式 SXM和PCIe是两种不同的接口形式，SXM接口直接将GPU连接到主板上，而PCIe接口通过插槽与主板连接。SXM接口提供更高的带宽和更低的延迟，适用于高性能计算和数据中心需求。而PCIe接口广泛应用于个人计算机、工作站和服务器等各种计算设备。
如何选择适合业务的GPU？ A100、V100、H100对比 V100是NVIDIA公司推出的高性能计算和人工智能加速器，属于Volta架构，它采用12nm FinFET工艺，拥有5120个CUDA核心和16GB-32GB的HBM2显存，配备第一代Tensor Cores技术，支持AI运算。
A100采用全新的Ampere架构。它拥有高达6912个CUDA核心和40GB的高速HBM2显存。A100还支持第二代NVLink技术，实现快速的GPU到GPU通信，提升大型模型的训练速度。A100增加了功能强大的新第三代Tensor Core，同时增加了对DL和HPC数据类型的全面支持，以及新的稀疏功能，可将吞吐量进一步翻倍。
在跑AI模型时，如果用PyTorch框架，相比上一代V100芯片，A100在BERT模型的训练上性能提升6倍，BERT推断时性能提升7倍。
H100配备132个SM，比A100的108个SM增加了22%。由于采用新的第四代Tensor Core，每个 H100 SM的速度都提升了2倍。在每个Tensor Core中，新的FP8格式和相应的Transformer引擎又将性能提升了2倍。最后，H100中更高的时钟频率将性能再提升了约1.3倍。通过这些改进，总体而言，H100的峰值计算吞吐量大约为A100的6倍。
Tesla A系列简单对比 A100、H100无论是在推理还是大模型训练中的性能都非常突出，但是价格也相对比较高。
我也找了些资料展示下Tesla A系列（A10、A16、A30、A40、A100）在业务能力和在大模型训练和推理上性能的对比，这里就不再赘述了。
相信看到这里，大家对GPU产品选型已经有了一定的想法。在选择时，大家可以参考GPU制造商的官方文档、性能比较表等资源，以获取更详细的信息和比较不同GPU之间的性能特点。当然最重要的是要明确自身业务的计算需求和任务类型。
]]></content>
  </entry>
  
  <entry>
    <title>浅析PWM控制电机转速的原理</title>
    <url>/post/hardware/a-brief-analysis-of-the-principle-of-pwm-control-of-motor-speed.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>PWM</tag>
      <tag>Motor Speed</tag>
    </tags>
    <content type="html"><![CDATA[经常使用的直流电机原理就是电生磁：通电导线会产生磁场。
也就是电磁感应 旋转磁场带动转子转动。
电动机是由定子和转子组成，一个产生旋转磁场，一个为磁极，电机的转子(轴承)就转起来了。
这便实现了电能-&gt;磁能-&gt;机械能的转换。
下面这个图可以更直观的理解：
PWM原理 关于PWM的原理请参照这篇文章： PWM原理及其应用  。
通过上文大概知道，通过PWM控制电机速度，实际上是控制供电电流的大小来实现。
通电导线在磁场中受到的力称为安培力，而安培力的公式：F=BIL。
其中，F是受力大小，I是电流大小，L是导线长度。在其他条件不变的情况下，控制其通过的电流即控制安培力的大小。
电机的电阻R 是基本不变的，那么电流 I = U/R，F= BLU/R。
在R B L不变的情况，控制安培力的大小，本质就是修改供电电压的大小。
我们也就知道，控制电机转速的本质就是给电机供不同的供电电压，电压越大，电机转速越快。
而PWM的本质就是脉宽调制，通过输出不同的占空比，从而将直流电压转换成不同电压值的模拟信号。
控制电机速度 占空比可以实现对电机转速的调节，我们知道，占空比是高电平在一个周期之中的比值，高电平的所占的比值越大，占空比就越大，对于直流电机来讲，电机输出端引脚是高电平电机就可以转动，当输出端高电平时，电机会转动，但是是一点一点的提速，在高电平突然转向低电平时，电机由于电感有防止电流突变的作用是不会停止的，会保持这原有的转速，以此往复，电机的转速就是周期内输出的平均电压值，所以实质上我们调速是将电机处于一种，似停非停，似全速转动又非全速转动的状态，那么在一个周期的平均速度就是我们占空比调出来的速度了。
总结 在电机控制中，电压越大，电机转速越快，而通过PWM输出不同的模拟电压，便可以使电机达到不同的输出转速。
当然，在电机控制中，不同的电机都有其适应的频率 频率太低会导致运动不稳定，如果频率刚好在人耳听觉范围，有时还会听到呼啸声。频率太高的电机可能反应不过来，正常的电机频率在 6-16kHZ之间为好。
输出的电压就不同，电机转速就不同。那我们可以知道，通过滑动变阻器或者更换不同电压的电源都可以实现电机的调速，但是在实际应用中显然PWM更方便些。
专业一点的话就是：
所谓PWM就是脉宽调制器，通过调制器给电机提供一个具有一定频率的脉冲宽度可调的脉冲电。脉冲宽度越大即占空比越大，提供给电机的平均电压越大，电机转速就高。反之脉冲宽度越小，则占空比越越小。提供给电机的平均电压越小，电机转速就低。
本文来源于 浅析PWM控制电机转速的原理  
]]></content>
  </entry>
  
  <entry>
    <title>Intel官方确认：14代酷睿中国特供版快来了</title>
    <url>/post/news/the-14th-core-process-dedicated-for-china-is-coming.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>Intel</tag>
      <tag>Core</tag>
    </tags>
    <content type="html"><![CDATA[ Intel  日前发布了14代酷睿的125W K/KF系列，这只是个开始，后续还有更多型号。
Intel在一次会议期间确认，14代酷睿的65W S系列桌面主流版本、55W HX系列高端移动版即将推出。
如果没什么意外的话，我们会在明年初的CES 2024期间看到它们登场，这也是的多年来的惯例了。
值得一提的是，14代酷睿同样会有针对中国市场的定制特供版本，出自成都封测工厂。
12代有i5-12490F，13代有i5-13490F、i7-13790F，14代继续有类似型号也不例外，但何时发布尚无说法，可能要更晚一些。
至于代号Meteor Lake的全新第一代酷睿Ultra，已经安排在12月14日提前发布，而到了CES上可能会有更多介绍和笔记本产品展示。
酷睿Ultra将带来Intel处理器诞生52年来史上最大的一次变革，首次在消费级领域采用分离式模块化架构，升级全新的Intel 4制造工艺和封装技术、全新的CPU架构与3D高性能混合架构、全新的锐炫GPU核显、全新的NPU AI引擎。
不过，酷睿Ultra仅限主流和轻薄笔记本领域，已知型号包括：
H45系列的酷睿Ultra 9 185H、酷睿Ultra 7 165H/155H、酷睿Ultra 5 135H/125H
U15系列的酷睿Ultra 7 155U、酷睿Ultra 5 125U
U9系列的Ultra 7 164U、酷睿Ultra 5 134U
Emerald Rapids可以视为现有第四代Sapphire Rapids的升级版本，平台兼容，Chiplet设计由四芯片简化为双芯片，但增加到最多64核心128线程，在同样的功耗水平下提供更高的性能和存储速度。
明年，Intel将推出首次纯E核设计的Sierra Forest，最多双芯堆叠288核心288线程，还有纯P核的Clearwater Forest，都升级Intel 3制造工艺。
]]></content>
  </entry>
  
  <entry>
    <title>怎么在Linux中高效运行终端命令</title>
    <url>/post/linux/how-to-execute-console-command-effectively-in-linux.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>command line</tag>
    </tags>
    <content type="html"><![CDATA[在 Linux 中，终端命令是非常重要的，因为它们是与操作系统进行交互的主要方式。以下是一些让你在 Linux 中高效运行终端命令的技巧。
使用历史命令 在终端中输入历史命令的方式是使用方向键向上或向下滚动。此外，你还可以使用以下命令：
 history：显示已输入的历史命令列表。 !!：重复最近的命令。 !&lt;number&gt;：重复一个特定编号的命令。 !&lt;string&gt;：重复以特定字符串开头的最近的命令。  例如，输入 !ls 将运行最近的 ls 命令。
使用别名 你可以设置别名来简化长命令的输入并减少打字次数。例如，将 ls -alh 设置为 ll，可以使用以下命令：
alias ll=&#39;ls -alh&#39; 你可以将别名添加到 ~/.bashrc 中，以便每次启动命令行时都自动设置别名。
使用 Tab 自动补全 当你在输入命令时按下 Tab 键时，它将自动填充所需的命令或路径等。
例如，输入 cd /u/l/b 然后按 Tab 键将自动补全为：
cd /usr/local/bin 此外，你可以使用 Tab 补全文件名、目录、命令和变量名称，以及其他多种选项。
组合使用命令 你可以通过使用管道、重定向、通配符和其他命令来将多个命令组合在一起执行。例如，运行以下命令会将文件 /var/log/messages 中包含关键字 &ldquo;error&rdquo; 的行输出到文件 errors.txt 中：
grep &#34;error&#34; /var/log/messages &gt; errors.txt 使用查找命令 在 Linux 中，你可以使用多个查找命令来查找文件、目录、文本和其他内容。以下是一些最常用的命令：
 find：查找文件和目录。 grep：在文件中查找文本。 locate：通过查找文件数据库来查找文件。  这些命令和其他命令的选项和参数不止于此。你可以查看相关文档以获取更多信息。
使用编辑器 当你需要编辑非常长或复杂的命令时，你可以将其复制到文本编辑器中编辑，然后复制回终端运行。这可以帮助你避免打字错误，并更容易发现和更正错误。
学习和使用快捷键 最后，学习和使用终端快捷键可以节省时间和提高效率。以下是一些常用的快捷键：
 Ctrl + c：停止当前运行的命令。 Ctrl + d：在行首输入此键将关闭当前 shell。 Ctrl + r：在历史命令中搜索。 Ctrl + l：清空终端屏幕。  当然，还有很多其他的快捷键，你可以在文档中查看完整列表。
综上所述，在 Linux 中高效运行终端命令需要使用多种技巧和工具，包括历史命令、别名、Tab 自动补全、命令组合、查找命令、文本编辑器和快捷键。通过使用这些技巧和工具，你可以更快、更准确地使用终端命令。
]]></content>
  </entry>
  
  <entry>
    <title>英特尔停止了CPU热电冷却技术的开发</title>
    <url>/post/server/Intel-stops-development-of-CPU-thermoelectric-cooling-technology.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Intel</tag>
      <tag>CPU</tag>
    </tags>
    <content type="html"><![CDATA[2020 年，英特尔在第十代酷睿“Comet Lake-S”处理器上推出了一种基于热电制冷（TEC）和液体冷却结合的 Cryo 冷却技术，旨在为台式机提供增强的性能和全新的超频体验。
Cryo 冷却技术基于珀耳帖效应，利用硬件、软件和冷却器的组合来精确控制冷却性能。该冷却系统的制造商在水冷头内部集成了热电（TEC）制冷板和控制电路，当 TEC 板通电时，TEC 的冷侧吸收 CPU 热量，而热侧则将热量传递给水冷头内的冷却液，以加快散热速度。系统内的电路和传感器，在智能软件的配合下可监控 CPU 的状况，以确保 CPU 周围不会产生凝露。
图：Cryo 冷却技术利用TEC制冷片+液冷的结合来增强 CPU 冷却
热电冷却利用珀耳帖效应来传递热量，具有结构紧凑和精确温度控制等优点，然而它几乎需要消耗同等的能量来传递热量，急剧增加了系统的能耗，而且还带来了电路板周围水汽冷凝导致的短路风险。
近期，英特尔在其支持页面发布的更新中透露，该公司已停止开发旨在为其顶级处理器提供增强散热的热电效应 Cryo 冷却技术。因此，英特尔将不再为其最新的第 14 代酷睿 &ldquo;Raptor Lake Refresh &ldquo;处理器提供 Cryo Cooling 软件支持。
英特尔公司在声明中写道：&ldquo;截至 2023 年 7 月 1 日，英特尔低温冷却技术解决方案的开发工作已经停止。&ldquo;所有版本的软件均按原样提供。2023 年 12 月 31 日之后，将不再提供功能、注释安全或其他更新。不支持英特尔酷睿处理器第 14 代。请向您的辅助冷却提供商咨询替代解决方案&rdquo;。
图：英特尔声明停止 Cryo 冷却技术的开发（截图自英特尔支持页面）
2020 年，EKWB 和 Cooler Master 相继为第十代酷睿“Comet Lake-S”处理器发布了 Cryo 冷却技术的散热器，然而在英特尔停止开发工作后，这些散热器已不再支持最新的 CPU 。
]]></content>
  </entry>
  
  <entry>
    <title>如何通过命令行重新启动 Linux</title>
    <url>/post/linux/how-to-start-linux-from-command-line-interface.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>command line</tag>
    </tags>
    <content type="html"><![CDATA[使用个人电脑工作的时候，可能会因为各种原因而关闭机器。对于 Linux   初学者来说，与电源相关（关机、重启等）的任务总是最后才想到如何去实现的，所以有可能对于如何重新启动远程服务器不太了解。
今天我们介绍一些可以用来通过终端来重新启动 Linux 系统的命令。
如果想要立刻重新启动 Linux 服务器，可使用如下命令：
reboot now 关机命令如下：
shutdown -r now 重启 Linux 的命令 关于 Linux 系统重启或者关机的命令，主要有以下三种：
 reboot halt poweroff  有一点需要知道，运行比如 halt 命令，特别是在使用选项的时候，可能会导致不稳定的结果，比如内存丢失、数据损坏。所以，在编辑文本的时候不要练习使用这些命令。另外，基于用户权限问题，你需要是 sudo 用户才能运行这些命令。
reboot 命令 reboot 命令语法如下所示：
reboot [options] reboot 将执行 halt 命令的操作，会停止所有的进程，然后系统重新启动，而不触发 ACPI 信号。
halt 命令 halt 命令的语法如下所示：
halt [options] 该命令会发出一个硬件命令，停止所有 CPU 进程。这个命令来自于早先的计算时代，当运行该命令时，会发送一个信号来停止所有进程，一旦这样做是安全的，用户就会收到一个通知，他们可以关闭机器。
现在执行 halt 命令的时候，也会停止所有进程，但是不会发送 ACPI（高级配置和电源接口）信号。
poweroff 命令 poweroff 命令的语法如下：
poweroff [options] 依据惯例，ACPI 信号是“停止”和“关机”之间的区别。你可能会发现，运行 halt 命令实际上会关闭电源，至少没有任何选项。为了确保这一结果，我们希望使用指定的 poweroff 命令。这会执行 halt 操作，但也会向硬件发送关闭电源的信号。
另外，可以使用 shutdown 命令带 -r 选项来重新启动系统。
重启命令的选项 下面我们介绍一些关于上述命令的常用选项。
force 顾名思义，就是强制关闭进程，这也意味着当前正在 ram 中运行的程序有可能会遭到损坏或者数据丢失，还有可能会丢失最近保存的数据。所以一般情况下我们不建议使用 force 选项。
-f --force Force immediate halt/power-off/reboot WTMP only 不执行操作，但是将注销事件写入 var/log/wtmp：
-w --wtmp-only No WTMP 执行指定的操作，但不创建记录。
-d --no-wtmp No Wall 在执行命令之前不发送 wall 消息，这意味着此刻登录到 系统中的用户 不会看到系统将会重启的信息。
--no-wall Don&#39;t send wall message before halt/power-off/reboot ]]></content>
  </entry>
  
  <entry>
    <title>发现了一个很棒的开源项目CSON</title>
    <url>/post/software/one-wonderful-open-source-project-CSON.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>CSON</tag>
      <tag>Android</tag>
      <tag>json</tag>
    </tags>
    <content type="html"><![CDATA[json是目前最为流行的文本数据传输格式，特别是在网络通信上广泛应用，随着物联网的兴起，在嵌入式设备上，也需要开始使用json进行数据传输，那么，如何快速简洁地用C语言进行json的序列化和反序列化呢
前言 当前，应用最广泛的C语言json解析库当属cJSON，但是，使用cJSON读json进行序列化和反序列化，需要根据key一个一个进行处理，会导致代码冗余，逻辑性不强，哪有没有更好的方法呢
思路 在Android平台，一般会使用gson等工具解析json，这些工具将json直接映射成对象，在C语言上使用对象的概念，我们需要借助结构体，然而，最大的问题在于，C语言没有高级语言具有的反射机制，直接从json映射到结构体对象几乎是不可能的
怎么解决呢，既然C语言没有反射机制，那么我们可以自己定义一套类似于反射的机制，这里我将其称之为结构体数据模型，在数据模型中，我们需要准确地描述结构体的特征，包括结构体各成员的名称，类型，在结构体中的偏移，有了这些，我们可以在解析josn的时候，将解析得到的数据直接写入到对应的内存里面去，或者是在序列化的时候，直接从对应的内存中读取数据，进行处理
实现 CSON正是采用上面说到的思路，使用数据模型对结构体进行描述，然后基于cJSON，根据数据模型进行解析，将解析得到的数据直接写入到对应的内存区域，从而实现从json到结构体对象的映射
CSON最基本的数据模型定义如下：
typedef struct cson_model { CsonType type; /**&lt; 数据类型 */ char *key; /**&lt; 元素键值 */ short offset; /**&lt; 元素偏移 */ } CsonModel; 通过type描述结构体成员的数据类型，key描述该成员在json中对应的字段，offset描述该结构体成员在结构体中的偏移，CSON在解析json的时候，根据type调用相应的cJSON API并传递key作为参数，得到解析出的数据，然后根据offset将数据写入到对应的内存空间
比如说这样一个结构体：
struct project { int id; char *name; } 该结构体包含两个成员，对于成员id，我们使用数据模型对其进行描述{.type=CSON_TYPE_CHAR, key=&ldquo;id&rdquo;, offset=0}，对于结构体的每个成员，都进行数据模型的定义，就可以得到一个完整的结构体数据模型，CSON会根据这个模型，进行解析
因为是通过直接写内存的方式，所以在写不同类型的量到内存中时，会多次用到强制转型，导致CSON中赋值的代码都类似于*(int *)((int)obj + model[i].offset) = (int)csonDecodeNumber(json, model[i].key);
当然，上面说到的数据模型，只适用于基本数据类型的数据，对于子结构体，链表，数组等，需要对数据模型的定义进行扩充，有兴趣的朋友可以直接阅读CSON源码
CSON使用实例 声明结构体 /** 项目结构体 */ struct project { int id; char *name; }; /** 仓库结构体 */ struct hub { int id; char *user; struct project *cson; }; 定义数据模型 对每一个需要使用cson的结构体，都需要定义相对应的数据模型
/** 项目结构体数据模型 */ CsonModel projectModel[] = { CSON_MODEL_OBJ(struct project), CSON_MODEL_INT(struct project, id), CSON_MODEL_STRING(struct project, name), }; /** 仓库结构体数据模型 */ CsonModel hubModel[] = { CSON_MODEL_OBJ(struct hub), CSON_MODEL_INT(struct hub, id), CSON_MODEL_STRING(struct hub, user), CSON_MODEL_STRUCT(struct hub, cson, projectModel, sizeof(projectModel)/sizeof(CsonModel)) }; 使用CSON解析 只需要定义好数据模型，就可以使用CSON读json进行序列化和反序列化
void csonDemo(void) { char *jsonDemo = &#34;{\&#34;id\&#34;: 1, \&#34;user\&#34;: \&#34;Letter\&#34;, \&#34;cson\&#34;: {\&#34;id\&#34;: 2, \&#34;name\&#34;: \&#34;cson\&#34;}}&#34;; /** 解析json */ struct hub *pHub = csonDecode(jsonDemo, hubModel, sizeof(hubModel)/sizeof(CsonModel)); printf(&#34;hub: id: %d, user: %s, project id: %d, project name: %s\r\n&#34;, pHub-&gt;id, pHub-&gt;user, pHub-&gt;cson-&gt;id, pHub-&gt;cson-&gt;name); /** 序列化对象 */ char *formatJson = csonEncodeFormatted(pHub, hubModel, sizeof(hubModel)/sizeof(CsonModel)); printf(&#34;format json: %s\r\n&#34;, formatJson); /** 释放结构体对象 */ csonFree(pHub, hubModel, sizeof(hubModel)/sizeof(CsonModel)); /** 释放序列化生成的json字符串 */ csonFreeJson(formatJson); } 运行结果： hub: id: 1, user: Letter, project id: 2, project name: cson format json: { &#34;id&#34;: 1, &#34;user&#34;: &#34;Letter&#34;, &#34;cson&#34;: { &#34;id&#34;: 2, &#34;name&#34;: &#34;cson&#34; } } 可以看到，无论是解析json，还是序列化结构体到json，在使用CSON的情况下，都只需要一行代码就可以解决，同样的操作，在使用原生cJSON的情况下，你可能需要多次判断，解析元素
项目地址 CSON项目已经发布到
Githubhttps://github.com/NevermindZZT/cson ]]></content>
  </entry>
  
  <entry>
    <title>RTX 4090今起正式在国内禁售 强制下架</title>
    <url>/post/news/RTX-4090-is-officially-banned-from-sale-in-China-starting-today.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>NVIDIA</tag>
      <tag>GeForce</tag>
      <tag>GPU</tag>
      <tag>RTX 4090</tag>
    </tags>
    <content type="html"><![CDATA[靴子终于落地。
时间走到11月17日，综合多方面的确切消息，RTX 4090显卡在国内的禁售令正式生效，无法继续生产、出货。
据业内人士称，只要品牌所属公司的主体在中国内地、港澳，就不能继续在国内生产和销售RTX 4090。
理论上，NVIDIA和台系品牌可以向美国商务部申请特批，但需要证明是民用而非商用，是否能得到批准也是未知数。
我们一度以为，在未来一段时间内，玩家仍然能在市面上买到一部分RTX 4090，但都是库存产品，尤其是在禁售前各厂商想尽办法囤积的。
但是很快，NVIDIA就通知各家品牌厂商，下架官方渠道销售的RTX 4090，今后不能再卖单卡，只能以整机预装的方式销售。
目前，各大电商平台上的品牌旗舰店都在陆续撤下RTX 4090，只剩少数品牌仍然在，但也不会保留多久了。
与此同时，NVIDIA中文官网也已经移除了RTX 4090显卡信息。
40系其他产品均正常显示，包括RTX 4060、RTX 4060Ti、RTX 4070、RTX 4070Ti、RTX 4080五款产品。
当然了，对于这种事情，美国方面不可能做出具体的解释，从上游的NVIDIA到下游的AIC品牌厂商也不可能正面回应，所以是不会有官方公开声明的。
早先有说法称，美国商务部允许在出口消费性应用领域申请豁免，RTX 4090得以在中国大陆、香港、澳门市场继续零售，只是不能作为商用，也不能代工、生产。
但是此后，政策发生了变化，RTX 4090在国内被全面禁售，时间被定为11月17日。
而在在二手平台上，有不少加价转卖的情况，有些售价甚至超过5万元，而这块卡的官方建议零售价为1.29万元。
这里我们想提醒大家，除非真的有刚性需求，不建议去抢购、囤积RTX 4090，尤其是不要高价购买。
至于未来能不能在国内买到RTX 4090的“特供版”，就得看NVIDIA和各家品牌厂商的努力了，快科技也会随时给大家带来最新消息。
]]></content>
  </entry>
  
  <entry>
    <title>详细讲解MMU—为什么嵌入式Linux没他不行</title>
    <url>/post/linux/why-embedded-linux-need-mmu.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>embedded linux</tag>
      <tag>mmu</tag>
    </tags>
    <content type="html"><![CDATA[MMU（Memory Management Unit，内存管理单元）是一种硬件模块，用于在 CPU 和内存之间实现虚拟内存管理。
MMU 内存管理 MMU（Memory Management Unit，内存管理单元）是一种硬件模块，用于在 CPU 和内存之间实现虚拟内存管理。
其主要功能是将虚拟地址转换为物理地址，同时提供访问权限的控制和缓存管理等功能。MMU 是现代计算机操作系统中重要的组成部分，可以提高系统的稳定性和安全性。
在内存管理方面，MMU 可以通过页面表（Page Table）实现虚拟内存管理。页面表是一种数据结构，记录了每个虚拟页面和其对应的物理页面之间的映射关系。
当 CPU 发出一个虚拟地址时，MMU 会通过页面表查找并将其转换为对应的物理地址。
此外，MMU 还可以通过页面表实现内存保护和共享等功能，从而提高系统的安全性和效率。
总之，MMU 是内存管理中一个重要的硬件组件，可以实现虚拟内存管理、内存保护、共享和缓存等功能，为现代计算机操作系统的稳定性和安全性提供支持。
举个例子 假设我们有一个程序，它需要访问两个内存区域：一个是只读的代码区域，一个是可读写的数据区域。
我们现在想要在一个没有 MMU 的系统上运行这个程序。如果没有 MMU，代码区域和数据区域就只能被映射到两个固定的物理地址上。这就意味着，如果程序尝试访问一个不正确的地址，可能会导致系统崩溃。
现在，如果我们在一个具有 MMU 的系统上运行这个程序，情况会有所不同。MMU 可以将程序尝试访问的地址映射到不同的物理地址，这样可以使得代码区域和数据区域在物理内存中不再是固定的位置。
这意味着，如果程序尝试访问不正确的地址，MMU 可以通过重新映射来保护系统不崩溃。
MMU 还可以将多个虚拟地址映射到同一个物理地址上，这就是所谓的页共享（page sharing），可以减少物理内存的使用。
如果没有 MMU，程序访问内存时只能使用物理地址，而物理地址是直接映射到内存芯片上的地址，程序可以随意访问任何一个物理地址。
这种情况下，程序如果访问了错误的地址或试图访问未被授权的地址，就会产生访问错误或非法访问，可能导致系统崩溃、数据丢失等问题。
而有了 MMU，程序访问的是虚拟地址，由 MMU 负责将虚拟地址映射到物理地址上，这样程序就无法直接访问物理地址。
同时，MMU 可以根据内存访问权限来限制程序对内存的访问，确保系统的安全性和稳定性。
因此，没有 MMU 时，程序可能会访问到其他地址，而有了 MMU，程序只能访问被允许访问的地址，可以有效地避免非法访问的问题。
为什么相同的虚拟地址空间在物理地址不会发生冲突呢？ 相同的虚拟地址空间在不同的进程中可能会映射到不同的物理地址，这个映射的过程是由 MMU 完成的。在操作系统中，每个进程都有独立的虚拟地址空间，且这些虚拟地址空间互不干扰。
MMU 会将每个进程的虚拟地址映射到对应的物理地址上，使得不同进程间的内存访问不会相互干扰。同时，MMU 也会提供一些安全机制，如页面保护等，来防止进程越界访问内存或访问其他进程的内存。
因此，MMU 起到了保护进程间内存互不干扰的作用，也是现代操作系统的重要组成部分。
页表是什么？ 页表是一种用于存储虚拟内存地址与物理内存地址映射关系的数据结构。在使用虚拟内存的系统中，每个进程都有自己的虚拟地址空间，而这些虚拟地址空间被分割成许多页（通常大小为 4KB 或更大），而不是一整块连续的内存。
因此，当进程需要访问某个虚拟地址时，需要将其翻译成对应的物理地址。这个翻译过程就是通过页表来完成的。
页表的基本原理是将虚拟地址划分成一个页号和一个偏移量。
页号用于在页表中查找对应的物理页帧号，而偏移量则用于计算该虚拟地址在物理页帧中的偏移量。通过这种方式，就可以将虚拟地址映射到物理地址，使得进程可以访问对应的内存区域。
页表一般由操作系统来维护，因为操作系统需要掌握虚拟地址和物理地址之间的映射关系。
在使用 MMU（Memory Management Unit）的硬件支持的系统中，当进程访问虚拟地址时，MMU 会通过页表将虚拟地址转换为物理地址，并将访问指向正确的物理地址。这样，进程就可以在不知道自己真实物理地址的情况下访问内存。
为什么没有 MMU 就无法运行 Linux 系统？ 这是因为 Linux 内核将虚拟地址空间分为多个页面，并将这些页面映射到物理地址空间上，以实现内存隔离、保护和虚拟内存等功能。
没有 MMU，就无法实现这种映射，从而无法运行 Linux 系统。
为什么有些较为简单的 SOC 可能没有 MMU，但仍然可以运行一些嵌入式操作系统或者裸机程序？  RTOS   可以运行在没有 MMU 的系统上，因为 RTOS 通常不需要进行内存保护和虚拟地址映射等高级特性。
相反，RTOS 的设计侧重于实时性和低延迟，因此通常只需要简单的内存管理和任务调度即可。
这使得 RTOS 可以运行在许多嵌入式系统上，包括一些没有 MMU 的系统。
]]></content>
  </entry>
  
  <entry>
    <title>BUCK电路减小输入纹波电压的方法</title>
    <url>/post/hardware/method-to-reduce-input-ripple-voltage-for-buck-circuit.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>Buck Circuit</tag>
      <tag>Ripple</tag>
    </tags>
    <content type="html"><![CDATA[本文讲述了BUCK电路减小输入纹波电压的方法。
简介 &ldquo;BUCK电路输入纹波电压的计算公式和最大值&quot;中分析了BUCK电路输入纹波电压的表达式如下所示：
其中，C_IN 是输入电容[F]，ESR_CIN 是输入电容的等效串联电阻参数[Ω]，F_SW 是开关频率[Hz]，I_OUT 是负载电流[A]，D 是降压电路CCM模式下的占空比[无量纲]。
此文，我们将基于上述公式(3.171)，分析总结BUCK电路减小输入纹波电压的方法。
减小输入纹波电压的方法 基于输入纹波电压公式(3.171)可知：
 在D、 I_OUT 不变的情况下，∆V_CIN 与 ESR_CIN 成正比关系 在D、 I_OUT 不变的情况下，∆V_CIN 与 C_IN 成反比关系 在D、 I_OUT 不变的情况下，∆V_CIN 与 F_SW 成反比关系  所以，理论上，减小 ESR_CIN 、增大 C_IN 和 F_SW ，都可以减小BUCK电路输入纹波电压的大小。
如果输入端使用了大容量的电解电容（通常具有较大的ESR），可以并联ESR较小的陶瓷电容，以达到减小输入端整体ESR，从而减小输入纹波电压的目的。所以，实际上，增大输入端电容 C_IN 的容值和并联低ESR的陶瓷电容，就是通常用于减小输入纹波电压的两种方法。
这是因为：
  BUCK电路的占空比 D=Vout/Vin，在 Vout 不变的条件下，会随着输入电压 Vin 改变的；公式(3.171)中的 D*(1-D) 仅在 D=0.5 时取得最大值0.25，在 D 取其他值时，D*(1-D) 的大小是不固定的；
  在降压电路设计完成或者已经工作之后，负载电流 I_OUT 的大小是由后端负载决定的。虽然实际降压电路中负载电流 I_OUT 的大小会影响输入纹波电压的大小，但是并不能期望通过减小负载电流 I_OUT 这个参数来降低输入纹波电压。所以，才有上述“负载电流 I_OUT 不变”的假设。
  在降压电路设计完成或者已经工作在CCM模式下之后，开关频率 F_SW 这个参数也是固定的，无法通过增大 F_SW 的方法来减小输入纹波电压。
  如果想通过增大 F_SW 减小输入纹波电压，则需要在电路设计时确认好环路响应等其他相关电路参数。但是，需要注意的是，开关频率这个参数是开关电源中“牵一发而动全身”的参数，在已经工作良好的电源电路的基础上，需要谨慎变更开关频率这个参数。
小结 此文，总结了实际应用中减小输入纹波电压的两种方法：增大输入端电容 C_IN 的容值、并联低ESR的陶瓷电容。
另外，输入电容在 PCB Layout 方面最优的摆件方案是：所有输入电容尽量靠近输入电源引脚、从远到输入电源引脚的电容值依次是从大到小（也就是先过滤低频纹波，再过滤高频纹波）。
]]></content>
  </entry>
  
  <entry>
    <title>PCB设计技巧十五问</title>
    <url>/post/hardware/15-questions-on-pcb-design-tips.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>PCB</tag>
      <tag>Crosstalk</tag>
      <tag>impedance</tag>
    </tags>
    <content type="html"><![CDATA[本文讲述了PCB设计相关的技巧!
如何选择PCB板材？ 选择PCB板材必须在满足设计需求和可量产性及成本中间取得平衡点，设计需求包含电气和机构这两部分
通常在设计非常高速的PCB板子(大于GHz的频率)时这材质问题会比较重要。
例如，现在常用的FR-4材质，在几个GHz的频率时的介质损(dielectric loss)会对信号衰减有很大的影响，可能就不合用，就电气而言，要注意介电常数(dielectric constant)和介质损在所设计的频率是否合用。
如何避免高频干扰？ 避免高频干扰的基本思路是尽量降低高频信号电磁场的干扰，也就是所谓的串扰(Crosstalk)，
可用拉大高速信号和模拟信号之间的距离，或加ground guard/shunt traces在模拟信号旁边，还要注意数字地对模拟地的噪声干扰。
在高速设计中，如何解决信号的完整性问题？ 信号完整性基本上是阻抗匹配的问题，而影响阻抗匹配的因素有信号源的架构和输出阻抗(output impedance)，走线的特性阻抗，负载端的特性，走线的拓朴(topology)架构等，解决的方式是靠端接(termination)与调整走线的拓朴。
差分布线方式是如何实现的？ 差分对的布线有两点要注意，一是两条线的长度要尽量一样长，另一是两线的间距(此间距由差分阻抗决定)要一直保持不变，也就是要保持平行，
平行的方式有两种，一为两条线走在同一走线层(side-by-side)，一为两条线走在上下相邻两层(over-under)
一般以前者side-by-side实现的方式较多。
对于只有一个输出端的时钟信号线，如何实现差分布线？ 要用差分布线一定是信号源和接收端也都是差分信号才有意义。
所以对只有一个输出端的时钟信号是无法使用差分布线的。
接收端差分线对之间可否加一匹配电阻？ 接收端差分线对间的匹配电阻通常会加, 其值应等于差分阻抗的值，这样信号品质会好些。
为何差分对的布线要靠近且平行？ 对差分对的布线方式应该要适当的靠近且平行，
所谓适当的靠近是因为这间距会影响到差分阻抗(differential impedance)的值, 此值是设计差分对的重要参数，需要平行也是因为要保持差分阻抗的一致性
若两线忽远忽近, 差分阻抗就会不一致, 就会影响信号完整性(signal integrity)及时间延迟(timing delay)。
如何处理实际布线中的一些理论冲突的问题   基本上, 将模/数地分割隔离是对的，要注意的是信号走线尽量不要跨过有分割的地方(moat), 还有不要让电源和信号的回流电流路径(returning current path)变太大。
  晶振是模拟的正反馈振荡电路, 要有稳定的振荡信号, 必须满足loop gain与phase的规范, 而这模拟信号的振荡规范很容易受到干扰, 即使加ground guard traces可能也无法完全隔离干扰，而且离的太远, 地平面上的噪声也会影响正反馈振荡电路。所以, 一定要将晶振和芯片的距离进可能靠近
  确实高速布线与EMI的要求有很多冲突，但基本原则是因EMI所加的电阻电容或ferrite bead, 不能造成信号的一些电气特性不符合规范，所以, 最好先用安排走线和PCB叠层的技巧来解决或减少EMI的问题, 如高速信号走内层。
  最后才用电阻电容或ferrite bead的方式, 以降低对信号的伤害。
  如何解决高速信号的手工布线和自动布线之间的矛盾？ 现在较强的布线软件的自动布线器大部分都有设定约束条件来控制绕线方式及过孔数目，
各家EDA公司的绕线引擎能力和约束条件的设定项目有时相差甚远。
例如, 是否有足够的约束条件控制蛇行线(serpentine)蜿蜒的方式, 能否控制差分对的走线间距等。
这会影响到自动布线出来的走线方式是否能符合设计者的想法。
另外, 手动调整布线的难易也与绕线引擎的能力有绝对的关系。
例如, 走线的推挤能力, 过孔的推挤能力, 甚至走线对敷铜的推挤能力等等。
所以, 选择一个绕线引擎能力强的布线器, 才是解决之道。
关于test coupon test coupon是用来以TDR (Time Domain Reflectometer) 测量所生产的PCB板的特性阻抗是否满足设计需求。
一般要控制的阻抗有单根线和差分对两种情况。
所以， test coupon上的走线线宽和线距(有差分对时)要与所要控制的线一样，最重要的是测量时接地点的位置。
为了减少接地引线(ground lead)的电感值， TDR探棒(probe)接地的地方通常非常接近量信号的地方(probe tip)， 所以， test coupon上量测信号的点跟接地点的距离和方式要符合所用的探棒。
在高速PCB设计中，信号层的空白区域可以敷铜，而多个信号层的敷铜在接地和接电源上应如何分配？ 一般在空白区域的敷铜绝大部分情况是接地，
只是在高速信号线旁敷铜时要注意敷铜与信号线的距离， 因为所敷的铜会降低一点走线的特性阻抗，
也要注意不要影响到它层的特性阻抗， 例如在dual stripline的结构时。
是否可以把电源平面上面的信号线使用微带线模型计算特性阻抗？ 电源和地平面之间的信号是否可以使用带状线模型计算？
是的， 在计算特性阻抗时电源平面跟地平面都必须视为参考平面。
例如四层板: 顶层-电源层-地层-底层， 这时顶层走线特性阻抗的模型是以电源平面为参考平面的微带线模型。
在高密度印制板上通过软件自动产生测试点一般情况下能满足大批量生产的测试要求吗？ 一般软件自动产生测试点是否满足测试需求必须看对加测试点的规范是否符合测试机具的要求。
另外，如果走线太密且加测试点的规范比较严，则有可能没办法自动对每段线都加上测试点，当然，需要手动补齐所要测试的地方。
添加测试点会不会影响高速信号的质量？ 至于会不会影响信号质量就要看加测试点的方式和信号到底多快而定。
基本上外加的测试点(不用线上既有的穿孔(via or DIP pin)当测试点)可能加在线上或是从线上拉一小段线出来。
前者相当于是加上一个很小的电容在线上，后者则是多了一段分支。
这两个情况都会对高速信号多多少少会有点影响，影响的程度就跟信号的频率速度和信号缘变化率(edge rate)有关。
影响大小可透过仿真得知
原则上测试点越小越好(当然还要满足测试机具的要求)分支越短越好。
若干PCB组成系统，各板之间的地线应如何连接？ 各个PCB板子相互连接之间的信号或电源在动作时，例如A板子有电源或信号送到B板子，一定会有等量的电流从地层流回到A板子 (此为Kirchoff current law)
这地层上的电流会找阻抗最小的地方流回去。
所以，在各个不管是电源或信号相互连接的接口处，分配给地层的管脚数不能太少，以降低阻抗，这样可以降低地层上的噪声。
另外，也可以分析整个电流环路，尤其是电流较大的部分，调整地层或地线的接法，来控制电流的走法(例如，在某处制造低阻抗，让大部分的电流从这个地方走)，降低对其它较敏感信号的影响。
]]></content>
  </entry>
  
  <entry>
    <title>25G/50G/100G以太网技术</title>
    <url>/post/server/25G-50G-100G-ethernet-technology.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Ethernet</tag>
      <tag>25G</tag>
      <tag>50G</tag>
      <tag>100G</tag>
    </tags>
    <content type="html"><![CDATA[在过去十年里，10G和40G技术占据了以太网市场的大部分。但随着用户对高带宽的需求以及特殊应用的发展需求， 25G/50G/100G  技术越来越受用户关注，它们凭借着能为高速率提供有效路径，逐渐在网络部署中脱颖而出。下面我们将着重介绍25G/50G/100G技术及其三者的关系。
25G 技术 25G以太网标准是2016年由IEEE面向云数据中心中服务器特推出的标准，该标准推出时间比10G/40G/100G以太网标准晚几年。
25G主要的优势是采用了SerDes技术，该技术是一种主流的时分多路复用（TDM）、点对点（P2P）的串行通信技术，它可充分利用传输媒体的信道容量，最大程度上减少所需的传输信道和器件引脚数目，从而提高信号的传输速率，大大降低通信成本。
目前，大多数交换机中使用的组件都运行的是时钟速率大约为10Ghz的SerDes，在不同组件间可提供10Gbps的传输速率。近年来由于SerDes技术快速发展，时钟速率为25Ghz的SerDes已成为经济上可行的选择之一，这导致10G和40G与25G在成本和效益上产生了差异性。
10G VS 25G 同样是一条SerDes通道，25G提供的吞吐量比10G所提供的吞吐量高出2.5倍。当10G网络升级到25G时，由于25G SFP28光模块可以使用10G网络布线时所用的LC跳线，无需重新布线，因此可有效节省成本。
40G VS 25G 40G采用4条10Gbps光纤通道（时钟速率为12.5Ghz的SerDes），而25G是采用的SerDes单通道，因此25G可提供更高端口密度。与此同时，由于市面上大多数的40G QSFP+光模块需要与MTP/MPO跳线搭配使用，因此10G-40G不可避免会增加线缆成本。
50G 技术 随着25G技术的成熟化以及用户对更高速率的要求，业界对50G抱有强烈的期待，2018年IEEE推出了与400G/200G以太网标准架构相同的50G以太网标准，该标准采用了PAM4技术，可有效提高带宽利用效率，成为了下一个高速连接服务器和数据中心的解决方案。
由于50G可以重复使用现有100G网络中25G的组件，因此可以有效降低成本。与此同时，50G成本是40G成本的一半，但其性能却提升了25%。
由于PAM4技术是将成对的比特映射单个符号中，因此每条50Gbit/s通道的总波特率为26.5625 Gbaud。50Gbaud PAM4可通过1250 Gbaud架构（仅需一个激光器）提供100G传输速率，这代表着使用一个激光器就可以将传输速率从10Gbps提升到100Gbps，足足增长了十倍。
与早期的NRZ技术相比，PAM4技术可以较低的成本提供更高的传输效率，因此被广泛应用于高速信号互联中。
100G 技术 100G以太网于2010年正式发布，后为了满足高速率、远距离以及某些特殊场景的需求，对该标准做出了大范围更改。正因标准的不断优化、技术方案的统一、产业链的发展以及带来的更高传输速率和更远传输距离（采用DWDM技术）等原因，100G正在逐步取代40G。
100G DWDM技术可在单个波长上实现远距离高容量的信号传输，尤其适用于高速光通信。其中，相干CFP DWDM光模块尤其适用于100G 城域网（MAN）或高达80千米的数据中心互连（DCI）或传输距离超过1000千米的超长链路。目前超100G DWDM技术也已经在DCI场景中商用。
此外，在多速率和多协议的网络情况下（如10G/40G/100G以太网协议和速率下），使用100G及超100G DWDM复用转发器可有效避免网络架构的重新设计及规划，它能直接将不同协议和不同速率的信号复合成高达100G/200G/400G的单个波长进行传输，提供灵活性高且具有成本效益的解决方案。
25G/50G/100G相关性 现在25G/50G/100G被广泛应用在云数据中心，且三者若是集合在一起可以实现10G-25G-50G-100G网络升级，而在25G和50G出现之前，100G网络升级都是通过10G-40G-100G方式实现，但该种方式效率低且成本贵。
相比之下，25G是升级到100G最具有成本效益的解决方案。若是采用25G进行100G网络升级可采用脊叶架构通过425G或者250G SerDes通道来实现，这样一来，25G可凭借着其兼容性基于现有的布线基础设施实现网络升级，提供更高传输效率和性能的同时，节省了资本性支出（CAPEX）和运营成本（OPEX）。
总而言之，25G-50G-100G网络升级路径可通过充分利用交换机端口功能降低单位带宽成本，同时为200G、400G网络升级奠定基础。
结语 25G/50G/100G可以很好地适应市场的需求，引领行业潮流。与早前的10G/40G相比，25G/50G/100G采用了先进的技术，在成本和性能方面具有一定的优势，无疑是目前最具有成本效益的解决方案。
]]></content>
  </entry>
  
  <entry>
    <title>Linux Shell 脚本监控磁盘利用率</title>
    <url>/post/linux/use-linux-shell-script-to-monitor-disk-usage.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>shell scripte</tag>
    </tags>
    <content type="html"><![CDATA[这是一个用于监控服务器磁盘利用率的shell脚本，它的功能和意义如下：
  第一行是一个特殊的注释，用于指定执行这个脚本的解释器，这里是bash。
  第三行到第十行是一些变量的定义，用于设置监控的参数，比如要监控哪些磁盘分区，报警的阈值是多少，检测的频率是多少，日志文件的位置和名称是什么等。
  第十二行到第二十四行是一个函数的定义，叫做send_mail，它的作用是发送邮件给指定的收件人，告知他们哪些磁盘分区已经超过了阈值。这个函数需要一个参数，就是超过阈值的分区名称和利用率。
  第二十六行到第四十八行是另一个函数的定义，叫做monitor_disk，它是主循环函数，它的作用是不断地检测磁盘利用率，并且如果发现有超过阈值的情况，就调用send_mail函数发送邮件，并且记录日志文件。这个函数没有参数，但是会使用前面定义的一些变量。
  第五十行是调用monitor_disk函数的语句，这样就可以开始执行监控任务了。
  #!/bin/bash # 监控服务器磁盘利用率的shell脚本 # 定义要监控的磁盘分区，可以有多个，用空格隔开 PARTITIONS=&#34;/dev/sda1 /dev/sdb1&#34; # 定义报警阈值，单位为百分比 THRESHOLD=80 # 定义检测频率，单位为秒 INTERVAL=60 # 定义日志文件的路径和名称 LOGFILE=/tmp/disk_monitor.log # 定义邮件发送函数，需要安装mailx命令 send_mail(){ # 定义收件人邮箱地址，可以有多个，用空格隔开 MAILTO=&#34;user1@example.com user2@example.com&#34; # 定义邮件主题 SUBJECT=&#34;Disk Usage Alert&#34; # 定义邮件正文 MESSAGE=&#34;The following partitions have reached the threshold of $THRESHOLD%: $1&#34; # 发送邮件 echo $MESSAGE | mailx -s &#34;$SUBJECT&#34; $MAILTO } # 定义主循环函数 monitor_disk(){ while true do # 获取当前时间 DATE=$(date &#34;+%Y-%m-%d %H:%M:%S&#34;) # 遍历要监控的磁盘分区 for PARTITION in $PARTITIONS do # 获取磁盘利用率，去掉百分号 USAGE=$(df -h | grep $PARTITION | awk &#39;{print $5}&#39; | sed &#39;s/%//&#39;) # 判断是否超过阈值 if [ $USAGE -ge $THRESHOLD ] then # 记录日志文件 echo &#34;$DATE$PARTITIONusage: $USAGE%&#34; &gt;&gt; $LOGFILE # 调用邮件发送函数，传入超过阈值的分区名称和利用率 send_mail &#34;$PARTITIONusage: $USAGE%&#34; fi done # 等待一定时间后再次检测 sleep $INTERVAL done } # 调用主循环函数 monitor_disk ]]></content>
  </entry>
  
  <entry>
    <title>UART通信</title>
    <url>/post/hardware/uart-communication.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>UART</tag>
    </tags>
    <content type="html"><![CDATA[UART——通用异步收发传输器，UART 作为异步串口通信协议的一种，工作原理是将传输数据的每个字符一位接一位地传输。在应用程序开发过程中使用频率较高的数据总线。 基于UART的数据传输是异步形式的串行数据传输。基于UART的串行数据传输不需要使用时钟信号来同步传输的发送端和接收端，而是依赖于发送设备和接收设备之间预定义的配置。
对于发送设备和接收设备来说，两者的串行通信配置（波特率、单位字的位数、奇偶校验、起始位数与结束位、流量控制）应该设置为完全相同。通过在数据流中插入特定的比特序列，可以指示通信的开始与结束。当发送一个字节数据的时候，需要在比特流的开头加上起始位，并在比特流的末尾加上结束位。数据字节的最低位紧接在起始位之后。
UART 串口的特点是将数据一位一位地顺序传送，只要2 根传输线就可以实现双向通信，一根线发送数据的同时用另一根线接收数据。
UART 串口通信有几个重要的参数，分别是波特率、起始位、数据位、停止位和奇偶检验位，对于两个使用UART 串口通信的端口，这些参数必须匹配，否则通
 起始位：表示数据传输的开始，电平逻辑为“0” 。 数据位：可能值有5、6、7、8、9，表示传输这几个bit 位数据。一般取值为8，因为一个ASCII 字符值为8 位。 奇偶校验位：用于接收方对接收到的数据进行校验，校验“1” 的位数为偶数(偶校验) 或奇数(奇校验)，以此来校验数据传送的正确性，使用时不需要此位也可以。 停止位：表示一帧数据的结束。电平逻辑为“1”。 波特率：串口通信时的速率，它用单位时间内传输的二进制代码的有效位(bit) 数来表示，其单位为每秒比特数bit/s(bps)。常见的波特率值有4800、9600、14400、38400、115200 等，数值越大数据传输的越快，波特率为115200 表示每秒钟传输115200 位数据。  引用地址： UART通信  
]]></content>
  </entry>
  
  <entry>
    <title>今年全球最大IPO即将诞生</title>
    <url>/post/news/arm-ipo-on-the-way.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>ARM</tag>
      <tag>IPO</tag>
    </tags>
    <content type="html"><![CDATA[ Arm  在被英伟达收购未果后开始寻求IPO方案，如果上市，该公司也将成为今年全球规模最大的IPO，有望重振全球低迷的IPO市场。
作者 | 第一财经 钱童心
软银旗下芯片设计公司Arm当地时间周一正式向美国证监会递交IPO申请。如果进展顺利，Arm将于下个月在纳斯达克上市。
Arm在被英伟达收购未果后开始寻求IPO方案，如果上市，该公司也将成为今年全球规模最大的IPO，有望重振全球低迷的IPO市场。
根据路透社消息，软银计划在IPO中出售Arm约10%的股份，并寻求600亿至700亿美元的估值；报道还称，苹果、亚马逊和英伟达等多家科技公司正在考虑成为Arm IPO的基石投资者，不过Arm方面未就此向第一财经记者作出回应。
Arm还希望进入AI云计算等领域实现增长，尽管这一努力目前收效尚不明显。
根据Arm最新披露的IPO文件，在截至今年3月31日的财年中，Arm的销售额下降1%至26.8亿美元，主要受到全球智能手机出货量下滑的影响。Arm截至6月30日的季度销售额下降2.5%至6.75亿美元。
Arm表示，2023财年中，全球出货的超过300亿颗芯片包含了Arm的技术。Arm超过50%的技术授权许可费收入来自智能手机和消费电子产品。而随着全球智能手机市场增长可能跌至十年来的最低点，Arm的收入模式也遭遇挑战。但Arm表示，新技术可能会在每颗芯片上产生更高的授权费。
值得关注的是，Arm近一个财年收入的24%来自中国。安谋科技是Arm最大的客户，也是Arm中国全部的收入来源。安谋科技独立于Arm，Arm仅间接持有其4.8%的股份。
Arm预计，随着美国和英国政府实施的出口管制，未来在中国的技术授权使用费可能会进一步下降。
Arm芯片设计已经开始用于苹果、亚马逊等科技巨头的自研芯片上，此外，Arm的技术还在云计算领域占据了全球约10%的市场份额，Arm架构的芯片主要用于网络以及数据中心服务器中的CPU。
在全球人工智能的热潮推动下，全球 数据中心  的增长前景可观。然而，业内质疑Arm仍游走在数据中心的边缘，并未打入核心市场。机器学习巨大的数据处理需求带来了GPU和网络芯片等加速数据处理器的销量激增，尽管英伟达的GPU需要结合Arm的CPU，例如英伟达最新发布的“超级芯片”GH200就包含基于Arm架构的CPU。
但业内认为，Arm技术在管理数据处理和传输功能方面仅发挥了辅助作用。“从某种程度上，Arm可以搭上英伟达的‘顺风车’，但并非所有英伟达的GPU都必须与Arm的CPU一起销售。”研究机构New Street Research分析师Rolf Bulk在报告中写道。他认为，Arm的真正机会仍然在于人工智能和机器学习从集中式云服务器转向最终用户使用的设备，例如手机、家用电器和机械部件等。
研究机构Gartner分析师盛陵海也对第一财经记者表示：“Arm没有GPU加速AI，从这波AI浪潮中获益不多。”
对此，Arm在IPO文件中强调，其技术对于人工智能应用仍然至关重要。Arm表示：“CPU在所有人工智能系统中都至关重要，无论是完全处理人工智能工作负载，还是与GPU或NPU等处理器协同使用。”
软银集团董事长CEO孙正义今年6月向投资者表示：“Arm将因人工智能的蓬勃发展实现指数级增长。Arm的技术是人工智能相关公司的核心，能够产生协同效应。”他还表示，软银资产的85%以上都与人工智能领域相关，Arm将在ChatGPT这类发明创造方面发挥重要作用。
不过Arm的IPO文件并未提供更多关于Arm人工智能战略的细节和线索。咨询公司Astris日本分析师Kirk Boodry表示：“OpenAI推出了可以利用大型语言模型来创建内容的工具，这一切主要是基于软件和平台，Arm与此没有任何关系。”Boodry给出的Arm估值约为470亿美元。
]]></content>
  </entry>
  
  <entry>
    <title>高端存储进化：技术和架构的革新</title>
    <url>/post/server/the-challenges-and-opportunities-for-high-end-storage.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Storage</tag>
    </tags>
    <content type="html"><![CDATA[在我们的讨论中，我们深入探讨了关于单体和分布式、可扩展的存储系统的话题，以了解Rob对高端存储发展的观点。他认为，FC的未来发展可能受限，并预测高端存储将与三大主要公有云平台进行集成。
Chris Mellor：高端块存储与双控制器存储有何区别？
Rob Young：可扩展性和可靠性。高端存储产品具备更多的可插拔端口和更大的吞吐量。就可靠性而言，随着Intel设备在高端和低端领域的广泛应用，多年来已经为高端产品和低端产品提供了更多的RAS（可靠性、可用性、可维护性）功能。高端产品在电源供应和其它一些组件方面的差距正在缩小（在某些情况下，由于物理上的限制，低端产品中无法容纳大型电源等组件）。而Infinidat的Infinibox在所有组件上都采用了N+2的配置，包括基于Intel的控制器头。IBM的DS8000系列基于Power架构，在RAS方面表现出色。
然而，不容忽视的是高端存储的历史。经过几十年的高端存储在实际运营中积累的稳定服务流程和丰富的熟练人员，对于在紧急情况下进行故障排除和维护企业级存储具有巨大优势。例如，我曾在一个现场遇到过一种情况，使用了新的存储解决方案，但现场人员没有完全按照不太清晰的步骤进行操作，结果导致了一次故障 —— 幸运的是，在正式投入使用之前就及时解决了问题。
Chris Mellor：高端存储制造商在当今市场面临哪些架构问题？
Rob Young：这是个有趣的问题。我最近就这个话题进行了几次讨论。历史是祝福，也是诅咒。问题在于，20年前的创新技术，在今天可能已经过时了。但是，如果企业级存储系统已经使用了很长时间，并且技术团队没有参与过更换的决策，那么贸然更换可能会导致不良的业务结果。
我在多个场合都亲眼目睹了这种情况。新的CIO、新的IT主管以及新的供应商推出了与你目前正在使用的解决方案不同的产品。多年来积累的流程和部门内部知识，不可能在短时间内就能轻易掌握。新进厂商在一定程度上缓解了这个问题。他们的API更易于使用，GUI界面更加友好，流程更加简化，使用HTML5取代Java，数据迁移在较少的历史操作系统情况下变得更加简单等等。在本地有PB级数据的情况下，甚至可以在一周内迁移测试/开发环境。
有些设计困于过时，创新进展缓慢，而新增功能则需要在引入过程中进行冻结。相比之下，Qumulo通过每两周一次的代码推送来透明地改变数据保护方式（2015年的一篇博客描述了他们如何逐步交付纠删码功能）。我指出，有一家供应商将永远无法将超过1000万行代码的高端存储迁移到云上。这种担忧是有原因的。我们应该预计，在RFP（请求报价）中，会出现这样一个选项：将同一存储同时放置在本地和三大主要云平台上。在那个时候，没有提供类似云端选项的存储供应商将陷入困境。这种情况可能已经在发生中；不过，我个人尚未亲眼见过。
Chris Mellor：纵向扩展（scale-up）和横向扩展（scale-out）在应对这些问题时效果如何？
Rob Young：一个有益的对比是Pure Storage/IBM/Dell/NetApp的中档产品与传统高端产品。可以在数据中心中分布多个双控存储，而数据中心本身可能在不同区域具有多个电源输入。通过在主机/操作系统/应用层面充分利用布局，极大地提高了可用性，并相应地进行了实施。这种逐步扩展的性质显然具有优势，并且具有单一的管理界面。
关于横向扩展，或许可以使用“一统全局”的方式？我们已经看到一些供应商将文件存储整合到传统的块存储中（Pure就是一个最近的例子），现在我们将会看到块存储逐渐融入传统的文件存储。Qumulo/PowerStore/Pure/Netapp可能会成为你处理各种需求的统一存储解决方案，但从架构的角度来看，这并不能给你带来那种踏实的感觉。例如，你不会希望备份数据流入与企业级存储相同的存储中。
不仅仅是勒索病毒，还有数据损坏的情况 —— 虽然罕见，但确实发生过。有很多理由，你不希望备份与你正在备份的企业数据存储在同一个存储中。我们已经见过这种情况。
关于横向扩展，我有一个总结性的观点。我认为未来 3-5 年，光纤通道将会被彻底取代，这将是一场重大的变革。为什么这么说呢？因为100Gbit以太网端口的成本将变得“便宜”，这将使我们终于能够像云服务商一样将网络和存储结合起来。目前，大多数大型企业使用独立的存储网络（例如SAN/FC），这使得存储流量与常规网络流量不会相互干扰。然而，随着廉价的100Gbit以太网的普及，这两者将开始融合在一起，就像云服务商一样。这不仅将带来便利，还将带来诸多优势。
另一个好处是，深入的传统FC SAN技能将不再是企业的需求，就像今天一样。这需要时间，但诸如NVMe的协议最终将走向端到端。
Chris Mellor：内存缓存（Infinidat风格）是否具有普适吸引力？它应该成为一种标准方法吗？
Rob Young：当我们谈论“内存缓存”时，我们指的是Infinidat所称的Neural Cache的独特方案。它能够显著加速I/O操作。归根结底，一切都与I/O有关。我撰写了一篇详细的文章，详细介绍了他们是如何实现这一点的，这实在是一项令人惊叹的工程成就。他们采用了Edward Fredkin的（他于6月去世，享年88岁；他是一位令人惊叹的多面手！）前缀树，Google使用这种方法在你输入时为下一个单词提供提示。
Infinidat使用这一方法来通过时间戳跟踪每个64K数据块，并且通过这个方法可以预先将接下来的一系列I/O加载到内存中。这导致了控制器内存的命中率高达90%以上。吸引力是不言而喻的，因为每个人都在努力加速日终和月末的运行。有时这些运行可能会出现问题，此时管理层会催促你何时能够重新运行。我们都有许多原因希望变得越来越快。Brian Carmody（前Infinidat CTO，现在在Volumez任职）谦虚地描述了他们最早执行Neural Cache的经历。
这种说法让我感到困惑。你看，有几项已经授予专利，涵盖了Infinidat正在进行的缓存工作。除非我漏掉了什么明显的事实，否则在专利过期之前，其它公司不会采取Infinidat所做的工作。
与此同时，有一些技术正在悄然逼近。我们看到控制器设计中出现了更大的内存。我猜测，将整个逻辑单元集成到内存中以弥补内存缓存I/O命中的差距可能正在逼近。
Infinidat的经典（磁盘）存储在随机读取I/O方面具有微小的挑战，在一些似乎具有部分随机I/O的应用中，他们的SSA（全闪存）系统解决了这种挑战。我们了解到Infinibox SSA的小块随机I/O（数据库事务I/O）具有300μs的上限延迟，这个数字引起了我们的注意。我们还看到Volumez将其小块I/O描述为316μs的延迟（包括与主机的通信，总共360μs），AWS的虚拟存储控制器显示其对NVMe-oF R5b实例的小块I/O读取为353μs（似乎是相同的临时后端）。
虽然其它供应商也会宣称自己的数字出色，但是细节却很有限，没有公开的细节数据。关键是，Infinidat似乎将位于延迟金字塔的顶端，其它几家则在300μs的水平，并通过PCI（云/VSAN）NVMe SSD进行直接连接。
我们会看到比300μs更快的端到端延迟吗？是的，甚至可能在今天就悄然存在。也许在下一代SLC变得更便宜（更普遍，或者下一代快速技术出现）时，我们会看到尺寸适中的SLC解决方案，其最大的小型I/O延迟在50-80μs的范围内（往返）。DSSD又焕发新生！最后，在大多数供应商中，小型I/O的内存读取缓存命中会是怎样的情况？对于大多数供应商来说，少于50μs，而Infinidat公开展示的实际速度甚至低于40μs。
Chris Mellor：专有闪存相对于商用现成产品具有哪些优势？
Rob Young：Pure Storage在其DirectFlash管理自定义模块方面展示了优势，通过零过度配置消除了垃圾收集和写放大。零过度配置意味着你得到你所支付的价值。VAST Data采用了类似的方案，使用了便宜的现成商用产品（COTS，Commercial Off-The-Shelf）QLC SSD（按他们的说法）。他们卓越的算法结合了耐久级别跟踪单元历史，如此轻微的操作，以至于他们的服务条款将在10年内更换磨损的QLC SSD。同样，我们了解到当PLC成为一种技术选择时，VAST定位于从与QLC SSD一起工作的1000次擦写周期转向500次的PLC擦写周期。
定制设计的优势是什么？就像Pure一样，它可以创建非常大的模块（目前为75TB），以在5个机架单位的空间中堆叠大量数据。SSD更加密集和节能。IBM的定制FCM速度非常快（低延迟是显著的FCM定制优势），并且具有内置和透明的零开销压缩。在当前情况下，随着模块级定制压缩的出现，这种优势在一定程度上减少。Intel已将QAT（QuickAssist Technology）技术整合到CPU中，压缩现在在CPU上进行。在2021年引入时，QAT成为了最新技术。曾经，Intel为存储OEM提供了单独的压缩卡。我不想深入讨论这一点。
让我们简要地分析一下对QLC技术的一些应用。Pure公司声称他们的QLC解决方案具备2至4毫秒的IO（读取）响应时间。在2023年，这是否适合作为一个事务性解决方案呢？实际上不太适合。这更适用于二级解决方案 —— 作为备份目标、用于AI/ML、用于Windows共享、处理大量I/O和带宽等。这非常符合他们的目标受众。
因此，在我们探讨这些解决方案时，要记住并非所有情况都适用于同一种解决方案，特别是对于事务性工作负载。并不存在适用于所有情况的通用解决方案。尽管如此，让我们关注最近Solidigm发布的D5-P5336产品。他们展示了一个110微秒的小块随机读取性能，被描述为在QLC封装中实现了TLC性能。这一性能比VAST目前使用的QLC快了5倍，对那些专注于商用解决方案的人们来说，无疑产生了重要的影响。
Chris Mellor：在云中使用临时存储的高速块存储存储实例，是否像Silk和Volumez一样，对本地块存储存储构成威胁？
Rob Young：Volumez是一个有意思的新兴厂商。我们已经看到Intersystems成为早期展示客户，他们正在使用Volumez进行基于云的Iris分析。而Volumez引人注目的地方在于其控制平面位于云中。
本地化存储增长停滞不前，而云存储在迅速增长。这些解决方案对本地化存储的威胁不会比自然发展的变化更大。
此外，Volumez采用了一种Kubernetes策略。是的，下一代开发着重于K8s，但许多企业就像航空母舰一样，变革进程缓慢。令人不意外的是，由于云端成本通常高于本地，我们预计某个时刻Volumez的客户可能会采取合理的做法，将测试/开发环境保留在本地，将生产环境置于云服务商中。在某些情况下，生产环境之所以置于云端，仅是为了为相邻的分析提供数据源，而且它的占用空间比测试/开发环境小。从此时开始，云端将主要主导分析领域，共享云的巨大规模几乎已经确保了这一趋势。
Chris Mellor：这些基于临时存储的公有云存储实例如何在本地重现？
Rob Young：Carmody告诉我们，将会出现一种本地版本的Volumez。与Volumez类似，AWS的VSA也使用临时存储。如何实现呢？在高速网络上使用JBOF，可能需要一段时间才能变得普遍，但供应商已经有了相关产品。
云在网络领域具有巨大的优势。企业的本地化部署在这方面滞后于云，其提供方式有所不同（传统的三层VM和独立的存储/网络）。Volumez/AWS VSA共同之处在于，它们没有我们所熟悉的传统存储控制器。
VAST Data的D节点是直通存储控制器，它们不会在本地缓存数据。VAST Data之所以能够这样做，是因为所有写入都在SCM中捕获（还有其它原因）。Glenn Lockwood在2019年2月写了一篇非常好的文章，描述了VAST Data的架构。有趣的是评论中的讨论，有猜测认为透传式D节点是一个理想的候选方案，可以过渡到直接的基于Fabric的JBOF连接方式。
就在这些评论之前，VAST Data的联合创始人Renen Hallak在Storage Field Day上谈到了以太网驱动器的潜在重现。在那一点上，直通存储控制器已经不再起作用。它才刚刚开始，企业的选择有限，但像VAST Data、Volumez和其它公司应该会推动基于网络的JBOF应用。无服务器基础设施正在向无控制器基础设施发展。这里有些遐想，但我们可以预见，几种存储解决方案将不再需要控制器，控制平面位于云中，轻松地在云和本地之间切换。对于软件领域的年轻人来说，“硬件是一种必须容忍的东西”是我们从新一代存储中看到的态度。
Chris Mellor：块存储如何利用CXL、内存池化和共享？
Rob Young：由于它是存储，基于CXL的内存池化是非常合适的。服务器基于CXL内存的250纳秒访问时间？论坛上有很多关于这个问题的讨论。从我的角度来看，如果本地内存比基于网络的内存快3-4倍，那么它可能在服务器领域很难推广。然而，正如上面提到的，将250纳秒的延迟添加到I/O流量中并不是一个问题。你可以看到，4、6、8、16个PowerMAX节点共享共同的CXL内存，在成本节省和允许Dell的PowerMAX和其它高端设计之间实现许多缓存共享的好处。
Chris Mellor：所有块存储是否都应该像Dell的PowerStore和NetApp的ONTAP那样提供文件存储？有哪些支持和反对的论点？
Rob Young：我在上面稍微提到了一些。反对的论点是功能的划分，限制了影响范围。只提供块存储也不是坏事。如果你在使用一个具有独立嵌入式存储的备份解决方案，那是一回事。但是，如果你作为客户需要将NFS共享呈现为备份目标，无论是在客户端本地还是备份服务器本身，你都必须进行分隔。正如前面提到的，Pure现在已将文件整合到了他们的块存储中，实现了统一的块和文件存储。
传统的高端存储仅支持块（或具有可疑功能的附加NFS）。Infinidat声称他们的15%客户仅使用他们的Infinibox作为文件存储，40%同时使用块和文件。支持的论点在于，如果我们看一下Infinidat，市场上是有需求的。同样地，Pure现在变成了最初的块/文件NetApp。如果可以的话，合并是一个有说服力的商业场景，或者将同一供应商的块用于一组存储，文件用于另一组。规模较小的场景和预算有限的机构也会进行组合。
反对的论点是将数据按不同目标分隔开（例如，用于生产等用途），并且客户的架构偏好会起主导作用。在这方面有很多技巧，没有一个固定的“标准做法”。我想提及一个隐藏的优势以及关于其他供应商的一个警告。Infinidat在NAS中使用虚拟MAC地址（Pure也是如此 - 据我所知）进行IP寻址。当控制器由于故障或升级而重新启动时，将IP地址平稳地切换到另一个控制器，几乎是瞬间完成的，而且对交换机来说是透明的。这种方法避免了不必要的ARP请求。与之相比，这里提到的某些解决方案之一（当然不只一个）通常需要长达60秒的IP故障转移时间，因为它涉及到ARP的处理。这使得供应商我所提到的那家公司的ESXi数据存储的NFS共享变得问题重重，而且他们并不是孤例。至于Infinidat的15%客户仅使用NFS/SMB的问题，其中许多客户将NFS用于ESXi环境。这些信息来自于Gartner的Peer Insights，可谓宝贵的资源。
Chris Mellor：像VAST Data、Qumulo和PowerScale这样的横向扩展文件存储，可能比块存储更受青睐，你怎么看？
Rob Young：简单的递增增长。多功能性。尽管可能存在矛盾的风险，但在一个平台上支持Windows共享、S3和NFS访问（但不包括备份！）
相同的API/界面带来了SMB的巨大优势，一个存储用作文件，另一个用作块存储。在VAST和Qumulo中，更现代的特性包括免费内置分析功能。在某些情况下，支持iSCSI/NFS的事务性IO目标（需注意一些限制）。Qumulo和PowerScale提供多种驱动器选择。NLSAS要便宜得多 - 仍然是 - 在这个问题上要注意别被吓坏了哦！对于一些应用程序，你需要便宜且大容量的存储。其中之一就是视频监控。这对于去重和压缩来说非常不友好。
就VAST Data的情况，你将会为即将到来的海量数据做好充分准备。VAST的Jeff Denworth撰写了一篇名为《传统NAS的致命一击》的文章，基本上指出高带宽即将带来重大影响。自从我读了那篇文章以来，我一直对此耿耿于怀，沉迷其中太久。他的预测是准确的，但正如马克·吐温所说：“做预测是困难的，特别是对未来做预测。”我们可以说的是，AI/ML向我们展示了一种真正解耦的解决方案，它在没有流量控制的情况下共享所有内容，是有优势的。
但是，随着整个技术堆栈变得更加强大，高带宽也将随之而来。这不仅仅适用于AI，而且对于一般情况下，随着PCIe 5变得普遍、64 Gbit光纤通道、100 Gbit以太网和性能更高的服务器的出现，传统的双控制器存储将在带宽突增时面临压力。备份和数据库属于病态的IO应用程序，它们会表现得不规则，产生更高的突发读/写。在某个时候，会出现对资源过度使用（以及更糟糕的情况）。
Chris Mellor：你如何看待单层全闪存存储与多层存储的相对优势？
Rob Young：明尼苏达州Eden Prairie的Compellent创始人Phil Soran提出了自动分层技术；多么酷的发明——但现在它的应用范围受限。
不再有分层。我理解这一点，这是一个成功的策略。我在银行业务的月末中遇到了多层次的问题。那些早已冷却到更低两层的数据块突然被再次调用执行。这些数据块不会立即迁移到性能更高的层级。这是一个棘手的问题。需要Infinidat来大部分解决分层挑战。缓存用于IO，数据用于后备存储。快速将数据放入缓存层（或数据已经在那里）是关键，它们可以提前处理IO请求。
每个人都喜欢采用稳定一致性的全闪存存储进行设置，然后就可以不再干预。IBM在其FS/V7K系列中提供了分层功能，它具有一些优势。根据预算和型号，你可以购买一层SCM，将数据从第一层NVMe SSD/FCM（Tier1）热升级到Tier0的SCM层，其中包含部分最热的数据。这里的优势在于“较慢”的Tier1在Tier0缺失时表现出很好的性能。鉴于SCM/SLC仍然相当昂贵，分层仍然有明确的使用场景。另外，还有你提到的FS9000，让我们将IBM FS9000的I/O延迟设置为小于300微秒但大于Infinidat SSA。此外，分层仍然适用于可以容忍较慢检索时间的数据使用者，例如视频播放（我指的是堆栈中廉价而慢速的NLSAS）。
]]></content>
  </entry>
  
  <entry>
    <title>英伟达再度释放AI“炸弹”</title>
    <url>/post/server/nvidia-launch-gh200-grace-hopper.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>AI</tag>
      <tag>NVIDIA</tag>
      <tag>GH200 Grace Hopper</tag>
    </tags>
    <content type="html"><![CDATA[近日，在计算机图形学顶会SIGGRAPH 2023现场，英伟达再度释放深夜“炸弹”，大模型专用芯片迎来升级版本。
英伟达在会上发布了新一代GH200 Grace Hopper平台，该平台依托于搭载全球首款搭载HBM3e处理器的新型Grace Hopper超级芯片——GH200，专为处理大语言模型、推荐系统、矢量数据库等全球最复杂的生成式AI工作负载而构建。
据悉，GH200芯片将成为世界上第一个配备HBM3e（High Bandwidth Memory 3e）内存的GPU芯片。
与当前一代产品相比，最新版本的GH200超级芯片内存容量增加了3.5倍，带宽增加了3倍；相比最热门的H100芯片，其内存增加1.7倍，传输频宽增加1.5倍。
在当前生成式AI不断激增的需求下，GH200超级芯片的推出，进一步吹响了AI算力之战的号角。
性能更高的GH200芯片 据介绍，GH200 Grace Hopper平台的HBM3e内存比当前HBM3快50%，可提供总计10TB/s的带宽。这使得新平台能够运行比上一版本大3.5倍的模型，同时凭借快3倍的内存带宽提升性能。
同时，该平台采用双配置，包括一个拥有144个Arm Neoverse内核、8 petaflops的AI性能和282GB最新HBM3e内存技术的单个服务器。
英伟达创始人兼首席执行官黄仁勋表示：“为了满足对生成式 AI不断激增的需求，数据中心需要能够满足特定需求的加速计算平台。全新GH200 Grace Hopper超级芯片平台以出色的内存技术和带宽，提高了吞吐量，在不影响性能的情况下可连接多GPU以整合性能，并且具有可以轻松部署到整个数据中心的服务器设计。”
据英伟达公布信息，新平台可以通过 NVIDIA NVLink™ 与其他超级芯片连接，使它们能够协同工作，从而部署当下大型生成式AI模型。这种高速、一致性技术使GPU可以完全访问CPU 内存，在双配置中可提供总计1.2TB的快速内存。
值得注意的是，新平台采用的新款超级芯片GH200与此前发布的H100相比，二者使用同样的GPU，但GH200将同时配备高达141G的内存和72核ARM中央处理器，每秒5TB带宽，内存增加了1.7倍，带宽增加了1.5倍。
新平台和芯片的加持，也让大模型训练的成本得到有效降低。黄仁勋表示，一台服务器可以同时装载两个GH200超级芯片，大型语言模型的推理成本将会大幅降低。
据介绍，投资800万美元Grace Hopper，就相当于8800个价值1亿美元的x86 GPU，意味着成本降低12倍，能耗降低20倍。
英伟达称，GH200已于5月全面投产，基于GH200 Grace Hopper平台的新系统将于2024年第二季度交付。
不过一个关键的问题是，英伟达没有透露超级芯片GH200的价格，这对计算成本高昂的大模型来说尤为重要，H100系列目前售价约为4万美元。
为什么内存对大模型重要 事实上，GH200超级芯片本身并不是一个新产品，而是今年5月在中国台北Computex展上发布的GH200芯片的更新版。
英伟达超大规模和高性能计算副总裁兼总经理伊恩·巴克（Ian Buck）表示：“我们对这款新的GH200感到非常兴奋。HBM3e不仅增加了GPU的容量和内存量，而且速度也更快。”
但为什么GPU内存这么重要？
这是因为随着支撑生成式人工智能应用程序的基础AI模型尺寸的增加，为了能够在不连接独立芯片和系统的情况下运行，大模型需要更大的内存量，以避免性能下降。
拥有更大的内存允许模型保留在单个GPU上，并且不需要多个系统或多个GPU来运行，而额外的内存只会提高 GPU的性能。
目前即使使用英伟达最顶级的H100芯片，有些模型也必须在其他GPU中“分解”模型才能运行。
据英伟达介绍，最新版本GH200配备141GB的HBM3e内存，旨在处理“世界上最复杂的生成式人工智能工作负载，涵盖大型语言模型、推荐系统和矢量数据库”。
对AI领域的影响 伟达的GH200超级芯片和DGX GH200超级计算机是AI领域的重大突破，它们为大规模生成式AI工作负载提供了前所未有的性能和内存空间，使得训练千亿甚至万亿参数的巨型模型成为可能。
这些模型可以在自然语言处理、计算机视觉、推荐系统、图形分析等领域实现更高的精度和效率，为人类解决更复杂的问题提供了强大的工具。
在多位AI从业者看来，当前大模型的训练需求过于迫切，对性能的要求也很高，而GPU的适配和生态转移都需要很长时间，因此目前大家都优先选择英伟达，和其他厂商的测试验证也在进行中。
一场新的算力之战已经拉开帷幕，如果说算力是一个江湖，那么此刻英伟达就是一名绝世高手。
它身怀加速计算的绝技，尤其在AI战场上一骑绝尘，似乎每一次都能精准地踏在浪潮的节奏上。从游戏PC市场、到深度学习的崛起、到云计算的普及、再到生成式AI的降临，英伟达的技术所向披靡。
回头看，英伟达早已超越了GPU本身的概念，AI成为最大的标签，算力的绝世武功撑起了新的万亿帝国。
2022年，英伟达推出了多款重磅产品，分别是基于全新Hopper架构的H100 GPU、CPU和GPU的合体Grace Hopper、两个CPU组合的Grace CPU Superchip，CPU的产品在2023年上市。
其中，设计GPU新架构Hopper时，英伟达增添了一个Transformer引擎，专门为Transformer算法做了硬件优化，加快AI计算的效率。
一位国内芯片从业者直言：“H100出来，其实就是一个新时代了，Grace-Hopper再一个组合，加上高配的互联，完全不给活路，英伟达赢家通吃，AMD、Intel继续苦追。”
同时他也表示：“目前国内一些企业还是在盯着CNN做优化，英伟达已经有Transformer引擎，然后AIGC火热，恰好能做支持。这个眼光，只能佩服他们的科学家们对这个领域深刻的认识。”
一位学术界人士也分析道：“从H100上，包括专用的Transformer引擎以及对FP8格式的支持，可以看到计算硬件在向应用定制的方向前进。Grace CPU说明了整合异构计算系统的重要性。单纯的加速器优化和设计已经不能够满足现在对于计算系统的算力和能效比的要求，需要各个部分的协同优化和设计。”
他还表示，Grace CPU通过提高通信带宽和在CPU和GPU之间建立一致（coherent）的内存模型来解决运算中的瓶颈，这也和学界（近存计算，存内计算）与业界（CXL，CCI等等系统互联协议）一直在关注的方向是一致的。
总而言之，在GPU和CPU的各种排列组合中，英伟达又将算力提升到了新高度。正如黄仁勋所言：“我们正在重新发明计算机，加速计算和人工智能标志着计算正在被重新定义。”
黄仁勋在采访中还提到，数据中心需要用的CPU越来越少，不再是传统上购买数百万个CPU，而是转而购买数百万个GPU。换言之，在他看来，AI算力江湖已经是GPU的主场。
英伟达的野心 事实上，随着ChatGPT引发AI大模型需求热潮，作为加速计算领导者，英伟达今年以来股价累计涨幅已超过210%，近三个月内涨幅就达56%，过去7年股价增长超40倍，目前市值冲破1.1万亿美元。
公开数据显示，英伟达占据全球80%以上的GPU服务器市场份额，同时拥有全球91.4%的企业GPU市场份额。
据投资者服务公司穆迪今年5月份发布的一份研究报告，英伟达在未来几个季度将实现“无与伦比”的收入增长，其数据中心业务的收入将超过竞争对手英特尔和AMD的总和。
但摩根士丹利策略分析师斯坦利（Edward Stanley）在最新报告中称，根据历史背景，英伟达的股价飙升处于“后期”阶段，摩根士丹利认为这标志着 AI 行业的“泡沫”。
GPU持续紧缺下，如今英伟达产品价格已同比上涨超30%，英伟达A800单卡现货近13万元一颗，eBay上H100售价高达4.5万美元。
同时，OpenAI的GPT-4大模型需要至少2.5万张英伟达A100 GPU芯片，而该公司目前至少已拥有1000万颗GPU芯片。
正如黄仁勋常说的，“你GPU买得越多，你越省钱”。主要原因是新的GPU产品能显著提升加速计算，比CPU性能更强、算力更大、功耗更低。
但英伟达的布局还不止于此。
一个现实问题是，高性能的算力也意味着高昂的价格。大模型训练成本动辄成千上百万美元，并不是所有公司都能承受。
而英伟达同时提出了云服务的解决方案NVIDIA AI foundations，黄仁勋表示要做“AI界的台积电”。台积电大大降低了芯片设计公司生产门槛，英伟达也要做代工厂的角色，通过和大模型厂商、云厂商合作提供高性价比的云服务。
在帮助下游企业降低大模型训练成本的同时，英伟达还在逐步参与到上游的产业链升级中。今年，英伟达牵手台积电、ASML、新思，发布了计算光刻库cuLitho。
计算光刻是在芯片设计和制造领域的关键步骤，也是最大的计算负载之一。计算光刻库的技术突破就在于，可以通过部署有大量GPU的DGX AI计算系统对计算光刻进行加速，使其达到原有的基于CPU的计算速度的几十倍，同时降低计算过程的总能耗。
这将有助于晶圆厂缩短原型周期时间、提高产量、减少碳排放，为2nm及更先进的工艺奠定基础，并为曲线掩模、高数值孔径极紫外、亚原子级光刻胶模型等新技术节点所需的新型解决方案和创新技术提供更多可能性。
在多位产业界人士看来，虽然短期内不会影响到下游的应用方面，但是这些上游的研发和升级将长期影响产业的发展，累积形成代际差。
“英伟达在GPU架构的迭代上，一直都有属于自己的发展路径，这几年的发展，也让英伟达跃居AI算力芯片领域的领导者，也因为领先，所以英伟达会思考如何做更多元的布局与行业内的深度合作，这样更能了解行业的需求，比方和台积电等合作便是很好的例子”，某芯片行业专家表示。
当然，英特尔和AMD都已经吹响反攻的号角。
7月，英特尔面向中国市场推出了AI芯片Habana Gaudi 2；6月，AMD推出AI芯片Instinct MI 300X，两者都直接对标英伟达100系列。
目前，在数据中心市场，英伟达和Intel、AMD形成三足鼎立之势。但随着GH200的正式发布，Grace CPU正式登台争角，最应该感到如芒在背的应该是Intel、AMD。虽说大家都知道GH200迟早发布，但等真正发布了，还是有所触动。
围绕着算力的权力游戏还将继续。
引用地址 英伟达再度释放AI“炸弹”  
]]></content>
  </entry>
  
  <entry>
    <title>I2C通讯不了？是不是硬件有问题</title>
    <url>/post/hardware/i2c-bus-communication-trouble-shooting.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>I2C</tag>
      <tag>ADC</tag>
      <tag>DAC</tag>
      <tag>EEPROM</tag>
    </tags>
    <content type="html"><![CDATA[做硬件我们经常会遇到各种各样的问题，一些通信接口也会出现，I2C自然也不例外。假如遇到I2C没反应，那么可能会出现这种情况：“软件工程师说，我软件都已经配好了，但是就是读写不到数据，是不是硬件有问题”。
这个时候，就需要我们了解I2C的通信时序，我们可以通过示波器抓取通信的波形，看是否满足通信时序要求，主机有没有发送数据？I2C通信地址对不对？如果主机有发送数据，从机是否有正常应答？通信信号质量是否OK？如此这般，一般是能够查到问题在哪里的。
基于上面的问题，这会要求我们掌握I2C的通信时序。毕竟，你只有知道它是长什么样子，你才能知道它对不对。下面就简单介绍下I2C的通信时序。
概述 I2C总线是一种十分流行并且强大的总线，其多用于一个主机（或多个）与单个或多个从设备通讯的场景。图1表明了多种不同的外设可以共享这种只需要两根线便可以连接到处理器的总线，相对于其他接口来说，这也是I2C总线可以提供的最大优势之一。
这篇应用笔记的目标是帮助用户理解I2C总线是如何工作的。
图1展示了一个典型的用于嵌入式系统中的I2C总线，其上挂载了多种从设备。作为I2C主机的从微控制器控制着IO拓展、不同传感器、EEPROM、多个ADC/多个DAC、等等。所有这些设备只需要通过来自主机的两根引脚来控制。
电特性 I2C总线使用开漏输出控制器，在同一线路上带有一个输入缓冲器，这样便可以允许在单根数据线上实现双向数据流传输。
用于双向通讯的开漏极 开漏输出极允许将总线上的电压拉低（大多数情况下是到地），或释放总线以允许其被上拉电阻拉高。当总线被主机或从机释放，线上的上拉电阻负责将线上电压上拉到电源轨。由于并没有设备可以在总线上输出高电平，这也就意味着总线在通讯中，将不会碰到一个设备输出高，而另一个设备试图输出低所导致的短路问题（电源轨到地）。I2C总线要求处于多主机环境下的单个主机在输出高而读回的实际总线电平为低时（这意味着另一个设备拉低了它）中止通讯，因为另一个设备正在使用总线。采用推挽输出方式的接口就没有这么自由了，这也正是I2C总线的一个优势。
图2展示了位于SDA/SCL线上的主从设备的内部简化结构，其由一个用于读取数据的缓冲器，以及一个用于发送数据的下拉场效应管组成。一个设备只被允许拉低总线（规定为短路到地）或释放总线（对地呈现高阻态）以允许上拉电阻拉升总线电平。当处理I2C设备时，有一个重要的概念需要阐明：没有设备可以保持总线为高。这个特性使得双向通讯得以实现。
开漏极拉低 正如前面章节所述，开漏输出只能将总线拉低，或者释放总线然后依靠上拉电阻拉高总线。图3展示了总线拉低时的电流流向。当逻辑电路想要发送一个低电平时，其会使能下拉场效应管，场效应管会通过短路到地的方式拉低线路。
开漏极释放总线 当从机或主机想要传输一个逻辑电平高，它只能通过使能场效应管的方式释放总线。这将会使得总线处于浮空状态，同时上拉电阻将会将总线电平拉高到供电轨，此电平被当作高电平看待。图4展示了电流如何流过用于拉高总线的上拉电阻。
I2C接口 I2C的常用操作 I2C总线是一种双向接口，其使用被称为主机的控制器与从设备进行通讯。从机不会主动传输任何数据，除非其被主机寻址。每个处于I2C总线上的设备均有独有的设备地址，以用于与位于同一总线上的其他设备做区分。很多从机需要在启动后进行配置以设置设备行为。这通常在主机访问从机的内部寄存器映射时完成，这些寄存器均有独一无二的寄存器地址。单个设备可以具有一个或多个寄存器，这些寄存器可以用来存储或读写数据。
I2C总线的物理接口由串行时钟线（SCL）和串行数据线（SDA）组成。SCL和SDA均需要通过上拉电阻连接到Vcc。上拉电阻的大小由I2C线路上的等效电容大小决定（想要了解更多，可以参考TI的I2C Pull-up Resistor Calculation这份文档，文档号：SLVA689；也可以看我的笔记里面的文章《I2C上升沿过长与上拉电阻》）。数据传送只能在总线空闲时初始化。如果SDA和SCL在一个STOP标志后均处于高电平状态，这时可以认为总线处在空闲状态。
主机访问从机的大体流程如下所示：
 假设一个主机想要向从机发送数据：   发送方主机发送一个START标志并且寻址接收方从机 发送方主机发送数据到接收方从机 发送方主机通过发送STOP标志结束传输  如果主机想要从从机接收/读取数据：   接收方主机发送START标志并寻址发送方从机 接收方主机发送需要读取的寄存器地址到发送方从机 接收方主机从发送方从机接收数据 接收方主机通过发送STOP标志结束通讯  START与STOP标志
主机可以通过发送START标志初始化与设备的I2C通讯，或者发送STOP标志结束通讯。当SCL处于高电平时，SDA上的下降沿意味着一个START标志，而SDA上的上升沿意味着一个STOP标志。
重复的START标志
重复的START标志与通常的START标志作用类似，其用于STOP标志后紧接START标志的情况时，用于代替这两者。它看上去与START标志一致，但是与START标志不同的是，重复的START标志在STOP标志之前出现（也就是总线不处于空闲状态时）。当主机希望开始一次新的通讯，但又不希望发送STOP标志使总线进入空闲状态时这会非常管用，这样可以防止当前主机的总线控制权被其他主机抢夺（当处于多主机环境下）。
数据有效性与字节格式
数据位伴随着SCL上的每一个时钟脉冲被传输。单个字节由SDA线上的8位数据组成，其可以是设备地址、寄存器地址或者读自/写入设备的数据。数据以大端在前（MSB）的方式传输。在START标志与STOP标志之间可以传输任意数量的数据字节。SDA线上的数据必须在时钟电平为高时保持稳定，因为SCL线为高时，SDA线上的变动将会被当作控制指令（START或STOP）。
应答（ACK）和非应答（NACK）
数据的每一字节（包括地址字节）后总是伴随着来自接收方的1位ACK位。ACK位使得接收方可以告知发送方当前字节已成功接收，并且可以发送下一字节。
在接收方发送ACK位前，发送方必须释放总线。接收方通过在ACK/NACK时钟周期（第9时钟周期）的低电平相位拉低SDA线来发送一个ACK位，如此一来，SDA线将会在ACK/NACK时钟周期的高电平相位保持为低电平。设置与保持时间必须着重注意。
如果SDA线在ACK/NACK时钟周期保持为高电平，这将会被作为NACK。有好几种状态将会导致NACK的产生：
 接收方无法进行接收或发送，因为其正在执行一些实时性功能（real-time function），无法与主机进行通讯。 在发送期间，接收方收到了无法识别的数据或指令。 在发送期间，接收方无法接收更多数据字节（也就是缓冲区满了）。 作为接收方的主机完成了数据读取，因此通过发送一个NACK通知从机。  I2C总线数据 数据可以写入/读自从机，但是这是通过读写从设备内部的寄存器完成的。
包含信息的寄存器处于从机的内存中，无论这些信息是配置信息还是一些需要回发给主机的采样数据。为了指示从机去执行某一任务，主机必须向这些寄存器内写入信息。
虽然通常来说I2C从机是具有多个寄存器的，但也需要注意并不是所有从机都是这样。对于一个只具有单个寄存器的简易从机来说，可以通过在从机地址后直接发送数据的方式来直接写这个单一的寄存器，而不需要再对寄存器进行寻址。一个通过I2C总线控制的8位I2C开关可以很好的作为单寄存器设备的例子。由于它通过1位来使能/失能一个通道，因此只需要1个寄存器，主机可以在从机地址后直接写入寄存器数据，跳过寄存器编码部分。
写位于I2C总线上的从机
要在I2C总线上执行写操作，主机会发送一个START标志以及从机地址到总线上，并且将最后1位（读写位）设为0以表明这是写操作。当从机发送应答位之后，主机便发送希望写入的寄存器地址。从机再一次应答，通知主机从机已准备好。这之后，主机开始发送寄存器数据到从机。当主机发送完所有需要发送的数据（有时只是一个字节），其将会通过发送STOP标志结束通讯。
图8展示了一个写入单个字节到从机寄存器的例子。
读位于I2C总线上的从机
从从机读取数据与写入数据类似，但是有一些额外的步骤。
为了读取从机，主机必须先指示从机自己想要读取哪个寄存器。这一步通过执行与写操作类似的开始通讯步骤完成，发送读写位为0的设备地址（意味着一次写操作），紧跟着希望读的寄存器的地址。一旦从机应答了此地址，主机将会再一次发送START标志，并发送读写位为1的设备地址（意味着一次读操作）。这时，从机将会应答读请求，同时主机释放总线但是保持到从机的时钟供应。在通讯流程的这一部分，主机将会作为接收方主机，同时从机将会作为发送方从机。
主机将会继续发送时钟脉冲，但是会释放SDA线以便于从机传输数据。在每个字节数据的结尾，主机将会发送一个ACK到从机，让从机知道主机准备好接收更多的数据。一旦主机接收完成期待的字节数量，它将会发送一个NACK，通知从机终止通讯并要求从机释放总线。紧接着主机将会发送一个STOP标志结束通讯。
图9展示了从从机寄存器读取单个字节的例子。
]]></content>
  </entry>
  
  <entry>
    <title>Linux iSCSI 网络磁盘</title>
    <url>/post/linux/linux-iSCSI-network-drive.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>iSCSI</tag>
      <tag>network drive</tag>
    </tags>
    <content type="html"><![CDATA[ISCSI网络磁盘是一种利用TCP/IP协议在网络上传输SCSI命令的技术，可以实现远程访问存储设备的功能。ISCSI网络磁盘可以用于存储整合和灾难恢复的场景，也可以节省专用光纤网络的成本。
介绍 如果你想使用ISCSI网络磁盘，你需要在服务器端安装和配置ISCSI目标服务，然后在客户端安装和配置ISCSI发起程序，通过IP地址或DNS名称连接到服务器上的虚拟磁盘，并进行格式化和使用。
iSCSI 优缺点 ISCSI网络磁盘的优点有：
 成本低廉：ISCSI网络磁盘可以利用现有的以太网和IP网络，无需额外的光纤网络和设备，节省了硬件和维护的费用。 部署简单：ISCSI网络磁盘可以通过IP地址或DNS名称进行连接，无需复杂的配置和调试，也方便了远程管理和扩展。 灵活性高：ISCSI网络磁盘可以支持多种类型的存储设备，如SCSI和SATA，也可以与传统的RAID磁盘阵列结合使用，提供更大的存储容量。  ISCSI网络磁盘的缺点有：
 性能较低：ISCSI网络磁盘的数据传输速度受到以太网和TCP/IP协议的限制，比光纤通道存储网络要慢得多。 安全性较差：ISCSI网络磁盘的数据在网络上可能会遭到拦截或篡改，需要额外的加密和验证机制来保证安全性。 技术不成熟：ISCSI网络磁盘是一种相对较新的技术，市场上支持该技术的软硬件产品还不够多，可能会遇到兼容性或稳定性的问题。  ISCSI网络磁盘如何提高性能？ ISCSI网络磁盘的性能受到多种因素的影响，如果想要提高性能，可以从以下几个方面进行优化：
 提高网络带宽：ISCSI网络磁盘的数据传输速度取决于网络的带宽，如果网络拥塞或者带宽不足，会导致数据包的丢失或延迟，影响性能。因此，可以通过升级网络设备，使用千兆网卡和交换机，或者使用多路径技术，来提高网络的带宽和可靠性。 使用专用网络：ISCSI网络磁盘的数据在网络上可能会与其他类型的流量发生冲突，造成干扰和抖动，影响性能。因此，可以通过使用专用的网络或者虚拟局域网（VLAN），来隔离ISCSI流量和其他流量，减少网络的负载和竞争。 使用硬件加速：ISCSI网络磁盘的数据在传输过程中需要进行封装和解封装，以及加密和验证等操作，这些操作会消耗服务器的CPU资源和内存资源，影响性能。因此，可以通过使用硬件加速设备，如ISCSI HBA或者TCP/IP卸载引擎（TOE），来减轻服务器的负担，提高数据处理的效率。  部署 Server 端 初始化配置
#关闭防火墙 systemctl stop firewalld systemctl disable firewalld #关闭selinux setenforce 0 sed -i &#39;s/SELINUX=enforcing/SELINUX=disabled/g&#39; /etc/selinux/config 安装 iSCSI 服务端软件包
yum -y install targetcli 配置 iSCSI 服务端
[root@Demo01 ~]# targetcli targetcli shell version 2.1.53 Copyright 2011-2013 by Datera, Inc and others. For help on commands, type &#39;help&#39;. /&gt; ls o- / ............................................................................ [...] o- backstores ................................................................. [...] | o- block ..................................................... [Storage Objects: 0] | o- fileio .................................................... [Storage Objects: 0] | o- pscsi ......................................................[Storage Objects: 0] | o- ramdisk ................................................... [Storage Objects: 0] o- iscsi ................................................................[Targets: 0] o- loopback ............................................................ [Targets: 0] /&gt; 创建iSCSI target名称及配置共享资源。
/&gt; cd /backstores/block /backstores/block&gt; create disk01 /dev/sdb Created block storage object disk0 using /dev/md0. /backstores/block&gt; cd / /&gt; ls o- / ............................................................................ [...] o- backstores ................................................................. [...] | o- block ..................................................... [Storage Objects: 1] | | o- disk0 ............................ [/dev/sdb (20.0GiB) write-thru deactivated] | | o- alua ...................................................... [ALUA Groups: 1] | | o- default_tg_pt_gp ...........................[ALUA state: Active/optimized] | o- fileio .................................................... [Storage Objects: 0] | o- pscsi ..................................................... [Storage Objects: 0] | o- ramdisk ................................................... [Storage Objects: 0] o- iscsi ............................................................... [Targets: 0] o- loopback ............................................................ [Targets: 0] /&gt; 创建iSCSI target名称及配置共享资源。
/iscsi&gt; create Created target iqn.2003-01.org.linux-iscsi.demo01.x8664:sn.c9eccc3e35be Created TPG 1. Global pref auto_add_default_portal=true Created default portal listening on all IPs (0.0.0.0), port 3260. /iscsi&gt; ls o- iscsi ................................................................... [Targets: 1] o- iqn.2003-01.org.linux-iscsi.demo01.x8664:sn.c9eccc3e35be ............. [TPGs: 1] o- tpg1 ...................................................... [no-gen-acls, no-auth] o- acls ................................................................. [ACLs: 0] o- luns ................................................................. [LUNs: 0] o- portals ........................................................... [Portals: 1] o- 0.0.0.0:3260 ...................... 创建一个设备目录
/iscsi&gt; cd iqn.2003-01.org.linux-iscsi.demo01.x8664:sn.c9eccc3e35be / /iscsi/iqn.20....745b21d6cad5&gt; cd tpg1/luns /iscsi/iqn.20...ad5/tpg1/luns&gt; create /backstores/block/disk0 Created LUN 0. 设置控制访问ACL
/iscsi/iqn.20...ad5/tpg1/luns&gt; cd .. /iscsi/iqn.20...21d6cad5/tpg1&gt; cd acls /iscsi/iqn.20...ad5/tpg1/acls&gt; create iqn.2003-01.org.linux-iscsi.demo01.x8664:sn.c9eccc3e35be Created Node ACL for iqn.2003-01.org.linux-iscsi.demo01.x8664:sn.c9eccc3e35be Created mapped LUN 0. 设置iSCSI服务端的监听IP地址和端口号。
/iscsi/iqn.20...ad5/tpg1/acls&gt; cd ../portals/ /iscsi/iqn.20.../tpg1/portals&gt; ls o- portals ................................................................... [Portals: 1] o- 0.0.0.0:3260 .................................................................... [OK] /iscsi/iqn.20.../tpg1/portals&gt; delete 0.0.0.0 3260 Deleted network portal 0.0.0.0:3260 /iscsi/iqn.20.../tpg1/portals&gt; create 192.168.10.10 Using default IP port 3260 Created network portal 192.168.10.10:3260. 配置完成最后 ls 查看
/&gt; ls o- / .......................................................... [...] o- backstores ............................................... [...] | o- block ................................... [Storage Objects: 1] | | o- disk01 ........... [/dev/sdb (20.0GiB) write-thru activated] | | o- alua .................................... [ALUA Groups: 1] | | o- default_tg_pt_gp ........ [ALUA state: Active/optimized] | o- fileio .................................. [Storage Objects: 0] | o- pscsi ................................... [Storage Objects: 0] | o- ramdisk ................................. [Storage Objects: 0] o- iscsi ............................................. [Targets: 1] | o- iqn.2003-01.org.linux-iscsi.demo01.x8664:sn.c9eccc3e35be [TPGs: 1] | o- tpg1 ................................ [no-gen-acls, no-auth] | o- acls ........................................... [ACLs: 1] | | o- iqn.2003-01.org.linux-iscsi.demo01.x8664:sn.c9eccc3e35be [Mapped LUNs: 1] | | o- mapped_lun0 ................. [lun0 block/disk01 (rw)] | o- luns ........................................... [LUNs: 1] | | o- lun0 ...... [block/disk01 (/dev/sdb) (default_tg_pt_gp)] | o- portals ..................................... [Portals: 1] | o- 192.168.10.25:3260 ................................ [OK] o- loopback .......................................... [Targets: 0 Client 端 安装客户端iSCSI 软件
yum -y install iscsi-initiator-utils 配置客户端
[root@linuxprobe ~]# vim /etc/iscsi/initiatorname.iscsi InitiatorName=iqn.2003-01.org.linux-iscsi.demo01.x8664:sn.c9eccc3e35be [root@linuxprobe ~]# systemctl restart iscsid [root@linuxprobe ~]# systemctl enable iscsid 连接访问iSCSI
iscsiadm -m discovery -t st -p 192.168.10.25 192.168.10.25:3260,1 iqn.2003-01.org.linux-iscsi.demo01.x8664:sn.c9eccc3e35be iscsiadm -m node -T iqn.2003-01.org.linux-iscsi.demo01.x8664:sn.c9eccc3e35be -p 192.168.10.25 --login 格式化
mkfs.xfs /dev/sdb meta-data=/dev/sdb isize=512 agcount=16, agsize=654720 blks = sectsz=512 attr=2, projid32bit=1 = crc=1 finobt=1, sparse=1, rmapbt=0 = reflink=1 data = bsize=4096 blocks=10475520, imaxpct=25 = sunit=128 swidth=256 blks naming =version 2 bsize=4096 ascii-ci=0, ftype=1 log =internal log bsize=4096 blocks=5120, version=2 = sectsz=512 sunit=0 blks, lazy-count=1 realtime =none extsz=4096 blocks=0, rtextents=0 挂载
mkdir /data mount /dev/sdb /data 查看挂载情况
df -TH Filesystem Type Size Used Avail Use% Mounted on /dev/mapper/centos-root xfs 19G 1.4G 17G 8% / devtmpfs devtmpfs 942M 0 942M 0% /dev tmpfs tmpfs 954M 0 954M 0% /dev/shm tmpfs tmpfs 954M 11M 944M 2% /run tmpfs tmpfs 954M 0 954M 0% /sys/fs/cgroup /dev/sda2 xfs 1.1G 144M 920M 14% /boot /dev/sda1 vfat 210M 12M 198M 6% /boot/efi tmpfs tmpfs 191M 0 191M 0% /run/user/0 /dev/sdb xfs 20G 19M 20G 1% /data ]]></content>
  </entry>
  
  <entry>
    <title>SSH远程连接服务详解</title>
    <url>/post/server/detailed-explanation-of-ssh-remote-connection-service.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>SSH</tag>
      <tag>Linux</tag>
    </tags>
    <content type="html"><![CDATA[SSH（Secure Shell ，安全外壳）是一种网络安全协议，通过加密和认证机制实现安全的访问和文件传输等业务。
SSH远程服务 SSH概述 what？ SSH（Secure Shell ，安全外壳）是一种网络安全协议，通过加密和认证机制实现安全的访问和文件传输等业务。
传统远程登录和文件传输方式，例如Telnet、FTP，使用明文传输数据，存在很多的安全隐患。随着人们对网络安全的重视，这些方式已经慢慢不被接受。SSH协议通过对网络数据进行加密和验证，在不安全的网络环境中提供了安全的网络服务。作为Telnet和其他不安全远程shell协议的安全替代方案，目前SSH协议已经被全世界广泛使用，大多数设备都支持SSH功能。
除了ssh，远程连接服务还有哪些？
# windows -rdp 端口 3389 remote desktop protocol # linux ssh 监听22端口 加密传输 默认支持root登录 telnet 监听23端口 明文传输 不支持root用户登录 ftp 监听21端口 why ssh？SSH服务主要功能？  提供远程连接服务器的服务 对传输的数据进行加密  传统的互联网通信使用明文传输数据，内容一旦被截获就会完全暴露，存在很多安全隐患。SSH协议通过对网络数据进行加密和验证，建立SSH客户端和SSH服务器之间的安全隧道，在不安全的网络环境中为网络服务提供了安全的传输通道。
SSH最常用的场景是远程登录和文件传输。在SSH协议出现之前，Telnet广泛应用于远程登录场景，为远程管理网络设备提供了极大便利，而FTP作为常用的文件传输协议，兼具操作简单和传输效率高的优点，但它们都存在相同的问题，即明文传输数据带来的安全隐患。SSH采用加密传输数据、提升认证强度等手段，克服了Telnet和FTP应用中的安全性问题，实现了安全的远程登录和文件传输业务。
SSH常用场景：
面试题：下列服务都是哪些端口
ftp 21 dns 53 ssh 22 telnet 23 mysql 3306 http 80 https 443 rsync 873 实践：使用网络抓包软件wireshark抓包验证telnet明文传输和ssh加密传输
 安装telnet并启动，查看端口  yum install telnet-server -y //telnet-client (或 telnet)，提供的是 telnet 客户端程序；telnet-server软件包才是真正的 Telnet server 软件包。 systemctl start telnet.socket xshell新建一个telnet连接，发现telnet无法用root登录。需先创建一个普通用户，创建密码  useradd xxx echo 1 | passwd --stdin xxx xshell使用普通用户进行telnet连接登录  安装wireshark，检测vmnet8网卡上telnet的流量  搜索wireshark包含telnet相关的流量
右键&ndash;&gt;追踪流&ndash;&gt;tcp流，看下都是明文的。
wireshark分析SSH流量，发现都是加密的  SSH工作原理简介 SSH由服务器和客户端组成，为建立安全的SSH通道，双方需要先建立TCP连接，然后协商使用的版本号和各类算法，并生成相同的会话密钥用于后续的对称加密。在完成用户认证后，双方即可建立会话进行数据交互。
常用SSH连接工具 由于SSH是一套协议标准，需要依赖基于SSH实现的工具完成SSH客户端和SSH服务器之间的连接，PuTTY和OpenSSH应运而生。
PuTTY是Windows上经典的免费SSH连接工具，通常用于使用SSH协议远程登录设备，最新版本可以在PuTTY官网下载。
OpenSSH是SSH协议的开源实现，支持在Unix操作系统上运行，最新版本可以在OpenSSH官网下载。目前Windows10已经包含OpenSSH客户端和服务器软件，可在“设置—应用—应用与功能—可选功能”中搜索安装。
SSH使用 查看Linux里的ssh软件包信息
# 查看Linux里的ssh软件包信息（Cent7系统默认安装中已包含SSH服务软件openssh和openssl） [root@web01 ~]# rpm -qa|grep openssh openssh-server-7.4p1-16.el7.x86_64 # ssh服务端软件，包括配置文件、守护进程SSHD，sshd-keygen秘钥创建工具等 openssh-7.4p1-16.el7.x86_64 openssh-clients-7.4p1-16.el7.x86_64 # ssh客户端软件。在ssh客户端软件中包含ssh、slogin远程登陆、scp远程拷贝、sftp文件传输、ssh-copy-id秘钥分发等应用程序。 用ssh登录其他远程服务器
# 用ssh登录其他远程服务器： ssh 当前用户@要连接的IP # //没有秘钥对认证时是密码认证 -p 指定端口 （默认-p22可省略） 比如拿web01连backup： [root@web01 ~]# ssh -p22 root@10.0.0.41 或者 [root@web01 ~]# ssh 10.0.0.41 //直接省略，默认使用当前登录用户 [root@web01 ~]# ssh root@10.0.0.41 &#39;ip a&#39; //登录之后查看backup机器的内容 ...输入密码 [root@backup ~]# ifconfig // 登录后变backup了 （省略输出） logout或exit退出当前用户 # -p怎么用？例如 [root@web01 ~]# vim /etc/ssh/sshd_config //web01改端口号为333： Port 333 [root@web01 ~]# systemctl restart sshd //重启ssh服务 再用backup连web01，发现连不上了： [root@backup ~]# ssh root@10.0.0.7 ssh: connect to host 10.0.0.7 port 22: Connection refused [root@backup ~]# ssh root@10.0.0.7 &#39;ifconfig&#39; ssh: connect to host 10.0.0.7 port 22: Connection refused -p指定端口号即可 [root@backup ~]# ssh -p 333 root@10.0.0.7 [root@backup ~]# ssh -p 333 root@10.0.0.7 &#39;ifconfig&#39; root@10.0.0.7&#39;s password: eth0: flags=4163&lt;UP,BROADCAST,RUNNING,MULTICAST&gt; mtu 1500 inet 10.0.0.7 netmask 255.255.255.0 broadcast 10.0.0.255 inet6 fe80::20c:29ff:fe63:27a prefixlen 64 scopeid 0x20&lt;link&gt; （省略输出） # 注意把端口号改回去，不然等下xshell也连不上了 scp远程复制命令
# scp 远程复制数据至远程服务器（全量复制） -r 表示递归拷贝目录 -p 表示在拷贝文件前后保持文件或目录属性不变 -l 限速(默认kb) 比如限速为8096kb：cp -rp -l 8096 （换算为MB，要除以 8096/8=1024KB=1MB） -P 指定端口，默认22端口可不写 推 scp 选项 要推的文件 要推到哪里 （用户@IP:目标路径） scp -r /etc/passwd root@10.0.0.41:/opt 拉 scp -r root@10.0.0.41:/opt/passwd /tmp # 注： 1、scp通过ssh协议加密方式进行拷贝 2、scp的连接用户作为拷贝文件或者目录的权限。比如本来属组属主xxx，拉过来之后变你当前登录用户 3、scp是全量拷贝，效率低 Sftp远程数据传输命令
[root@web01 ~]# sftp root@10.0.0.41 //默认可以通过sftp命令连接sftp服务 root@10.0.0.41&#39;s password: Connected to 10.0.0.41. sftp&gt; get 1.txt /tmp #//sftp使用get下载文件至于本地服务器 Fetching /root/1.txt to /tmp/1.txt /root/1.txt 100% 6 1.0KB/s 00:00 sftp&gt; get backup.sh File &#34;/root/backup.sh&#34; not found. sftp&gt; put /root/2.txt /toot #//sftp使用put上传本地文件于远程服务器 ]]></content>
  </entry>
  
  <entry>
    <title>信号带宽与上升沿的关系</title>
    <url>/post/dsp/signal-bandwidth-vs-rising-edge.html</url>
    <categories><category>DSP</category>
    </categories>
    <tags>
      <tag>Signal Bandwidth</tag>
    </tags>
    <content type="html"><![CDATA[前面我发过一篇文章，探讨的是带宽和上升时间的系数0.35是怎么来的？
Part1 $$ \displaystyle BW = \frac{0.35}{Tr} $$
虽然我们找到了这个系数关系，确实是在0.35~0.4之间。其实当时我留有疑问，我发现随着方波分解的次数变多（几万次），最高频率fmax也在增加，上升时间Tr也在加快，但是“0.35”这个系数不稳了。
Part 02 我们复盘一下当时的做法：
首先，用傅里叶级数（FS）分解方波，
然后，逐渐增大谐波次数，获得最高次谐波的频率fmax，找出此时合成方波边沿10-90%的上升时间Tr，
最后，对这些谐波fmax和对应合成波的Tr做乘积，找出他们的系数关系。
很漂亮的值！趋于0.35。但是当我逐渐继续提高分解的次数，fmax变大，Tr变小，它们的乘积，不再是“0.35”。
感觉它在发散，而且那个“锯齿波”，像极了S参数里的相位逐渐递增，强迫纠正到主值区间的图。
所以那篇文章我用委婉的语气用了一个“大概”，
所以这个0.35大概就是通过分解方波信号，通过FS求得子信号的最高频率和此时信号的上升沿，去拟合出来的一个值。
Part 03 本来这个问题当时就不打算研究了，我甚至一度怀疑自己的做法错了，伯格丁的书，也只是用语言描述了这种经验公式的由来。
直到昨天后台有个同学问我要了下源码，我重新review了下流程，观察数据后，找到了问题，matlab代码上设置的采样率不够，随着分解次数，信号频率fmax增大，边沿Tr加快后，matlab判断的时候稳态值&gt;0.1和&gt;0.9，两个t重合，获取不到Tr。
提高Fs采样率后，问题得以解释清楚，虽然还有一点发散，但是不影响，10G以内，公式正确！
我们最后看一下波图，
采样率低：
提高采样率：
这个0.38很漂亮，用一张索雷博的公式漫画：
Part 04 随着方波分解次数提高，信号边沿几乎垂直，如果还是想要观察边沿的细节，这时对采样率提出了极高的要求，code里面观察10G的信号，我的采样率已经设置到了2000G。
]]></content>
  </entry>
  
  <entry>
    <title>VxWorks技术资料免费下载</title>
    <url>/post/vxworks/free-vxworks-technical-resouce.html</url>
    <categories><category>VxWorks</category>
    </categories>
    <tags>
      <tag>VxWorks</tag>
    </tags>
    <content type="html"><![CDATA[VxWorks技术资料免费下载，资源来源网络，版权归原作者所有！
板级支持包(BSP)相关   Wind River Workbench3.3使用技巧    VxWorks 6.9 BSP开发指南    使用VxWorks 7内核 shell 来访问设备的寄存器    VxWorks内核解读-1    VxWorks内核解读-2    VxWorks内核解读-3    VxWorks内核解读-4    VxWorks内核解读-5    VxWorks内核解读-6    VxWorks内核解读-7    VxWorks Workbench开发环境快速介绍    第5章 VxWorks 网卡驱动-2    第5章 VxWorks 网卡驱动    第4章 VxWorks PCI驱动-3    第4章 VxWorks PCI驱动-2    第4章 VxWorks PCI驱动-1    第3章 VxWorks中断驱动程序原理-4    第3章 VxWorks中断驱动程序原理-3    第3章 VxWorks中断驱动程序原理-2    第3章 VxWorks中断驱动程序原理    第2章 串口驱动原理-6    第2章 串口驱动原理-5    第2章 串口驱动原理-4    第2章 串口驱动原理-3    第2章 串口驱动原理-2    第2章 串口驱动原理    VxWorks 代码分析    VxWorks 7 之用户管理    VxWorks 7：添加shell组件    VxWorks 7：编译并启动AM57xx的VxBL    VxWorks7.0下SD卡驱动流程及文件系统格式化    在Raspberry Pi 4开发板上使用VxWorks 7    基于“龙芯”的VxWorks系统函数在轨更新研究    VxWorks开发教程(中文版)    VxWorks7.0下基于zynq的boot启动程序    VxWorks6.6下基于VxBus的以太网驱动开发    基于Zedboard的VxWorks 7.0调试总结    VxWorks 7还有bootrom吗    LEON VxWorks 6.7通用BSP手册    VxWorks组件技术的研究    为Pentium4的PC机移植VxWorks 6.9 BSP    移植Linux Kernel SM750 驱动到VxWorks 7    VxWorks BSP简介    基于VxWorks的PCI-RapidIO桥驱动设计    基于VxWorks的时统卡驱动程序设计    基于IO设备驱动机制的CAN设备驱动程序设计    实时操作系统VxWorks下IO设备驱动程序的编写技巧    基于VxWorks的FLASH存储器实时存取管理方案    U-Boot和VxWorks 7的集成    SPARC架构的VxWorks 7板级支持包BSP    如何在VmWare上运行VxWorks 7    VxWorks的镜像类型简介    VxWorks 7 VxBus具体设备参数    VxWorks操作系统中TFFS快速格式化方法的实现    如何在Virtual Box上运行VxWorks 7    VxWorks的EDR组件介绍    VxWorks下的文件系统介绍    VxWorks 网络协议源代码    VxWorks6.8操作系统下NVMe驱动设计    基于龙芯1E1F航天应用平台与VxWorks系统的VxBus型驱动设计    VxWorks操作系统在OMAP平台上的移植    VxWorks启动过程解析    VxWorks下USB主机接口开发    VxWorks下字符设备的驱动开发    VxWorks下的SD卡开发    基于VxWorks操作系统下大硬盘的实现    基于VxWorks下dosFS的块设备开发研究    移植Linux Kernel SM750 驱动到VxWorks 7    VxWorks Kernel Shell的启用    VxWorks系统下Page Fault浅析    VxWorks通过源码编译库文件    VxWorks系统中vxbus机制总结    实测VxWorks响应PCIe中断的最小时间间隔    基于AT91RM9200的VxWorks END网络驱动开发    基于EBD9200的VxWorks BSP设计和实现    基于LPC2210的VxWorks BSP移植    基于VxWorks的BSP技术分析    VxWorks环境下内存文件系统的应用    基于VxWorks系统的PCI配置与应用    基于VXWORKS的RS485 MVB网关的设计与实现    基于VxBus的驱动程序架构分析    基于VxBus和MPC8569E千兆网驱动开发和实现    VxWorks概述    基于Tornado和Tilcon的嵌入式GIS图形编辑软件的开发    基于MPC8270的VxWorks BSP的移植    基于MPC850 VxWorks系统的BSP设计    VxWorks的内存配置和管理    VxWorks在ARM7应用系统上的BSP设计    VxWorks内存管理机制的研究    VxWorks在S3C2410上的BSP设计    一种基于vxBus的PPC与FPGA高速互联的驱动设计方法    VxWorks中串行通信的研究    基于VxBus的高速数据采集卡驱动程序开发    VxWorks下增强型网络驱动程序的设计与实现    实时操作系统任务调度策略的研究与设计    嵌入式实时操作系统BSP的探讨    嵌入式实时操作系统VxWorks下BSP分析及VxWorks裁减    嵌入式语音通信系统中VxWorks BSP的设计实现    VxWorks下基于 VxBus 的设备驱动开发    VxWorks 官方源代码    VxWorks下的多串口卡设计    VxWorks下SL811HS的Host 驱动源码    VxWorks操作系统中PCI总线驱动程序的设计与实现    VxWorks BSP开发中的PCI配置方法    TDSCDMA拉远基站BSP的开发    VxBus的A429接口驱动    Flash文件系统分析及其在VxWorks中的实现    UBoot在Mini6410上的移植    P1010 VxWorks 6.6 BSP    ZYNQ 7020 运行 VxWorks 7.0 系统    Using VxWorks 7 BSP with the Zynq-7000 AP SoC    三星6410的烧写工具[BOOT]源码    Tornado编译生成vxworks.bin镜像的方法    Tornado编译VxWorks的本质及过程    MINI6410 VxWorks实验大纲    Bootrom功能改进经验谈    ARM LPC2210的VxWorks BSP源码    Freescale的MPC8641D的VxWorks BSP    VxWorks下MPC8280网络驱动的开发    基于TI的ARM Cortex A8芯片TI 335X的TQ335x开发板的VxWorks BSP    4端口RS-232/422/485通讯卡MIC-3612在VxWorks下的驱动源码    VxWorks下PMC - FPGA板卡驱动的开发与研究    VxWorks下的USB驱动程序原理与分析    在虚拟机Virtual Box上跑VxWorks    PowerPC处理器上VxWorks异常和中断处理过程解析    ARM9 AT91RM9200上Philips CAN芯片SJA1000的VxWorks驱动    PCI总线在VxWorks中的实现    VxWorks vxbus驱动程序的组织结构    VxWorks vxbus设备驱动程序的分类    VxWorks booting process    基于VxBus的设备驱动开发    MPC8247 VxWorks软件操作手册    VxWorks for PowerPC的内存分配    VxWorks环境下双网卡冗余备份技术的实现    VxWorks系统下的RTL8139驱动程序改进    基于VxWorks的双端口网卡智能双冗余驱动    VxWorks中封装函数库的方法及库文件的使用方法    ARM7系统S3C4510b上的VxWorks BSP设计    VxWorks的启动流程    VxWorks下END网络驱动编写概述    基于VxWorks的网卡驱动设计    S3C2440 VxWorks BSP移植    VxWorks串口驱动的研究与实现    基于VxWorks的TFFS文件系统的研究与实现    基于VxWorks的NAND FLASH驱动程序设计    嵌入式操作系统VxWorks中TFFS文件系统的构建    VxWorks在PowerPC系统上的移植与实现    VxWorks下PC104 CAN驱动程序设计    固捷PATA硬盘在vxworks68下的驱动    应用程序(APP)相关   北邮VxWorks网络编程讲义    VxWorks系统下的多任务编程    VxWorks内存泄漏检查代码    VxWorks任务编程中常见异常分析    VxWorks下硬盘测速程序代码    VxWorks 6.9下如何进行C++开发    VxWorks问答100例    VxWorks的多任务以及任务间通信    VxWorks 6.6 的FTP服务端访问权限设置方法    VxWorks 6.9 配置多网口    VxWorks下Telnet客户端的C语言实现代码    VxWorks网络编程TCP协议应用代码    VxWorks程序开发实践    VxWorks下基于UDP的网络通信源码    《VxWorks7编程指南》笔记（十）I/O系统：异步I/O    《VxWorks7编程指南》笔记（九）I/O系统：其他I/O    《VxWorks7编程指南》笔记（八）I/O系统：标准I/O    《VxWorks7编程指南》笔记（七）I/O系统：基础I/O    《VxWorks7编程指南》笔记（六）I/O系统：简介    《VxWorks7编程指南》笔记（五）看门狗时钟    《VxWorks7编程指南》笔记（四）中断服务程序ISR    《VxWorks7编程指南》笔记（三）信号机制    《VxWorks7编程指南》笔记（二）多任务    《VxWorks7编程指南》笔记（一）内存管理    针对航电系统的实时操作系统VxWorks 7的安全评估    VxWorks 7.0下基于VxBus的定时器子系统    风河拥抱物联网演讲    VxWorks常用命令    VxWorks获得CPU使用情况的代码    VxWorks下计算程序的执行时间    一种VxWorks系统CPU利用率图形化显示方法的设计与实现    在VxWorks 7上创建加密的文件系统分区    基于VxWorks新型映像的三模冗余启动机制研究    用VxWorks 7和Ubuntu Linux测量网络带宽    VxWorks 操作系统指南    基于VxWorks的PDFlib库文件研究与应用    基于VxWorks的双GPS测向系统设计    基于VxBus架构的温度监控模块实现    Workbench3.x-VxWorks6.x仿真测试和调试指南    VxWorks 6.9下的ifconfig网络配置命令    VxWorks下的信号量    VxWorks Shell下常用的命令    VxWorks下广播Broadcast编程    VxWorks下的kprintf调用    VxWorks操作系统之实时多任务    VxWorks下的管道Pipe介绍    一个大学实习生使用VxWorks SDK的经历和体会    VxWorks下的C++调用    爬游无人潜水器导航控制系统设计    VxWorks系统下人机交互界面软件跨平台兼容的研究与应用    VxWorks下的看门狗WatchDog    VxWorks Task之计数信号量    VxWorks设备驱动    基于VxWorks的在线编程技术    VxWorks下主控并行处理分析    VxWorks在某实时显控设备中的应用    嵌入式实时操作系统VxWorks及其开发环境Tornado    VxWorks编译环境下对代码注释的要求    VxWorks系统下的文件大小    VxWorksTask的调度策略    VxWorks下任务的控制    VxWorks下任务的删除    VxWorks下任务的创建    VxWorks下Task中的系统任务    VxWorks下的Task 状态    VxWorks下的RTP是什么    VxWorks下的Task是什么    VxWorks的应用程序自启动的方法    VxWorks Kernel Shell命令简介    基于GPU FPGA芯片原型的VxWorks下驱动软件开发    一种基于VxWorks的飞行仿真实时管理系统    VxWorks实验五[时间片轮转调度]    基于MPC8260和VxWorks实现快速以太网通信    基于VxWorks的多任务程序设计及通信管理    基于VxWorks的数据采集存储装置设计    基于VxWorks的水声扩频通信系统    基于VxWorks的VoIP网关软件的设计与实现    基于VxWorks平台的SCTP协议软件设计实现    实时操作系统VxWorks在微机保护中的应用    基于PowerPC在VxWorks下的仿真系统设计    VxWorks环境下socket的实现    VxWorks实时操作系统及其在PC104下以太网编程的应用    VxWorks多任务编程中的异常研究    VxWorks下的多重定时器设计    VxWorks下基于BSD4_4规范的网络程序设计    SNMPv1v2c代理在实时操作系统VxWorks内的实现    RTOS VxWorks 在WCDMA BTS平台中的应用    VxWorks应用技巧两例    VxWorks下基于缓冲队列的全双工网络通讯    基于VxWorks的多任务程序设计    VxWorks快速启动的实现方法[上电到应用程序1秒]    NAT在嵌入式系统VxWorks中的设计与实现    Linux与VxWorks任务调度机制分析    VxWorks下的冗余CAN通讯模块设计    VxWorks平台下计算CPU的利用率    VxWorks 6.9及WorkBench 3.3常见配置    VxWorks6.9的EDR功能-设备异常恢复、异常记录    VXWORKS 6.9 KERNEL PROGRAMMING - ISRs    VxWorks 6.9 kernel programming - POSIX    解决VmWare下下载大型工程.out出现WTX Error 0x100de的问题    VxWorks6.6下ftp server的配置    VxWorks下辅助时钟aux clk的使用示例    VxWorks中的sysClkRateGet()返回系统时钟详解    基于VxWorks 跨平台异常处理模块的研究与实现    如何开启VxWorks6.8的Telnet Server    VxWorks几种常用的延时方法    UDP communication between VxWorks68 and Windows    VxWorks6.6移植嵌入式ICE中间件解决方案    一种智能1394B接口模块设计与实现    基于ARM处理器的MVB 2类设备研究    多功能车辆总线控制器芯片(MVBC)的帧收发器设计    基于VxWorks 5.5部署Tilcon的应用    PowerPC在车辆显控系统中的应用    基于VPX总线的高级计算平台的研究与设计    MVB总线在地铁列车控制系统中的应用    基于VxWorks的嵌入式实时PLC设计    基于FPGA片上PowerPC在VxWorks下的千兆网通信    实时操作系统VxWorks在跟踪雷达系统中的应用    Vxworks下X1226与MPC8247的通信    VxWorks解决注释不匹配编译报错的问题    为VxWorks6.X制作X86启动盘    在VxWorks6.x下编译Berkeley数据库    机载大屏幕显示器高速通信系统设计    VxWorks应用程序加载的另一种思路    基于Matlab和VxWorks的无人机飞控系统半物理仿真平台研究    各个版本的tornado及其安装key    VxWorks的压缩技术    VxWorks信号量分析    基于VxWorks的视频采集系统的设计与实现    基于VxWorks的双冗余热切换以太网的设计与实现    基于“龙芯”的VxWorks系统函数在轨更新研究    VxWorks下的组播源码    VxWorks操作系统下的多任务管理    VxWorks实时操作系统下RTP介绍和使用方法    VxWorks镜像在线升级的方法    基于Vxworks实时操作系统的串口通信程序设计与实现    VxWorks下基于select的TCP服务器端socket编程源码    VxWorks下文件读写示例    VxWorks任务间的同步与通信之事件    VxWorks中的任务锁与中断锁    VxWorks网络编程    PowerPC下PCI、PCI-E设备的配置空间    VxWorks PCI配置方法    VxWorks动态加载详解    VxWorks动态加载.out文件    VxWorks的任务间通信    VxWorks系统下任务分析    VxWorks下的串口测试程序设计和源码    VxWorks网络协议栈浅析    VxWorks下的调试组件和命令    VxWorks系统下在NorFlash和SPI Flash上mount文件系统    VxWorks startup启动脚本    VxWorks load加载文件到内存    VxWorks的输入输出重定向    VxWorks下如何得到卷大小    VxWorks编程API介绍    基于VxWorks系统的航电激励器设计与实现    清华大学课件VxWorks实验教程    图形相关   QT 4.8.5 在 VxWorks 6.8和6.9 系统下的使用方法    在VxWorks下进行OpenGL编程环境的搭建    风河推出OpenGL 3D全新图像处理套件    QT下的串口编程    VxWorks 7 技术简介    基于VxWorks的3D图形组件的设计    基于Tilcon航海标绘台界面设计    基于Tilcon的综合导航信息处理装置界面设计    基于Tilcon的指控系统多任务人机交互软件设计    基于Tilcon的嵌入式系统人机界面开发技术    基于Tilcon的交互式多页面的设计    基于Tilcon的VxWorks图形界面开发技术    WindML工业平台下开发S1d13506驱动及显示功能的实现    VxWorks的WindML图形界面程序的框架分析    基于Tilcon的VxWorks简单动画开发    基于VxWorks的WindML图形界面开发方法    基于Tilcon的IO控制板可视化测试软件的设计和实现    基于VxWorks的数据采集与重演软件的图形界面的设计与实现    基于VxWorks的通信服务器实时多任务软件设计    基于嵌入式的Tilcon用户图形界面设计与开发    基于VxWorks的Zinc人机界面的设计与实现    基于VxWorks操作系统的WindML图形操控界面实现方法    基于VxWorks嵌入式系统的中文平台研究与实现    基于VxWorks实时控制系统中文交互界面开发平台    基于Tilcon的某武器显控系统界面设计    指挥系统中VxWorks下汉字显示技术    基于FreeType的VxWorks中文显示方案    在VxWorks系统中使用TrueType字库    基于VxWorks系统的MiniGUI图形界面开发    VxWorks上的一种GUI系统的设计与实现    T9输入法在Tilcon下的实现    嵌入式图形系统Tilcon及应用研究    VxWorks下图形用户界面开发中双缓冲技术应用    VxWorks5.5平台下矢量字体显示的实现    WindML中Mesa的应用    Wind River Tilcon Graphics Suite 5.8.1    基于VxWorks操作系统的三维图形驱动开发    VxWorks操作系统图形模式下显示驱动设计    嵌入式操作系统VxWorks中的显控程序设计    VxWorks汉字显示解决方案    WindML、FreeType和TrueType三者相结合实现矢量字体的显示    WorldWind软件在VxWorks下的移植    VxWorks 5.5中WindML3.0的配置和运行    MiniGUI在VxWorks环境下的移植    VxWorks下WindML相关知识和图形设备驱动程序开发    VxWorks 6.8操作系统下QT的安装设置和运行方法   ]]></content>
  </entry>
  
  <entry>
    <title>VxWorks任务编程中常见异常分析</title>
    <url>/post/vxworks/analysis-of-common-exception-in-vxworks-task-programming.html</url>
    <categories><category>VxWorks</category>
    </categories>
    <tags>
      <tag>VxWorks</tag>
      <tag>Task</tag>
      <tag>Programming</tag>
      <tag>Exception</tag>
    </tags>
    <content type="html"><![CDATA[在任务运行过程中,会出现一些异常的情况,导致任务不能正常运行或者对操作系统造成影响。一般来说,这些异常是由程序的逻辑错误造成的,防止这些异常情况的出现和出现后进行补救就有格外重要的意义。
代码重入与共享 在应用中,可能会出现多个任务调用同一段代码的情况,由于任务占用CPU是串行的,不会出现代码资源使用冲突。但是,不同优先级的任务同时调用同一段代码,则可能出现低优先级任务执行某一函数时被执行该函数的高优先级任务打断的情况,如果函数中要改写全局变量而没有使用互斥,就有可能导致错误的存取。例如在中断中调用内存分配或者释放函数,如果某个任务正在调用内存分配函数或者是内存释放函数,打断该任务时会造成异常,可能导致内存泄漏,甚至有可能会因在中断中异常而reboot。另外,如果多个任务共用的代码中有全局变量且使用目的不同,或者多个任务的代码中有全局变量同名的情况,则有可能造成变量使用中的错误。VxWorks提供了任务变量（taskVar）的方法来解决这个问题,任务可以将使用的全局变量作为任务变量独立使用,添加的任务变量保存在任务的上下文中,任务切换时保存当前内容。
符号表的使用  VxWorks  中有模块（module）的概念。装载模块完成目标代码文件在内存中的链接,并可以将目标代码文件中的函数与全局变量加入符号表。符号表中的符号对C语言编写的函数以原来名字命名,对于C++语言的函数则是在后面加上形参的数据类型作为符号名。如f1( )的符号名为f1__Fv,最后的v表示void类型;f2(int)符号名为f2__Fi,f3(int,int)为f3__Fii,依此类推。代码的编译过程中并不对要使用的函数和变量进行检查。例如调用一个并不存在的函数编译并不报错,编译器认为此函数可能在操作系统内核中或者已经下载的目标文件中,但在目标文件下载时会找不到要调用的函数。如果符号表中的符号出现了重名,譬如两次下载的目标文件中有函数重名,则要作散列处理,之后对该函数的调用是最后加入符号表的函数,而之前已经装载的模块则不会受到影响。如果应用程序中使用了与操作系统内核同名的符号,则对操作系统某些API函数的调用将会失败。
特殊的任务保护 在VxWorks中,当一个任务被删除,其它任务不会得到通知,而且由于任务间的独立性,每一个任务可以无限制地删除其它任务。在应用中,我们可能会把需要保护任务误删除。VxWorks提供的两个函数taskSafe()和taskUnsafe()将通知意外删除任务而引起的问题。当任务调用taskSafe()时,从调用的那一刻起,该任务就被保护起来而不会被其它任务删除。如果任务1试图删除已经调用taskSafe()的任务2,则任务1将被阻塞,直到任务2调用taskUnsafe()。保护只能由任务自己实现,一个任务不能safe或unsafe另外一个任务。taskSafe()和taskUnsafe()支持嵌套模式。如果有嵌套发生,一个计数器将开始工作,每有一个taskSafe()被调用,则计数器加1;调用1个taskUnsafe(),则计数器减1。只有当计数器为0时,才能删除该任务。
有时为了执行效率等原因,任务的运行需要禁止基于优先级的抢占,这可以通过调用taskLock()实现。如果任务1调用taskLock()禁止了高优先级任务对它的抢占,当任务1被阻塞或被暂停,核心将调度下一个具有最高优先级的就绪任务运行。如果这时任务1又就绪且被调度运行,抢占又被禁止。但是,禁止基于优先级的抢占可以阻止任务切换,却并不会屏蔽中断。调用taskUnLock()可以解除优先级抢占的禁止,通过调用taskLock()和taskUnLock()可以实现对临界资源的互斥访问。
任务调度中CPU的占用 如前所述,不同优先级的任务是通过抢占获得CPU使用权的,如果不选时间片轮转,相同优先级的任务之间也是抢占CPU的。任务就绪队列中正在运行的任务如果不主动放弃CPU,则其它同优先级的任务不会得到运行,这样就有可能看到几个同优先级的任务状态同为READY,但实际上只有一个任务在运行的现象。比如在一个任务中用taskSpawn()函数创建一个同优先级或低优先级的任务,如果原任务一直占用CPU,新任务就不会开始运行。调用函数taskDelay()可以使任务放弃CPU一定的时间,从而实现任务间时间上的同步;也可以放弃CPU零时间,将任务移至同优先级就绪队列的末尾,这样就可以实现多个同优先级的任务并发运行。另外,由于中断能够打断任务的运行,中断处理函数中执行的代码就要尽可能少地占用CPU,并且中断中不能有获取信号量的操作。一旦处于等待之中,所有的任务均得不到运行,用户可能会有CPU不响应的错觉。
堆栈越界 如前所述,每一个任务都有自己的堆栈,任务创建时进行初始化。每个堆栈的大小是固定,但是任务运行过程中并不对堆栈的使用进行限制。由于VxWorks不对内存访问作限制,栈顶超越了原定的值后出现越界,这样操作系统中该任务堆栈以外的内存区域就可能被改写,会造成难以预料的结果,甚至可能造成任务的上下文区域被改写而任务消失。造成越界的原因主要是在函数中定义了比较大的数组,以致进栈时越界。这样在编写程序时,就要求在堆栈许可的范围内定义数组。如果确实需要比较大的内存空间,可以使用操作系统的内存分配函数来获得内存。由于堆栈越界后有可能使任务的控制信息被破坏,使得对堆栈越界的检测比较困难,例如可以在栈底写入一串特殊字符,用另外一个任务或者中断服务程序经常来检查是否被改写来判断越界。
CPU异常 在VxWorks中,当任务的指令执行中出现了指令非法、地址寻址错误、总线错、除数为0等情况时,就会出现CPU异常。比较常见的情况是,指针地址非法或者数组下标越界就有可能存取有效地址空间以外的地址而造成CPU异常。VxWorks提供一个异常处理句柄（handler）和一个名为tExcTask的任务来处理异常。异常出现后任务成为挂起状态（suspend）,并且不能转变为其它状态。在VxWorks中,有一个异常向量表来对应各种异常,外部中断也作为一种特殊的异常。VxWorks的做法是把多种异常的处理映射到同一个异常处理函数进行处理,并且VxWorks提供了向这个异常处理函数中钩挂用户的异常处理函数的接口excHookAdd(),也可以将某一个异常向量映射到指定的处理函数。
任务调试模式下的多任务调试 在任务调试模式下，在一个集成环境中，在一个任务中调试，在另一个任务中设置断点，设置的断点不起作用。这是因为一个调试器只能处理一个TCB（任务控制块），每个任务都有一个TCB，因此一个调试器只能调试一个任务，要调试几个任务就要启动几个调试器。一个集成环境只能启动一个调试器，所以要调试几个任务就要启动几个集成环境。另外，需要在被调试的任务的待调试的第一条语句前加入taskSuspend(0)语句，挂起该任务，否则任务就可能会在调试前被执行。
下面是多任务调试的测试用例的源代码
/* VxWorks includes */ #include &#34;vxWorks.h&#34;#include &#34;taskLib.h&#34;#include &#34;stdio.h&#34;#include &#34;msgQLib.h&#34;int g_lTaskATid; int g_lTaskBTid; MSG_Q_ID g_MsgQ1id; MSG_Q_ID g_MsgQ2id; void MultiTaskTestTaskA(void) { char cMsgToTaskB[100]; char cMsgFromTaskB[100]; sprintf(cMsgToTaskB, &#34;To TaskB \n&#34;); printf(&#34; Hello from MultiTaskTestTaskA \n&#34;); /*start point of debugging for MultiTaskTestTaskA */ taskSuspend(0); for (;;) { printf(&#34; Hello from MultiTaskTestTaskA \n&#34;); /*Send message to MultiTaskTestTaskB */ msgQSend(g_MsgQ1id, cMsgToTaskB, sizeof(cMsgToTaskB), WAIT_FOREVER, MSG_PRI_NORMAL); /*Receive message from MultiTaskTestTaskB */ msgQReceive(g_MsgQ2id, cMsgFromTaskB, 100, WAIT_FOREVER); printf(&#34;%s&#34;, cMsgFromTaskB); } } void MultiTaskTestTaskB(void) { char cMsgToTaskA[100]; char cMsgFromTaskA[100]; sprintf(cMsgToTaskA, &#34;To TaskA \n&#34;); printf(&#34; Hello from MultiTaskTestTaskB \n&#34;); /*start point of debugging for MultiTaskTestTaskA */ taskSuspend(0); for (;;) { printf(&#34; Hello from MultiTaskTestTaskB \n&#34;); /*Send message to MultiTaskTestTaskA */ msgQSend(g_MsgQ2id, cMsgToTaskA, sizeof(cMsgToTaskA), WAIT_FOREVER, MSG_PRI_NORMAL); /*Receive message from MultiTaskTestTaskA */ msgQReceive(g_MsgQ1id, cMsgFromTaskA, 100, WAIT_FOREVER); printf(&#34;%s&#34;, cMsgFromTaskA); } } /*This function spawns MultiTaskTestTaskA and MultiTaskTestTaskB , creates g_MsgQ1id and g_MsgQ2id , is entry for debugging.*/ void MultiTaskTestInit(void) { printf(&#34; Hello from MultiTaskTestInit \n&#34;); g_MsgQ1id = msgQCreate(20, 100, MSG_Q_FIFO); if (g_MsgQ1id == NULL) { printf(&#34; ERROR: create g_MsgQ1 error \n&#34;); } g_MsgQ2id = msgQCreate(20, 100, MSG_Q_FIFO); if (g_MsgQ1id == NULL) { printf(&#34; ERROR: create g_MsgQ2 error \n&#34;); } printf(&#34; Spawning a new task called MultiTaskTestTaskA \n\n&#34;); g_lTaskATid = taskSpawn(&#34;MultiTaskTestTaskA&#34;, 100, 0, 10000, (FUNCPTR) MultiTaskTestTaskA, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0); if (g_lTaskATid == ERROR) { printf(&#34; ERROR: task did not spawn \n&#34;); exit(1); } printf(&#34; Spawning a new task called MultiTaskTestTaskB\n&#34;); g_lTaskBTid = taskSpawn(&#34;MultiTaskTestTaskB&#34;, 100, 0, 10000, (FUNCPTR) MultiTaskTestTaskB, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0); if (g_lTaskBTid == ERROR) { printf(&#34; ERROR: task did not spawn \n&#34;); exit(1); } exit(0); } 多任务调试步骤：  用-g选项编译源代码产生目标文件 下载产生的目标文件 在MultiTaskTestInit函数的开始设置断点 把MultiTaskTestInit设置为调试任务的人口函数 单步执行产生MultiTaskTestTaskA任务的语句后可以在串口（超级终端）上看到字符串Hello from MultiTaskTestTaskA，用Browser查看任务，可以看到任务MultiTaskTestTaskA出于挂起态（suspended），表明程序执行了taskSuspend(0)语句。 运行另一个Tornado集成环境 Attach任务MultiTaskTestTaskA 在语句msgQReceive(g_MsgQ2id,cMsgFromTaskB,100,WAIT_FOREVER)的下一条语句处设置断点 运行任务MultiTaskTestTaskA。可以看到没有执行到断点处，用Browser查看任务状态，MultiTaskTestTaskA出于阻塞态（pended），因为它在等待消息。 单步执行MultiTaskTestInit到产生MultiTaskTestTaskB任务的下一条语句，可以看到MultiTaskTestTaskB任务处于挂起态 再运行另一个Tornado集成环境 Attach任务MultiTaskTestTaskB 在语句msgQReceive(g_MsgQ1id,cMsgFromTaskA,100,WAIT_FOREVER)下一条语句处设置断点 运行任务MultiTaskTestTaskB。可以看到执行到断点处停下。这是因为MultiTaskTestTaskA任务已经发送一条消息到MultiTaskTestTaskB的接收队列中。 此时，可以看到MultiTaskTestTaskA任务也运行到断点处，因为为MultiTaskTestTaskB任务已经发送一条消息到MultiTaskTestTaskA的接收队列中。  系统调试模式下程序的调试 Tornado集成环境提供两种调试模式：任务调试模式和系统调试模式。在任务调试模式下，在一个集成环境下一个时间内只能调试一个任务。调试只影响当前被调试的任务，其它任务正常运行。在系统调试模式下，可以同时调试多个任务、中断服务程序（ISR），调试影响整个系统。
Tornado1.0集成环境下，在系统模式下进行程序调试，主机与目标机之间必须使用串口通信。Tornado2.0集成环境提供了通过网口进行系统模式调试的功能。
系统缺省使用网口通信，如果需要使用串口通信，需要修改文件C: \ Tornado \ target \ config \ all \ configAll.h的一些宏定义，修改为：
#define WDB_COMM_TYPE	WDB_COMM_SERIAL /* 使用串口通信 */#define WDB_TTY_CHANNEL	0 /* 使用第一个串口 */#define WDB_TTY_BAUD	38400 /* 波特率: 38400bps */重新编译链接vxWorks。
在启动目标服务器时，要选择串口通信，并进行相应配置。
系统调试模式下多任务的调试： 调试使用的源代码与任务调试模式中使用的代码相同。但是，需要去掉为了能够在任务调试模式下进行多任务调试的MultiTaskTestTaskA和MultiTaskTestTaskB中的语句taskSuspend(0);
多任务调试步骤：  用-g选项编译源代码产生目标文件。 下载产生的目标文件。 在MultiTaskTestInit函数的开始设置断点。 在Debugger命令窗口输入命令attach system进入系统调试模式。 在Shell窗口输入命令sp MultiTaskTestInit产生一个以MultiTaskTestInit为入口函数的任务，因为整个系统都停下了，新产生的任务还没有执行，这可以通过在Debugger命令窗口输入命令info threads显示当前系统中的任务列表看出来。 执行菜单命令Debug | Continue继续运行程序。 系统在设置的断点处停下。 在函数MultiTaskTestTaskA中的语句msgQReceive(g_MsgQ2id,cMsgFromTaskB, 100,WAIT_FOREVER)的下一条语句处设置断点。 在函数MultiTaskTestTaskB中的语句msgQReceive(g_MsgQ1id,cMsgFromTaskA, 100,WAIT_FOREVER)的下一条语句处设置断点。 执行菜单命令Debug | Continue继续运行程序。 程序在任务MultiTaskTestTaskB中的断点处停下（为什么不是在任务MultiTaskTestTaskA中停下？请考虑）。 执行菜单命令Debug | Continue继续运行程序。 程序在任务MultiTaskTestTaskA中的断点处停下。 执行菜单命令Debug | Continue继续运行程序。 程序又一次在任务MultiTaskTestTaskA中的断点处停下（为什么停两次？请考虑）。 执行菜单命令Debug | Continue继续运行程序。 程序在任务MultiTaskTestTaskB中的断点处停下。  中断服务程序的调试 中断服务程序只能在系统调试模式下调试，不能在任务调试模式下调试。因为中断服务程序是作为系统的一部分运行，不是以任务方式运行，因此不需要为它产生任务。
中断服务程序调试步骤：
 用-g选项编译源代码产生目标文件。 下载产生的目标文件。 在MultiTaskTestInit函数的开始设置断点。 在Debugger命令窗口输入命令attach system进入系统调试模式。 执行菜单命令Debug | Continue继续运行程序。 如果产生相应的中断，程序就会在中断服务程序的断点处停下。进行需要的调试。  原文连接： VxWorks任务编程中常见异常分析  
]]></content>
  </entry>
  
  <entry>
    <title>Linux进程管理工具htop</title>
    <url>/post/linux/linux-system-process-management-tool-htop.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Process</tag>
      <tag>Top</tag>
      <tag>htop</tag>
    </tags>
    <content type="html"><![CDATA[今天我要给大家分享一个比Top更好用的进程管理工具htop（High Top）。
前言 相信用过Linux操作系统的同学对Top应该都不陌生，我们通过Top命令可以查看CPU的占用率以及每个进程的详细信息，但是今天我要给大家分享一个比Top更好用的进程管理工具htop（High Top）。
htop功能介绍 htop 是一个高级系统监控工具，可用于查看正在运行的进程和占用资源的情况。它提供了更多功能和更友好的交互界面，常常被用作 top 命令的替代品，使用户可以更方便地管理进程和资源。
下面给大家总结一下htop 工具常用的一些功能：
 查看进程和资源使用情况。 显示系统中运行进程的树形结构。 支持鼠标操作以及键盘快捷方式。 可以按 CPU 占用率、内存占用量等来排序显示进程列表。 将进程列表中各个进程以不同颜色标识出来，以方便识别。 显示各个进程的资源使用情况，包括 CPU 占用率、内存占用量、虚拟内存占用量等。 可以显示各个进程的命令行参数。 显示系统的 CPU 和内存使用情况，包括 CPU 占用率、内存总量、已经使用的内存、闲置内存和实际可用内存等。 提供了许多快捷键，以便于你在使用时更加方便，包括筛选进程显示、刷新显示、增加/减少进程优先级、杀掉进程等。 允许自定义配置，包括设置显示选项、排序选项、颜色选项、进程筛选选项、日志选项等。  如何安装htop？ htop 工具在 Linux 系统中是一个常见的应用，通常可以通过包管理器进行安装。在 Debian/Ubuntu 和 Red Hat/CentOS 等发行版中，安装方法分别如下：
Debian/Ubuntu sudo apt-get update sudo apt-get install htop Red Hat/CentOS sudo yum install epel-release sudo yum install htop 通过上面的命令将从软件包存储库中下载并安装 htop 工具，安装成功后可以输入指令htop查看是否安装成功。
如何使用htop？ 启动 htop 后，默认情况下会打开它的主界面，显示当前运行的进程和他们所占用的资源。以下是 htop 的主要特点：
 支持鼠标操作以及键盘快捷方式。 可以按 CPU 占用率、内存占用量等来排序显示进程列表。 进程列表中将各个进程以不同颜色标识出来，以方便识别。 将进程和系统的资源使用情况显示在头部和屏幕底部，包括 CPU 和内存占用率、交换空间使用情况以及已运行时间等。  htop 界面说明 启动 htop 后，你将看到它非常直观的界面。以下是主要组成部分：
顶部 顶部一栏显示的是系统的整体状态，包含了当前时间、系统已经运行的时间、负载平均值、CPU 占用率、内存占用量、swap 使用量等信息。当你需要了解基础的系统资源使用情况时，这个部分是非常有用的。
进程列表 在中间部分，htop 显示了整个系统中各个进程的情况，包括进程 ID，进程状态，进程所在用户，CPU 占用率，内存占用量、虚拟内存占用量和进程名。可以通过鼠标或键盘上下移动光标并选择不同的进程。
底部 底部显示系统的 CPU 和内存使用情况，包括 CPU 占用率、内存总量、已经使用的内存、闲置内存和实际可用内存等。同时还包含长期和短期的 CPU 负载平均值。
htop 快捷键 htop 工具提供了许多快捷键，以便于你在使用时更加方便，以下是常用的一些：
F1 — 帮助菜单 F2 — 设置选项 F3/F4 — 筛选进程显示 F5 — 刷新显示 F6 — 切换排序方式 F7/F8 — 增加/减少进程优先级 F9 — 杀掉进程 F10 — 退出htop htop 配置选项 htop 工具还允许您按照自己的习惯自定义配置。你可以通过按 F2 进入设置选项来配置它们。包括但不限于：
 显示选项：选择要在进程列表中显示哪些列。 排序选项：自定义进程列表中各个字段的排序方式。 颜色选项：修改 htop 中各种状态显示的颜色。 进程筛选选项：可以指定只显示或隐藏特定用户或进程。 日志选项：启用系统记录功能，并将 htop 记录到指定文件。  原文连接: Linux进程管理工具htop  
]]></content>
  </entry>
  
  <entry>
    <title>嵌入式开发中的C语言-测试</title>
    <url>/post/software/c-programming-language-test.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>Embedded</tag>
      <tag>C programming language</tag>
      <tag>Test</tag>
    </tags>
    <content type="html"><![CDATA[思维再缜密的程序员也不可能编写完全无缺陷的C语言程序，测试的目的正是尽可能多的发现这些缺陷并改正。
这里说的测试，是指程序员的自测试。前期的自测试能够更早的发现错误，相应的修复成本也会很低，如果你不彻底测试自己的代码，恐怕你开发的就不只是代码，可能还会声名狼藉。
优质嵌入式C程序跟优质的基础元素关系密切，可以将函数作为基础元素，我们的测试正是从最基本的函数开始。判断哪些函数需要测试需要一定的经验积累，虽然代码行数跟逻辑复杂度并不成正比，但如果你不能判断某个函数是否要测试，一个简单粗暴的方法是：当函数有效代码超过20行，就测试它。
程序员对自己的代码以及逻辑关系十分清楚，测试时，按照每一个逻辑分支全面测试。很多错误发生在我们认为不会出错的地方，所以即便某个逻辑分支很简单，也建议测试一遍。第一个原因是我们自己看自己的代码总是不容易发现错误，而测试能暴露这些错误；另一方面，语法正确、逻辑正确的代码，经过编译器编译后，生成的汇编代码很可能与你的逻辑相差甚远。
比如我们前文提及的使用volatile以及不使用volatile关键字编译后生成的汇编代码，再比如我们用低优化级别编译和使用高优化级别编译后生成的汇编代码，都可能相差很大，实际运行测试，可以暴漏这些隐含错误。最后，虽然可能性极小，编译器本身也可能有BUG，特别是构造复杂表达式的情况下（应极力避免复杂表达式）。
使用硬件调试器测试 使用硬件调试器（比如J-link）测试是最通用的手段。可以单步运行、设置断点，可以很方便的查看当前寄存器、变量的值。在寻找缺陷方面，使用硬件调试器测试是最简单却又最有效的手段。
硬件调试器已经在公司普遍使用，这方面的测试不做介绍，想必大家都已经很熟悉了。
有些缺陷很难缠 就像没有一种方法能完美解决所有问题，在实际项目中，硬件调试器也有难以触及的地方。可以举几个例子说明：
 使用了比较大的协议栈，需要跟进到协议栈内部调试的缺陷  比如公司使用lwIP协议栈，如果跟踪数据的处理过程，需要从接收数据开始一直到应用层处理数据，之间会经过驱动层、IP层、TCP层和应用层，会经过十几个文件几十个函数，使用硬件调试器跟踪费时费力；
 具有随机性的缺陷  有一些缺陷，可能是不定时出现的，有可能是几分钟出现，也有可能是几个小时甚至几天才出现，像这样的缺陷很难用硬件调试器捕捉到；
 需要外界一系列有时间限制的输入条件触发，但这一过程中有缺陷  比如我们用组合键来完成某个功能，规定按下按键1不小于3秒后松开，然后在6秒内分别按下按键2、按键3、按键4这三个按键来执行我们的特定程序，要测试类似这种过程，硬件调试器很难做到；
除了测试缺陷需要，有时候我们在做稳定性测试时，需要知道软件每时每刻运行到那些分支、执行了哪些操作、我们关心的变量当前值是什么等等，这些都表明，我们还需要一种和硬件调试器互补的测试手段。
这个测试手段就是在程序中增加额外调试语句，当程序运行时，通过这些调试语句将运行信息输出到可以方便查看的设备上，可以是PC机、LCD显示屏、存储卡等等。
以串口输出到PC机为例，下面提供完整的测试思路。在此之前，我们先对这种测试手段提一些要求：
 必须简单易用  我们在初学C语言的时候，都接触过printf函数，这个函数可以方便的输出信息，并可以将各种变量格式化为指定格式的字符串，我们应当提供类似的函数；
 调试语句必须方便的从代码中移除  在编码阶段，我们可能会往程序中加入大量的调试语句，但是程序发布时，需要将这些调试语句从代码中移除，这将是件恐怖的过程。我们必须提供一种策略，可以方便的移除这些调试语句。
简单易用的调试函数 使用库函数printf。以MDK为例，方法如下   初始化串口
  重构fputc函数，printf函数会调用fputc函数执行底层串口的数据发送。
  /** * @brief 将C库中的printf函数重定向到指定的串口. * @param ch:要发送的字符 * @param f:文件指针 */ int fputc(int ch, FILE *f) { /* 这里是一个跟硬件相关函数，将一个字符写到UART */ //举例： USART_SendData(UART_COM1, (unit8_t) ch); 	return ch; } 在Options for Targer窗口，Targer标签栏下，勾选Use MicroLIB前的复选框以便避免使用半主机功能。（注：标准C库printf函数默认开启半主机功能，如果非要使用标准C库，请自行查阅资料）  构建自己的调试函数 使用库函数比较方便，但也少了一些灵活性，不利于随心所欲的定制输出格式。自己编写类似printf函数则会更灵活一些，而且不依赖任何编译器。下面给出一个完整的类printf函数实现，该函数支持有限的格式参数，使用方法与库函数一致。
同库函数类似，该也需要提供一个底层串口发送函数（原型为：int32_t UARTwrite(const uint8_t *pcBuf, uint32_t ulLen)），用来发送指定数目的字符，并返回最终发送的字符个数。
#include &lt;stdarg.h&gt; /*支持函数接收不定量参数*/  const char * const g_pcHex = &#34;0123456789abcdef&#34;; /** * 简介: 一个简单的printf函数,支持\%c, \%d, \%p, \%s, \%u,\%x, and \%X. */ void UARTprintf(const uint8_t *pcString, ...) { uint32_t ulIdx; uint32_t ulValue; //保存从不定量参数堆栈中取出的数值型变量  uint32_t ulPos, ulCount; uint32_t ulBase; //保存进制基数,如十进制则为10,十六进制数则为16  uint32_t ulNeg; //为1表示从变量为负数  uint8_t *pcStr; //保存从不定量参数堆栈中取出的字符型变量  uint8_t pcBuf[32]; //保存数值型变量字符化后的字符  uint8_t cFill; //&#39;%08x&#39;-&gt;不足8个字符用&#39;0&#39;填充,cFill=&#39;0&#39;;  //&#39;%8x &#39;-&gt;不足8个字符用空格填充,cFill=&#39; &#39;  va_list vaArgP; va_start(vaArgP, pcString); while(*pcString) { // 首先搜寻非%核字符串结束字符  for(ulIdx = 0; (pcString[ulIdx] != &#39;%&#39;) &amp;&amp; (pcString[ulIdx] != &#39;\0&#39;); ulIdx++) { } UARTwrite(pcString, ulIdx); pcString += ulIdx; if(*pcString == &#39;%&#39;) { pcString++; ulCount = 0; cFill = &#39; &#39;; again: switch(*pcString++) { case &#39;0&#39;: case &#39;1&#39;: case &#39;2&#39;: case &#39;3&#39;: case &#39;4&#39;: case &#39;5&#39;: case &#39;6&#39;: case &#39;7&#39;: case &#39;8&#39;: case &#39;9&#39;: { // 如果第一个数字为0, 则使用0做填充,则用空格填充)  if((pcString[-1] == &#39;0&#39;) &amp;&amp; (ulCount == 0)) { cFill = &#39;0&#39;; } ulCount *= 10; ulCount += pcString[-1] - &#39;0&#39;; goto again; } case &#39;c&#39;: { ulValue = va_arg(vaArgP, unsigned long); UARTwrite((unsigned char *)&amp;ulValue, 1); break; } case &#39;d&#39;: { ulValue = va_arg(vaArgP, unsigned long); ulPos = 0; if((long)ulValue &lt; 0) { ulValue = -(long)ulValue; ulNeg = 1; } else { ulNeg = 0; } ulBase = 10; goto convert; } case &#39;s&#39;: { pcStr = va_arg(vaArgP, unsigned char *); for(ulIdx = 0; pcStr[ulIdx] != &#39;\0&#39;; ulIdx++) { } UARTwrite(pcStr, ulIdx); if(ulCount &gt; ulIdx) { ulCount -= ulIdx; while(ulCount--) { UARTwrite(&#34; &#34;, 1); } } break; } case &#39;u&#39;: { ulValue = va_arg(vaArgP, unsigned long); ulPos = 0; ulBase = 10; ulNeg = 0; goto convert; } case &#39;x&#39;: case &#39;X&#39;: case &#39;p&#39;: { ulValue = va_arg(vaArgP, unsigned long); ulPos = 0; ulBase = 16; ulNeg = 0; convert: //将数值转换成字符  for(ulIdx = 1; (((ulIdx * ulBase) &lt;= ulValue) &amp;&amp;(((ulIdx * ulBase) / ulBase) == ulIdx)); ulIdx *= ulBase, ulCount--) { } if(ulNeg) { ulCount--; } if(ulNeg &amp;&amp; (cFill == &#39;0&#39;)) { pcBuf[ulPos++] = &#39;-&#39;; ulNeg = 0; } if((ulCount &gt; 1) &amp;&amp; (ulCount &lt; 16)) { for(ulCount--; ulCount; ulCount--) { pcBuf[ulPos++] = cFill; } } if(ulNeg) { pcBuf[ulPos++] = &#39;-&#39;; } for(; ulIdx; ulIdx /= ulBase) { pcBuf[ulPos++] = g_pcHex[(ulValue / ulIdx)% ulBase]; } UARTwrite(pcBuf, ulPos); break; } case &#39;%&#39;: { UARTwrite(pcString - 1, 1); break; } default: { UARTwrite(&#34;ERROR&#34;, 5); break; } } } } //可变参数处理结束  va_end(vaArgP); } 对调试函数进一步封装 上文说到，我们增加的调试语句应能很方便的从最终发行版中去掉，因此我们不能直接调用printf或者自定义的UARTprintf函数，需要将这些调试函数做一层封装，以便随时从代码中去除这些调试语句。参考方法如下：
#ifdef MY_DEBUG #define MY_DEBUG(message) do { \ {UARTprintf message;} \ } while(0) #else #define MY_DEBUG(message) #endif /* PLC_DEBUG */在我们编码测试期间，定义宏MY_DEBUG，并使用宏MY_DEBUGF（注意比前面那个宏多了一个‘F’）输出调试信息。经过预处理后，宏MY_DEBUGF(message)会被UARTprintf message代替，从而实现了调试信息的输出；当正式发布时，只需要将宏MY_DEBUG注释掉，经过预处理后，所有MY_DEBUGF(message)语句都会被空格代替，而从将调试信息从代码中去除掉。
]]></content>
  </entry>
  
  <entry>
    <title>如何在去耦电路中选择耦合电容的容量</title>
    <url>/post/hardware/selection-of-the-coupling-capacitor-capacity-in-the-decoupling-circuit.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>Decoupling</tag>
      <tag>Coupling Circuit</tag>
      <tag>Capacitor</tag>
    </tags>
    <content type="html"><![CDATA[耦合指信号由第一级向第二级传递的过程，一般不加注明时往往是指交流耦合。
退耦是指对电源采取进一步的滤波措施，去除两级间信号通过电源互相干扰的影响。耦合常数是指耦合电容值与第二级输入阻抗值乘积对应的时间常数。
退耦有三个目的   将电源中的高频纹波去除，将多级放大器的高频信号通过电源相互串扰的通路切断。
  大信号工作时，电路对电源需求加大，引起电源波动，通过退耦降低大信号时电源波动对输入级/高电压增益级的影响。
  形成悬浮地或是悬浮电源，在复杂的系统中完成各部分地线或是电源的协调匹配，有源器件在开关时产生的高频开关噪声将沿着电源线传播。
  去耦电容的主要功能就是提供一个局部的直流电源给有源器件，以减少开关噪声在板上的传播和将噪声引导到地。
干扰的耦合方式 干扰源产生的干扰信号是通过一定的耦合通道对电控系统发生电磁干扰作用的。干扰的耦合方式无非是通过导线、空间、公共线等作用在电控系统上。分析下来主要有以下几种：
直接耦合 这是干扰侵入最直接的方式，也是系统中存在最普遍的一种方式。如干扰信号通过导线直接侵入系统而造成对系统的干扰。对这种耦合方式，可采用滤波去耦的方法有效地抑制电磁干扰信号的传入。
公共阻抗耦合 这也是常见的一种耦合方式，常发生在两个电路的电流有共同通路的情况。公共阻抗耦合有公共地和电源阻抗两种。防止这种耦合应使耦合阻抗趋近于零，使干扰源和被干扰对象间没有公共阻抗。
电容耦合 又称电场耦合或静电耦合，是由于分布电容的存在而产生的一种耦合方式。
电磁感应耦合 又称磁场耦合，是由于内部或外部空间电磁场感应的一种耦合方式，防止这种耦合的常用方法是对容易受干扰的器件或电路加以屏蔽。
辐射耦合 电磁场的辐射也会造成干扰耦合，是一种无规则的干扰。这种干扰很容易通过电源线传到系统中去。另当信号传输线较长时，它们能辐射干扰波和接收干扰波，称为长线效应。
漏电耦合 所谓漏电耦合就是电阻性耦合，这种干扰常在绝缘降低时发生。去耦电容一般容量比较大，也就是避免噪声耦合到其他部分的意思；旁路电容容量小，提供低阻抗的噪声回流路径。
其实这种说法也可以算没有什么大错误。但是查阅了相关资料，才发现其实decouple和bypass从根本上来说没有任何区别，两者在称谓上可以互换。两者的作用低俗一点说：当电源用。
所谓噪声其实就是电源的波动。电源波动来自于两个方面：电源本身的波动，负载对电流需求变化和电源系统相应能力的差别带来的电压波动。而去耦和旁路电容都是相对负载变化引起的噪声来说。
所以它们两个没有必要做区分。而且实际上电容值的大小，数量也是有理论根据可循的，如果随意选择，可能会在某些情况下遇到去耦电容（旁路）和分布参数发生自激振荡的情况。
所以真正意义上的去耦和旁路都是根据负载和供电系统的实际情况来说的，没有必要去做区分，也没有本质区别。
]]></content>
  </entry>
  
  <entry>
    <title>0欧电阻、电感、磁珠单点接地时有什么区别</title>
    <url>/post/hardware/difference-between-inductor-resistor-magnetic-beeds-when-pull-down-to-ground.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>Inductor</tag>
      <tag>Resistor</tag>
      <tag>Magnetic Beeds</tag>
    </tags>
    <content type="html"><![CDATA[只要是地，最终都要接到一起，然后入大地。如果不接在一起就是“浮地”，存在压差，容易积累电荷，造成静电。地是参考0电位，所有电压都是参考地得出的，地的标准要一致，故各种地应短接在一起。
一般认为大地能够吸收所有电荷，始终维持稳定，是最终的地参考点。虽然有些板子没有接大地，但发电厂是接大地的，板子上的电源最终还是会返回发电厂入地。如果把模拟地和数字地大面积直接相连，会导致互相干扰。
通常使用的单点接地的方法有以下四种： *使用磁珠连接 *使用电容连接 *使用0欧姆电阻连接 *使用电感连接
上述四种接地方法的区别： *磁珠的等效电路相当于带阻限波器，只对某个频点的噪声有显著抑制作用，使用时需要预先估计噪点频率，以便选用适当型号。对于频率不确定或无法预知的情况，磁珠不合适。　*电容，通交阻直，容易造成“浮地”。 *电感体积大，杂散参数多，不稳定。 *0欧电阻相当于很窄的电流通路，能够有效地限制环路电流，使噪声得到抑制。电阻在所有频带上都有衰减作用(0欧电阻也有阻抗)，这点比磁珠强。
0欧姆电阻的作用  在电路中没有任何功能，只是在PCB上为了调试方便或兼容设计等原因。　 可以做跳线用，如果某段线路不用，直接不贴该电阻即可（不影响外观）。 在匹配电路参数不确定的时候，以0欧姆代替，实际调试的时候，确定参数，再以具体数值的元件代替。　 测某部分电路的耗电流的时候，可以去掉0ohm电阻，接上电流表，这样方便测耗电流。 布线时，如果实在布不过去了，也可以加一个0欧的电阻  在高频信号下，充当电感或电容用（与外部电路特性有关），主要是解决EMC问题。如地与地，电源和IC Pin间  单点接地（指保护接地、工作接地、直流接地在设备上相互分开,各自成为独立系统。）  熔丝作用  跨接时用于电流回路：当分割电地平面后，造成信号最短回流路径断裂，此时，信号回路不得不绕道，形成很大的环路面积，电场和磁场的影响就变强了，容易干扰/被干扰。在分割区上跨接0欧电阻，可以提供较短的回流路径，减小干扰。 配置电路：一般情况下，产品上不要出现跳线和拨码开关。有时用户会乱动设置，易引起误会，为了减少维护费用，应用0欧电阻代替跳线等焊在板子上。空置跳线在高频时相当于天线，用贴片电阻效果好。  磁珠 磁珠专用于抑制信信号线、电源线上的高频噪声和尖峰干扰，还具有吸收静电脉冲的能力。 磁珠是用来吸收超高频信号，象一些RF电路，PLL，振荡电路，含超高频存储器电路（DDR，SDRAM，RAMBUS等）都需要在电源输入部分加磁珠，而电感是一种蓄能元件，用在LC振荡电路，中低频的滤波电路等，其应用频率范围很少超过50MHZ。 磁珠有很高的电阻率和磁导率，等效于电阻和电感串联，但电阻值和电感值都随频率变化。
磁珠的功能 主要是消除存在于传输线结构（电路）中的RF噪声，RF能量是叠加在直流传输电平上的交流正弦波成分，直流成分是需要的有用信号，而射频RF能量却是无用的电磁干扰沿着线路传输和辐射（EMI）。要消除这些不需要的信号能量，使用片式磁珠扮演高频电阻的角色（衰减器），该器件允许直流信号通过，而滤除交流信号。通常高频信号为30MHz以上，然而，低频信号也会受到片式磁珠的影响。
磁珠有很高的电阻率和磁导率，它等效于电阻和电感串联，但电阻值和电感值都随频率变化。它比普通的电感有更好的高频滤波特性，在高频时呈现阻性，所以能在相当宽的频率范围内保持较高的阻抗，从而提高调频滤波效果。
作为电源滤波，可以使用电感。磁珠的电路符号就是电感但是型号上可以看出使用的是磁珠在电路功能上，磁珠和电感是原理相同的，只是频率特性不同罢了。
注：磁珠的单位是欧姆，而不是亨利，这一点要特别注意。因为磁珠的单位是按照它在某一频率 产生的阻抗来标称的，阻抗的单位也是欧姆。
电感 电感是闭合回路的一种属性。当线圈通过电流后，在线圈中形成磁场感应，感应磁场又会产生感应电流来抵制通过线圈中的电流。这种电流与线圈的相互作用关系称为电的感抗，也就是电感，单位是“亨利（H）”。
磁珠与电感的区别  电感是储能元件，而磁珠是能量转换（消耗）器件。电感多用于电源滤波回路，侧重于抑止传导性干扰； 磁珠多用于信号回路，主要用于EMI方面。磁珠用来吸收超高频信号，象一些RF电路，PLL，振荡电路，含超高频存储器电路（DDR，SDRAM，RAMBUS等）都需要在电源输入部分加磁珠，而电感是一种储能元件，用在LC振荡电路、中低频的滤波电路等，其应用频率范围很少超过50MHz。在电路功能上，磁珠和电感是原理相同的，只是频率特性不同罢了。 ]]></content>
  </entry>
  
  <entry>
    <title>嵌入式开发中的C语言</title>
    <url>/post/software/c-programming-language-in-embedded.html</url>
    <categories><category>Software</category>
    </categories>
    <tags>
      <tag>Embedded</tag>
      <tag>C programming language</tag>
    </tags>
    <content type="html"><![CDATA[本文首先分析了C语言的陷阱和缺陷，对容易犯错的地方进行归纳整理；
摘要：本文首先分析了C语言的陷阱和缺陷，对容易犯错的地方进行归纳整理；分析了编译器语义检查的不足之处并给出防范措施，以Keil MDK编译器为例，介绍了该编译器的特性、对未定义行为的处理以及一些高级应用；在此基础上，介绍了防御性编程的概念，提出了编程过程中就应该防范于未然的多种措施；提出了测试对编写优质嵌入式程序的重要作用以及常用测试方法；最后，本文试图以更高的层次看待编程，讨论一些通用的编程思想。
编程思想 编程风格 《计算机程序的构造和解释》一书在开篇写到：程序写出来是给人看的，附带能在机器上运行。
整洁的样式 使用什么样的编码样式一直都颇具争议性的，比如缩进和大括号的位置。因为编码的样式也会影响程序的可读性，面对一个乱放括号、对齐都不一致的源码，我们很难提起阅读它的兴趣。我们总要看别人的程序，如果彼此编码样式相近，读起源码来会觉得比较舒适。但是编码风格的问题是主观的，永远不可能在编码风格上达成统一意见。因此只要你的编码样式整洁、结构清晰就足够了。除此之外，对编码样式再没有其它要求。
提出匈牙利命名法的程序员、前微软首席架构师Charles Simonyi说：我觉得代码清单带给人的愉快同整洁的家差不多。你一眼就能分辨出家里是杂乱无章还是整洁如新。这也许意义不大。因为光是房子整洁说明不了什么，它仍可能藏污纳垢！但是第一印象很重要，它至少反映了程序的某些方面。我敢打赌，我在3米开外就能看出程序拙劣与否。我也许没法保证它很不错，但如果从3米外看起来就很糟，我敢保证这程序写得不用心。如果写得不用心，那它在逻辑上也许就不会优美。
清晰的命名 变量、函数、宏等等都需要命名，清晰的命名是优秀代码的特点之一。命名的要点之一是名称应能清晰的描述这个对象，以至于一个初级程序员也能不费力的读懂你的代码逻辑。我们写的代码主要给谁看是需要思考的：给自己、给编译器还是给别人看？我觉得代码最主要的是给别人看，其次是给自己看。如果没有一个清晰的命名，别人在维护你的程序时很难在整个全貌上看清代码，因为要记住十多个以上的糟糕命名的变量是件非常困难的事；而且一段时间之后你回过头来看自己的代码，很有可能不记得那些糟糕命名的变量是什么意思。
为对象起一个清晰的名字并不是简单的事情。首先能认识到名称的重要性需要有一个过程，这也许跟谭式C程序教材被大学广泛使用有关：满书的a、b、c、x、y、z变量名是很难在关键的初学阶段给人传达优秀编程思想的；其次如何恰当的为对象命名也很有挑战性，要准确、无歧义、不罗嗦，要对英文有一定水平，所有这些都要满足时，就会变得很困难；此外，命名还需要考虑整体一致性，在同一个项目中要有统一的风格，坚持这种风格也并不容易。
关于如何命名，Charles Simonyi说：面对一个具备某些属性的结构，不要随随便便地取个名字，然后让所有人去琢磨名字和属性之间有什么关联，你应该把属性本身，用作结构的名字。
恰当的注释 注释向来也是争议之一，不加注释和过多的注释我都是反对的。不加注释的代码显然是很糟糕的，但过多的注释也会妨碍程序的可读性，由于注释可能存在的歧义，有可能会误解程序真实意图，此外，过多的注释会增加程序员不必要的时间。如果你的编码样式整洁、命名又很清晰，那么，你的代码可读性不会差到哪去，而注释的本意就是为了便于理解程序。
这里建议使用良好的编码样式和清晰的命名来减少注释，对模块、函数、变量、数据结构、算法和关键代码做注释，应重视注释的质量而不是数量。如果你需要一大段注释才能说清楚程序做什么，那么你应该注意了：是否是因为程序变量命名不够清晰，或者代码逻辑过于混乱，这个时候你应该考虑的可能就不是注释，而是如何精简这个程序了。
数据结构 数据结构是程序设计的基础。在设计程序之前，应该先考虑好所需要的数据结构。
前微软首席架构师Charles Simonyi：编程的第一步是想象。就是要在脑海中对来龙去脉有极为清晰的把握。在这个初始阶段，我会使用纸和铅笔。我只是信手涂鸦，并不写代码。我也许会画些方框或箭头，但基本上只是涂鸦，因为真正的想法在我脑海里。我喜欢想象那些有待维护的结构，那些结构代表着我想编码的真实世界。一旦这个结构考虑得相当严谨和明确，我便开始写代码。我会坐到终端前，或者换在以前的话，就会拿张白纸，开始写代码。这相当容易。我只要把头脑中的想法变换成代码写下来，我知道结果应该是什么样的。大部分代码会水到渠成，不过我维护的那些数据结构才是关键。我会先想好数据结构，并在整个编码过程中将它们牢记于心。
开发过以太网和操作系统SDS 940的Butler Lampson：（程序员）最重要的素质是能够把问题的解决方案组织成容易操控的结构。
开发CP/M操作系统的Gary.A：如果不能确认数据结构是正确的，我是决不会开始编码的。我会先画数据结构，然后花很长时间思考数据结构。在确定数据结构之后我就开始写一些小段的代码，并不断地改善和监测。在编码过程中进行测试可以确保所做的修改是局部的，并且如果有什么问题的话，能够马上发现。
微软创始人比尔·盖茨：编写程序最重要的部分是设计数据结构。接下来重要的部分是分解各种代码块。
编写世界上第一个电子表格软件的Dan Bricklin：在我看来，写程序最重要的部分是设计数据结构，此外，你还必须知道人机界面会是什么样的。
我们举个例子来说明。在介绍防御性编程的时候，提到公司使用的LCD显示屏抗干扰能力一般，为了提高LCD的稳定性，需要定期读出LCD内部的关键寄存器值，然后跟存在Flash中的初始值相比较。需要读出的LCD寄存器有十多个，从每个寄存器读出的值也不尽相同，从1个到8个字节都有可能。如果不考虑数据结构，编写出的程序将会很冗长。
void lcd_redu(void) { 读第一个寄存器值; if(第一个寄存器值==Flash存储值) { 读第二个寄存器值; if(第二个寄存器值==Flash存储值) { ... 读第十个寄存器值; if(第十个寄存器值==Flash存储值) { 返回; } else { 重新初始化LCD; } } else { 重新初始化LCD; } } else { 重新初始化LCD; } } 我们分析这个过程，发现能提取出很多相同的元素，比如每次读LCD寄存器都需要该寄存器的命令号，都会经过读寄存器、判断值是否相同、处理异常情况这一过程。所以我们可以提取一些相同的元素，组织成数据结构，用统一的方法去处理这些数据，将数据与处理过程分开来。
我们可以先提取相同的元素，将之组织成数据结构：
typedef struct { uint8_t lcd_command; //LCD寄存器  uint8_t lcd_get_value[8]; //初始化时写入寄存器的值  uint8_t lcd_value_num; //初始化时写入寄存器值的数目  }lcd_redu_list_struct; 这里lcd_command表示的是LCD寄存器命令号；lcd_get_value是一个数组，表示寄存器要初始化的值，这是因为对于一个LCD寄存器，可能要初始化多个字节，这是硬件特性决定的；lcd_value_num是指一个寄存器要多少个字节的初值，这是因为每一个寄存器的初值数目是不同的，我们用同一个方法处理数据时，是需要这个信息的。
就本例而言，我们将要处理的数据都是事先固定的，所以定义好数据结构后，我们可以将这些数据组织成表格：
/*LCD部分寄存器设置值列表*/ lcd_redu_list_struct const lcd_redu_list_str[]= { {SSD1963_Get_Address_Mode,{0x20} ,1}, /*1*/ {SSD1963_Get_Pll_Mn ,{0x3b,0x02,0x04} ,3}, /*2*/ {SSD1963_Get_Pll_Status ,{0x04} ,1}, /*3* {SSD1963_Get_Lcd_Mode ,{0x24,0x20,0x01,0xdf,0x01,0x0f,0x00} ,7}, /*4*/ {SSD1963_Get_Hori_Period ,{0x02,0x0c,0x00,0x2a,0x07,0x00,0x00,0x00},8}, /*5*/ {SSD1963_Get_Vert_Period ,{0x01,0x1d,0x00,0x0b,0x09,0x00,0x00} ,7}, /*6*/ {SSD1963_Get_Power_Mode ,{0x1c} ,1}, /*7*/ {SSD1963_Get_Display_Mode,{0x03} ,1}, /*8*/ {SSD1963_Get_Gpio_Conf ,{0x0F,0x01} ,2}, /*9*/ {SSD1963_Get_Lshift_Freq ,{0x00,0xb8} ,2}, /*10* }; 至此，我们就可以用一个处理过程来完成数十个LCD寄存器的读取、判断和异常处理了：
/** * lcd 显示冗余 * 每隔一段时间调用该程序一次 */ void lcd_redu(void) { uint8_t tmp[8]; uint32_t i,j; uint32_t lcd_init_flag; lcd_init_flag =0; for(i=0;i&lt;sizeof(lcd_redu_list_str)/sizeof(lcd_redu_list_str[0]);i++) { LCD_SendCommand(lcd_redu_list_str[i].lcd_command); uyDelay(10); for(j=0;j&lt;lcd_redu_list_str[i].lcd_value_num;j++) { tmp[j]=LCD_ReadData(); if(tmp[j]!=lcd_redu_list_str[i].lcd_get_value[j]) { lcd_init_flag=0x55; //一些调试语句，打印出错的具体信息  goto handle_lcd_init; } } } handle_lcd_init: if(lcd_init_flag==0x55) { //重新初始化LCD  //一些必要的恢复措施  } } 通过合理的数据结构，我们可以将数据和处理过程分开，LCD冗余判断过程可以用很简洁的代码来实现。更重要的是，将数据和处理过程分开更有利于代码的维护。比如，通过实验发现，我们还需要增加一个LCD寄存器的值进行判断，这时候只需要将新增加的寄存器信息按照数据结构格式，放到LCD寄存器设置值列表中的任意位置即可，不用增加任何处理代码即可实现！这仅仅是数据结构的优势之一，使用数据结构还能简化编程，使复杂过程变的简单，这个只有实际编程后才会有更深的理解。
]]></content>
  </entry>
  
  <entry>
    <title>i.MXRT中FlexSPI外设不常用的读选通采样时钟源</title>
    <url>/post/hardware/read-select-sampling-clk-source-of-flexspi.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>i.MXRT</tag>
      <tag>FlexSPI</tag>
    </tags>
    <content type="html"><![CDATA[今天给大家分享的是i.MXRT中FlexSPI外设不常用的读选通采样时钟源 - loopbackFromSckPad。
最近碰到一个客户，他们在 i.MXRT500 上使能了 FlexSPI-&gt;MCR0[RXCLKSRC] = 2（即 loopbackFromSckPad），这个选项字面上的意思是设置读选通采样时钟源为 SCK 引脚，这个选项在恩智浦官方的代码包里未曾使能过。客户在使用过程中遇到高频时 SCK 引脚被降压的问题（从正常的 1.8V 降至 1.2V），那么这个 loopbackFromSckPad 选项到底是什么作用以及有什么使用限制呢？
 Note1: 参考手册里显示支持 loopbackFromSckPad 选项的型号有 i.MXRT1040/1050/1060/1064/1180/500 Note2: 参考手册里没有提及支持 loopbackFromSckPad 选项的型号有 i.MXRT1010/1015/1020/1024/1160/1170/600   为什么存在Read Strobe？ 对于串行 SPI 接口存储器，FlexSPI 外设主要支持如下两种读数据时序：一是所谓的经典 SPI 模式，IO0 (MOSI) 专用于发送命令和地址，IO1 (MISO) 专用于接收数据（图中上面的时序）。二是 Multi-I/O SPI 模式，SIO[n:0] 一起用于发送命令地址以及接收数据（图中下面的时序）。
显然经典 SPI 模式下 IO[1:0] 是单向的，而 Multi-I/O SPI 模式下，SIO[n:0] 是双向的。当 SIO 用于双向传输时，过程中必然存在引脚方向切换，而 FlexSPI 外设在处理 SIO 方向切换时无法做到零等待周期读取数据，这就是为什么 Multi-I/O SPI 读时序中总是会存在 Dummy 周期。
因为 Dummy 周期的存在，FlexSPI 外设内部实际上有一个 Read Strobe 信号（即 DQS）来控制数据的选通性（即什么时候开始数据有效，将数据存入内部 FIFO）。更直白点说，Read Strobe 信号的存在就是由于 FlexSPI 外设无法支持如下这种情况的读时序（下图中 COMMAND 实际应为 COMMAND&amp;ADDR）。
FlexSPI内部Read Strobe设计 在 i.MXRT 参考手册里有如下 FlexSPI 前端采样单元框图，其中 ipp_ind_dqs_fa/b_int[x] 即是 Read Strobe 信号，它控制着 FIFO 中实际数据的存储。
ipp_ind_dqs_fa/b_int[x] 信号共有四种来源，最原始的信号源由 FlexSPI-&gt;MCR0[RXCLKSRC] 选择，中间可能还会经过 DLLxCR 单元（这部分以后会另写文章单独介绍）、Phase Chain 单元做处理，然后送到采样单元里。
下图是 FlexSPI-&gt;MCR0[RXCLKSRC] = 0 的情况，此时 Read Strobe 经由 ipp_do_dqs0_fa/b 纯内部 loopback 回来，没有经过任何延迟单元。这种配置一般仅用于经典 SPI 传输模式（低速 60MHz SDR 场合），适用低容量 SPI NOR / EEPROM，这时候 FlexSPI DQS Pad 可用作其它功能或者 GPIO。
下图是 FlexSPI-&gt;MCR0[RXCLKSRC] = 1 的情况，此时 Read Strobe 经由悬空的 DQS 引脚 ipp_do_dqs1_fa/b 再 loopback 回来，此时有了 DQS 引脚绕一圈的延迟。这种配置可用于 Multi-I/O SPI 传输模式（较高速 133MHz SDR 场合），适用不含 DQS 引脚的大容量 QuadSPI NOR Flash，但是 FlexSPI DQS Pad 需要悬空。
下图是 FlexSPI-&gt;MCR0[RXCLKSRC] = 3 的情况，此时 Read Strobe 完全由外部存储器的 DQS 引脚输出 ipp_ind_dqs3_fa/b 直通进来。这种配置可用于 Multi-I/O SPI 传输模式（最高速 166MHz/200MHz DDR 场合），适用于包含 DQS 引脚的 OctalSPI NOR Flash，这时 FlexSPI DQS Pad 与外部存储器相连。
loopbackFromSckPad选项意义 前面铺垫了那么多，终于来到本文的主题了，即下图 FlexSPI-&gt;MCR0[RXCLKSRC] = 2 的情况，此时 Read Strobe 经由 SCK 引脚 ipp_ind_sck_fa/b 再 loopback 回来，此时有了 SCK 引脚绕一圈的延迟。
这种配置从应用角度与 FlexSPI-&gt;MCR0[RXCLKSRC] = 1（即 loopbackFromDqsPad） 差不多，也可用于 Multi-I/O SPI 传输模式（较高速 133MHz SDR 场合），适用不含 DQS 引脚的大容量 QuadSPI NOR Flash，但是这时候 FlexSPI DQS Pad 被解放出来了，这也是它的最主要意义。
别小看只是省了一个 DQS 引脚，也许你认为 i.MXRT I/O 那么多，省一个引脚意义不大，但是如果某些 FlexSPI 引脚组不带 DQS 信号，你又想配置 FlexSPI 以 60MHz 以上频率去访问 Flash，这时候 FlexSPI-&gt;MCR0[RXCLKSRC] = 2 选项就会帮上大忙了。
loopbackFromSckPad使用限制 FlexSPI-&gt;MCR0[RXCLKSRC] = 2 选项虽好，但有如下两个实际使用限制：
 存在信号完整性问题：主要出现在 SCK 频率过高或者板级 PCB 上 SCK 信号走线过长时。 SCK自由运行模式下不可用：对于某些 FPGA 应用，有时需要设置 FlexSPI-&gt;MCR0[SCKFREERUNEN] = 1，即 SCK 需要持续给外部设备内部 PLL 提供参考时钟。   至此，i.MXRT中FlexSPI外设不常用的读选通采样时钟源 - loopbackFromSckPad痞子衡便介绍完毕了。
]]></content>
  </entry>
  
  <entry>
    <title>RS-485接口电路设计完全指南</title>
    <url>/post/hardware/design-guide-of-rs-485-interface-circuit.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>UART</tag>
      <tag>RS-485</tag>
    </tags>
    <content type="html"><![CDATA[本设计指南讨论如何设计RS-485接口电路。文中讨论了平衡传输线标准的必要性，并给出了一个过程控制设计例子。文中还分标题讨论了线路负载、信号衰减、失效保护和电流隔离。
为什么需要平衡传输线标准 本文的重点在于工业最广泛使用的平衡传输线标准：ANSI/TIA/EIA-485-A（以下简称485）。在回顾一些485标准的关键方面后，通过一个工厂自动化例子，介绍实际项目中如何实施差分传输结构。
远距离、高噪声环境下，计算机组件和外设之间的数据传输通常是困难的，如果有可能的话，尽量使用单端驱动器和接收器。对于这种需要远距离通讯的系统，推荐使用平衡数字电压接口。
485是一个平衡（差分）数字传输线接口，是为了改善TIA/EIA-232（以下简称232）的局限性而开发出来的。485具有以下特性：
  通讯速率高 – 可达到50M bits/s
  通讯距离远 – 可达到1200米（注：100Kbps情况下）
  差分传输 – 较小的噪声辐射
  多驱动器和接收器
  在实际应用中，如果两个或更多计算机之间需要价格低廉、连接可靠的数据通讯，都可以使用485驱动器、接收器或收发器。一个典型的例子是销售终端机和中心计算机之间使用485传输信息。使用双绞线传输平衡信号具有较低的噪声耦合，加上485具有很宽的共模电压范围，所以485允许高达50M bit/s的速率通讯，或者在低速情况下具有数千米通讯距离。
由于485用途广泛，越来越多的标准委员会将485标准作为它们通讯标准的物理层规范。包括ANSI的SCSI（小型计算机系统接口）、Profibus标准、DIN测量总线以及中国的的多功能电能表通讯协议标准DL/T645。 平衡传输线标准485于1983年开发，用于主机与外设之间的数据、时钟或控制线的数据传输接口。标准仅规定了电气层，其它的像协议、时序、串行或并行数据以及链接器全部由设计者或更高层协议定义。
最初，485标准被定义为是对TIA/EIA-422标准（以下简称422）的灵活性方面升级。鉴于422仅是单工通讯（注：422使用两对差分通讯线，发送使用一对，接收使用一对，所以数据在一条线上是单向传输的），485允许在一对信号线上有多个驱动器和接收器，有利于半双工通讯（见图1）。
和422一样，485没有规定最大电缆长度，但是在使用24-AWG电缆、100kbps条件下，可以传输1.2km；485同样没有限制最大信号速率，而是由上升沿时间和位时间的比率限制，这和232相似。在大多数情况下，因为传输线效应和外界噪声影响，电缆长度比驱动器更能限制信号速率。
系统设计注意事项 线负载 在485标准中，线负载要考虑线路终端和传输线上的负载。是否对传输线终端匹配取决于系统设计，也受传输线长度和信号速率的影响（一般情况下，低速短距离可以不进行终端匹配）。
传输线终端匹配 可以将传输线划分为两种模型：分布式参数模型[1]和集总参数模型[2]。测试传输线属于哪种模型取决于信号的渡越（上升/下降）时间tt与驱动器输出到线缆末端的传播时间tpd。
如果2tpd≥tt/5，则传输线必须按照分布式参数模型处理，并且必须处理好传输线终端匹配；其它情况下，传输线看作节点参数模型，这时传输线终端匹配不是必须的。
注1：分布式参数模型 - 电路中的电压和电流是时间的函数而且与器件的几何尺寸和空间位置有关。
注2：集总参数模型 - 电路中任意两个端点间的电压和流入任一器件端点的电流完全确定，与器件的几何尺寸和空间位置无关。
单位负载概念 挂接在同一485通讯总线上的驱动器和接收器，其最大数量取决于它们的负载特性。驱动器和接收器的负载都是相对单位负载而衡量的。485标准规定一根传输总线上最多可以挂接32个单位负载。
单位负载定义为：在12V共模电压环境中，允许通过稳态负载1mA电流，或者是在-7V共模电压环境中，允许通过稳态负载0.8mA电流。单位负载可能由驱动器、接收器和失效保护电阻组成，但不包括AC终端匹配电阻。
图2给出了SN75LBC176A收发器单位负载计算的例子。因为这款设备将驱动器和接收器集成到一起构成了收发器（即驱动器输出和接收器输入连接到了同一根总线上），因此很难分别获取驱动器泄漏电流和接收器输入电流。为了便于计算，将接收器输入阻抗看作12 kΩ并给收发器1mA电流。这可以代表一个单位负载，一跟传输总线上允许32个这样的负载。
只要接收器的输入阻抗大于12kΩ，那么可以在一根传输总线上使用多于32个这样的收发器。
信号衰减和失真 一个有用的常识是：在最大信号速率（单位：Hz）通讯的条件下，允许信号衰减-6dB。一般情况下，电缆供应商会提供信号衰减图表。图3所示的曲线显示了24-AWG电缆衰减和频率的关系。
确定随机噪声、抖动、失真等对信号影响程度的最简单方法是使用眼图。图4显示使用20AWG双绞线电缆500米处、不同信号速率下，接收端的信号失真情况。当信号速率进一步增加，抖动的影响变得更加显著。在1Mbit/s时，抖动大约为5%，而在3.5Mbit/s时，信号开始彻底被淹没，传输质量严重降级。在实际系统中，可允许的最大抖动一般要小于5%。
故障保护和失效保护 故障保护 和其它任何系统设计一样，必须习惯性的考虑故障应对措施，不论这些故障是自然产生还是因环境诱导产生。对于工厂控制系统，通常要求对极端噪声电压进行防护。485提供的差分传输机制，特别是宽共模电压范围，使得485对噪声具有一定的免疫力。但面对复杂恶劣环境时，其免疫力可能不足。
有几种方法可以提供保护，最有效的方法是通过电流隔离，后面会讨论这个方法。电流隔离能够提供更好的系统级保护，但是价格也更高。更流行并且比较便宜的方案是使用二极管保护。使用二极管方法代替电流隔离是一种折衷方法，在更低层次上提供保护。外接二极管和内部集成瞬态保护二极管的例子如下图所示：
图5所示485收发器SN75LBC176外接二极管来防止瞬态毛刺。
RT通常是终端匹配电阻，等于电缆特性阻抗R0。
图6所示内部集成瞬态抑制二极管的485收发器SN75LBC184，用于既希望使用完整485功能，PCB空间又受限的场合。SN75LBC184在内部集成了保护二极管，针对高能量电气噪声环境，可直接替换SN75LBC176。
失效保护 许多485应用也要求提供失效保护，失效保护对于应用层是很有用的，需要仔细考虑并充分理解。
在任何多个驱动器/接收器共用同一总线的接口系统中，驱动器大多数时间处于非活动状态，这个状态被称为总线空闲状态。当驱动器处于空闲状态时，驱动器输出高阻态。当总线空闲时，沿线电压处于浮空状态（也就是说，不确定是高电平还是低电平）。这可能会造成接收器被错误地触发为高电平或低电平（取决于环境噪声和线路浮空前最后一次电平极性）。
显然，这种情况是不受欢迎的。在接收器前面需要有相关电路，将这种不确定状态变成已知的、预先约定好的电平，这称之为失效保护。此外，失效保护还要能防止因短路而引起的数据错误。
有很多方法可以实现失效保护，包括增加硬件电路和使用软件协议。尽管软件协议实现起来比较复杂，但这是优先推荐的方法。但是因为大多数系统设计师、硬件设计师更喜欢使用硬件实现失效保护，增加硬件电路实现失效保护更经常被使用。
无论出现短路还是开路情况，失效保护电路必须为接收器提供明确的输入电压。如果通讯线所处环境非常恶劣，则线路终端匹配也是必须的。
目前很多厂商开始将一些失效保护电路（如开路失效保护）集成到芯片内部。通常这些额外的电路只是在接收器同相输入端增加一个大阻值上拉电阻、在接收器反相端增加一个大阻值下拉电阻。这两个电阻通常在100KΩ左右，这些电阻和终端匹配电阻形成一个潜在的驱动器，仅能提供几个mV的差分电压。
因此，这个电压（接收器临界电压）并不足以切换接收器状态。使用这样的内部上下拉电阻允许总线不进行终端匹配，但是会显著的降低最大信号速率和可靠性。
图7给出了一些485接口通用外置失效保护电路，每个电路都尽力维持接收器输入端电压不小于最小临界值并在一个或多个故障条件（开路、空闲、短路）下，维持一个已知的逻辑状态。在这些电路中，R2代表传输线阻抗匹配电阻，并成为电压驱动器的一部分：产生稳态偏置电压。这里假设每个接收器代表1个单位负载。
图7右半部分的表格中列出了一些典型电阻和电容值、提供的失效保护类型、使用的单位负载个数和信号失真。在下一节中，会通过对短路失效电路中的电阻值计算，来说明如何修改这些电阻值以便适用于特定设计。
要实现短路保护，需要更多的电阻。当电缆短路时，传输线阻抗变为零，终端匹配电阻也背短路。在接收器输入端串联额外的电阻可以实现短路失效保护。
图8所示的额外电阻R3仅能用于驱动器和接收器分离的场合。现在的绝大部分485驱动器和接收器都集成到一个芯片上（称之为收发器），并且在内部连接到同一个总线上，这种收发器不可以使用短路失效保护。如果需要进行短路保护，可以选择内部集成短路保护的收发器或者使用驱动器和接收器分离的器件，比如SN75ALS180。如果在收发器使用短路失效保护电路，则电阻R3会引起输出信号额外的失真。驱动器和接收器分离的器件SN75ALS180不会有这个问题，因为驱动器是直接连到总线上的，旁路掉了R3。
下面对电阻值经行计算。如果传输线短路，R2从电路中移除，则接收器输入端电压为：
VID = VCC * 2R3 / (2R1 + 2R3)
对于485应用，标准规定接收器可识别最低至200mV的输入信号。因此当VID&gt; VIT或者VID &gt; 200mV，能够确定一个已知状态。这是第一个设计约束条件：
VCC* 2R3 / (2R1 + 2R3) &gt; 200mV
当传输线上为高阻态时，接收器受到R1、R2和R3的影响，其输入电压为：
VID = VCC* (R2 + 2R3) / (2R1 + R2 + 2R3)
得到第二个设计约束条件：
VCC * (R2 + 2R3) / (2R1 + R2 + 2R3) &gt; 200mV
传输线会受终端匹配电阻R2与两倍的(R1+R3)并联影响。传输线的特性阻抗Zo与之相匹配，这得到第三个设计约束条件：
Zo = 2R2 * (R1 + R3) / (2R1 + R2 +2R3)
其它设计约束条件包括由失效保护电路提供的额外线负载、由R3和R1引起的信号失真以及接收器输入电阻。
注：SN75HVD10等3.3V 485收发器以及更新产品内部集成了短路/开路失效保护电路。
电流隔离 计算机和工业串行接口往往处于噪声环境中，可能会影响数据传输的完整性。对于任何接口电路，经过测试的可以改善噪声性能的方法是电流隔离。
在数据通讯系统中，隔离是指多个驱动器和接收器之间没有直接电流流通。隔离变压器为系统提供电源，光耦或数字隔离器件提供数据隔离。电流隔离可以去除地环流，抑制噪声电压。因此，使用这种技术可以抑制共模噪声，降低其它辐射噪声。
举一个例子，图9显示了过程控制系统的一个节点，通过485链路连接数据记录器和主计算机。
当临近的电动机启动时，数据记录器和计算机的地电势会出现瞬间不同，这通常会引起一个大电流。如果数据通讯没有采用隔离方案，数据可能会丢失，更坏的情况下会损害计算机。
电路描述 图9所示的原理图是分布式监视、控制和管理系统的一个节点，这种方案通常用于过程控制。数据通过一对双绞线传输，地线使用屏蔽层。这类应用常常需要低功耗，因为许多远程分站使用电池或者要求有备用电池（电容停电后，需要设备能使用备用电池工作一定时间）。
此外，使用低功耗计数，可以使用小型隔离变压器。如图9所示，收发器使用SN65HVD10，当然任何TI公司3.3V或5V RS485收发器、3.3-V TIA/EIA-644 LVDS或者3.3-V TIA/EIA-899 M-LVDS收发器都可以使用这个电路。
操作原理 图9所示的例子可用于3.3V或5V，电源使用变压器隔离，数据信号采用数字隔离器隔离。因为485收发器需要隔离电源，可调LDO稳压器必须被隔离。可以使用与非门振荡电路驱动隔离变压器实现这一功能。变压器的输出电压经过调整、滤波后，供低压差线性稳压器使用。
在高EMI环境中，这种方法常用于预防其它远距离供电子系统的噪声耦合到主电源。TPS7101用于给其它电子元件供电，最多提供500mA电流。通过调节偏置电阻R7，TPS7101可输出3.3V或5V，具体阻值见BOM清单。
数据信号隔离又三通道数字隔离器ISO7231M完成。该设备可以通过150Mbps信号速率，提供2.5KV（rms）电压隔离和50KV/us瞬间放电保护。
过程控制设计举例 为了获得更多485系统设计知识，一个比较好的方法是看具体的例子。考虑这样一个系统：系统容量为1个主控制器、数个分站的工厂自动化系统，每个分站都可以发送和接收数据。
系统特性如下所示，通用规格见图10。
  最远分站距主控制器500米
  31台分站（加上主机共32台设备）
  信号传输速率为500 kbit/s
  半双工通讯
  遵循485标准的设备以500 kbit/s传输数据，要求驱动器输出渡越（上升/下降）时间tt不能大于0.3个单位间隔时间（UI），所以有：
tt≤ 0.3 * UI
tt≤ 0.3 * (1 /(500 * 103) ) = 600ns
如果电缆传输信号速度等于光在真空中的传播速度，则信号传输延时tpd为3.33ns/m，乘以传输线长度500米，为1667ns。
根据2.1节的公式可以确定传输线是分布式参数模型还是节点参数模型：若2tpd ≥ tt/5，则认为传输线为分布式参数模型。显然，3334 &gt; 120，所以本例的传输线模型为分布式参数模型。在工业环境中，这种传输线必须要终端匹配。
关于衰减，尽管信号速率为500 kbit/s的基本频率为250 kHz，我们仍然按照500 kHz来计算衰减，这是因为信号中其实包含更高频的部分。根据最大衰减不要超过-6dB的经验法则，要求500米电缆末端最大衰减小于-6dB，即0.36dB/30米。
我们查看图3所示的图表，这是电缆厂商提供的衰减与频率关系的图表，500 kHz频率对应的衰减为0.5dB/30米还要多一些，超过设计约束条件0.14dB/30米。在本例中这是允许的，因为稍微减少保守规则提供的噪声容限是可以接受的。
]]></content>
  </entry>
  
  <entry>
    <title>嵌入式工程师的100本专业书籍</title>
    <url>/post/linux/embedded-book.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Embedded</tag>
      <tag>E Books</tag>
    </tags>
    <content type="html"><![CDATA[嵌入式工程师的100本专业书籍，推荐给需要的朋友！
001《大话数据结构》
002《鸟哥的 linux 私房菜》
003《疯狂 android 讲义》
004《第一行代码》
005《linux 内核设计与实现》
006《驱动设计开发》
007《linux 内核解密》
008《unix 环境高级编程》
009《linux 内核设计与实现》
010《essential C++》
011《嵌入式 linux》
012《linux 设备驱动》
013《C 语言深度解剖》
014《linux 下的 C编程》
015《C Primer Plus（第五版）》
016《ARM 体系结构与编程（第二版）》
017《lINUX 设备驱动开发详解（第三版）》
018《android 开发艺术探讨》
019《c++plus》
020《Unix 环境高级编程》
021《与大数据同行——学习和教育的未来》
022《用户体验的要素》
023《编程与艺术》
024《ARM 嵌入式体系结构与接口技术》
025《cortex-m0 接口编程》
026《C 语言程序设计:现代方法》
027《C++ Primer》
028《数据结构》(严蔚敏)
029《算法导论》
030《Linux 设备驱动开发》
031《代码大全》
032《深入理解计算机系统》
033《UNIX 环境高级编程》
034《计算机安全原理》
035《UNIX 网络编程》
036《HeadFirst 设计模式》
037《linux 驱动》（宋保华）
038《C++ primer4》
039《qt5 精彩实例》
040《ldd3》
041《C++高级编程》
042《C语言教程》
043《实战 linux 编程精髓》
044《ARM 教程》
045《JAVA 编程思想》
046《HTML+CSS 网页设计与布局从入门到精通》
047《C 语言深度解剖》
048《深度实践嵌入式 Linux 系统移植》
049《unix 高级编程》
050《C 嵌入式一站式教学》
051《编译原理》
052《深度实践嵌入式 Linux 系统移植》
053《UNIX 环境高级编程》
054《linux 网络编程》
055《C 语言程序设计》
056《unix 环境高级编程》
057《嵌入式 linuxc 语言程序设计基础教程》
058《Java 编程思想》
059《TCP/IP 详解》
060《linux 技术手册》
061《C 语言深度剖析》
062《Unix 高级环境编程》
063《C++primerplus》
064《QT》
065《C 程序设计》
066《C 和指针》
067《C++primer》
068《C 程序设计语言》
069《ProgrammingC#》
070《thinking in C++》
071《Linux Device driver》
072《Linux kernel development》
073《软件工程》
074《C 和指针》
075《Android 核心代码》
076《Android 技术内幕》
077《Android 底层移植》
078《Unix 编程手册（上下卷）》
079《Linux 驱动设计第三版》
080《ARM 实战开发》
081《unix 环境高级编程》
082《tcp/ip 编程详解》
083《Linux 网络编程》
084《Unix 编程艺术》
085《计算机程序的构造和解释》
086《C Primer plus》
087《LINUX 权威指南》
088《LINUX 设备驱动程序》
089《The C Programming Language》
090《ajax 高级程序设计》
091《angula js 权威教程》
092《ARM 体系结构》
093《Unix 环境高级编程》
094《Linux 设备驱动程序》
095《现代操作系统》
096《TCP/IP 协议详解》
097《嵌入式 C 语言设计模式》
098《Struts In Action》
099《C 程序设计语言（第二版）》
100《深入理解 Linux 内核（第三版）》
]]></content>
  </entry>
  
  <entry>
    <title>处理器互联：Gen-Z 终“认输”，并入CXL</title>
    <url>/post/server/gen-z-vs-cxl.html</url>
    <categories><category>Server</category>
    </categories>
    <tags>
      <tag>Gen-Z</tag>
      <tag>CXL</tag>
    </tags>
    <content type="html"><![CDATA[据报道，Gen-Z 互连背后的推动者正在认输。资料显示，制造商 AMD、架构设计公司ARM、两家服务器供应商戴尔和 HPE、内存制造商美光和 FPGA 专家赛灵思自 2016 年以来一直在开发 Gen-Z，以便通过协议处理器、PCI- Express 内存和加速器进行通信。
然而，Gen-Z 联盟缺少两个重要的名字：英特尔和英伟达。虽然英伟达最终在 2020 年 8 月加入该联盟。但英特尔推出了相互竞争的互连 Compute Express Link (CXL)，改联盟的支持者有阿里巴巴、思科、戴尔 EMC、Facebook、谷歌、HPE、华为和微软。
当 AMD、 ARM  、IBM、Nvidia 和 Xilinx 于 2019 年夏末加入Gen-Z联盟时，我们能明显察觉到它们将面临困难时期。两个财团随后相互合作——但自 2020 年 5 月以来没有发布任何新闻稿，Gen-Z也沉默了。现在，Gen-Z 想要完全停止自己的开发，将这个领域留给 CXL。
Gen-Z 并入 CXL 从CXL支持者提供的消息可以看到，GenZ的做法是希望将所有规格和资产转移到CXL联盟，但这仍需要各方的同意。值得一提的是，行业内仍有 CCIX 和 OpenCAPI与之竞争，但行业正在朝着 CXL 方向发展。
AMD 的 Infinity Fabric 专门用于将其自己的 Eypc 处理器与 Instinct 加速器耦合，就像 Nvidia 的 NV-Link 与 IBM 的 Power CPU 及其自己的 GPU 加速器（如 A100）一样。
英特尔即将推出的用于服务器的处理器系列 Sapphire Rapids 是第一代能够处理 CXL，它在第一次迭代中基于 PCI Express 5.0，但希望快速切换到 PCIe 6.0 以获得更高的传输速率。AMD 紧随其后的是 CPU 系列 Epyc 7004，别名 Genoa。三星已经宣布 CXL 内存扩展器为 PCIe DRAM。
前情提要：CXL与GEN-Z联手 从某种角度看，再现上世纪80年代末和90年代初的总线大战会很有趣。供应商之间为争夺他们所控制的标准而进行的斗争最终导致了PCI-X和PCI-Express总线的创建，这些总线以及分支InfiniBand interconnect在服务器领域占据了20年的主导地位，以及分支InfiniBand interconnect，它最初是作为一个通用的交换结构来连接高带宽和低延迟的所有东西。这可能要比其他情况下花费更长的时间——改写历史是很困难的。
但我们可以告诉你的是，我们在过去几个月里讨论过，那些经历过总线战争的勇士们已经从他们创造的历史中吸取了教训，他们不愿意在运输和协议方面进行旷日持久的战斗，这些协议为混合计算引擎提供了内存一致性。原因是我们没有时间听这些废话，而且随着全球经济很可能陷入衰退，我们更没有时间听这些鬼话和自我膨胀。
这就是为什么我们在同一周于去年9月在圣何塞举办了下一次I/O平台活动，这是一个愉快的巧合，而不是计划，所有关键一致性工作的成员——英特尔的Compute Express Link（CXL）、IBM的Concordent Accelerator Interface（CAPI）和OpenCAPI superset，Xilinx的Accelerators缓存一致性互连（CCIX）和AMD的Infinity Fabric、Nvidia的NVLink互连和Hewlett-Packard Enterprise的Gen-Z互连，以及戴尔早期大力支持的，所有这些都支持Intel的CXL协议互连，它本身就是PCI Express 5.0的超集，用于连接处理器和加速器并共享它们的内存。我们同时在这里做了一个非常深入的研究，这又是一个巧合。称之为调和收敛。
CXL和它的连贯内存互连被设计成将处理器与它们的加速器和系统内的内存类存储连接起来，Gen-Z最初被设计成一个内存结构，可以有许多不同的计算引擎挂在它上面，共享各种各样的内存。没有规定说CXL不能扩展到服务器的金属外壳之外，以在一个、两个或三个机架上的多个服务器节点上提供一致的内存访问(例如，就像GigaIO正在进行的PCI-Express交换互连一样)。同样，也没有规定Gen-Z不能用作服务器节点中的协议。嗯，根据经济学原理，CXL可能比Gen-Z更便宜，这主要是由于硅光子学涉及到长距离的相干性。(我们还深入研究了HPE在2019年9月编写的Gen-Z交换芯片，并且还审查了Gen-Z联盟正在原型化以创建池主内存的Gen-Z内存服务器。)
不过，根据Gen-Z联盟主席、戴尔服务器架构和技术主管Kurtis Bowman与CXL联盟主席、英特尔技术项目主管Jim Pappas签署的一份谅解备忘录，这两个可能交战的阵营已经埋下了仇恨。他们已经决定完全不使用任何hatchets，并努力使CXL和Gen-Z能够在适当的地方互操作和互连。具体来说，他们已经成立了一个联合工作组来解决这些分歧，努力使这些技术保持一致。(仔细想想，这似乎是合理的。)
Bowman和Pappas在过去的几个月里都和我们讨论过使用CXL作为服务器内部Gen-Z织物的潜在安装点，我们怀疑这就是他们如何分割Gen-Z硅的方法，直到Gen-Z硅大量生产出来。HPE Gen-Z芯片组的高带宽硅光子学将是Cadillac版本的连接服务器到内存(要么是原始的、聚合的内存，要么是加速器或协处理器内部的内存)，而CXL端口将是Chevy版本，具有更短的距离和更低的带宽。
Pappas解释说：“两种方案的DNA中都有记忆。“使用CXL，你触及的范围有限，因为它基本上是PCI-Express。但有了Gen-Z，您就有了更大的距离——机架、行甚至数据中心。但归根结底，你有一个连贯的CPU接口，即CXL，然后Gen-Z让你把所有的接口都带到更远的地方，让它工作。”
目前还没有尝试合并传输或协议的说法，但从长远来看，如果CXL最终成为运行在各种硅光子学传输（包括但不限于Gen-Z）上的协议，我们不会感到惊讶。在某种程度上，PCI Express将不是系统总线，因此CXL不能无限期地绑定到该总线。但是，这是很多很多年以后的事了。
在CXL和Gen-Z的工作方式上存在一些差异，需要协调，以便它们能够正确地相互交谈。
Bowman解释说：“CXL是一个真正的硬件一致性设计，应用软件根本不需要意识到这一点。”“Gen-Z没有内置的硬件一致性，因此它正在寻找一个软件一致性模型，并使用原子等技术来实现这一点。如果您的应用程序想要跨越一个大的内存空间并共享特定的区域，则必须编写软件才能利用这一点。我们无法在硬件中实现Gen-Z一致性的原因是，连接到内存的机器之间的snoop循环将消耗大部分结构带宽。你可以两全其美。如果您需要硬件一致性互连，CXL是一种方法，如果您需要一种结构来共享机架内或跨行的资源，那么Gen-Z是一种方法。但这种一致性将在软件中实现。”
我们面临的问题是，谁将成为CXL和Gen-Z的开路先锋。当然，答案之一是微软及其庞大的Azure公共云。微软公司Azure云的杰出工程师Leendert van Doorn是CXL和Gen-Z联合体的董事会成员，他分享了一些他对这将如何工作的想法。
“我把CXL看作是一个本地的节点互连，”van Doorn说。“一旦你开始考虑分解(disaggregation)——特别是在机架级别上——你就需要去做别的事情，因为PCI Express 5.0没有扩展到那么远。是的，您可以构建重定时器，而且有些人过去曾经构建过基于PCI Express的结构，但他们遇到了一些挑战。这些都是Gen-Z已经解决和解决的挑战，我们现在讨论的实际上是CXL和Gen-Z之间的接口。现在，我们是否会看到在一个具有CXL的节点内以较小的规模进行分解？是的，当然。我们期待看到。但是，当您可以将其扩展到机架上或希望跨整个机器行进行扩展时，真正的分解收益就会发挥作用。那就是您需要研究另一种结构(fabric)技术的时候了。”
那么，微软如何在其基础设施中利用CXL和Gen-Z呢?van Doorn给出了一些提示，这些提示与我们一直以来的想法是一致的。例如，我们有基于机架的flash模块在NVM-Express上共享数据到一个服务器机架，我们可以有基于机架的主内存(持久的或动态的，我们不关心)在Gen-Z上共享数据。
“我的服务器大约50%的成本是内存，”van Doorn说。因此，如果我能更有效地使用这些内存，并在系统之间共享它们，就会有巨大的好处。所以你可以想象系统在节点上有一定量的内存，然后在服务器之间共享另一块内存，根据需要从池中取出。”
一切都会归结为延迟。van Doorn说，DRAM内存访问在节点内部大约80纳秒，而通过快速NUMA互连，对远程存储器的典型访问大约为135纳秒。虽然操作系统内核可以在一定程度上屏蔽这种影响，但它们是显而易见的。这就是为什么机架外的主内存池（即使使用Gen-Z）将更具挑战性，因为它们将增加额外的延迟-根据范围的不同，从数百纳秒到毫秒不等。但是，对于其他持久性介质（其固有速度比主存储器慢），由于该介质增加了设备延迟，使用Gen-Z这样的协议跨越许多机架、行甚至更远，因为Gen-Z结构互连将比设备快得多。而且Gen-Z的延迟比以太网或InfiniBand要低得多，从长远来看，这应该是row和数据中心级存储互连的首选结构。不管怎样，这就是理论。
最后，延迟和可替换性的相互作用将发挥出来，我们认为，一旦这些协议得到强化，设备出现，人们将试图在服务器节点中放置尽可能少的内存和存储，以摆脱并创建可组合池来扩展它。这将是最好的经济和技术意义。
另一个问题是，CXL和Gen-Z何时会成为数据中心基础设施的常规部分?Gen-Z开发工具现在已经可供联盟成员使用，Bowman说早期的采用者将在2022年上线，到2023年到2024年将成为主流。根据Pappas的说法，对于CXL，硅即将投入使用，它将在2020年进行调试，通常在那之后的一年才会投入系统。
Compute Express Link 标准介绍 Compute Express Link (CXL) 是一种开放式互连新标准，面向 CPU 和专用加速器的密集型工作负载，这些负载都需要在主机和设备之间实现高效稳定的存储器访问。最近宣布成立了一个支持该新标准的联盟，同时发布了 CXL 1.0 规范。本文介绍了片上系统 (SoC) 设计人员需要了解的一些 CXL 关键特性，以确定这种新的互连技术在其 AI、机器学习和云计算应用程序设计中的最佳使用和实现方式。
PCI Express (PCIe) 已经存在多年，最近完成的 PCIe 基础规范 5.0 版本现在能够以高达 32GT/s 的速度实现 CPU 和外设的互连。然而，在具有大型共享内存池和许多需要高带宽设备的环境中，PCIe 受到了一些限制。PCIe 没有指定支持一致性的机制，并且不能高效地管理隔离的内存池，因为每个 PCIe 层级都要共享一个 64 位地址空间。此外，PCIe 链路的延迟可能过高，无法高效管理系统中多个设备的共享内存。
CXL 标准通过提供利用 PCIe 5.0 物理层和电气元件的接口来消除其中一些限制，同时提供极低延迟路径，用于主机处理器和需要共享内存资源的设备（如加速器和内存扩展器）之间进行内存访问和一致缓存。支持的 CXL 标准模式主要围绕采用 x16 通道配置并以 32GT/s 运行的 PCIe 5.0 PHY（表 1）。x8 和 x4 通道配置也支持 32GT/s，以支持分叉。任何比 x4 通道窄或比 32GT/s 慢的模式都被称为降级模式，这类模式在目标应用中显然不常见。虽然 CXL 可以为许多应用带来立竿见影的性能优势，但是某些设备不需要与主机进行密切交互，而是主要需要在处理大型数据对象或连续流时发出工作提交和完成事件的信号。对于此类设备，在加速接口使用 PCIe 就很合适，而 CXL 没有明显优势。
CXL 标准定义了 3 个协议，这些协议在通过标准 PCIe 5.0 PHY 以 32 GT/s 传输之前一起动态复用：
CXL.io 协议本质上是经过一定改进的 PCIe 5.0 协议，用于初始化、链接、设备发现和列举以及寄存器访问。它为 I/O 设备提供了非一致的加载/存储接口。
CXL.cache 协议定义了主机和设备之间的交互，允许连接的 CXL 设备使用请求和响应方法以极低的延迟高效地缓存主机内存。
CXL.mem 协议提供了主机处理器，可以使用加载和存储命令访问设备连接的内存，此时主机 CPU 充当主设备，CXL 设备充当从属设备，并且可以支持易失性和持久性存储器架构。
三个协议产生的数据都通过仲裁和多路复用 (ARB/MUX) 模块一起动态复用，然后被移交到 PCIe 5.0 PHY，进而以 32GT/s 的速度进行传输。ARB/MUX 在 CXL 链路层（CXL.io 和 CXL.cache/mem）发出的请求之间进行仲裁，并根据仲裁结果复用数据，仲裁结果使用加权循环仲裁，权重由主机设置。ARB/MUX 还处理链路层发出的功耗状态转换请求，向物理层创建实现有序降耗操作的单个请求。
CXL 通过固定宽度的 528 位微片传输数据，该微片由四个 16 字节时隙组成，并添加了两个字节 CRC：（4 x 16 + 2 = 66 字节= 528 位）。插槽采用多种格式定义，可专用于 CXL.cache 协议或 CXL.mem 协议。片头定义了插槽格式，并携带允许事务层将数据正确路由到预期协议的信息。
由于 CXL 使用 PCIe 5.0 PHY 和电气元件，它可以有效地插入到任何可以通过 Flex Bus 使用 PCIe 5.0 的系统中。Flex Bus 是一个灵活的高速端口，可以静态配置为支持 PCIe 或 CXL。图 2 举例显示了 Flex Bus 链路。这种方法使 CXL 系统能够利用 PCIe 重定时器；但是，目前 CXL 仅定义为直连 CPU 链路，因此无法利用 PCIe 交换机。随着标准的逐步完善，交换功能可能会被添加到标准中；如果是这样，则需要创建新的 CXL 交换机。
]]></content>
  </entry>
  
  <entry>
    <title>Cortex-A8与STM32的区别</title>
    <url>/post/hardware/difference-between-cortex-a8-and-stm32.html</url>
    <categories><category>hardware</category>
    </categories>
    <tags>
      <tag>STM32</tag>
      <tag>ARM Cortex A8</tag>
    </tags>
    <content type="html"><![CDATA[Cortex-A8是ARM公司研发的一款微处理器内核。
STM32为ST公司（意法半导体）系列产品的简称，尤其是以STM32系列中Cortex-M3与Cortex-M4架构MCU（单片机）最为著称。
Cortex-A8 ARM Cortex™-A8处理器基于 ARMv7 体系结构，处理器主频常见从300MHz至1GHz不等，单核，能够运行WinCE、Linux、Android、RTOS等软件系统。
基于Cortex-A8内核的典型微处理器，包括苹果A4芯片、NXP(原飞思卡尔)i.MX5X系列芯片、三星S5PV210芯片、TI OMAP35XX与AM335X系列芯片等。通用市场中，三星S5PV210与TI AM335X应用较为广泛。
TI AM335X系列处理器2011年推出，宣传仅需5美金，在当时轰动整个市场！且该处理器支持三大系统与TI 裸机OS。
武汉万象奥科姜新博士在2011年当年也基于AM3359(TI 最早量产版本)设计开发出了AM335x核心板。
HD335X-CORE Cortex-A8核心板，软件开源，集成硬件加密保护用户软件知识产权，支持2路网口、2路CAN、6路串口，可选128MB~1GB内存，可选128MB~8GB存储。针对不同应用，万象奥科提供二次开发支持与定制服务支持，最大程度满足个性化项目需求。
STM32 STM32是ST公司（意法半导体）“成名之作”，资料丰富、入门简单、生态完善，曾一度成为MCU的代名词。“代表作”包括STM32F101、STM32F103、STM32F107等。
目前STM32系列已覆盖ARM Cortex®-M0，M0+，M3, M4和M7内核，切中高性能、低成本、低功耗的嵌入式应用。主流产品（STM32F0、STM32F1、STM32F3）、超低功耗产品（STM32L0、STM32L1、STM32L4、STM32L4+）、高性能产品（STM32F2、STM32F4、STM32F7、STM32H7）等。
2019年，ST公司推出STM32MP1系列MPU，支持Cortex-A7内核+Cortex-M4内核。两个内核之间分工明确、配合默契，Cortex-A7 内核可用于开源操作系统（如Linux）负责图形图像处理与通信存储功能，Cortex-M4 内核则专用于实时及低功耗任务处理。
同样，武汉万象奥科亦基于STM32MP1系列处理器推出了HD-MP157-CORE核心板。
区别 基于大家“共识”层面信息，Cortex-A8代表了典型的嵌入式MPU（微处理器），STM32代表了MCU（单片机）。
微处理器一般支持MMU，可以运行Linux、Android等复杂操作系统，可以开发较为复杂的业务与程序逻辑，但功耗相较于MCU通常会高。
MCU一般运行RTOS或前后台软件，擅长实时任务处理，更适合低功耗、超低功耗应用需求。
]]></content>
  </entry>
  
  <entry>
    <title>如何在一台Linux主机上同时访问多个Github账户</title>
    <url>/post/github/how-to-access-multiple-github-accounts-on-linux.html</url>
    <categories><category>Git</category>
    </categories>
    <tags>
      <tag>github</tag>
      <tag>multiple accounts</tag>
    </tags>
    <content type="html"><![CDATA[想必很多程序员都遇到过下面这个Github最著名报错，本文就将简要介绍以下针对这个报错的终极解决方案。
&ldquo;ERROR: Permission to xxx.git denied to XXX&rdquo;
ERROR: Permission to hbxn740150254/BestoneGitHub.git denied to Chenzuohehe. fatal: Could not read from remote repository.Please make sure you have the correct access rights and the repository exists. 当你遇到上述问题的时候，解决方法是要重新生成一个SSH KEY
生成SSH KEY //先进入本地ssh目录 AppledeiMac:~ Apple$ cd ~/.ssh //查看当前已有的密钥文件 AppledeiMac:.ssh Apple$ ls id_rsa id_rsa.pub known_hosts //生成密钥 AppledeiMac:.ssh Apple$ ssh-keygen -t rsa -C &#34;iMac_personnal_publicKey&#34; Generating public/private rsa key pair. Enter file in which to save the key (/Users/Apple/.ssh/id_rsa): /Users/Apple/.ssh/id_rsa_personal Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /Users/Apple/.ssh/id_rsa_personal. Your public key has been saved in /Users/Apple/.ssh/id_rsa_personal.pub. The key fingerprint is: SHA256:1gepuxDHwJRnFbKvc0Zq/NGrFGE9kEXS06jxatPPrSQ iMac_personnal_publicKey The key&#39;s randomart image is: +---[RSA 2048]----+ | ....=*oo | | o. ooo=+ . | | oo. =+o. | | o =.o.. | | . S =o. | | = =++. | | . B.=.Eo.. | | o B . +o .| | . o.. .. | +----[SHA256]-----+ //再次查看密钥文件，可以看到刚刚添加的密钥文件已经生成了 AppledeiMac:.ssh Apple$ ls id_rsa id_rsa_personal known_hosts id_rsa.pub id_rsa_personal.pub SSH是什么？他是一种远程登录服务，登录后连接到服务器的终端上，然后就可以进行相关的操作了。Github服务器也支持ssh登录（当然只给你控制仓库上传和下载）。
第一步，就是要生成私钥和公钥密钥对，这是一种加密方式，它给出一对密码，私钥加密，公钥可以解密，公钥加密，私钥可以解密，其中，公钥是可以公开发行的，别人用你的公钥加密了数据，这个密文数据发给你，你就能用私钥进行解密。然后你拿到对方的公钥，同样的步骤，你就可以发加密后的信息给他。这就达成了加密通信。理论上是很难破解的，只要你藏好私钥。
ssh-keygen命令会生成一对秘钥，在Linux中一般是放在~/.ssh/目录下面。秘钥文件是一个文本文件，可以打开读取。把公钥内容复制粘贴到服务器上面，服务器就拥有你的公钥了。
创建密钥对会让你输入私钥的名字：比如id_rsa是私钥，id_rsa.pub就是公钥。
但是，如果你有很多对秘钥，服务器怎么知道你要用哪个呢？答案在第三步。
将公钥添加到Github的SSH keys里面 打开新生成的~/.ssh/id_rsa_personal.pub文件，复制里面的内容，然后将内容添加到GitHub上SSH keys里面 配置SSH config文件 没有config文件则创建一个，终端输入touch config，创建完以后用vim或者任何一个编辑器打开。
在不影响默认的github设置下我们重新添加一个Host，建一个自己能辨识的github别名，我取的是github-personal，新建的帐号使用这个别名做clone和更新动作。或者直接复制代码添加到已有的config文件里面，添加之后的样子请参考下面的内容。
#Default GitHub Host github.com HostName github.com User git IdentityFile ~/.ssh/id_rsa Host github-personal HostName github.com User git IdentityFile ~/.ssh/id_rsa_personal 用新的Host别名来访问Github 将GitHub SSH仓库地址中的git@github.com替换成新建的Host别名
如原地址是git@github.com:hbxn740150254/BestoneGitHub.git替换后应该是：github-personal:hbxn740150254/BestoneGitHub.git 或者 git@github-personal:hbxn740150254/BestoneGitHub.git，经过亲自测试，都是可以的。
如果是新建的仓库，直接使用替换后的URL clone即可。如果已经使用原URL Clone过了，可以使用命令修改：
//进入项目文件夹目录 AppledeiMac:.ssh Apple$ cd /Users/Apple/Desktop/BestoneDemo //修改之前 Apple$ git remote -v github git@github.com:hbxn740150254/BestoneGitHub.git (fetch) github git@github.com:hbxn740150254/BestoneGitHub.git (push) //修改 remote set-url AppledeiMac:BestoneDemo Apple$ git remote set-url origin github-personal:hbxn740150254/BestoneGitHub.git //验证是否修改成功 //使用修改后的github-personal SSH连接，连接成功用户是hbxn740150254，此时公钥是id_rsa_personal AppledeiMac:BestoneDemo Apple$ ssh -T github-personal Hi hbxn740150254! You&#39;ve successfully authenticated, but GitHub does not provide shell access. //使用默认的git@github.com SSH去连接,连接成功用户是FaxeXian，此时公钥是id_rsa AppledeiMac:.ssh Apple$ ssh -T git@github.com Hi FaxeXian! You&#39;ve successfully authenticated, but GitHub does not provide shell access. //修改之后 AppledeiMac:BestoneDemo Apple$ git remote -v github github-personal:hbxn740150254/BestoneGitHub.git (fetch) github github-personal:hbxn740150254/BestoneGitHub.git (push) 如果github账户如果还是显示之前id_rsa密钥账户的话，请把你的密钥加入sshAgent代理中
apple:.ssh apple$ eval &#34;$(ssh-agent -s)&#34; Agent pid 19795 //添加密钥 id_rsa_personal apple:.ssh apple$ ssh-add id_rsa_personal Identity added: id_rsa_personal (github-personal) //添加默认密钥 id_rsa apple:.ssh apple$ ssh-add id_rsa //密钥有密码的话就会要你提示输入 passphrase Enter passphrase for id_rsa: //测试用密钥isa是否连接成功github apple:.ssh apple$ ssh -T git@github.com Hi hbxn740150254! You &#39;ve successfully authenticated, but GitHub does not provide shell access. //测试密钥id_rsa_personal是否连接成功github apple:.ssh apple$ ssh -T git@github-personal Hi FaxeXian! You&#39;ve successfully authenticated, but GitHub does not provide shell access. 至此，你就可以在这一台电脑上通过两个公钥来分别访问不同的Github账号了，是不是很方便！
]]></content>
  </entry>
  
  <entry>
    <title>Linux 进程概念: 冯 • 诺依曼体系结构</title>
    <url>/post/linux/linux-process-concept-von-neumann-architecture.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Process</tag>
      <tag>Von Neumann Architecture</tag>
    </tags>
    <content type="html"><![CDATA[在 1945 年冯诺依曼和其他计算机科学家们提出了计算机具体实现的报告，其遵循了[图灵机]的设计，而且还提出用电子元件构造计算机，并约定了用二进制进行计算和存储。
冯诺依曼体系结构 冯诺依曼体系，最重要的是定义计算机基本结构为 5 个部分，分别是[运算器]、控制器、存储器、输入设备、输出设备，这 5 个部分也被称为冯诺依曼模型。
下图为冯 • 诺依曼体系结构流程图：
运算器、控制器是在中央处理器里的，存储器就是我们常见的内存，输入输出设备则是计算机外接的设备，比如键盘就是输入设备，显示器就是输出设备。 
我们常见的计算机，如笔记本。我们不常见的计算机，如服务器，大部分都遵守冯诺依曼体系，截至目前，我们所认识的计算机，都是有一个个的硬件组件组成。
存储单元和输入输出设备要与中央处理器打交道的话，离不开总线。所以，它们之间的关系如下图：
接下来，分别介绍内存、中央处理器、总线、输入输出设备。
输入、输出设备 输入设备向计算机输入数据，计算机经过计算后，把数据输出给输出设备。  常见的输入和输出设备有：
 输入设备：键盘，话筒，摄像头，磁盘，网卡等等… 输出设备：显示器，音响，磁盘，网卡，显卡等等…  注意：同种设备在不同场景下可能属于输入设备，也可能属于输入设备。
中央处理器 中央处理器也就是我们常说的 CPU，它是由运算器和控制器组成。
CPU 内部还有一些组件，常见的有寄存器、控制单元 和 逻辑运算单元 等。其中，控制单元负责控制 CPU 工作，逻辑运算单元负责计算，而寄存器可以分为多种类，每种寄存器的功能又不尽相同。
CPU 中的寄存器主要作用是存储计算时的数据，你可能好奇为什么有了内存还需要寄存器？原因很简单，因为内存离 CPU 太远了，而寄存器就在 CPU 里，还紧挨着控制单元和逻辑运算单元，自然计算时速度会很快。
常见的寄存器种类：
 通用寄存器，用来存放需要进行运算的数据，比如需要进行加和运算的两个数据。 程序计数器，用来存储 CPU 要执行下一条指令「所在的内存地址」，注意不是存储了下一条要执行的指令，此时指令还在内存中，程序计数器只是存储了下一条指令「的地址」。 指令寄存器，用来存放当前正在执行的指令，也就是指令本身，指令被执行完成之前，指令都存储在这里。  内存 内存，也就是所谓的存储器。
我们的程序和数据都是存储在内存，存储的区域是线性的。
在计算机数据存储中，存储数据的基本单位是字节（byte），1 字节等于 8 位（8 bit）。每一个字节都对应一个内存地址。
内存的地址是从 0 开始编号的，然后自增排列，最后一个地址为内存总字节数 - 1，这种结构好似我们程序里的数组，所以内存的读写任何一个数据的速度都是一样的。
思考一个问题： 当我们的体系结构中，有了输入、输出设备和 CPU 以后，就能正常工作了，那么为什么还需要内存呢？
从技术角度来说 CPU 的运算速度 &gt; &raquo; 寄存器的速度 &gt; &raquo; L1~L3Cache &gt; &raquo; 内存 &gt; &raquo; 外设（磁盘）&gt; &raquo; 光盘磁带
也就是说，输入设备和输出设备相对于 CPU 来说是非常慢的。
如果没有内存的话，那么当前这个体系整体呈现出来的就是：输入设备和输出设备很慢，而 CPU 很快。
相信大家知道木桶原理吧，那么最终整个体系结构所呈现出来的速度将会是很慢的。
所以，从数据角度出发，外设几乎不和 CPU 打交道，它是直接和内存打交道，CPU 也同样如此。
进言之，内存在我们看来，就是体系结构的一个大的缓存，用来适配外设和 CPU 速度不均的问题！
从成本角度来说 既然上面说了内存是用来适配外设和 CPU 速度不均的问题，那么为什么不直接在 CPU 里面开发一个类似于内存的东西呢？
这个想法可以，但是如果真要去实现的话，那么一台计算机的成本起码得 10W+，而计算机它是蔓延全世界的，也就是说人人都能用得起的！
寄存器的价格 &gt; &raquo; 内存 &gt; &raquo; 外设 (磁盘)
所以内存就是方便我们使用较低的成本，获得较高的性能。
总线 总线是用于 CPU 和内存以及其他设备之间的通信，总线可分为 3 种：   地址总线，用于指定 CPU 将要操作的内存地址； 数据总线，用于读写内存的数据； 控制总线，用于发送和接收信号，比如中断、设备复位等信号，CPU 收到信号后自然进行响应，这时也需要控制总线；  当 CPU 要读写内存数据的时候，一般需要通过下面这三个总线：
 首先要通过「地址总线」来指定内存的地址； 然后通过「控制总线」控制是读或写命令； 最后通过「数据总线」来传输数据；  局部性原理 我相信大家应该还有个疑惑：就是，先将输入设备的数据交给内存，再由内存将数据交给 CPU，这个过程真的比 CPU 直接从输入设备获取数据更快吗？
说明这个问题之前，我们首先需要知道：内存具有数据存储的能力。虽然内存的大小只有 4G/8G，但是既然内存有大小，那么它就有预装数据的能力，而这就是提高该体系结构效率的秘诀。
这里不得不说到的就是 局部性原理：根据统计学原理，当一个数据正在被访问时，那么下一次有很大可能会访问其周围的数据。所以当 CPU 需要获取某一行数据时，内存可以将该行数据之后的数据一同加载进来，而 CPU 处理数据和内存加载数据是可以同时进行的，这样下次 CPU 就可以直接从内存当中获取数据。
输出数据的时候也一样，CPU 处理完数据后直接将数据放到内存当中，当输出设备需要时再在内存当中获取即可，这也就有了我们平常所说的缓冲区的概念。
例如，缓冲区满了才将数据打印到屏幕上，使用 fflush 函数将缓冲区当中的数据直接输出之类的，都是将内存当中的数据直接拿到输出设备当中进行显示输出。
总结 冯 • 诺依曼体系结构核心原理为：用户输入的数据先放到内存当中，CPU 读取数据的时候就直接从内存当中读取，CPU 处理完数据后又写回内存当中，然后内存再将数据输出到输出设备当中，最后由输出设备进行输出显示。
我们可以知道，站在硬件角度或是数据层面上，CPU 和外设不能直接交互，而是通过内存，也就是说，所有设备都只能和内存打交道。
由此可以说明一个问题：为什么程序运行之前必须先加载到内存？
因为可执行程序（文件）是在硬盘（外设）上的，而 CPU 只能从内存当中获取数据，所以必须先将硬盘上的数据加载到内存，也就是必须先将程序加载到内存。
数据的流动过程 对冯诺依曼的理解，不能停留在概念上，要深入到对软件数据流理解上。
从你登录上 QQ 和某位朋友聊天开始，数据的流动过程是怎样的呢？从你打开窗口，开始给他发消息，到他的到消息之后的数据流动过程。
要使用 QQ，首先需要联网，而你和你的朋友的电脑都是冯诺依曼体系结构，在你向朋友发送消息这个过程中，你的电脑当中的键盘充当输入设备，显示器和网卡充当输出设备，你朋友的电脑当中的网卡充当输入设备，显示器充当输出设备。
刚开始你在键盘当中输入消息，键盘将消息加载到内存，此时你的显示器就可以从内存获取消息进而显示在你自己的显示器上，此时你就能在你自己的电脑上看到你所发的消息了。
在键盘将消息加载到内存后，CPU 从内存获取到消息后对消息进行各种封装，然后再将其写回内存，此时你的网卡就可以从内存获取已经封装好的消息，然后在网络当中经过一系列处理（这里忽略网络处理细节）。
之后你朋友的网卡从网络当中获取到你所发的消息后，将该消息加载到内存当中，你朋友的 CPU 再从内存当中获取消息并对消息进行解包操作，然后将解包好的消息写回内存，最后你朋友的显示器从内存当中获取消息并显示在他的电脑上。
那么如果是在 QQ 上发送文件呢？
首先你的文件最开始是在你本地的磁盘上的，先从磁盘上把文件读到内存中，文件里面的东西其实还是数据，把数据再经过 CPU 封装成报文，然后刷新到我们的内存中，定期再经过网卡，把数据刷新到网卡上，然后再发出去。
传文件的本质就是：两端的磁盘进行通信。 ]]></content>
  </entry>
  
  <entry>
    <title>40个简单但有效的Linux Shell脚本示例</title>
    <url>/post/linux/40-simple-and-useful-linux-shell-script.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>shell script</tag>
    </tags>
    <content type="html"><![CDATA[历史上，shell一直是类Unix系统的本地命令行解释器。它已被证明是Unix的主要功能之一，并发展成为一个全新的主题。Linux提供了各种功能强大的shell，包括Bash、Zsh、Tcsh和Ksh。这些外壳最令人惊讶的特性之一是其可编程性。创建简单而有效的Linux shell脚本来处理日常工作非常容易。
Hello World 程序员经常通过学习hello world程序来学习新语言。这是一个简单的程序，将字符串“HelloWorld”打印到标准输出中。然后，使用vim或nano等编辑器创建hello-world.sh文件，并将以下行复制到其中。
#!/bin/bash echo &#34;Hello World&#34; 保存并退出文件。接下来，您需要使用以下命令使该文件可执行。
$ chmod a+x hello-world.sh 可以使用以下两个命令中的任何一个来运行此命令。
$ bash hello-world.sh $ ./hello-world.sh 它将打印出传递给脚本内部回显的字符串。
使用echo打印 echo命令用于在bash中打印信息。它类似于C函数“printf”，并提供了许多常见选项，包括转义序列和重定向。将以下行复制到名为echo.sh的文件中，并使其可执行，如上所述。
#!/bin/bash echo &#34;Printing text&#34; echo -n &#34;Printing text without newline&#34; echo -e &#34;\nRemoving \t special \t characters\n&#34; 运行脚本以查看其功能。-e选项用于告诉echo传递给它的字符串包含特殊字符，需要扩展功能。
使用注释 注释对文档很有用，是高质量代码库的要求。将注释放在处理关键逻辑的代码中是一种常见的做法。要注释掉一行，只需在其前面使用#（hash）字符。例如，请查看下面的bash脚本示例。
#!/bin/bash  # Adding two values ((sum=25+35)) #Print the result echo $sum 此脚本将输出数字60。首先，在某些行之前使用#检查注释的使用方式。不过，第一行是一个例外。它被称为shebang，让系统知道在运行这个脚本时要使用哪个解释器。
多行注释 许多人使用多行注释来记录他们的shell脚本。在下一个名为comment.sh的脚本中检查这是如何完成的。
#!/bin/bash : &#39; This script calculates the square of 5. &#39; ((area=5*5)) echo $area 注意多行注释是如何放置在内部的：“和”字符。
While循环 while循环构造用于多次运行某些指令。查看以下名为while.sh的脚本，以更好地理解此概念。
#!/bin/bash #!/bin/bash i=0 while [ $i -le 2 ] do echo Number: $i ((i++)) done 因此，while循环采用以下形式。
#!/bin/bash while [ condition ] do commands 1 commands n done 方括号周围的空格是必填的。
For循环 for循环是另一种广泛使用的bashshell构造，它允许用户高效地迭代代码。下面演示了一个简单的示例。
#!/bin/bash  for (( counter=1; counter&lt;=10; counter++ )) do echo -n &#34;$counter&#34; done printf &#34;\n&#34; 接收用户输入 #!/bin/bash  echo -n &#34;Enter Something:&#34; read something echo &#34;You Entered: $something&#34; If语句 if CONDITION then STATEMENTS fi 只有当条件为真时，才会执行这些语句。fi关键字用于标记if语句的结尾。下面显示了一个快速示例。
#!/bin/bash  echo -n &#34;Enter a number: &#34; read num if [[ $num -gt 10 ]] then echo &#34;Number is greater than 10.&#34; fi 如果通过输入提供的数字大于10，上述程序将仅显示输出。-gt表示大于；类似地-lt表示小于-le表示小于等于；且-ge表示大于等于。此外，还需要[[]]。
使用If Else进行更多控制 将else构造与if结合起来，可以更好地控制脚本的逻辑。下面显示了一个简单的示例。
#!/bin/bash  read n if [ $n -lt 10 ]; then echo &#34;It is a one digit number&#34; else echo &#34;It is a two digit number&#34; fi 其他部分需要放在if的动作部分之后和fi之前。
使用AND运算符 AND运算符允许我们的程序检查是否同时满足多个条件。由AND运算符分隔的所有部分必须为true。否则，包含AND的语句将返回false。查看下面的bash脚本示例，以更好地了解AND的工作原理。
#!/bin/bash  echo -n &#34;Enter Number:&#34; read num if [[ ( $num -lt 10 ) &amp;&amp; ( $num%2 -eq 0 ) ]]; then echo &#34;Even Number&#34; else echo &#34;Odd Number&#34; fi AND运算符由&amp;&amp;符号表示。
使用OR运算符 OR运算符是另一个关键的构造，它允许我们在脚本中实现复杂、健壮的编程逻辑。与AND相反，当OR运算符的任一操作数为真时，由OR运算符组成的语句返回真。仅当由OR分隔的每个操作数为假时，它才返回假。
#!/bin/bash  echo -n &#34;Enter any number:&#34; read n if [[ ( $n -eq 15 || $n -eq 45 ) ]] then echo &#34;You won&#34; else echo &#34;You lost!&#34; fi 这个简单的示例演示了OR运算符如何在Linuxshell脚本中工作。只有当用户输入数字15或45时，它才会宣布用户为获胜者。||符号表示OR运算符。
使用El if elif语句代表else if，并为实现链逻辑提供了一种方便的方法。通过评估以下示例，了解elif的工作原理。
#!/bin/bash  echo -n &#34;Enter a number: &#34; read num if [[ $num -gt 10 ]] then echo &#34;Number is greater than 10.&#34; elif [[ $num -eq 10 ]] then echo &#34;Number is equal to 10.&#34; else echo &#34;Number is less than 10.&#34; fi 上面的程序是不言自明的，所以我们不会逐行剖析它。相反，更改脚本中的变量名称和值等部分，以检查它们如何一起工作。
case 条件 switch构造是Linux bash脚本提供的另一个强大功能。它可以用于需要嵌套条件的地方，但不希望使用复杂的if-else elif链。看看下一个例子。
#!/bin/bash  echo -n &#34;Enter a number: &#34; read num case $num in 100) echo &#34;Hundred!!&#34; ;; 200) echo &#34;Double Hundred!!&#34; ;; *) echo &#34;Neither 100 nor 200&#34; ;; esac 条件写在case和esac关键字之间。*）用于匹配除100和200以外的所有输入。
命令行参数 在许多情况下，直接从命令shell获取参数是有益的。下面的示例演示了如何在bash中执行此操作。
#!/bin/bash echo &#34;Total arguments : $#&#34; echo &#34;First Argument = $1&#34; echo &#34;Second Argument = $2&#34; 运行此脚本时，在其名称后添加两个附加参数。我将其命名为test.sh，调用过程概述如下。
$ ./test.sh Hey Howdy 因此，$1用于访问第一个参数，$2用于访问第二个参数，依此类推。最后，$#用于获取参数总数。
使用名称获取参数 下面的示例显示了如何获取带有名称的命令行参数。
#!/bin/bash  for arg in &#34;$@&#34; do index=$(echo $arg | cut -f1 -d=) val=$(echo $arg | cut -f2 -d=) case $index in X) x=$val;; Y) y=$val;; *) esac done ((result=x+y)) echo &#34;X+Y=$result&#34; 将此脚本命名为test.sh，并按如下所示调用它。
$ ./test.sh X=44 Y=100 它应该返回X+Y=144。这里的参数存储在“$@”中，脚本使用Linuxcut命令获取它们。
连接字符串 字符串处理对于广泛的现代bash脚本来说非常重要。值得庆幸的是，它在bash中更加舒适，并允许以更精确、简洁的方式实现这一点。请参见下面的示例，了解bash字符串连接。
#!/bin/bash  string1=&#34;Ubuntu&#34; string2=&#34;Pit&#34; string=$string1$string2 echo &#34;$stringis a great resource for Linux beginners.&#34; 字符串截取 与许多编程语言不同，bash不提供任何用于剪切字符串部分的内置函数。然而，下面的示例演示了如何使用参数展开来实现这一点。
#!/bin/bash Str=&#34;Learn Bash Commands from UbuntuPit&#34; subStr=${Str:0:20} echo $subStr 该脚本应打印出“学习Bash命令”作为其输出。参数展开形式为${VAR_NAME:S:L}。这里，S表示起始位置，L表示长度。
使用cut 做截取 可以在脚本中使用Linux cut命令来截取字符串的一部分，也就是子字符串。下一个示例显示了如何做到这一点。
#!/bin/bash Str=&#34;Learn Bash Commands from UbuntuPit&#34; #subStr=${Str:0:20} subStr=$(echo $Str| cut -d &#39; &#39; -f 1-3) echo $subStr 添加两个值 在Linux shell脚本中执行算术运算非常容易。下面的示例演示了如何从用户接收两个数字作为输入并将它们相加。
#!/bin/bash echo -n &#34;Enter first number:&#34; read x echo -n &#34;Enter second number:&#34; read y (( sum=x+y )) echo &#34;The result of addition=$sum&#34; 如您所见，在bash中添加数字相当简单。
添加多个值 您可以使用循环获取多个用户输入并将其添加到脚本中。以下示例显示了这一点。
#!/bin/bash sum=0 for (( counter=1; counter&lt;5; counter++ )) do echo -n &#34;Enter Your Number:&#34; read n (( sum+=n )) #echo -n &#34;$counter &#34; done printf &#34;\n&#34; echo &#34;Result is: $sum&#34; 但是，省略(())将导致字符串串联而不是相加。所以，在你的程序中检查类似的情况。
Bash中的函数 与任何编程方言一样，函数在Linux shell脚本中扮演着重要角色。它们允许管理员创建自定义代码块以供频繁使用。下面的演示将概述函数如何在Linux bash脚本中工作。
#!/bin/bash function Add() { echo -n &#34;Enter a Number: &#34; read x echo -n &#34;Enter another Number: &#34; read y echo &#34;Adiition is: $(( x+y ))&#34; } Add 这里我们像以前一样添加了两个数字。但在这里，我们使用了一个名为Add的函数来完成这项工作。因此，每当您需要再次添加时，只需调用此函数，而不必再次编写该部分。
具有返回值的函数 最神奇的功能之一是允许数据从一个函数传递到另一个函数。它在各种场景中都很有用。查看下一个示例。
#!/bin/bash  function Greet() { str=&#34;Hello $name, what brings you to UbuntuPit.com?&#34; echo $str } echo &#34;-&gt; what&#39;s your name?&#34; read name val=$(Greet) echo -e &#34;-&gt; $val&#34; 这里，输出包含从Greet（）函数接收的数据。
从Bash脚本创建目录 使用shell脚本运行系统命令的能力使开发人员的工作效率大大提高。下面的简单示例将向您展示如何在shell脚本中创建目录。
#!/bin/bash echo -n &#34;Enter directory name -&gt;&#34; read newdir cmd=&#34;mkdir $newdir&#34; eval $cmd 该脚本只需调用标准shell命令mkdir，并在仔细查看时将目录名传递给它。这个程序应该在文件系统中创建一个目录。您还可以传递命令以在backticks（“）内部执行，如下所示。
`mkdir $newdir` 确认存在后创建目录 如果当前工作目录中已包含同名文件夹，则上述程序将无法运行。例如，下面的程序将检查是否存在名为$dir的文件夹，如果找不到，则只创建一个。
#!/bin/bash echo -n &#34;Enter directory name -&gt;&#34; read dir if [ -d &#34;$dir&#34; ] then echo &#34;Directory exists&#34; else `mkdir $dir` echo &#34;Directory created&#34; fi 使用eval编写此程序以提高bash脚本编写技能。 读取文件 Bash脚本允许用户非常有效地读取文件。下面的示例将展示如何使用shell脚本读取文件。首先，创建一个名为editors.txt的文件，其中包含以下内容。
1. Vim 2. Emacs 3. ed 4. nano 5. Code 此脚本将输出上述5行中的每一行。
#!/bin/bash file=&#39;editors.txt&#39; while read line; do echo $line done &lt; $file 删除文件 以下程序将演示如何在Linux shell脚本中删除文件。程序将首先要求用户提供文件名作为输入，如果文件名存在，则将其删除。Linux rm命令在此处执行删除操作。
#!/bin/bash echo -n &#34;Enter filename -&gt;&#34; read name rm -i $name 让我们输入editors.txt作为文件名，并在要求确认时按y。它应该删除该文件。
附加到文件 下面的shell脚本示例将向您展示如何使用bash脚本将数据附加到文件系统上的文件。它向早期的editors.txt文件添加了一行。
#!/bin/bash echo &#34;Before appending the file&#34; cat editors.txt echo &#34;6. NotePad++&#34; &gt;&gt; editors.txt echo &#34;After appending the file&#34; cat editors.txt 现在您应该注意到，我们直接从Linux bash脚本使用日常终端命令。
测试文件存在 下一个shell脚本示例显示如何检查bash程序中文件的存在。
#!/bin/bash filename=$1 if [ -f &#34;$filename&#34; ]; then echo &#34;File exists&#34; else echo &#34;File does not exist&#34; fi 我们直接从命令行传递文件名作为参数。
从Shell脚本发送邮件 从bash脚本发送电子邮件非常简单。下面的简单示例将演示一种从bash应用程序执行此操作的方法。
#!/bin/bash recipient=”admin@example.com” subject=”Greetings” message=”Welcome to UbuntuPit” `mail -s $subject $recipient &lt;&lt;&lt; $message` 它将向收件人发送包含给定主题和消息的电子邮件。
解析日期和时间 下一个bash脚本示例将向您展示如何使用脚本处理日期和时间。同样，Linuxdate命令用于获取必要的信息，我们的程序执行解析。
#!/bin/bash year=`date +%Y` month=`date +%m` day=`date +%d` hour=`date +%H` minute=`date +%M` second=`date +%S` echo `date` echo &#34;Current Date is: $day-$month-$year&#34; echo &#34;Current Time is: $hour:$minute:$second&#34; 运行此程序以了解其工作原理。此外，尝试从终端运行date命令。
sleep命令 sleep命令允许shell脚本在指令之间暂停。它在许多场景中都很有用，例如执行系统级作业。下一个示例显示了shell脚本中的sleep命令。
#!/bin/bash echo &#34;How long to wait?&#34; read time sleep $time echo &#34;Waited for $timeseconds!&#34; 该程序暂停最后一条指令的执行，直到$time秒，在本例中，用户提供了这一点。
wait命令 wait命令用于暂停Linux bash脚本中的系统进程。查看下面的示例，详细了解这在bash中的工作方式。
#!/bin/bash echo &#34;Testing wait command&#34; sleep 5 &amp; pid=$! kill $pid wait $pid echo $pid was terminated. 显示上次更新的文件 有时，您可能需要为某些操作查找最后更新的文件。下面的简单程序向我们展示了如何在bash中使用awk命令执行此操作。它将列出当前工作目录中最近更新或创建的文件。
#!/bin/bash  ls -lrt | grep ^- | awk &#39;END{print $NF}&#39; 为了简单起见，我们将避免在本示例中描述awk的功能。相反，您可以简单地复制此代码来完成任务。
添加批处理扩展 下面的示例将对目录中的所有文件应用自定义扩展名。创建一个新目录，并将一些文件放在其中以供演示。我的文件夹共有五个文件，每个文件名为test，后跟（0-4）。我已将此脚本编程为在文件末尾添加（.UP）。您可以添加所需的任何扩展名。
#!/bin/bash dir=$1 for file in `ls $1/*` do mv $file $file.UP done 首先，不要从任何常规目录尝试此脚本；相反，请从测试目录运行此命令。此外，您需要提供文件的目录名作为命令行参数。对当前工作目录使用句点（.）。
打印文件或目录的数量 下面的Linuxbash脚本查找给定目录中存在的文件或文件夹的数量。它使用Linux find命令来执行此操作。首先，需要传递目录名以从命令行搜索文件。
#!/bin/bash  if [ -d &#34;$@&#34; ]; then echo &#34;Files found: $(find &#34;$@&#34; -type f | wc -l)&#34; echo &#34;Folders found: $(find &#34;$@&#34; -type d | wc -l)&#34; else echo &#34;[ERROR] Please retry with another folder.&#34; exit 1 fi 如果指定的目录不可用或存在权限问题，程序将要求用户重试。
清理日志文件 下一个简单的示例演示了在现实生活中使用shell脚本的简便方法。该程序只需删除/var/log目录中的所有日志文件。您可以更改保存此目录的变量以清理其他日志。
#!/bin/bash LOG_DIR=/var/log cd $LOG_DIR cat /dev/null &gt; messages cat /dev/null &gt; wtmp echo &#34;Logs cleaned up.&#34; 请记住以root身份运行此Linuxshell脚本。
使用Bash备份脚本 Shell脚本提供了一种强大的方法来备份文件和目录。以下示例将备份过去24小时内修改的每个文件或目录。该程序使用find命令执行此操作。
#!/bin/bash  BACKUPFILE=backup-$(date +%m-%d-%Y) archive=${1:-$BACKUPFILE} find . -mtime -1 -type f -print0 | xargs -0 tar rvf &#34;$archive.tar&#34; echo &#34;Directory $PWDbacked up in archive file \&#34;$archive.tar.gz\&#34;.&#34; exit 0 备份过程成功后，它将打印文件和目录的名称。
检查你是否是root用户 下面的示例演示了通过Linux bash脚本快速确定用户是否为root用户的方法。
#!/bin/bash ROOT_UID=0 if [ &#34;$UID&#34; -eq &#34;$ROOT_UID&#34; ] then echo &#34;You are root.&#34; else echo &#34;You are not root&#34; fi exit 0 此脚本的输出取决于运行它的用户。它将根据$UID匹配根用户。
从文件中删除重复行 文件处理需要相当长的时间，并在许多方面阻碍了管理员的工作效率。例如，在文件中搜索重复项可能会成为一项艰巨的任务。幸运的是，您可以使用一个简短的shell脚本来完成此操作。
#! /bin/sh  echo -n &#34;Enter Filename-&gt; &#34; read filename if [ -f &#34;$filename&#34; ]; then sort $filename | uniq | tee sorted.txt else echo &#34;No $filenamein $pwd...try again&#34; fi exit 0 上面的脚本逐行遍历文件并删除所有重复的行。然后，它将新内容放入新文件，并保持原始文件的完整性。
系统维护 我经常使用一个小的Linuxshell脚本来升级我的系统，而不是手动升级。下面的简单shell脚本将向您展示如何做到这一点。
#!/bin/bash  echo -e &#34;\n$(date &#34;+%d-%m-%Y --- %T&#34;)--- Starting work\n&#34; apt-get update apt-get -y upgrade apt-get -y autoremove apt-get autoclean echo -e &#34;\n$(date &#34;+%T&#34;)\t Script Terminated&#34; 该脚本还处理不再需要的旧包。您需要使用sudo运行此脚本，否则它将无法正常工作。
]]></content>
  </entry>
  
  <entry>
    <title>Linux中touch命令的8个实际例子</title>
    <url>/post/linux/8-examples-of-touch-cmd-in-linux.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>touch</tag>
    </tags>
    <content type="html"><![CDATA[在本文中，我们将介绍一些有用的 Linux   实际示例touch command。这touch command是一个标准程序Unix/Linux操作系统，用于创建、更改和修改文件的时间戳。在开始接触命令示例之前，请查看以下选项。
touch命令选项   -a, 只更改访问时间 -c, 如果文件不存在，不创建 -d, 更新访问和修改时间 -m, 只更改修改时间 -r, 使用文件的访问和修改次数 -t, 使用指定时间创建文件  如何创建一个空文件  以下 touch 命令创建一个名为的空（零字节）新文件sheena.
 # touch sheena 如何创建多个文件  通过使用 touch 命令，您还可以创建多个文件。例如，以下命令将创建 3 个名为的文件，sheena,meena和temp.
 # touch sheena meena temp 如何更改文件访问和修改时间 更改或更新名为的文件的上次访问和修改时间temp， 使用-a选项如下。以下命令设置文件的当前时间和日期。如果temp文件不存在，它将创建具有名称的新空文件。  # touch -a temp  find 命令使用时间戳来列出和查找文件。
 如何避免创建新文件 使用-c带有 touch 命令的选项可避免创建新文件。例如，以下命令不会创建名为temp如果它不存在。  # touch -c temp ##如何更改文件修改时间
如果您想更改名为的文件的唯一修改时间temp，然后使用-m带有触摸命令的选项。请注意，它只会更新文件的最后修改时间（而不是访问时间）。  # touch -m temp ##明确设置访问和修改时间
 您可以使用显式设置时间-c和-t带有触摸命令的选项。格式如下。
 # touch -c -t YYDDHHMM temp  例如，以下命令设置文件的访问和修改日期和时间temp作为17:30(17:30 p.m.)August 10当年（2021）。
 # touch -c -t 12101730 temp  接下来验证文件的访问和修改时间temp， 和ls -l命令。
 # ls -l total 2 -rw-r--r--. 1 root root 0 Dec 10 17:30 temp 如何使用另一个文件的时间戳  以下触摸命令与-r选项，将更新文件的时间戳meena带有时间戳temp文件。因此，两个文件都拥有相同的时间戳。
 # touch -r temp meena 使用指定时间创建文件  如果你想创建一个指定时间而不是当前时间的文件，那么格式应该是。
 # touch -t YYMMDDHHMM.SS rumenz  例如下面的命令 touch 命令-t选项将给出rumenz归档时间戳18:30:55 p.m.在August 5,2021.
 # touch -t 202108051830.55 rumenz ]]></content>
  </entry>
  
  <entry>
    <title>C语言回调函数，提升C技巧必备</title>
    <url>/post/linux/c-programming-callback-function.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>c</tag>
      <tag>callback</tag>
    </tags>
    <content type="html"><![CDATA[本文简要介绍了C语言编程中的回调函数
函数指针 在讲回调函数之前，我们需要了解函数指针。
我们都知道，C语言的灵魂是指针，我们经常使用整型指针，字符串指针，结构体指针等。
int *p1; char *p2; STRUCT *p3; // STRUCT为我们定义的结构体 但是好像我们一般很少使用函数指针，我们一般使用函数都是直接使用函数调用。
下面我们来了解一下函数指针的概念和使用方法。
概念 函数指针是指向函数的指针变量。
通常我们说的指针变量是指向一个整型、字符型或数组等变量，而函数指针是指向函数。
函数指针可以像一般函数一样，用于调用函数、传递参数。
函数指针的定义方式为：
函数返回值类型 (* 指针变量名) (函数参数列表);  “函数返回值类型”表示该指针变量可以指向具有什么返回值类型的函数；“函数参数列表”表示该指针变量可以指向具有什么参数列表的函数。这个参数列表中只需要写函数的参数类型即可。
我们看到，函数指针的定义就是将“函数声明”中的“函数名”改成“（指针变量名）”。但是这里需要注意的是：“（指针变量名）”两端的括号不能省略，括号改变了运算符的优先级。如果省略了括号，就不是定义函数指针而是一个函数声明了，即声明了一个返回值类型为指针型的函数。
那么怎么判断一个指针变量是指向变量的指针变量还是指向函数的指针变量呢？首先看变量名前面有没有“”，如果有“”说明是指针变量；其次看变量名的后面有没有带有形参类型的圆括号，如果有就是指向函数的指针变量，即函数指针，如果没有就是指向变量的指针变量。
最后需要注意的是，指向函数的指针变量没有 ++ 和 – 运算。
一般为了方便使用，我们会选择：
typedef 函数返回值类型 (* 指针变量名) (函数参数列表);  比如：
typedef int (*Fun1)(int); //声明也可写成int (*Fun1)(int x)，但习惯上一般不这样。 typedef int (*Fun2)(int, int); //参数为两个整型，返回值为整型 typedef void (*Fun3)(void); //无参数和返回值 typedef void* (*Fun4)(void*); //参数和返回值都为void*指针 如何用函数指针调用函数 给大家举一个例子：
int Func(int x); /*声明一个函数*/ int (*p) (int x); /*定义一个函数指针*/ p = Func; /*将Func函数的首地址赋给指针变量p*/ p = &amp;Func; /*将Func函数的首地址赋给指针变量p*/ 赋值时函数 Func 不带括号，也不带参数。由于函数名 Func 代表函数的首地址，因此经过赋值以后，指针变量 p 就指向函数 Func() 代码的首地址了。
下面来写一个程序，看了这个程序你们就明白函数指针怎么使用了：
#include &lt;stdio.h&gt;int Max(int, int); //函数声明 int main(void) { int(*p)(int, int); //定义一个函数指针  int a, b, c; p = Max; //把函数Max赋给指针变量p, 使p指向Max函数  printf(&#34;please enter a and b:&#34;); scanf(&#34;%d%d&#34;, &amp;a, &amp;b); c = (*p)(a, b); //通过函数指针调用Max函数  printf(&#34;a = %d\nb = %d\nmax = %d\n&#34;, a, b, c); return 0; } int Max(int x, int y) //定义Max函数 { int z; if (x &gt; y) { z = x; } else { z = y; } return z; } 特别注意的是，因为函数名本身就可以表示该函数地址（指针），因此在获取函数指针时，可以直接用函数名，也可以取函数的地址。
p = Max可以改成 p = &amp;Max c = (*p)(a, b) 可以改成 c = p(a, b)  函数指针作为某个函数的参数 既然函数指针变量是一个变量，当然也可以作为某个函数的参数来使用的。示例：
#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt; typedef void(*FunType)(int); //前加一个typedef关键字，这样就定义一个名为FunType函数指针类型，而不是一个FunType变量。 //形式同 typedef int* PINT; void myFun(int x); void hisFun(int x); void herFun(int x); void callFun(FunType fp,int x); int main() { callFun(myFun,100);//传入函数指针常量，作为回调函数  callFun(hisFun,200); callFun(herFun,300); return 0; } void callFun(FunType fp,int x) { fp(x);//通过fp的指针执行传递进来的函数，注意fp所指的函数有一个参数 } void myFun(int x) { printf(&#34;myFun: %d\n&#34;,x); } void hisFun(int x) { printf(&#34;hisFun: %d\n&#34;,x); } void herFun(int x) { printf(&#34;herFun: %d\n&#34;,x); } 输出：
myFun: 100 hisFun: 200 herFun: 300 函数指针作为函数返回类型 有了上面的基础，要写出返回类型为函数指针的函数应该不难了，下面这个例子就是返回类型为函数指针的函数：
void (* func5(int, int, float ))(int, int) { ... } 在这里， func5 以 (int, int, float) 为参数，其返回类型为 void (\*)(int, int) 。在C语言中，变量或者函数的声明也是一个大学问，想要了解更多关于声明的话题，可以参考我之前的文章 - C专家编程》读书笔记(1-3章)。这本书的第三章花了整整一章的内容来讲解如何读懂C语言的声明。
函数指针数组 在开始讲解回调函数前，最后介绍一下函数指针数组。既然函数指针也是指针，那我们就可以用数组来存放函数指针。下面我们看一个函数指针数组的例子：
/* 方法1 */ void (*func_array_1[5])(int, int, float); /* 方法2 */ typedef void (*p_func_array)(int, int, float); p_func_array func_array_2[5]; 上面两种方法都可以用来定义函数指针数组，它们定义了一个元素个数为5，类型是 * void (\*)(int, int, float) * 的函数指针数组。
函数指针总结 函数指针常量 ：Max；函数指针变量：p；
数名调用如果都得如(*myFun)(10)这样，那书写与读起来都是不方便和不习惯的。所以C语言的设计者们才会设计成又可允许myFun(10)这种形式地调用（这样方便多了，并与数学中的函数形式一样）。
在函数指针变量也可以存入一个数组内。数组的声明方法：int (*fArray[10]) ( int );
 回调函数 什么是回调函数 我们先来看看百度百科是如何定义回调函数的：
回调函数就是一个通过函数指针调用的函数。如果你把函数的指针（地址）作为参数传递给另一个函数，当这个指针被用来调用其所指向的函数时，我们就说这是回调函数。回调函数不是由该函数的实现方直接调用，而是在特定的事件或条件发生时由另外的一方调用的，用于对该事件或条件进行响应。  这段话比较长，也比较绕口。下面我通过一幅图来说明什么是回调：
假设我们要使用一个排序函数来对数组进行排序，那么在主程序(Main program)中，我们先通过库，选择一个库排序函数(Library function)。但排序算法有很多，有冒泡排序，选择排序，快速排序，归并排序。同时，我们也可能需要对特殊的对象进行排序，比如特定的结构体等。库函数会根据我们的需要选择一种排序算法，然后调用实现该算法的函数来完成排序工作。这个被调用的排序函数就是回调函数(Callback function)。
结合这幅图和上面对回调函数的解释，我们可以发现，要实现回调函数，最关键的一点就是要将函数的指针传递给一个函数(上图中是库函数)，然后这个函数就可以通过这个指针来调用回调函数了。注意，回调函数并不是C语言特有的，几乎任何语言都有回调函数。在C语言中，我们通过使用函数指针来实现回调函数。
我的理解是：把一段可执行的代码像参数传递那样传给其他代码，而这段代码会在某个时刻被调用执行，这就叫做回调。
如果代码立即被执行就称为同步回调，如果过后再执行，则称之为异步回调。
回调函数就是一个通过函数指针调用的函数。如果你把函数的指针（地址）作为参数传递给另一个函数，当这个指针被用来调用其所指向的函数时，我们就说这是回调函数。
回调函数不是由该函数的实现方直接调用，而是在特定的事件或条件发生时由另外的一方调用的，用于对该事件或条件进行响应。
为什么要用回调函数？ 因为可以把调用者与被调用者分开，所以调用者不关心谁是被调用者。它只需知道存在一个具有特定原型和限制条件的被调用函数。
简而言之，回调函数就是允许用户把需要调用的方法的指针作为参数传递给一个函数，以便该函数在处理相似事件的时候可以灵活的使用不同的方法。
int Callback() // /&lt; 回调函数 { // TODO  return 0; } int main() // /&lt; 主函数 { // TODO  Library(Callback); // /&lt; 库函数通过函数指针进行回调  // TODO  return 0; } 回调似乎只是函数间的调用，和普通函数调用没啥区别。
但仔细看，可以发现两者之间的一个关键的不同：在回调中，主程序把回调函数像参数一样传入库函数。
这样一来，只要我们改变传进库函数的参数，就可以实现不同的功能，这样有没有觉得很灵活？并且当库函数很复杂或者不可见的时候利用回调函数就显得十分优秀。
怎么使用回调函数？ int Callback_1(int a) // /&lt; 回调函数1 { printf(&#34;Hello, this is Callback_1: a = %d &#34;, a); return 0; } int Callback_2(int b) // /&lt; 回调函数2 { printf(&#34;Hello, this is Callback_2: b = %d &#34;, b); return 0; } int Callback_3(int c) // /&lt; 回调函数3 { printf(&#34;Hello, this is Callback_3: c = %d &#34;, c); return 0; } int Handle(int x, int (*Callback)(int)) // /&lt; 注意这里用到的函数指针定义 { Callback(x); } int main() { Handle(4, Callback_1); Handle(5, Callback_2); Handle(6, Callback_3); return 0; } 如上述代码：可以看到，Handle() 函数里面的参数是一个指针，在 main() 函数里调用 Handle() 函数的时候，给它传入了函数 Callback_1()/Callback_2()/Callback_3() 的函数名，这时候的函数名就是对应函数的指针，也就是说，回调函数其实就是函数指针的一种用法。
下面是一个四则运算的简单回调函数例子： #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt; /**************************************** * 函数指针结构体 ***************************************/ typedef struct _OP { float (*p_add)(float, float); float (*p_sub)(float, float); float (*p_mul)(float, float); float (*p_div)(float, float); } OP; /**************************************** * 加减乘除函数 ***************************************/ float ADD(float a, float b) { return a + b; } float SUB(float a, float b) { return a - b; } float MUL(float a, float b) { return a * b; } float DIV(float a, float b) { return a / b; } /**************************************** * 初始化函数指针 ***************************************/ void init_op(OP *op) { op-&gt;p_add = ADD; op-&gt;p_sub = SUB; op-&gt;p_mul = &amp;MUL; op-&gt;p_div = &amp;DIV; } /**************************************** * 库函数 ***************************************/ float add_sub_mul_div(float a, float b, float (*op_func)(float, float)) { return (*op_func)(a, b); } int main(int argc, char *argv[]) { OP *op = (OP *)malloc(sizeof(OP)); init_op(op); /* 直接使用函数指针调用函数 */ printf(&#34;ADD = %f, SUB = %f, MUL = %f, DIV = %f\n&#34;, (op-&gt;p_add)(1.3, 2.2), (*op-&gt;p_sub)(1.3, 2.2), (op-&gt;p_mul)(1.3, 2.2), (*op-&gt;p_div)(1.3, 2.2)); /* 调用回调函数 */ printf(&#34;ADD = %f, SUB = %f, MUL = %f, DIV = %f\n&#34;, add_sub_mul_div(1.3, 2.2, ADD), add_sub_mul_div(1.3, 2.2, SUB), add_sub_mul_div(1.3, 2.2, MUL), add_sub_mul_div(1.3, 2.2, DIV)); return 0; } 回调函数实例（很有用） 一个 GPRS 模块联网的小项目，使用过的同学大概知道 2G、4G、NB 等模块要想实现无线联网功能都需要经历模块上电初始化、注册网络、查询网络信息质量、连接服务器等步骤，这里的的例子就是，利用一个状态机函数（根据不同状态依次调用不同实现方法的函数），通过回调函数的方式依次调用不同的函数，实现模块联网功能，如下：
/********* 工作状态处理 *********/ typedef struct { uint8_t mStatus; uint8_t (* Funtion)(void); //函数指针的形式 } M26_WorkStatus_TypeDef; //M26的工作状态集合调用函数  /********************************************** ** &gt;M26工作状态集合函数 ***********************************************/ M26_WorkStatus_TypeDef M26_WorkStatus_Tab[] = { {GPRS_NETWORK_CLOSE, M26_PWRKEY_Off }, //模块关机  {GPRS_NETWORK_OPEN, M26_PWRKEY_On }, //模块开机  {GPRS_NETWORK_Start, M26_Work_Init }, //管脚初始化  {GPRS_NETWORK_CONF, M26_NET_Config }, //AT指令配置  {GPRS_NETWORK_LINK_CTC, M26_LINK_CTC }, //连接调度中心  {GPRS_NETWORK_WAIT_CTC, M26_WAIT_CTC }, //等待调度中心回复  {GPRS_NETWORK_LINK_FEM, M26_LINK_FEM }, //连接前置机  {GPRS_NETWORK_WAIT_FEM, M26_WAIT_FEM }, //等待前置机回复  {GPRS_NETWORK_COMM, M26_COMM }, //正常工作  {GPRS_NETWORK_WAIT_Sig, M26_WAIT_Sig }, //等待信号回复  {GPRS_NETWORK_GetSignal, M26_GetSignal }, //获取信号值  {GPRS_NETWORK_RESTART, M26_RESET }, //模块重启 } /********************************************** ** &gt;M26模块工作状态机，依次调用里面的12个函数 ***********************************************/ uint8_t M26_WorkStatus_Call(uint8_t Start) { uint8_t i = 0; for(i = 0; i &lt; 12; i++) { if(Start == M26_WorkStatus_Tab[i].mStatus) { return M26_WorkStatus_Tab[i].Funtion(); } } return 0; } 所以，如果有人想做个 NB 模块联网项目，可以 copy 上面的框架，只需要修改回调函数内部的具体实现，或者增加、减少回调函数，就可以很简洁快速的实现模块联网。
]]></content>
  </entry>
  
  <entry>
    <title>DDR、DDR2、DDR3、DDR4、LPDDR区别</title>
    <url>/post/hardware/difference-between-different-generation-DDRs.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>DDR</tag>
    </tags>
    <content type="html"><![CDATA[今天我们和大家介绍一下各代DDR的区别
什么是DDR DDR是Double Data Rate的缩写，即“双比特翻转”。DDR是一种技术，中国大陆工程师习惯用DDR称呼用了DDR技术的SDRAM，而在中国台湾以及欧美，工程师习惯用DRAM来称呼。
DDR的核心要义是在一个时钟周期内，上升沿和下降沿都做一次数据采样，这样400MHz的主频可以实现800Mbps的数据传输速率。
每一代DDR的基本区别 关键技术解释 VTT VTT为DDR的地址线，控制线等信号提供上拉电源，上拉电阻是50Ω左右。VTT=1/2VDDQ，并且VTT要跟随VDDQ，因此需要专用的电源同时提供VDDQ和VTT。例如芯片TPS51206DSQT，LP2996。用专门的电源芯片，还有一个重要的原因，在Fly-by的拓扑中，VTT提供电流，增强DDR信号线的驱动能力。
DDR的接收器是一个比较器，其中一端是VREF，另一端是信号，例如地址线A2在有VTT上拉的时候，A2的信号在0和1.8V间跳动，当A2电压高于VTT时，电流流向VTT。当A2低于VTT时，VTT流向DDR。因此VTT需要有提供电流和吸收电流的能力，一般的开关电源不能作为VTT的提供者。此外，VTT电源相当于DDR接收器信号输入端的直流偏执，且这个偏执等于VREF，因此VTT的噪声要越小越好，否则当A2的状态为高阻态时，DDR接收器的比较器容易产生误触发。
上文说过，VTT相当于DDR接收器的直流偏执，其实如果没有VTT，这个直流偏执也存在，它在芯片的内部，提供电流的能力很弱。如果只有1个或2个DDR芯片，走Fly-by拓扑，那么不需要外部的VTT上拉。如果有2个以上的DDR芯片，则一定需要VTT上拉。
Prefetch Prefetch字面意思就是预存取，每一代的DDR预存取大小不同，详见第2章中表格。以DDR3为例，它的Prefetch=8n，相当于DDR的每一个IO都有一个宽度为8的buffer，从IO进来8个数据后，在第8个数据进来后，才把这8个数据一次性的写入DDR内部的存储单元。下图是一个形象的解释，同时我们关注一下几个速率。DDR3的时钟是800MHz，Data Rate是1600Mbps，由于这个Buffer的存在，DDR内部的时钟只需要200MHz就可以了（注意DDR内部不是双比特翻转采样）。
我们来做一个频率对照表，如下：
DDR内部的最小存储单元（1bit）是一个晶体管+一个电容，电容会放电，需要不断的“刷新”（充电）才能保持正常的工作状态，由于电容充放电需要时间，DDR内部的频率受限于此，很难提高，目前技术一般在100~200MHz。因此需要用Prefetch技术来提内部数据高吞吐率（其实就是串并转换原理）。Prefetch位宽的提高，是DDR2,3,4非常显著的变化。
第一段提到，对于DDR3，在第8个数据进来后，FIFO满了，然后才把这8个数据一次性的写入DDR内部的存储单元，那么必须要求DDR的内部时钟和外部时钟有一定的约束关系，FIFO满的时候一定是以DQS下降沿采样结束的，数据手册中对DQS的下降沿与clk有一个建立时间和保持时间的约束要求的目的原来是这样。
SSTL SSTL（Stub Series Terminated Logic）接口标准也是JEDEC所认可的标准之一。该标准专门针对高速内存(特别是SDRAM)接口。SSTL规定了开关特点和特殊的端接方案。
SSTL标准规定了IC供电，IO的DC和AC输入输出门限，差分信号门限，Vref电压等。SSTL_3是3.3V标准，SSTL_2是2.5V标准，SSTL_18是1.8V标准，SSTL_15是1.5V。
SSTL最大的特点是需要终端匹配电阻，也叫终端终结电阻，上拉到VTT（1/2VDDQ）。这个短接电阻最大的作用是为了信号完整性，特别是在1拖多的Fly-by走线拓扑下，还能增强驱动能力。
Bank 以下图为例，一个Bank中包含若干个Array，Array相当于一个表单，选中“行地址”和“列地址”后，表单中的一个单元格就被选中，这个单元格就是一个bit。Bank中的所有Array的行地址是连在一起的，列地址也是。那么选中“行地址”和“列地址”后，将一起选中所有Array的bit。有多少个array，就有多少个bit被选中。以DDR3为例，Data线宽度是32，prefetch是8，那么Array就有32x8=256.内部一次操作会选中256bit的数据。
Bank数量越多，需要的Bank选择线越多，DDR3有8个bank，需要3个BA信号BA0~2。BA，行地址，列地址共同组成了存储单元的访问地址，缺一不可。
DDR的容量计算 下图是DDR3 1Gb的寻址配置，以其中128Mbx8为例说明，其中x8表示IO数据（DQ）位宽度。
 DDD容量=2Bank Addressx2Row Addressx2Col Addressx位宽=23x214x210x8=1Gb Page Site=2Col Addressx位宽➗8（Byte)  我的理解是，这个page size更像是逻辑上的一个页，并不是一个bank中，一行的所有bit，因为一行的所有bit要考虑prefetch宽度。
上表是JESD-3D中的表格，Row Address和Column Address都是真实需要寻址的地址，其他用途的地址比如A10，A12或者A11等并没有计算在内。在计算时，不要因为有A13，就认为Column Address就是A0~A13。
Burst Burst字面意思是突发，DDR的访问都是以突发的方式连续访问同一行的相邻几个单元。进行Brust时，需要有几个参数：
 Burst Length：一次突发访问几个列地址。 Read/Write: 是读还是写 Starting Column：从哪一列开始Burst Burst：突发的顺序。  下图是DDR3中突发类型和顺序，Burst是通过A12/BC#选择的。但对于DDR，DDR2和DDR4，不一定就是通过A12/BC#，详见PIN定义章节。
DDR的tRDC，CL，tAC 在实际工作中，Bank地址与相应的行地址是同时发出的，此时这个命令称之为“行激活”（Row Active）。在此之后，将发送列地址寻址命令与具体的操作命令（是读还是写），这两个命令也是同时发出的，所以一般都会以“读/写命令”来表示列寻址。根据相关的标准，从行有效到读/写命令发出之间的间隔被定义为tRCD，即RAS to CAS Delay（RAS至CAS延迟，RAS就是行地址选通脉冲，CAS就是列地址选通脉冲），我们可以理解为行选通周期。tRCD是DDR的一个重要时序参数，广义的tRCD以时钟周期（tCK，Clock Time）数为单位，比如tRCD=3，就代表延迟周期为两个时钟周期，具体到确切的时间，则要根据时钟频率而定，DDR3-800，tRCD=3，代表30ns的延迟。
接下来，相关的列地址被选中之后，将会触发数据传输，但从存储单元中输出到真正出现在内存芯片的 I/O 接口之间还需要一定的时间（数据触发本身就有延迟，而且还需要进行信号放大），这段时间就是非常著名的 CL（CAS Latency，列地址脉冲选通潜伏期）。CL 的数值与 tRCD 一样，以时钟周期数表示。如 DDR3-800，时钟频率为 100MHz，时钟周期为 10ns，如果 CL=2 就意味着 20ns 的潜伏期。不过CL只是针对读取操作。
由于芯片体积的原因，存储单元中的电容容量很小，所以信号要经过放大来保证其有效的识别性，这个放大/驱动工作由S-AMP负责，一个存储体对应一个S- AMP通道。但它要有一个准备时间才能保证信号的发送强度（事前还要进行电压比较以进行逻辑电平的判断），因此从数据I/O总线上有数据输出之前的一个时钟上升沿开始，数据即已传向S-AMP，也就是说此时数据已经被触发，经过一定的驱动时间最终传向数据I/O总线进行输出，这段时间我们称之为 tAC（Access Time from CLK，时钟触发后的访问时间）。
目前内存的读写基本都是连续的，因为与CPU交换的数据量以一个Cache Line（即CPU内Cache的存储单位）的容量为准，一般为64字节。而现有的Rank位宽为8字节（64bit），那么就要一次连续传输8次，这就涉及到我们也经常能遇到的突发传输的概念。突发（Burst）是指在同一行中相邻的存储单元连续进行数据传输的方式，连续传输的周期数就是突发长度（Burst Lengths，简称BL）。
在进行突发传输时，只要指定起始列地址与突发长度，内存就会依次地自动对后面相应数量的存储单元进行读/写操作而不再需要控制器连续地提供列地址。这样，除了第一笔数据的传输需要若干个周期（主要是之前的延迟，一般的是tRCD+CL）外，其后每个数据只需一个周期的即可获得。
突发连续读取模式：只要指定起始列地址与突发长度，后续的寻址与数据的读取自动进行，而只要控制好两段突发读取命令的间隔周期（与BL相同）即可做到连续的突发传输。
谈到了突发长度时。如果BL=4，那么也就是说一次就传送4×64bit的数据。但是，如果其中的第二笔数据是不需要的，怎么办？还都传输吗？为了屏蔽不需要的数据，人们采用了数据掩码（Data I/O Mask，简称DQM）技术。通过DQM，内存可以控制I/O端口取消哪些输出或输入的数据。这里需要强调的是，在读取时，被屏蔽的数据仍然会从存储体传出，只是在“掩码逻辑单元”处被屏蔽。DQM由北桥控制，为了精确屏蔽一个P-Bank位宽中的每个字节，每个DIMM有8个DQM 信号线，每个信号针对一个字节。这样，对于4bit位宽芯片，两个芯片共用一个DQM信号线，对于8bit位宽芯片，一个芯片占用一个DQM信号，而对于 16bit位宽芯片，则需要两个DQM引脚。
在数据读取完之后，为了腾出读出放大器以供同一Bank内其他行的寻址并传输数据，内存芯片将进行预充电的操作来关闭当前工作行。还是以上面那个Bank示意图为例。当前寻址的存储单元是B1、R2、C6。如果接下来的寻址命令是B1、R2、C4，则不用预充电，因为读出放大器正在为这一行服务。但如果地址命令是B1、R4、C4，由于是同一Bank的不同行，那么就必须要先把R2关闭，才能对R4寻址。从开始关闭现有的工作行，到可以打开新的工作行之间的间隔就是tRP（Row Precharge command Period，行预充电有效周期），单位也是时钟周期数。
ODT ODT是内建核心的终结电阻，它的功能是让一些信号在终结电阻处消耗完，防止这些信号在电路上形成反射。换句话说就是在片内设置合适的上下拉电阻，以获得更好的信号完整性。被ODT校准的信号包括：
 DQ, DQS, DQS# and DM for x4 configuration DQ, DQS, DQS#, DM, TDQS and TDQS# for X8 configuration DQU, DQL, DQSU, DQSU#, DQSL, DQSL#, DMU and DML for X16 configuration  当一个CPU挂了很多个DDR芯片的时候，他们是共用控制线，地址线的，走线肯定要分叉，如果没有中端匹配电阻，肯定会产生信号完整性问题。那么如果只有一个DDR芯片的时候，需不需要呢？正常情况下，走线很短，有符合规则，是不需要的。
下图是DDR中的IO上下拉电阻，RON是DDR的输出结构的上下拉电阻，RTT是DDR输入结构的上下拉电阻。这两个电阻的阻值都是可调的。
下图是RON的调节，注意这不是ODT的任务，调节是通过寄存器实现。
下图是RTT的调节，是ODT要做的事情，而且RTT的档位要多，也是通过寄存器调节的。
注意，DDR3的PIN定义上有一个引脚是ODT，如果ODT=0，DRAM Termination State功能关闭；ODT=1，DRAM Termination State的功能参考寄存器设置。如下是一个真值表。因为DRAM Termination State非常耗电，所以不用的时候最好不要打开。
DDR3的ZQ ZQ信号在DDR3时代开始引入，要求在ZQ引脚放置一个240Ω±1%的高精度电阻到地，注意必须是高精度。而且这个电阻是必须的，不能省略的。进行ODT时，是以这个引脚上的阻值为参考来进行校准的。
校准需要调整内部电阻，以获得更好的信号完整性，但是内部电阻随着温度会有些细微的变化，为了将这个变化纠正回来，就需要一个外部的精确电阻作为参考。详细来讲，就是为RTT和RON提供参考电阻。
OCD OCD 是在 DDR-II 开始加入的新功能，而且这个功能是可选的，有的资料上面又叫离线驱动调整。OCD的主要作用在于调整 I/O 接口端的电压，来补偿上拉与下拉电阻值， 从而调整DQS 与 DQ 之间的同步确保信号的完整与可靠性。调校期间，分别测试 DQS 高电平和 DQ高电平，以及 DQS 低电平和 DQ 高电平的同步情况。如果不满足要求，则通过设定突发长度的地址线来传送上拉 / 下拉电阻等级（加一档或减一档），直到测试合格才退出 OCD 操作，通过 OCD 操作来减少 DQ 、 DQS的倾斜从而提高信号的完整性及控制电压来提高信号品质。由于在一般情况下对应用环境稳定程度要求并不太高，只要存在差分 DQS时就基本可以保证同步的准确性， 而且 OCD 的调整对其他操作也有一定影响， 因此 OCD 功能在普通台式机上并没有什么作用，其优点主要体现在对数据完整性非常敏感的服务器等高端产品领域。
DDR3的PIN定义 下面是三星K4B4G0446Q/K4B4G0846Q的PIN定义，每一个都有很详细的解释。
以x8的配置为例，如下是其Ball Map。
  一对时钟线CK和CKn
  数据线DQ0~DQ7共8位。
  一对差分对DQS和DQSn
  地址线A0~A15，其中，A10和A12有特殊用途。
  行选中信号RASn
  列选中信号CASn
  写使能Wen
  片选CSn
  Bank选择BA0~2
  一个Reset信号，是DDR3新增的一项重要功能，并为此专门准备了一个引脚。这一引脚将使DDR3的初始化处理变得简单。当Reset命令有效时，DDR3 内存将停止所有的操作，并切换至最少量活动的状态，以节约电力。在Reset期间，DDR3内存将关闭内在的大部分功能，所有数据接收与发送器都将关闭，且所有内部的程序装置将复位，DLL（延迟锁相环路）与时钟电路将停止工作，甚至不理睬数据总线上的任何动静。这样一来，该功能将使DDR3达到最节省电力的目的。
  ZQ和ODT PIN上文已经说明。
  DDR的走线规则 DDR的信号线需要分组：
数据线一组（DQ,DQS,DQM），误差控制在20mil以内；
控制线一组（Address，控制线，时钟），以时钟为中心，误差控制在100mil以内。
]]></content>
  </entry>
  
  <entry>
    <title>什么是DSP</title>
    <url>/post/dsp/what-is-dsp.html</url>
    <categories><category>DSP</category>
    </categories>
    <tags>
      <tag>DSP</tag>
    </tags>
    <content type="html"><![CDATA[嵌入式工程师都知道什么是CPU、MCU，还有一位成员——DSP，DSP到底是什么？
DSP概述 DSP（digital signal processor）是一种独特的微处理器，有自己的完整指令系统，是以数字信号来处理大量信息的器件。其最大特点是内部有专用的硬件乘法器和哈佛总线结构对大量的数字信号处理的速度快。一个数字信号处理器在一块不大的芯片内包括有控制单元、运算单元、各种寄存器以及一定数量的存储单元等等，在其外围还可以连接若干存储器，并可以与一定数量的外部设备互相通信，有软、硬件的全面功能，本身就是一个微型计算机。
DSP采用的是哈佛设计，即数据总线和地址总线分开，使程序和数据分别存储在两个分开的空间，允许取指令和执行指令完全重叠。也就是说在执行上一条指令的同时就可取出下一条指令，并进行译码，这大大的提高了微处理器的速度。另外还允许在程序空间和数据空间之间进行传输，因为增加了器件的灵活性。
当今的数字化时代背景下，DSP己成为通信、计算机、消费类电子产品等领域的基础器件。
根据数字信号处理的要求，DSP芯片一般具有如下的一些主要特点：
 在一个指令周期内可完成一次乘法和一次加法。 程序和数据空间分开，可以同时访问指令和数据。 片内具有快速RAM，通常可通过独立的数据总线在两块中同时访问。 具有低开销或无开销循环及跳转的硬件支持。 快速的中断处理和硬件I/O支持。 具有在单周期内操作的多个硬件地址产生器。 可以并行执行多个操作。 支持流水线操作，使取指、译码和执行等操作可以重叠执行。  与通用微处理器相比，DSP芯片的其他通用功能相对较弱些。
DSP 芯片的诞生过程 DSP 芯片的诞生是时代所需。20世纪60年代以来，随着计算机和信息技术的飞速发展，数字信号处理技术应运而生并得到迅速的发展。在 DSP 芯片出现之前数字信号处理只能依靠微处理器来完成。但由于微处理器较低的处理速度不快，根本就无法满足越来越大的信息量的高速实时要求。
上世纪 70 年代，DSP芯片的理论和算法基础已成熟。但那时的DSP仅仅停留在教科书上，即使是研制出来的 DSP 系统也是由分立元件组成的，其应用领域仅局限于军事、航空航天部门。
 1978 年， AMI 公司发布世界上第一个单片 DSP 芯片 S2811，但没有现代 DSP芯片所必须有的硬件乘法器； 1979 年， 美国 Intel 公司发布的商用可编程器件 2920 是 DSP 芯片的一个主要里程碑，但其依然没有硬件乘法器； 1980 年，日本 NEC 公司推出的 MPD7720 是第一个具有硬件乘法器的商用 DSP芯片，从而被认为是第一块单片 DSP 器件； 1982 年世界上诞生了第一代 DSP 芯片 TMS32010 及其系列产品。这种 DSP 器件采用微米工艺 NMOS 技术制作，虽功耗和尺寸稍大，但运算速度却比微处理器快了几十倍。  DSP 芯片的问世是个里程碑，它标志着 DSP 应用系统由大型系统向小型化迈进了一大步。至 80 年代中期，随着 CMOS 工艺的 DSP 芯片应运而生，其存储容量和运算速度都得到成倍提高，成为语音处理、图像硬件处理技术的基础。
80 年代后期，第三代 DSP 芯片问世，运算速度进一步提高，其应用范围逐步扩大到通信、计算机领域；
90 年代 DSP 发展最快，相继出现了第四代和第五代 DSP 芯片。第五代与第四代相比系统集成度更高，将 DSP 芯核及外围元件综合集成在单一芯片上。
进入 21 世纪后，第六代 DSP 芯片横空出世。第六代芯片在性能上全面碾压第五代芯片，同时基于商业目的的不同发展出了诸多个性化的分支，并开始逐渐拓展新的领域。
DSP 芯片的应用领域 如今，各种各样的DSP器件已相当丰富。大大小小封装形式的DSP器件，已广泛应用于各种产品的生产领域，而且DSP的应用领域仍在不断地扩大，发展迅速异常。
DSP芯片强调数字信号处理的实时性。DSP作为数字信号处理器将模拟信号转换成数字信号，用于专用处理器的高速实时处理。它具有高速，灵活，可编程，低功耗的界面功能，在图形图像处理，语音处理，信号处理等通信领域起到越来越重要的作用。
根据美国的权威资讯公司统计，目前 DSP 芯片在市场上应用最多的是通信领域，其次是计算机领域。
DSP芯片的应用领域 1）DSP芯片在多媒体通信领域的应用。 媒体数据传输产生的信息量是巨大的，多媒体网络终端在整个过程中需要对获取的信息量进行快速分析和处理，因此 DSP 被运用在语音编码，图像压缩和减少语音通信上。如今 DSP 对于语音解码计算产生实时效果，设计协议要求已经成为最基本的一条国际标准。
2）DSP芯片在工业控制领域的应用。 在工业控制领域， 工业机器人被广泛应用，对机器人控制系统的性能要求也越来越高。机器人控制系统重中之重就是实时性，在完成一个动作的同时会产生较多的数据和计算处理，这里可以采用高性能的 DSP。DSP通过应用到机器人的控制系统后，充分利用自身的实时计算速度特性，使得机器人系统可以快速处理问题，随着不断提高 DSP 数字信号芯片速度，在系统中容易构成并行处理网络，大大提高控制系统的性能，使得机器人系统得到更为广泛的发展。
3）DSP芯片在仪器仪表领域的应用。 DSP 丰富的片内资源可以大大简化仪器仪表的硬件电路，实现仪器仪表的 SOC 设计。器仪表的测量精度和速度是一项重要的指标，使用 DSP 芯片开发产品可使这两项指标大大提高。例如 TI 公司的 TMS320F2810 具有高效的 32 位 CPU 内核，12 位 A/D 转换器，丰富的片上存储器和灵活的指挥系统，为高精密仪器搭建了广阔的平台。高精密仪器现在已经发展成为 DSP 的一个重要应用，正处于快速传播时期，将推动产业的技术创新。
4）DSP芯片在汽车安全与无人驾驶领域的应用。 汽车电子系统日益兴旺发达起来，诸如装设红外线和毫米波雷达，将需用 DSP 进行分析。如今，汽车愈来愈多，防冲撞系统已成为研究热点。而且，利用摄像机拍摄的图像数据需要经过 DSP 处理，才能在驾驶系统里显示出来，供驾驶人员参考。
5）DSP芯片在军事领域的应用。 DSP 的功耗低、体积小、实时性反应速度都是武器装备中特别需要的。如机载空空导弹，在有限的体积内装有红外探测仪和相应的 DSP信号处理器等部分，完成目标的自动锁定与跟踪。先进战斗机上装备的目视瞄准器和步兵个人携带的头盔式微光仪，需用 DSP 技术完成图像的滤波与增强，智能化目标搜索捕获。DSP 技术还用于自动火炮控制、巡航导弹、预警飞机、相控阵天线等雷达数字信号处理中。
未来DSP技术将向以下几个方向继续发展： 1）DSP芯核集成度越来越高。 缩小 DSP 芯片尺寸一直是 DSP 技术的发展趋势，当前使用较多的是基于 RISC 结构，随着新工艺技术的引入，越来越多的制造商开始改进DSP 芯核，并且把多个 DSP 芯核、 MPU 芯核以及外围的电路单元集成在一个芯片上，实现了 DSP 系统级的集成电路。
2）可编程DSP芯片将是未来主导产品。 随着个性化发展的需要， DSP 的可编程化为生产厂商提供了更多灵活性，满足厂家在同一个 DSP 芯片上开发出更多不同型号特征的系列产品，也使得广大用户对于 DSP 的升级换代。例如冰箱、洗衣机，这些原来装有微控制器的家电如今已换成可编程 DSP 来进行大功率电机控制。
3）定点DSP占据主流。 目前，市场上所销售的 DSP 器件中，占据主流产品的依然是16 位的定点可编程 DSP 器件，随着 DSP 定点运算器件成本的不断低，能耗越来越小的优势日渐明显，未来定点 DSP 芯片仍将是市场的主角。
DSP芯片的分类 DSP的芯片可以按照以下的三种方式进行分类。
（1）按基础特性分 这是根据DSP芯片的工作时钟和指令类型来分类的。如果DSP芯片在某时钟频率范围内的任何频率上能正常工作，除计算速度有变化外，没有性能的下降，这类DSP芯片一般称之为静态DSP芯片。
如果有两种或两种以上的DSP芯片,它们的指令集和相应的机器代码机管脚结构相互兼容,则这类DSP芯片称之为一致性的DSP芯片。
（2）按数据格式分 这是根据DSP芯片工作的数据格式来分类的。数据以定点格式工作的DSP芯片称之为定点DSP芯片。以浮点格式工作的称为DSP芯片。不同的浮点DSP芯片所采用的浮点格式不完全一样，有的DSP芯片采用自定义的浮点格式，有的DSP芯片则采用IEEE的标准浮点格式。
（3）按用途分 按照DSP芯片的用途来分，可分为通用型DSP芯片和专用型的DSP芯片。通用型DSP芯片适合普通的DSP应用，如TI公司的一系列DSP芯片。专用型DSP芯片为特定的DSP运算而设计，更适合特殊的运算，如数字滤波，卷积和FFT等。
DSP芯片的基本结构 DSP芯片的基本结构包括： （1）哈佛结构。哈佛结构的主要特点是将程序和数据存储在不同的存储空间中，即程序存储器和数据存储器是两个相互独立的存储器，每个存储器独立编址，独立访问。与两个存储器相对应的是系统中设置了程序总线和数据总线，从而使数据的吞吐率提高了一倍。由于程序和存储器在两个分开的空间中，因此取指和执行能完全重叠。
（2）流水线操作。流水线与哈佛结构相关，DSP芯片广泛采用流水线以减少指令执行的时间，从而增强了处理器的处理能力。处理器可以并行处理二到四条指令，每条指令处于流水线的不同阶段。
（3）专用的硬件乘法器。乘法速度越快，DSP处理器的性能越高。由于具有专用的应用乘法器，乘法可在一个指令周期内完成。
（4）特殊的DSP指令。特殊的DSP指令DSP芯片是采用特殊的指令。
（5）快速的指令周期。快速的指令周期哈佛结构、流水线操作、专用的硬件乘法器、特殊的DSP指令再加上集成电路的优化设计可使DSP芯片的指令周期在200ns以下。
DSP系统的特点、构成和设计过程 数字信号处理系统是以数字信号处理为基础，因此具有数字处理的全部特点：
 接口方便。DSP系统与其它以现代数字技术为基础的系统或设备都是相互兼容，这样的系统接口以实现某种功能要比模拟系统与这些系统接口要容易的多。 编程方便。DSP系统中的可编程DSP芯片可使设计人员在开发过程中灵活方便地对软件进行修改和升级。 稳定性好。DSP系统以数字处理为基础，受环境温度以及噪声的影响较小，可靠性高。 精度高。16位数字系统可以达到的精度。 可重复性好。模拟系统的性能受元器件参数性能变化比较大，而数字系统基本上不受影响，因此数字系统便于测试，调试和大规模生产。 集成方便。DSP系统中的数字部件有高度的规范性，便于大规模集成。   DSP系统的设计过程  根据需求确定DSP系统的性能指标 算法研究及模拟实现和功能验证 选择适合的DSP芯片和外围组件 软件设计及调试 硬件设计及调试 系统集成及测试  定点DSP和浮点DSP的区别 一般来说，定点DSP处理器具有速度快，功耗低，价格便宜的特点；而浮点DSP处理器则计算精确，动态范围大，速度快，易于编程，功耗大，价格高。
而它们的区别，还可以从各方面去比较。
 宏观上  从宏观上讲，浮点DSP比定点DSP的动态范围大得多。定点运算中，程序员必须时刻关注溢出的发生，为了防止溢出，要么不断进行移位定标，要么做截尾。前者耗费大量时间和空间，后者则带来精度的损失。相反，浮点运算DSP扩大了动态范围，提高了精度，节省了运算时间和存储空间，因而大大减少了定标，移位和溢出检查。
硬件上  单纯从技术的角度来看，定点与浮点的区别主要在两个方面，即硬件和软件。硬件上的区别来自于：浮点DSP处理器具有浮点/整数乘法器，整数/浮点算术逻辑运算单元ALU，适合存放扩展精度的浮点结果的寄存器等。
软件上  再看看在软件开发上的不同之处，主要有浮点DSP编程的特点以及注意事项；定点DSP进行浮点运算时的定标，移位，检测溢出操作。比较两个浮点数时，永远不要使用操作符==来判断是否相等。即使比较两个相同的数，还是可能有微小的舍入差别。甚至定义精确的0，也不是很安全，尽管C语言中有0的表示，永远不要写这样的代码(x==0)，而应该写成(fabs(x) &lt; TINY)，其中TINY定义为一个很小的值，也就是处理器的浮点格式舍入误差。
应用实例  另外一个比较重要区别涉及应用场合对定点与浮点dsp处理器的选择。设计师关心的是最后的系统性能、成本以及上市时间。
例如，在移动电视中，没必要进行浮点处理。而在军用雷达中，经常用到浮点处理器。
DSP芯片的选择依据  运算速度 运算精度 功耗 价格 硬件资源 开发工具 ]]></content>
  </entry>
  
  <entry>
    <title>如何为Ubuntu 22.04安装拼音输入法</title>
    <url>/post/linux/how-to-install-pinyin-for-ubuntu-22.04.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>Input Method</tag>
      <tag>Pinyin</tag>
    </tags>
    <content type="html"><![CDATA[本文的指令原本只是针对Vanilla Ubuntu，而且只是针对Ubuntu 22.04来讲述基于简体汉字的基本拼音输入法。
Ubuntu到目前为止都没有提供一个简单，很好的文档化的指南来描述如何添加拼音输入法。但是，为了在Ubuntu 22.04上获得基本的拼音输入法的支持，你可以简单地：
依次打开 Settings(设定) -&gt; Region &amp; Language(区域和语言) -&gt; Manage Installed Languages(管理安装的语言) -&gt; Install / Remove languages(安装/删除语言)。
选择Chinese(Simplified)，确保键盘输入法系统已经选择了Ibus，然后点Apply(应用)，重启系统。
重新登陆系统，再次打开Settings(设定)，依次选择到键盘。
点击输入源的&quot;+&ldquo;图标，选择中文(中国)，然后中文(智能拼音)。
现在你应该可以看到一个小的&quot;en&quot;图表(或者你的Ubuntu安装的任何语言代码)在你的主屏幕的右上角，你可以点击然后看到可用的输入法的列表，包含中文(智能拼音)。
选中中文(智能拼音)，然后打开任何可以接受输入的应用(比如gedit, openoffice, vim, etc.)，你也可以通过快捷键 Win+space来进行输入法的切换。
再次重新启动系统，确保输入法的图表还在那儿。
]]></content>
  </entry>
  
  <entry>
    <title>Linux下大文件切割与合并</title>
    <url>/post/linux/linux-big-file-cut-and-cat.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>file</tag>
    </tags>
    <content type="html"><![CDATA[往往是因为网络传输的限制，导致很多时候，我们需要在 Linux 系统下进行大文件的切割。这样将一个大文件切割成为多个小文件，进行传输，传输完毕之后进行合并即可。
文件切割split 在 Linux 系统下使用 split 命令进行大文件切割很方便  命令语法 split [-a] [-d] [-l &lt;行数&gt;] [-b &lt;字节&gt;] [-C &lt;字节&gt;] [要切割的文件] [输出文件名] 使用实例 $ split -l 300000 users.sql /data/users_ $ split -d -l 300000 users.sql /data/users_ $ split -d -b 100m users.sql /data/users_ 帮助信息 $ split --help 文件合并 - cat 在 Linux 系统下使用 cat 命令进行多个小文件的合并也很方便  命令语法 cat [-n] [-e] [-t] [输出文件名] 使用实例 $ cat /data/users_* &gt; users.sql 帮助信息 $ cat --h ]]></content>
  </entry>
  
  <entry>
    <title>从实用的角度聊聊MOS管</title>
    <url>/post/hardware/mosfet-tube-application-introduction.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>MOS Tube</tag>
    </tags>
    <content type="html"><![CDATA[说起MOS管，有些人的脑子里可能是一团浆糊。大部分的教材都会告诉你长长的一段话：MOS管全称金属氧化半导体场效应晶体管
英文名Metal-Oxide-Semiconductor Field-Effect Transistor，属于绝缘栅极场效晶体管，以硅片为秤体，利用扩散工艺制作&hellip;&hellip;.有N沟道和P沟道两个型。不仅如此，它还有两个兄弟，分别是结型场效应管以及晶体场效应管&hellip;
面对这么大一段话，我不知道你有没有搞明白，反正我大学里是完全没有搞明白，学了一个学期就学了个寂寞。
那么，为什么这些教材要这么的反人类，他们难道就不能好好写说人话吗？
我大概分析了一下，因为同一本教材他需要面对不同专业的学生，所以教材最重要的是严谨。和全面相比是不是通俗易懂就没有那么重要了。而且一般的教材也不会告诉你学了有什么用，这就导致了在学习中你很容易迷失在这些概念中，抓不到重点。
那本文呢，我想根据自己的工作学习经历，抛开书本上这些教条的框架，从应用侧出发来给大家介绍一下MOS管里面最常见的，也是最容易使用的一种：增强型NMOS管，简称NMOS。当你熟悉了这个NMOS的使用之后，再回过头去看这个教材上的内容，我相信就会有不同的体会了。
NMOS的用法 首先来看这么一张简单的图（图1），我们可以用手去控制这个开关的开合，以此来控制这个灯光的亮灭。
图1
那如果我们想要用Arduino或者单片机去控制这个灯泡的话，就需要使用MOS管来替换掉这个开关了。为了更加符合我们工程的实际使用习惯呢，我们需要把这张图稍微转换一下，就像如图2这样子。
图2
那这两张图是完全等价的，我们可以看到MOS管是有三个端口，也就是有三个引脚，分别是GATE、DRAIN和SOURCE。至于为啥这么叫并不重要，只要记住他们分别简称G、D、S就可以。
图3
我们把单片机的一个IO口接到MOS管的gate端口，就可以控制这个灯泡的亮灭了。当然别忘了供电。当这个单片机的IO口输出为高的时候，NMOS就等效为这个被闭合的开关，指示灯光就会被打开；那输出为低的时候呢，这个NMOS就等效为这个开关被松开了，那此时这个灯光就被关闭，是不很简单。
那如果我们不停的切换这个开关，那灯光就会闪烁。如果切换的这个速度再快一点，因为人眼的视觉暂留效应，灯光就不闪烁了。此时我们还能通过调节这个开关的时间来调光，这就是所谓的PWM波调光，以上就是MOS管最经典的用法，它实现了单片机的IO口控制一个功率器件。当然你完全可以把灯泡替换成其他的器件。器件比如说像水泵、电机、电磁铁这样的东西。
图4：PWM波调光
如何选择NMOS 明白了NMOS的用法之后呢，我们来看一下要如何选择一个合适的NMOS，也就是NMOS是如何选型的。
那对于一个初学者来说，有四个比较重要的参数需要来关注一下。第一个是封装，第二个是Vgs(th)，第三个是Rds(on)上，第四个是Cgs。
封装比较简单，它指的就是一个MOS管这个外形和尺寸的种类也有很多。一般来说封装越大，它能承受的电流也就越大。为了搞明白另外三个参数呢，我们先要来介绍一下NMOS的等效模型。
图5：NMOS等效模型
MOS其实可以看成是一个由电压控制的电阻。这个电压指的是G、S的电压差，电阻指的是D、S之间的电阻。这个电阻的大小会随着G、S电压的变化而变化。当然它们不是线性对应的关系，实际的关系差不多像这样的，横坐标是G、S电压差。
图6：Rds与Vgs关系图
纵坐标是电阻的值，当G、S的电压小于一个特定值的时候呢，电阻基本上是无穷大的。然后这个电压值大于这个特定值的时候，电阻就接近于零，至于说等于这个值的时候会怎么样，我们先不用管这个临界的电压值，我们称之为Vgs(th)，也就是打开MOS管需要的G、S电压，这是每一个MOS管的固有属性，我们可以在MOS管的数据手册里面找到它。
图7：MOS管数据手册
显然，Vgs(th)一定要小于这个高电平的电压值，否则就没有办法被正常的打开。所以在你选择这个MOS管的时候，如果你的高电平是对应的5V，那么选3V左右的Vgs(th)是比较合适的。太小的话会因为干扰而误触发，太大的话又打不开这个MOS管。
接下来，我们再来看看NMOS的第二个重要参数Rdson，刚才有提到NMOS被完全打开的时候，它的电阻接近于零。但是无论多小，它总归是有一个电阻值的，这就是所谓的Rds(on)。它指的是NMOS被完全打开之后，D、S之间的电阻值。同样的你也可以在数据手册上找到它。这个电阻值当然是越小越好。越小的话呢，它分压分的少，而且发热也相对比较低。但实际情况一般Rds(on)越小，这个NMOS的价格就越高，而且一般对应的体积也会比较大。所以还是要量力而行，选择恰好合适。
最后说一下Cgs，这个是比较容易被忽视的一个参数，它指的是G跟S之间的寄生电容。所有的NMOS都有，这是一个制造工艺的问题，没有办法被避免。
那它会影响到NMOS打开速度，因为加载到gate端的电压，首先要给这个电容先充电，这就导致了G、S的电压并不能一下子到达给定的一个数值。
图8
它有一个爬升的过程。当然因为Cgs比较小，所以一般情况下我们感觉不到它的存在。但是当我们把这个时间刻度放大的时候，我们就可以发现这个上升的过程了。对于这个高速的PWM波控制场景是致命的。当PWM波的周期接近于这个爬升时间时，这个波形就会失真。一般来说Cgs大小和Rds(on)是成反比的关系。Rds(on)越小，Cgs就越大。所以大家要注意平衡他们之间的关系。
以上就是关于NMOS大家需要初步掌握的知识了，希望能对大家有所帮助。
]]></content>
  </entry>
  
  <entry>
    <title>MOS管驱动电路设计</title>
    <url>/post/hardware/the-drive-circuit-design-of-MOS-tube.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>MOS Tube</tag>
    </tags>
    <content type="html"><![CDATA[MOS管因为其导通内阻低，开关速度快，因此被广泛应用在开关电源上。而用好一个MOS管，其驱动电路的设计就很关键。下面分享几种常用的驱动电路。
电源IC直接驱动 电源IC直接驱动是最简单的驱动方式，应该注意几个参数以及这些参数的影响。
 查看电源IC手册的最大驱动峰值电流，因为不同芯片，驱动能力很多时候是不一样的。 了解MOS管的寄生电容，如图C1、C2的值，这个寄生电容越小越好。如果C1、C2的值比较大，MOS管导通的需要的能量就比较大，如果电源IC没有比较大的驱动峰值电流，那么管子导通的速度就比较慢，就达不到想要的效果。  推挽驱动 当电源IC驱动能力不足时，可用推挽驱动。 这种驱动电路好处是提升电流提供能力，迅速完成对于栅极输入电容电荷的充电过程。这种拓扑增加了导通所需要的时间，但是减少了关断时间，开关管能快速开通且避免上升沿的高频振荡。
加速关断驱动 MOS管一般都是慢开快关。在关断瞬间驱动电路能提供一个尽可能低阻抗的通路供MOSFET栅源极间电容电压快速泄放，保证开关管能快速关断。 为使栅源极间电容电压的快速泄放，常在驱动电阻上并联一个电阻和一个二极管，如上图所示，其中D1常用的是快恢复二极管。这使关断时间减小，同时减小关断时的损耗。Rg2是防止关断的时电流过大，把电源IC给烧掉。
如上图，是我之前用的一个电路，量产至少上万台，推荐使用。 用三极管来泄放栅源极间电容电压是比较常见的。如果Q1的发射极没有电阻，当PNP三极管导通时，栅源极间电容短接，达到最短时间内把电荷放完，最大限度减小关断时的交叉损耗。 还有一个好处，就是栅源极间电容上的电荷泄放时电流不经过电源IC，提高了可靠性。
隔离驱动 为了满足高端MOS管的驱动，经常会采用变压器驱动。其中R1目的是抑制PCB板上寄生的电感与C1形成LC振荡，C1的目的是隔开直流，通过交流，同时也能防止磁芯饱和。
]]></content>
  </entry>
  
  <entry>
    <title>SPI总线详解</title>
    <url>/post/hardware/spi-bus-introduction.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>SPI</tag>
    </tags>
    <content type="html"><![CDATA[SPI是串行外设接口（Serial Peripheral Interface）的缩写，是一种高速的，全双工，同步的通信总线，并且在芯片的管脚上只占用四根线，节约了芯片的管脚，同时为PCB的布局上节省空间，提供方便，正是出于这种简单易用的特性，越来越多的芯片集成了这种通信协议，比如AT91RM9200。
什么是SPI？ SPI是串行外设接口(Serial Peripheral Interface)的缩写，是 Motorola 公司推出的一种同步串行接口技术，是一种高速、全双工、同步的通信总线。
SPI优点  支持全双工通信 通信简单 数据传输速率块 SPI电路图  缺点 没有指定的流控制，没有应答机制确认是否接收到数据，所以跟IIC总线协议比较在数据可靠性上有一定的缺陷。
特点  高速、同步、全双工、非差分、总线式 主从机通信模式  SPI电路连接  SPI的通信原理很简单，它以主从方式工作，这种模式通常有一个主设备和一个或多个从设备，有三线制和四线制之分。信号线包括SDI(串行数据输入 Serial Digital IN)、SDO(串行数据输出 Serial Digital OUT)、SCLK(时钟)、CS(片选)。 SDO/MOSI – 主设备数据输出，从设备数据输入 SDI/MISO – 主设备数据输入，从设备数据输出 SCLK – 时钟信号，由主设备产生; CS/SS – 从设备使能信号，由主设备控制。当有多个从设备的时候，因为每个从设备上都有一个片选引脚接入到主设备机中，当主设备和某个从设备通信时将需要将从设备对应的片选引脚电平拉低(一般低有效)。  SPI通信模式分析 SPI通信有4种不同的模式，不同的从设备在出厂时配置模式已经固定， 这是不能改变的，但通信双方设备必须工作在同一模式下，所以可以对主设备的SPI模式进行配置，通过CPOL（时钟极性）和CPHA（时钟相位）来控制主设备的通信模式。
具体模式具体如下：
 Mode0：CPOL=0，CPHA=0 Mode1：CPOL=0，CPHA=1 Mode2：CPOL=1，CPHA=0 Mode3：CPOL=1，CPHA=1     模式 CPOL CPHA     Mode0 0 0   Mode1 0 1   Mode2 1 0   Mode3 1 1    时钟极性CPOL是用来配置SCLK电平的有效态的;
时钟相位CPHA是用来配置数据采样是发生在第几个边沿的。
 CPOL=0表示当SCLK=0时处于空闲态，所以SCLK处于高电平时有效； CPOL=1表示当SCLK=1时处于空闲态，所以SCLK处于低电平时有效； CPHA=0表示数据采样是在第1个边沿，数据发送在第2个边沿； CPHA=1表示数据采样是在第2个边沿，数据发送在第1个边沿； SPI主模块和与之通信的外设通信时，两者的时钟相位和极性应该保持一致。  SPI 时序详解 CPOL=0，CPHA=0：此时空闲态时，SCLK处于低电平，数据采样是在第1个边沿，也就是SCLK由低电平到高电平的跳变，所以数据采样是在上升沿，数据发送是在下降沿。
CPOL=0，CPHA=1：此时空闲态时，SCLK处于低电平，数据发送是在第1个边沿，也就是SCLK由低电平到高电平的跳变，所以数据采样是在下降沿，数据发送是在上升沿。
CPOL=1，CPHA=0：此时空闲态时，SCLK处于高电平，数据采集是在第1个边沿，也就是SCLK由高电平到低电平的跳变，所以数据采集是在下降沿，数据发送是在上升沿。
CPOL=1，CPHA=1：此时空闲态时，SCLK处于高电平，数据发送是在第1个边沿，也就是SCLK由高电平到低电平的跳变，所以数据采集是在上升沿，数据发送是在下降沿。
注意：SPI主设备能够控制时钟信号，因为SPI通信并不像UART或者IIC通信那样有专门的通信周期、通信起始信号、通信结束信号；所以SPI协议只能通过控制时钟信号线，在没有数据交流的时候，时钟线要么是保持高电平，要么是保持低电平。
例如：工作在模式0这种时序（CPOL＝0，CPHA＝0），如下：
我们来关注SCK的第一个时钟周期，在时钟的前沿采样数据（上升沿，第一个时钟沿），在时钟的后沿输出数据（下降沿，第二个时钟沿）。首先来看主器件，主器件的输出口（MOSI）输出的数据bit1，在时钟的前沿被从器件采样，那主器件是在何时刻输出bit1的呢？bit1的输出时刻实际上在SCK信号有效以前，比SCK的上升沿还要早半个时钟周期。bit1的输出时刻与SSEL信号没有关系。再来看从器件，主器件的输入口MISO同样是在时钟的前沿采样从器件输出的bit1的，那从器件又是在何时刻输出bit1的呢。从器件是在SSEL信号有效后，立即输出bit1，尽管此时SCK信号还没有起效。
从这张图就可以很清楚的看出主从器件的bit1是怎样输出的。
]]></content>
  </entry>
  
  <entry>
    <title>10个超赞的C语言开源项目</title>
    <url>/post/linux/ten-great-c-language-open-source-project.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>C language</tag>
      <tag>open source</tag>
    </tags>
    <content type="html"><![CDATA[今天给大家分享10个超赞的C语言开源项目，希望这些内容能对大家有所帮助！
Webbench Webbench是一个在 Linux 下使用的非常简单的网站压测工具。
它使用fork()模拟多个客户端同时访问我们设定的URL，测试网站在压力下工作的性能。
最多可以模拟 3 万个并发连接去测试网站的负载能力。Webbench使用C语言编写，代码非常简洁，源码加起来不到 600 行。
项目地址 http://home.tiscali.cz/~cz210552/webbench.html Tinyhttpd tinyhttpd是一个超轻量型Http Server，使用C语言开发，全部代码只有 502 行（包括注释），附带一个简单的 Client
可以通过阅读这段代码理解一个 Http Server 的本质。
项目地址 http://sourceforge.net/projects/tinyhttpd/ cJSON cJSON是C语言中的一个JSON编解码器，非常轻量级，C文件只有 500 多行，速度也非常理想。
虽然cJSON功能不是非常强大，但cJSON的小身板和速度是最值得赞赏的。
其代码被非常好地维护着，结构也简单易懂，可以作为一个非常好的C语言项目进行学习。
项目主页 http://sourceforge.net/projects/cjson/ CMockery CMockery是google发布的用于C单元测试的一个轻量级的框架。
它很小巧，对其他开源包没有依赖，对被测试代码侵入性小。
CMockery 的源代码行数不到3K，阅读一下will_return和mock的源代码就一目了然了。
主要特点  免费且开源，google 提供技术支持； 轻量级的框架，使测试更加快速简单； 避免使用复杂的编译器特性，对老版本的编译器来讲，兼容性好； 并不强制要求待测代码必须依赖 C99 标准，这一特性对许多嵌入式系统的开发很有用。   项目地址 http://code.google.com/p/cmockery/downloads/list Libev libev 是一个开源的事件驱动库，基于 epoll、kqueue 等 OS 提供的基础设施。
其以高效出名，它可以将 IO 事件、定时器、和信号统一起来，统一放在事件处理这一套框架下处理。
基于 Reactor 模式，效率较高，并且代码精简（4.15 版本 8000 多行），是学习事件驱动编程的很好的资源。
项目地址 http://software.schmorp.de/pkg/libev.html Memcached Memcached 是一个高性能的分布式内存对象缓存系统，用于动态 Web 应用以减轻数据库负载。
它通过在内存中缓存数据和对象来减少读取数据库的次数，从而提供动态数据库驱动网站的速度。
Memcached 基于一个存储键/值对的 hashmap。Memcached-1.4.7 的代码量还是可以接受的，只有 10K 行左右。
项目地址 http://memcached.org/ Lua Lua 很棒，在任何支持 ANSI C 编译器的平台上都可以轻松编译通过。 Lua 的代码数量足够小，5.1.4 仅仅 1.5W 行，去掉空白行和注释估计能到 1W 行。
项目地址 http://www.lua.org/ SQLite SQLite 是一个开源的嵌入式关系数据库，实现自包容、零配置、支持事务的 SQL 数据库引擎。其特点是高度便携、使用方便、结构紧凑、高效、可靠。
足够小，大致 3 万行C代码，250K。
项目地址 http://www.sqlite.org/ UNIX v6 UNIX V6 的内核源代码包括设备驱动程序在内约有 1 万行，这个数量的源代码，初学者是能够充分理解的。有一种说法是一个人所能理解的代码量上限为 1 万行，UNIX V6 的内核源代码从数量上看正好在这个范围之内。
看到这里，大家是不是也有“如果只有 1 万行的话没准儿我也能学会”的想法呢？
另一方面，最近的操作系统，例如 Linux   最新版的内核源代码据说超过了 1000 万行。
就算不是初学者，想完全理解全部代码基本上也是不可能的。
项目地址 http://minnie.tuhs.org/cgi-bin/utree.pl?file=V6 NETBSD NetBSD 是一个免费的，具有高度移植性的 UNIX-like 操作系统。
NetBSD 计划的口号是：“Of course it runs NetBSD”。
它设计简洁，代码规范，拥有众多先进特性，使得它在业界和学术界广受好评。
由于简洁的设计和先进的特征，使得它在生产和研究方面，都有卓越的表现，而且它也有受使用者支持的完整的源代码。
许多程序都可以很容易地通过 NetBSD Packages Collection 获得。
]]></content>
  </entry>
  
  <entry>
    <title>Linux环境监控工具基础参考</title>
    <url>/post/linux/linux-environment-monitor-tool.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>monitor tool</tag>
    </tags>
    <content type="html"><![CDATA[Linux 操作系统有很多自带和第三方监控工具，这篇文章从不同维度整理了一些，但仅限基础了解，因为，单独讲任何一个指令，都可以成篇文章，具体指令参数，可以检索 man，从中理解。
CPU top(任务管理工具)
top -n 1 -b vmstat(展现给定时间间隔的服务器的状态值，包括服务器的 CPU 使用率，内存使用)
vmstat 1 10 #每1秒采集一次共采集10次 pidstat(进程实时监控)
pidstat -u 1 -p pid mpstat(多 CPU 实时监控工具)
mpstat -P ALL 1 5 sar(性能监控和瓶颈检查)
sar -u dstat(dstat 是一个可以取代 vmstat，iostat，netstat 和 ifstat 这些命令的多功能产品)
dstat 2 10 #每2秒采集一次共采集10次 内存 top
top -n 1 -b pidstat
pidstat -r free(查看当前系统的物理内存使用情况)
free -mh sar(性能监控和瓶颈检查)
sar -r 10 3 #每10秒采样一次，连续采样3次 vmstat
vmstat 2 1 磁盘 IO iostat(IO 实时监控)
iostat -d -x -k 1 10 iotop(监控系统中各个进程对 IO 的使用量)
iotop pidstat
示例: pidstat -d sar
sar -d vmstat
vmstat 2 1 网络 netstat(监控 TCP/IP 网络)
netstat -nltup iftop(实时流量监控工具)
iftop -i em2 ss(获取 socket 统计信息，他可以显示和 netstat 类似的内容)
ss -aA tcp sar
sar -n EDEV 1 5 tcpdump(抓包工具)
tcpdump -i em1 host 192.168.1.1 and port 80 tcpflow(分析网络流量)
tcpflow -i em1 port 80 nload(用于查看 Linux 网络流量状况，实时输出)
nload -t 200 -i 1024 -o 128 -U M 系统负载 (1) CPU 负载说明
 如果某个程序频繁的进行计算、逻辑判断等操作，那么此类程序主要依赖于 CPU 的处理速度，故称之为 &ldquo;计算密集型程序&rdquo;。
 (2) IO 负载说明
 如果某个程序频繁的从磁盘中读取写入文件，那么这种类型的操作主要依赖于磁盘的读取速度，也就是输入输出 (input/output)，简写为 I/O。此类 I/O 负载的程序，称为 I/O 密集型程序。
 top
top uptime
uptime sar
sar -q 1 20 其他工具  htop(类似 top，比 top 更加人性化) glances(类似 top，基于 Python 的系统遥测监控工具) strace(常用来跟踪进程执行时的系统调用和所接收的信号) dtrace(动态跟踪) valgrind(内存泄漏检测) dmesg(内核信息) ]]></content>
  </entry>
  
  <entry>
    <title>详解TCP和UDP协议的原理和区别</title>
    <url>/post/linux/tcp-and-udp-principle-and-difference.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>tcp</tag>
      <tag>udp</tag>
    </tags>
    <content type="html"><![CDATA[ 最近重新认知了一下TCP和UDP的原理以及区别，做一个简单的总结。
 作用 首先，tcp和udp都是工作再传输层，用于程序之间传输数据的。数一般包含：文件类型，视频类型，jpg图片等。
区别 TCP是基于连接的，而UDP是基于非连接的。
tcp传输数据稳定可靠，适用于对网络通讯质量要求较高的场景，需要准确无误的传输给对方，比如，传输文件，发送邮件，浏览网页等等。
udp的优点是速度快，但是可能产生丢包，所以适用于对实时性要求较高但是对少量丢包并没有太大要求的场景。比如：域名查询，语音通话，视频直播等。udp还有一个非常重要的应用场景就是隧道网络，比如：vpn，VXLAN。
以人与人之间的通信为例：UDP协议就相当于是写信给对方，寄出去信件之后不能知道对方是否收到信件，信件内容是否完整，也不能得到及时反馈，而TCP协议就像是打电话通信，在这一系列流程都能得到及时反馈，并能确保对方及时接收到。如下图：
TCP通信的过程 tcp是如何保证以上过程的:分为三个步骤，三次握手，传输确认，四次挥手。三次握手是建立连接的过程。
三次握手 当客户端向服务端发起连接时，会先发一包连接请求数据，过去询问一下，能否与你建立连接？这包数据称之为SYN包，如果对端同意连接，则回复一包SYN+ACK包，客户端收到之后，发送一包ACK包，连接建立，因为这个过程中互相发送了三包数据，所以称之为三次握手。
为什么要三次握手而不是两次握手？
**这是为了防止，因为已失效的请求报文，突然又传到服务器，引起错误，**这是什么意思？
假设采用两次握手建立连接，客户端向服务端发送一个syn包请求建立连接，因为某些未知的原因，并没有到达服务器，在中间某个网络节点产生了滞留，为了建立连接，客户端会重发syn包，这次的数据包正常送达，服务端发送syn+ack之后就建立起了连接，但是第一包数据阻塞的网络突然恢复，第一包syn包又送达到服务端，这是服务端会认为客户端又发起了一个新的连接，从而在两次握手之后进入等待数据状态，服务端认为是两个连接，而客户端认为是一个连接，造成了状态不一致，如果在三次握手的情况下，服务端收不到最后的ack包，自然不会认为连接建立成功，所以三次握手本质上来说就是为了解决网络信道不可靠的问题，为了在不可靠的信道上建立起可靠的连接，经过三次握手之后，客户端和服务端都进入了数据传输状态。
数据传输 数据传输： 一包数据可能会被拆成多包发送,如何处理丢包问题，这些数据包到达的先后顺序不同，如何处理乱序问题？针对这些问题，tcp协议为每一个连接建立了发送缓冲区，从建立链接后的第一个字节的序列号为0，后面每个字节的序列号就会增加1，发送数据时，从数据缓冲区取一部分数据组成发送报文，在tcp协议头中会附带序列号和长度，接收端在收到数据后需要回复确认报文，确认报文中的ack等于接受序列号加长度，也就是下包数据发送的起始序列号，这样一问一答的发送方式，能够使发送端确认发送的数据已经被对方收到，发送端也可以发送一次的连续的多包数据，接受端只需要回复一次ack就可以了如图：
四次挥手 处于连接状态的客户端和服务端，都可以发起关闭连接请求，此时需要四次挥手来进行连接关闭，假设客户端主动发起连接关闭请求，他给服务端发起一包FIN包，标识要关闭连接，自己进入终止等待1装填，服务端收到FIN包，发送一包ACK包，标识自己进入了关闭等待状态，客户端进入终止等待2状态。这是第二次挥手，服务端此时还可以发送未发送的数据，而客户端还可以接受数据，待服务端发送完数据之后，发送一包FIN包，最后进入确认状态，这是第3次挥手，客户端收到之后恢复ACK包，进入超时等待状态，经过超时时间后关闭连接，而服务端收到ACK包后，立即关闭连接，这是第四次挥手。为什么客户端要等待超时时间这是为了保证对方已经收到ACK包，因为假设客户端发送完最后一包ACK包后释放了连接，一旦ACK包在网络中丢失，服务端将一直停留在 最后确认状态，如果等待一段时间，这时服务端会因为没有收到ack包重发FIN包，客户端会响应 这个FIN包进行重发ack包，并刷新超时时间，这个机制跟第三次握手一样。也是为了保证在不可靠的网络链路中进行可靠的连接断开确认。
UDP协议 udp:首先udp协议是非连接的，发送数据就是把简单的数据包封装一下，然后从网卡发出去就可以了，数据包之间并没有状态上的联系，正因为udp这种简单的处理方式，导致他的性能损耗非常少，对于cpu,内存资源的占用也远小于tcp,但是对于网络传输过程中产生的丢包，udp并不能保证，所以udp在传输稳定性上要弱于tcp，所以，tcp和udp的主要却别：tcp传输数据稳定可靠，适用于对网络通讯质量要求较高的场景，需要准确无误的传输给对方，比如，传输文件，发送邮件，浏览网页等等，udp的优点是速度快，但是可能产生丢包，所以适用于对实时性要求较高但是对少量丢包并没有太大要求的场景。比如：域名查询，语音通话，视频直播等。udp还有一个非常重要的应用场景就是隧道网络，比如：vpn，VXLAN。
]]></content>
  </entry>
  
  <entry>
    <title>分享一种通信协议的应用编程原理和思路</title>
    <url>/post/linux/communication-protocol-programming-principle-and-idea.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>programming</tag>
      <tag>uart</tag>
      <tag>can</tag>
      <tag>usb</tag>
    </tags>
    <content type="html"><![CDATA[ 嵌入式开发过程中，UART、 CAN、 USB等通信基本离不开通信协议。
 下面给大家分享一种通信协议（MAVLink）在应用编程中的编程原理和思路。
应用编程主要内容 发送和接收说明 利用MAVLink通信协议进行编程，主要实现的功能就是：
发送端 将需要发送的数据（如：SysState, BatVol），添加MAVLink通信协议，通过硬件（如：UART、CAN）发送出去。
接收端 硬件（如：UART、CAN）接收到的数据，通过MAVLink协议解析，得到一帧完整的MAVLink数据包，提取发送端发送的数据（如：SysState, BatVol），将得到的数据应用到我们程序中。
主要流程：数据 -&gt; MAVLink封装 -&gt; 发送 -&gt; 接收 -&gt; MAVLink解析 -&gt;数据
发送和接收流程图 该流程图是结合我上一篇文章提供的源代码例程画出来，包含的只是主要内容，更多细节没有在流程图中呈现。
提示：
我提供例程是针对初学者提供比较单一发送和接收例程（MDK-ARM和EWARM包含各自的发送和接收工程）。
而实际项目可能会：
  发送和接收在一个工程；
  包含操作系统；
  发送、接收数据FIFO（队列）处理；
  所以，实际项目，请按需修改我提供的源码。
MAVLink函数接口详细说明 这一章节讲述发送和接收主要用到的函数接口，请参考我提供的源代码例程理解。 为方便初学者理解，我将其分为发送和接收两个部分来讲述。
发送主要函数接口 上面是我提供例程的代码，主要讲4个接口。
MAVLink_SendTest 这个接口是根据自己情况进行封装函数，用于应用程序调用，这里不多说。
mavlink_msg_sys_info_pack 这个函数接口主要目的：将变量信息（SysID、CompID、SysState、BatVol）打包，最终得到MAVLink_Msg这个消息包。
mavlink_msg_to_send_buffer 将上一步得到的MAVLink_Msg转换成我们要发送的数据BUF缓存。
MAV_USART_SendNByte 这个函数接口也是我自己根据硬件（UART）封装的，如果你是其它硬件通信，只需要封装一个类似的接口（参数具有BUF，LEN）即可。
发送数据的流程：从应用代码 -&gt; 底层硬件（发送出去）。
如果要深入了解，可以先熟悉软件流程，再结合源代码工程，同时参看接口函数具体实现。相信你很快就明白了。
接收主要函数接口 上面是我提供例程的代码（方便截图，去掉了部分），主要讲以上4点内容。
MAV_USART_GetByte 该函数接口也是硬件底层通信接口，请根据自己情况修改，只需要传递数据（流）进来即可。
mavlink_parse_char MAVLink解析是按照一个一个字符进行解析，我们接收到一个字符，就对其进行解析，直到解析完（根据返回标志判断）一帧数据为止。
if(MAVLINK_MSG_ID_SYS_INFO == MAVLinkMsg.msgid) 这里就是对解析好的一包完整消息进行分类判断吧。其实，我是想说，这个地方还有两个ID需要进行判断，SysID系统ID和CompID部件ID。
我提供例程为方便初学者快速理解，未提供SysID和CompID判断，在后续应用编程中会用到。
mavlink_msg_sys_info_get_voltage_battery 通过该接口获取消息变量，看图中说明文字，前面是消息，后面是消息变量。
接收数据的流程：从底层硬件（接收数据） -&gt; 应用代码。
以上就是发送和接收的主要函数接口，如果你只是简单的进行通信，这几个接口就够你使用了。当然，更高级的编程应用还需要你进一步掌握其中的内容。
]]></content>
  </entry>
  
  <entry>
    <title>Linux之awk使用技巧</title>
    <url>/post/linux/awk-usage-skills.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>awk</tag>
    </tags>
    <content type="html"><![CDATA[AWK 是一种处理文本文件的语言，是一个强大的文本分析工具。
之所以叫 AWK 是因为其取了三位创始人 Alfred Aho，Peter Weinberger, 和 Brian Kernighan 的 Family Name 的首字符。
打印文件的第一列
awk &#39;{print $1}&#39; vxworks.txt 打印文件的前两列
awk &#39;{print $1,$2}&#39; vxworks.txt 打印文件的最后一列
awk &#39;{print $NF}&#39; vxworks.txt 打印文件的总行数
awk &#39;END{print NR}&#39; vxworks.txt 打印文件的第一行
awk &#39;NR==1{print}&#39; vxworks.txt NR是指awk正在处理的记录位于文件中的位置（行号）
打印文件的第3行第2列
sed -n &#39;3,1p&#39; vxworks.txt | awk &#39;{print $2}&#39; 删除空行
awk &#39;NF&#39; vxworks.txt 打印奇数行
awk &#39;b=!b&#39; vxworks.txt 打印文件按#分割后,行长度为3的所有行
awk -F &#39;#&#39; &#39;if(NF==3){print}&#39; vxworks.txt NF是指awk正在处理的记录包含几个域（字段），这与域分隔符有关，默认为空
统计Linux系统中每个用户所用的shell
cat /etc/passwd | awk -F &#34;:&#34; &#39;{print $1&#34; : &#34;$7}&#39; 用awk统计linux系统中所有的用户数
cat /etc/passwd | awk &#39;{count++}END{ print count}&#39; 统计某个文件夹下文件所占的字节数
ls -l | awk &#39;BEGIN{size=0}{size=size+$5}END{print size}&#39; 统计某个文件夹下文件所占的字节数,按M显示
ls -l | awk &#39;BEGIN{size=0}{size=size+$5}END{print size}&#39; netstat结合awk统计TCP连接数
netstat -tunlp | awk &#39;/^tcp/{++a[$6]}END{for(i in a) print i,a[i]}&#39; 过滤空行
awk &#39;/^[^$]/ {print $0}&#39; vxworks.txt 列运算
awk &#39;/^[^$]/ {print $0}&#39; vxworks.txt cat 1.txt 1 2 3 求和
cat 1.txt | awk &#39;{a+=$1}END{print a}&#39; 求平均值
cat 1.txt | awk &#39;{a+=$1}END{print a/NR}&#39; 求列的最大值
cat 1.txt | awk &#39;BEGIN{a=0}{if($1&gt;a) a=$1 fi}END{print a}&#39; ]]></content>
  </entry>
  
  <entry>
    <title>关于Linux下的crontab，你不知道的那些知识点</title>
    <url>/post/linux/linux-crontab-knowledge.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>crontab</tag>
    </tags>
    <content type="html"><![CDATA[实际工作中，crontab出现的问题是多种多样的，下面就深入介绍下crontab在具体工作中容易出现的问题和解决问题的办法。
crontab能干啥 crond是linux下用来周期性的执行某种任务或等待处理某些事件的一个守护进程，与windows下的计划任务类似，当安装完成操作系统后，默认会安装此服务工具，并且会自动启动crond进程，crond进程每分钟会定期检查是否有要执行的任务，如果有要执行的任务，则自动执行该任务。
Linux下的任务调度分为两类，系统任务调度和用户任务调度。
 系统任务调度：系统周期性所要执行的工作，比如写缓存数据到硬盘、日志清理等。 用户任务调度：用户定期要执行的工作，比如用户数据备份、定时邮件提醒等。用户可以使用 crontab 工具来定制自己的计划任务。所有用户定义的crontab 文件都被保存在 /var/spool/cron目录中。其文件名与用户名一致。  关于crontab的用途，在企业实际应用中非常广泛，常见的有定时数据备份、定时系统检测、定时数据收集、定时更新配置、定时生成报表等等。
crontab应用实例 crontab使用格式 crontab常用的使用格式有如下两种：
crontab [-u user] [file] crontab [-u user] [-e|-l|-r |-i] 选项含义如下：
  -u user：用来设定某个用户的crontab服务，例如，“-u ixdba”表示设定ixdba用户的crontab服务，此参数一般有root用户来运行。
  file：file是命令文件的名字,表示将file做为crontab的任务列表文件并载入crontab。如果在命令行中没有指定这个文件，crontab命令将接受标准输入（键盘）上键入的命令，并将它们载入crontab。
  -e：编辑某个用户的crontab文件内容。如果不指定用户，则表示编辑当前用户的crontab文件。
  -l：显示某个用户的crontab文件内容，如果不指定用户，则表示显示当前用户的crontab文件内容。
  -r：从/var/spool/cron目录中删除某个用户的crontab文件，如果不指定用户，则默认删除当前用户的crontab文件。
  -i：在删除用户的crontab文件时给确认提示。
  crontab文件语法 用户所建立的crontab文件中，每一行都代表一项任务，每行的每个字段代表一项设置，它的格式共分为六个字段，前五段是时间设定段，第六段是要执行的命令段，格式如下：
minute hour day month week command 其中：
? minute：表示分钟，可以是从0到59之间的任何整数。 ? hour：表示小时，可以是从0到23之间的任何整数。 ? day：表示日期，可以是从1到31之间的任何整数。 ? month：表示月份，可以是从1到12之间的任何整数。 ? week：表示星期几，可以是从0到7之间的任何整数，这里的0或7代表星期日。 ? command：要执行的命令，可以是系统命令，也可以是自己编写的脚本文件。 在以上各个字段中，还可以使用以下特殊字符：
? 星号（）：代表所有可能的值，例如month字段如果是星号，则表示在满足其它字段的制约条件后每月都执行该命令操作。 ? 逗号（,）：可以用逗号隔开的值指定一个列表范围，例如，“1,2,5,7,8,9” ? 中杠（-）：可以用整数之间的中杠表示一个整数范围，例如“2-6”表示“2,3,4,5,6” ? 正斜线（/）：可以用正斜线指定时间的间隔频率，例如“0-23/2”表示每两小时执行一次。同时正斜线可以和星号一起使用，例如/10，如果用在minute字段，表示每十分钟执行一次。 几个crontab例子 0 /3 /usr/local/apache2/apachectl restart 表示每隔3个小时重启apache服务一次。
30 3 6 /webdata/bin/backup.sh 表示每周六的3点30分执行/webdata/bin/backup.sh脚本的操作。
0 0 1,20 fsck /dev/sdb8 表示每个月的1号和20号检查/dev/sdb8磁盘设备。
10 5 /5 * echo &#34;&#34;&gt;/usr/local/apache2/log/access_log 表示每个月的5号、10号、15号、20号、25号、30号的5点10分执行清理apache日志操作。
系统级任务调度/etc/crontab 在/etc目录下有一个crontab文件，这个就是系统任务调度的配置文件。
/etc/crontab文件包括下面几行：
SHELL=/bin/bash PATH=/sbin:/bin:/usr/sbin:/usr/bin MAILTO=root HOME=/ # run-parts 01 * * * * root run-parts /etc/cron.hourly 02 4 * * * root run-parts /etc/cron.daily 22 4 * * 0 root run-parts /etc/cron.weekly 42 4 1 * * root run-parts /etc/cron.monthly 从上面的示例文件可看出，crontab的任务列表主要由两部分组成：环境变量配置与定时任务配置。可能大家在工作中更多是只用到了任务配置部分。
前四行是用来配置crond任务运行的环境变量，第一行SHELL变量指定了系统要使用哪个shell，这里是bash，第二行PATH变量指定了系统执行命令的路径，第三行MAILTO变量指定了crond的任务执行信息将通过电子邮件发送给root用户，如果MAILTO变量的值为空，则表示不发送任务执行信息给用户，第四行的HOME变量指定了在执行命令或者脚本时使用的主目录。第六至九行就是crontab执行格式的具体写法。
##crontab调试解析神器
通常在使用crontab添加任务时，我们会依靠自己已有知识编写定时语句。当需要测试语句是否正确时，还需要在服务器上不断调试，，这种方式太不高效了。有没有一款工具，只要我们给出语句，就能告诉具体执行时间以及对错呢？还真有，下面介绍一款老外开发的crontab在线解析工具。
工具地址：https://crontab.guru
给出这个工具的截图如下：
好用不好用，你试试就知道。
crontab使用的各种坑 环境变量问题 当我们刚使用crontab时，运维老鸟们一般会告知所有命令尽量都使用绝对路径，以防错误。这是为什么？这就和我们下面要谈的环境变量有关了。
首先，获取shell终端环境变量，内容如下：
[root@SparkWorker1 dylogs]# env XDG_SESSION_ID=1629 HOSTNAME=SparkWorker1 TERM=linux SHELL=/bin/bash HISTSIZE=1000 SSH_CLIENT=172.16.213.132 50080 22 HADOOP_PREFIX=/opt/hadoop/current CATALINA_BASE=/opt/hadoop/current/share/hadoop/httpfs/tomcat SSH_TTY=/dev/pts/1 QT_GRAPHICSSYSTEM_CHECKED=1 USER=root MAIL=/var/spool/mail/root PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/usr/java/default/bin:/opt/hadoop/current/bin:/opt/hadoop/current/sbin:/root/bin PWD=/data/dylogs LANG=zh_CN.UTF-8 HOME=/root 要获取crontab环境变量信息，可以设置如下计划任务：
* * * * * /usr/bin/env &gt; /tmp/env.txt 等待片刻，env.txt输出内容如下：
[root@SparkWorker1 dylogs]# cat /tmp/env.txt XDG_SESSION_ID=1729 SHELL=/bin/sh USER=root PATH=/usr/bin:/bin PWD=/root LANG=zh_CN.UTF-8 SHLVL=1 HOME=/root LOGNAME=root XDG_RUNTIME_DIR=/run/user/0 _=/usr/bin/env 从上面输出结果可知，shell命令行的PATH值为
PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/usr/java/default/bin:/opt/hadoop/current/bin:/opt/hadoop/current/sbin:/root/bin 而crontab中的PATH值为：
PATH=/usr/bin:/bin 对比crontab环境变量与shell终端环境变量的输出，可以发现两者的差异很大。大家可能遇到过，在shell命令行执行脚本都没有问题，而放到crontab后却执行异常，或者执行失败，此时，我们就需要考虑是否命令涉及的环境变量在crontab和shell命令行间存在差异。
例如，我们在crontab中执行了如下定时任务：
20 16 * * * php autosave.php 而如果我们的php是安装在/usr/local/bin/目录下的话，那么上面这个定时任务由于无法找到php命令，会运行失败。
那么，知道了环境变量问题，可能导致计划任务无法正常执行，怎么才能避免这个问题呢，这个交给大家一个终极大招，可以在crontab中加入如下配置，保证你的计划任务执行不会出现环境变量问题：
* * * * * source /$HOME/.bash_profile &amp;&amp; command 这个其实是在执行计划任务命令之前，先加载了用户环境变量信息，由此可保证所有环境变量都可正常加载。
定时时间配置误区 时间是crontab的核心，稍微配置不当，就会出现问题，先看在整点时间设置时可能出现的错误，例如，设定每天2点执行一次任务，很多朋友可能这么写过：
* 2 * * * command 很明显，这个时间写法是错误的，当我们听到每天2点执行一次某任务时，很多人会把重点放在2点，而忽略了执行一次的需求。上面这个定时任务他会在2点开始执行，每分钟执行一次，总共执行60次。
正确的写法应该是这样的：
0 2 * * * command 这个才表示每天2点0分执行command对应的任务。
特殊符号%问题 %在crontab中是特殊符号，具体含义如下：
第一个%表示标准输入的开始，其余%表示换行符，看下面两个例子：
* * * * * cat &gt;&gt; /tmp/cat.txt 2&gt;&amp;1 % stdin out 查看/tmp/cat.txt的内容为：
stdin out 再看下面这个例子：
* * * * * cat &gt;&gt; /tmp/cat1.txt 2&gt;&amp;1 % stdin out 1 % stdin out 2 % stdin out 3 查看 /tmp/cat1.txt的内容如下：
stdin out 1 stdin out 2 stdin out 3 有输出内容可知，第一个%表示标准输入的开始，其余%表示换行符。
既然&quot;%&ldquo;是特殊字符,那么在crontab中使用时，就要特别注意，怎么使用这些特殊字符呢，很明显，使用转移字符即可，例如：
* * * * * cat &gt;&gt; /tmp/cat2.txt 2&gt;&amp;1 % Special character escape \%. 查看输出/tmp/cat2.txt 输出内容如下：
Special character escape %. 可以看到，执行成功了，并成功避开这个坑了。
关于crontab的输出重定向 在crontab执行的计划任务中，有些任务如果不做输出重定向，那么原本会输出到屏幕的信息，会以邮件的形式输出到某个文件中，例如，执行下面这个计划任务：
* * * * * /bin/date 这个计划任务是没有做输出重定向的，他的主要用途是输出时间，由于没有配置输出重定向，那么这个时间信息默认将以邮件的形式输出到/var/spool/mail/$USER（这个$USER对应的是系统用户，这里是root用户）文件中，大致内容如下：
From root@SparkWorker1.localdomain Fri Sep 21 12:58:02 2022 Return-Path: &lt;root@SparkWorker1.localdomain&gt; X-Original-To: root Delivered-To: root@SparkWorker1.localdomain Received: by SparkWorker1.localdomain (Postfix, from userid 0) id F2745192AE; Fri, 21 Sep 2022 12:58:01 +0800 (CST) From: &#34;(Cron Daemon)&#34; &lt;root@SparkWorker1.localdomain&gt; To: root@SparkWorker1.localdomain Subject: Cron &lt;root@SparkWorker1&gt; /bin/date Content-Type: text/plain; charset=UTF-8 Auto-Submitted: auto-generated Precedence: bulk X-Cron-Env: &lt;XDG_SESSION_ID=1820&gt; X-Cron-Env: &lt;XDG_RUNTIME_DIR=/run/user/0&gt; X-Cron-Env: &lt;LANG=zh_CN.UTF-8&gt; X-Cron-Env: &lt;SHELL=/bin/sh&gt; X-Cron-Env: &lt;HOME=/root&gt; X-Cron-Env: &lt;PATH=/usr/bin:/bin&gt; X-Cron-Env: &lt;LOGNAME=root&gt; X-Cron-Env: &lt;USER=root&gt; Message-Id: &lt;20220921045801.F2745192AE@SparkWorker1.localdomain&gt; Date: Fri, 21 Sep 2022 12:58:01 +0800 (CST) 2022年 09月 21日 星期五 12:58:01 CST 由此可见，输出内容还是很多的，如遇到任务有大量输出的话，会占用大量磁盘空间，显然，这个邮件输出最好关闭，怎么关闭呢，只需设置MAILTO环境变量为空即可，上面的计划任务，可做如下修改：
MAILTO=&#34;&#34; * * * * * /bin/date 这样，就不会发邮件信息到/var/spool/mail/$USER下了，但是问题并没有彻底解决，关闭mail功能后，输出内容将继续写入到/var/spool/clientmqueue中，长期下去，可能占满分区的inode资源，导致任务无法执行。
为了避免此类问题发生，建议任务都加上输出重定向，例如，可以在crontab文件中设置如下形式，忽略日志输出：
0 */3 * * * /usr/local/apache2/apachectl restart &gt;/dev/null 2&gt;&amp;1 其中，“/dev/null 2&gt;&amp;1”表示先将标准输出重定向到/dev/null，然后将标准错误重定向到标准输出，由于标准输出已经重定向到了/dev/null，因此标准错误也会重定向到/dev/null，这样日志输出问题就解决了。
调试crontab问题的一般思路 要解决crontab相关异常问题，可按照如下思路进行调试：
（1）、通过/var/log/cron日志确认任务是否执行
（2）、如未执行则分析定时语句，是否是环境变量问题、特殊字符问题、时间配置问题、权限问题等。
（3）、确认crond服务开启，如果定时语句也正确，检查crond服务是否开启。
Systemd方式(centos7及以上)
[root@SparkWorker1 spool]# systemctl status crond.service SysVinit方式(centos7以下)
[root@SparkWorker1 spool]# service crond status （4）确认定时任务中命令是否执行成功
这个问题可通过输出获取错误信息进行调试，方法就是利用重定向获取输出，然后进行分析。举例如下：
* * * * * python /usr/local/dyserver/dypos.py &gt;&gt; /tmp/dypos.log 2&gt;&amp;1 通过加上“/tmp/dypos.log 2&gt;&amp;1”，就可以很快定位问题，因为这个dypos.py脚本在执行的时候会把错误信息都输出到dypos.log 中，接着查看dypos.log文件，问题一目了然：
[root@SparkWorker1 spool]# cat /tmp/dypos.log /bin/sh: python: 未找到命令 /bin/sh: python: 未找到命令 显示python命令没有找到，很明显的就可以确定是环境变量的问题。这种方式定位问题非常有效。
]]></content>
  </entry>
  
  <entry>
    <title>I2C总线接上拉电阻的原因</title>
    <url>/post/hardware/why-add-pull-up-resistor-for-i2c.html</url>
    <categories><category>Hardware</category>
    </categories>
    <tags>
      <tag>I2C</tag>
    </tags>
    <content type="html"><![CDATA[I2C为什么要接上拉电阻？因为它是开漏输出。
为什么是开漏输出？ I2C协议支持多个主设备与多个从设备在一条总线上，如果不用开漏输出，而用推挽输出，会出现主设备之间短路的情况。所以总线一般会使用开漏输出。
为什么要接上拉电阻？ 接上拉电阻是因为I2C通信需要输出高电平的能力。一般开漏输出无法输出高电平，如果在漏极接上拉电阻，则可以进行电平转换。
I2C由两条总线SDA和SCL组成。连接到总线的器件的输出级必须是漏极开路，都通过上拉电阻连接到电源，这样才能够实现“线与”功能。当总线空闲时，这两条线路都是高电平。
上拉电阻阻值怎么确定？ 一般IO端口的驱动能力在2mA～4mA量级。
考虑到功耗问题，阻值不能过小
如果上拉阻值过小，VDD灌入端口的电流将较大，功耗会很大，导致端口输出的低电平值增大(I2C协议规定，端口输出低电平的最高允许值为0.4V)。故通常上拉电阻应选取不低于1K的电阻（当VDD＝3V时，灌入电流不超过3mA）。
考虑到速度问题，阻值不能过大
它取决于上拉电阻和线上电容形成的RC延时，RC延时越大，波形越偏离方波趋向于正弦波，数据读写正确的概率就越低，所以上拉电阻不能过大。
I2C总线上的负载电容不能超过400pF。当I2C总线上器件逐渐增多时，总线负载电容也相应增加。当总的负载电容大于400pF时，就不能可靠的工作。这也是I2C的局限性。
建议上拉电阻可选用1.5K，2.2K，4.7K。
I2C总线基本操作 根据I2C总线规范，总线空闲时两根线都必须为高。假设主设备A需要启动I2C，他需要在SCL高电平时，将SDA由高电平转换为低电平作为启动信号。
主设备A在把SDA拉高后，它需要再检查一下SDA的电平。为什么? 因为线与，如果主设备A拉高SDA时，已经有其他主设备将SDA拉低了，由于 1 &amp; 0 = 0 那么主设备A在检查SDA电平时, 会发现不是高电平，而是低电平。说明其他主设备抢占总线的时间比它早，主设备A只能放弃占用总线。如果SDA是高电平，说明主设备A可以占用总线，然后主设备A将SDA拉低，开始通信。
因此，模拟I2C一定要将GPIO端口设置为开漏输出并加上拉电阻。
]]></content>
  </entry>
  
  <entry>
    <title>Linux编程之经典多级时间轮定时器</title>
    <url>/post/linux/linux-programming-multiple-time-wheel-timer.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>timer</tag>
    </tags>
    <content type="html"><![CDATA[mmap用于把文件映射到内存空间中，简单说mmap就是把一个文件的内容在内存里面做一个映像。
多级时间轮实现框架 上图是5个时间轮级联的效果图。中间的大轮是工作轮，只有在它上的任务才会被执行；其他轮上的任务时间到后迁移到下一级轮上，他们最终都会迁移到工作轮上而被调度执行。
多级时间轮的原理也容易理解：就拿时钟做说明，秒针转动一圈分针转动一格；分针转动一圈时针转动一格；同理时间轮也是如此：当低级轮转动一圈时，高一级轮转动一格，同时会将高一级轮上的任务重新分配到低级轮上。从而实现了多级轮级联的效果。
多级时间轮对象 多级时间轮应该至少包括以下内容：
 每一级时间轮对象 轮子上指针的位置 关于轮子上指针的位置有一个比较巧妙的办法：那就是位运算。比如定义一个无符号整型的数：  通过获取当前的系统时间便可以通过位操作转换为时间轮上的时间，通过与实际时间轮上的时间作比较，从而确定时间轮要前进调度的时间，进而操作对应时间轮槽位对应的任务。
为什么至少需要这两个成员呢？
 定义多级时间轮，首先需要明确的便是级联的层数，也就是说需要确定有几个时间轮。 轮子上指针位置，就是当前时间轮运行到的位置，它与真实时间的差便是后续时间轮需要调度执行，它们的差值是时间轮运作起来的驱动力。  多级时间轮对象的定义
//实现5级时间轮 范围为0~ (2^8 * 2^6 * 2^6 * 2^6 *2^6)=2^32 struct tvec_base { unsigned long current_index; pthread_t thincrejiffies; pthread_t threadID; struct tvec_root tv1; /*第一个轮*/ struct tvec tv2; /*第二个轮*/ struct tvec tv3; /*第三个轮*/ struct tvec tv4; /*第四个轮*/ struct tvec tv5; /*第五个轮*/ }; 时间轮对象 我们知道每一个轮子实际上都是一个哈希表，上面我们只是实例化了五个轮子的对象，但是五个轮子具体包含什么，有几个槽位等等没有明确(即struct tvec和struct tvec_root)。
#define TVN_BITS 6 #define TVR_BITS 8 #define TVN_SIZE (1&lt;&lt;TVN_BITS) #define TVR_SIZE (1&lt;&lt;TVR_BITS) struct tvec { struct list_head vec[TVN_SIZE];/*64个格子*/ }; struct tvec_root{ struct list_head vec[TVR_SIZE];/*256个格子*/ }; 此外，每一个时间轮都是哈希表，因此它的类型应该至少包含两个指针域来实现双向链表的功能。这里我们为了方便使用通用的struct list_head的双向链表结构。
定时任务对象 定时器的主要工作是为了在未来的特定时间完成某项任务，而这个任务经常包含以下内容：
 任务的处理逻辑(回调函数) 任务的参数 双向链表节点 到时时间  定时任务对象的定义
typedef void (*timeouthandle)(unsigned long ); struct timer_list{ struct list_head entry; //将时间连接成链表  unsigned long expires; //超时时间  void (*function)(unsigned long); //超时后的处理函数  unsigned long data; //处理函数的参数  struct tvec_base *base; //指向时间轮 }; 在时间轮上的效果图：
双向链表 在时间轮上我们采用双向链表的数据类型。采用双向链表的除了操作上比单链表复杂，多占一个指针域外没有其他不可接收的问题。而多占一个指针域在今天大内存的时代明显不是什么问题。至于双向链表操作的复杂性，我们可以通过使用通用的struct list结构来解决，因为双向链表有众多的标准操作函数，我们可以通过直接引用list.h头文件来使用他们提供的接口。
struct list可以说是一个万能的双向链表操作框架，我们只需要在自定义的结构中定义一个struct list对象即可使用它的标准操作接口。同时它还提供了一个类似container_of的接口，在应用层一般叫做list_entry，因此我们可以很方便的通过struct list成员找到自定义的结构体的起始地址。
关于应用层的log.h, 我将在下面的代码中附上该文件。如果需要内核层的实现，可以直接从linux源码中获取。
联结方式 多级时间轮效果图：
多级时间轮C语言实现 双向链表头文件: list.h 提到双向链表，很多的源码工程中都会实现一系列的统一的双向链表操作函数。它们为双向链表封装了统计的接口，使用者只需要在自定义的结构中添加一个struct list_head结构，然后调用它们提供的接口，便可以完成双向链表的所有操作。这些操作一般都在list.h的头文件中实现。Linux源码中也有实现（内核态的实现）。他们实现的方式基本完全一样，只是实现的接口数量和功能上稍有差别。可以说这个list.h文件是学习操作双向链表的不二选择，它几乎实现了所有的操作：增、删、改、查、遍历、替换、清空等等。这里我拼凑了一个源码中的log.h函数，终于凑够了多级时间轮中使用到的接口。
#if !defined(_BLKID_LIST_H) &amp;&amp; !defined(LIST_HEAD) #define _BLKID_LIST_H #ifdef __cplusplus extern &#34;C&#34; { #endif /* * Simple doubly linked list implementation. * * Some of the internal functions (&#34;__xxx&#34;) are useful when * manipulating whole lists rather than single entries, as * sometimes we already know the next/prev entries and we can * generate better code by using them directly rather than * using the generic single-entry routines. */ struct list_head { struct list_head *next, *prev; }; #define LIST_HEAD_INIT(name) { &amp;(name), &amp;(name) } #define LIST_HEAD(name) \ struct list_head name = LIST_HEAD_INIT(name) #define INIT_LIST_HEAD(ptr) do { \ (ptr)-&gt;next = (ptr); (ptr)-&gt;prev = (ptr); \ } while (0) static inline void __list_add(struct list_head *entry, struct list_head *prev, struct list_head *next) { next-&gt;prev = entry; entry-&gt;next = next; entry-&gt;prev = prev; prev-&gt;next = entry; } /** * Insert a new element after the given list head. The new element does not * need to be initialised as empty list. * The list changes from: * head → some element → ... * to * head → new element → older element → ... * * Example: * struct foo *newfoo = malloc(...); * list_add(&amp;newfoo-&gt;entry, &amp;bar-&gt;list_of_foos); * * @param entry The new element to prepend to the list. * @param head The existing list. */ static inline void list_add(struct list_head *entry, struct list_head *head) { __list_add(entry, head, head-&gt;next); } /** * Append a new element to the end of the list given with this list head. * * The list changes from: * head → some element → ... → lastelement * to * head → some element → ... → lastelement → new element * * Example: * struct foo *newfoo = malloc(...); * list_add_tail(&amp;newfoo-&gt;entry, &amp;bar-&gt;list_of_foos); * * @param entry The new element to prepend to the list. * @param head The existing list. */ static inline void list_add_tail(struct list_head *entry, struct list_head *head) { __list_add(entry, head-&gt;prev, head); } static inline void __list_del(struct list_head *prev, struct list_head *next) { next-&gt;prev = prev; prev-&gt;next = next; } /** * Remove the element from the list it is in. Using this function will reset * the pointers to/from this element so it is removed from the list. It does * NOT free the element itself or manipulate it otherwise. * * Using list_del on a pure list head (like in the example at the top of * this file) will NOT remove the first element from * the list but rather reset the list as empty list. * * Example: * list_del(&amp;foo-&gt;entry); * * @param entry The element to remove. */ static inline void list_del(struct list_head *entry) { __list_del(entry-&gt;prev, entry-&gt;next); } static inline void list_del_init(struct list_head *entry) { __list_del(entry-&gt;prev, entry-&gt;next); INIT_LIST_HEAD(entry); } static inline void list_move_tail(struct list_head *list, struct list_head *head) { __list_del(list-&gt;prev, list-&gt;next); list_add_tail(list, head); } /** * Check if the list is empty. * * Example: * list_empty(&amp;bar-&gt;list_of_foos); * * @return True if the list contains one or more elements or False otherwise. */ static inline int list_empty(struct list_head *head) { return head-&gt;next == head; } /** * list_replace - replace old entry by new one * @old : the element to be replaced * @new : the new element to insert * * If @old was empty, it will be overwritten. */ static inline void list_replace(struct list_head *old, struct list_head *new) { new-&gt;next = old-&gt;next; new-&gt;next-&gt;prev = new; new-&gt;prev = old-&gt;prev; new-&gt;prev-&gt;next = new; } /** * Retrieve the first list entry for the given list pointer. * * Example: * struct foo *first; * first = list_first_entry(&amp;bar-&gt;list_of_foos, struct foo, list_of_foos); * * @param ptr The list head * @param type Data type of the list element to retrieve * @param member Member name of the struct list_head field in the list element. * @return A pointer to the first list element. */ #define list_first_entry(ptr, type, member) \ list_entry((ptr)-&gt;next, type, member) static inline void list_replace_init(struct list_head *old, struct list_head *new) { list_replace(old, new); INIT_LIST_HEAD(old); } /** * list_entry - get the struct for this entry * @ptr: the &amp;struct list_head pointer. * @type: the type of the struct this is embedded in. * @member: the name of the list_struct within the struct. */ #define list_entry(ptr, type, member) \ ((type *)((char *)(ptr)-(unsigned long)(&amp;((type *)0)-&gt;member))) /** * list_for_each - iterate over elements in a list * @pos: the &amp;struct list_head to use as a loop counter. * @head: the head for your list. */ #define list_for_each(pos, head) \ for (pos = (head)-&gt;next; pos != (head); pos = pos-&gt;next) /** * list_for_each_safe - iterate over elements in a list, but don&#39;t dereference * pos after the body is done (in case it is freed) * @pos: the &amp;struct list_head to use as a loop counter. * @pnext: the &amp;struct list_head to use as a pointer to the next item. * @head: the head for your list (not included in iteration). */ #define list_for_each_safe(pos, pnext, head) \ for (pos = (head)-&gt;next, pnext = pos-&gt;next; pos != (head); \ pos = pnext, pnext = pos-&gt;next) #ifdef __cplusplus } #endif #endif /* _BLKID_LIST_H */这里面一般会用到一个重要实现：container_of, 它的原理这里不叙述
调试信息头文件: log.h 这个头文件实际上不是必须的，我只是用它来添加调试信息(代码中的errlog(), log()都是log.h中的宏函数)。它的效果是给打印的信息加上颜色，效果如下：
log.h的代码如下：
#ifndef _LOG_h_ #define _LOG_h_ #include &lt;stdio.h&gt;#define COL(x) &#34;\033[;&#34; #x &#34;m&#34; #define RED COL(31) #define GREEN COL(32) #define YELLOW COL(33) #define BLUE COL(34) #define MAGENTA COL(35) #define CYAN COL(36) #define WHITE COL(0) #define GRAY &#34;\033[0m&#34; #define errlog(fmt, arg...) do{ \ printf(RED&#34;[#ERROR: Toeny Sun:&#34;GRAY YELLOW&#34; %s:%d]:&#34;GRAY WHITE fmt GRAY, __func__, __LINE__, ##arg);\ }while(0) #define log(fmt, arg...) do{ \ printf(WHITE&#34;[#DEBUG: Toeny Sun: &#34;GRAY YELLOW&#34;%s:%d]:&#34;GRAY WHITE fmt GRAY, __func__, __LINE__, ##arg);\ }while(0) #endif 时间轮代码: timewheel.c /* *毫秒定时器 采用多级时间轮方式 借鉴linux内核中的实现 *支持的范围为1 ~ 2^32 毫秒(大约有49天) *若设置的定时器超过最大值 则按最大值设置定时器 **/ #include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;pthread.h&gt;#include &lt;sys/time.h&gt;#include &#34;list.h&#34;#include &#34;log.h&#34; #define TVN_BITS 6 #define TVR_BITS 8 #define TVN_SIZE (1&lt;&lt;TVN_BITS) #define TVR_SIZE (1&lt;&lt;TVR_BITS)  #define TVN_MASK (TVN_SIZE - 1) #define TVR_MASK (TVR_SIZE - 1)  #define SEC_VALUE 0 #define USEC_VALUE 2000  struct tvec_base; #define INDEX(N) ((ba-&gt;current_index &gt;&gt; (TVR_BITS + (N) * TVN_BITS)) &amp; TVN_MASK)  typedef void (*timeouthandle)(unsigned long ); struct timer_list{ struct list_head entry; //将时间连接成链表  unsigned long expires; //超时时间  void (*function)(unsigned long); //超时后的处理函数  unsigned long data; //处理函数的参数  struct tvec_base *base; //指向时间轮 }; struct tvec { struct list_head vec[TVN_SIZE]; }; struct tvec_root{ struct list_head vec[TVR_SIZE]; }; //实现5级时间轮 范围为0~ (2^8 * 2^6 * 2^6 * 2^6 *2^6)=2^32 struct tvec_base { unsigned long current_index; pthread_t thincrejiffies; pthread_t threadID; struct tvec_root tv1; /*第一个轮*/ struct tvec tv2; /*第二个轮*/ struct tvec tv3; /*第三个轮*/ struct tvec tv4; /*第四个轮*/ struct tvec tv5; /*第五个轮*/ }; static void internal_add_timer(struct tvec_base *base, struct timer_list *timer) { struct list_head *vec; unsigned long expires = timer-&gt;expires; unsigned long idx = expires - base-&gt;current_index; #if 1  if( (signed long)idx &lt; 0 ) /*这里是没有办法区分出是过时还是超长定时的吧?*/ { vec = base-&gt;tv1.vec + (base-&gt;current_index &amp; TVR_MASK);/*放到第一个轮的当前槽*/ } else if ( idx &lt; TVR_SIZE ) /*第一个轮*/ { int i = expires &amp; TVR_MASK; vec = base-&gt;tv1.vec + i; } else if( idx &lt; 1 &lt;&lt; (TVR_BITS + TVN_BITS) )/*第二个轮*/ { int i = (expires &gt;&gt; TVR_BITS) &amp; TVN_MASK; vec = base-&gt;tv2.vec + i; } else if( idx &lt; 1 &lt;&lt; (TVR_BITS + 2 * TVN_BITS) )/*第三个轮*/ { int i = (expires &gt;&gt; (TVR_BITS + TVN_BITS)) &amp; TVN_MASK; vec = base-&gt;tv3.vec + i; } else if( idx &lt; 1 &lt;&lt; (TVR_BITS + 3 * TVN_BITS) )/*第四个轮*/ { int i = (expires &gt;&gt; (TVR_BITS + 2 * TVN_BITS)) &amp; TVN_MASK; vec = base-&gt;tv4.vec + i; } else /*第五个轮*/ { int i; if (idx &gt; 0xffffffffUL) { idx = 0xffffffffUL; expires = idx + base-&gt;current_index; } i = (expires &gt;&gt; (TVR_BITS + 3 * TVN_BITS)) &amp; TVN_MASK; vec = base-&gt;tv5.vec + i; } #else  /*上面可以优化吧*/; #endif  list_add_tail(&amp;timer-&gt;entry, vec); } static inline void detach_timer(struct timer_list *timer) { struct list_head *entry = &amp;timer-&gt;entry; __list_del(entry-&gt;prev, entry-&gt;next); entry-&gt;next = NULL; entry-&gt;prev = NULL; } static int __mod_timer(struct timer_list *timer, unsigned long expires) { if(NULL != timer-&gt;entry.next) detach_timer(timer); internal_add_timer(timer-&gt;base, timer); return 0; } //修改定时器的超时时间外部接口 int mod_timer(void *ptimer, unsigned long expires) { struct timer_list *timer = (struct timer_list *)ptimer; struct tvec_base *base; base = timer-&gt;base; if(NULL == base) return -1; expires = expires + base-&gt;current_index; if(timer-&gt;entry.next != NULL &amp;&amp; timer-&gt;expires == expires) return 0; if( NULL == timer-&gt;function ) { errlog(&#34;timer&#39;s timeout function is null\n&#34;); return -1; } timer-&gt;expires = expires; return __mod_timer(timer,expires); } //添加一个定时器 static void __ti_add_timer(struct timer_list *timer) { if( NULL != timer-&gt;entry.next ) { errlog(&#34;timer is already exist\n&#34;); return; } mod_timer(timer, timer-&gt;expires); } /*添加一个定时器 外部接口 *返回定时器 */ void* ti_add_timer(void *ptimewheel, unsigned long expires,timeouthandle phandle, unsigned long arg) { struct timer_list *ptimer; ptimer = (struct timer_list *)malloc( sizeof(struct timer_list) ); if(NULL == ptimer) return NULL; bzero( ptimer,sizeof(struct timer_list) ); ptimer-&gt;entry.next = NULL; ptimer-&gt;base = (struct tvec_base *)ptimewheel; ptimer-&gt;expires = expires; ptimer-&gt;function = phandle; ptimer-&gt;data = arg; __ti_add_timer(ptimer); return ptimer; } /* *删除一个定时器 外部接口 * * */ void ti_del_timer(void *p) { struct timer_list *ptimer =(struct timer_list*)p; if(NULL == ptimer) return; if(NULL != ptimer-&gt;entry.next) detach_timer(ptimer); free(ptimer); } /*时间轮级联*/ static int cascade(struct tvec_base *base, struct tvec *tv, int index) { struct list_head *pos,*tmp; struct timer_list *timer; struct list_head tv_list; /*将tv[index]槽位上的所有任务转移给tv_list,然后清空tv[index]*/ list_replace_init(tv-&gt;vec + index, &amp;tv_list);/*用tv_list替换tv-&gt;vec + index*/ list_for_each_safe(pos, tmp, &amp;tv_list)/*遍历tv_list双向链表，将任务重新添加到时间轮*/ { timer = list_entry(pos,struct timer_list,entry);/*struct timer_list中成员entry的地址是pos, 获取struct timer_list的首地址*/ internal_add_timer(base, timer); } return index; } static void *deal_function_timeout(void *base) { struct timer_list *timer; int ret; struct timeval tv; struct tvec_base *ba = (struct tvec_base *)base; for(;;) { gettimeofday(&amp;tv, NULL); while( ba-&gt;current_index &lt;= (tv.tv_sec*1000 + tv.tv_usec/1000) )/*单位：ms*/ { struct list_head work_list; int index = ba-&gt;current_index &amp; TVR_MASK;/*获取第一个轮上的指针位置*/ struct list_head *head = &amp;work_list; /*指针指向0槽时，级联轮需要更新任务列表*/ if(!index &amp;&amp; (!cascade(ba, &amp;ba-&gt;tv2, INDEX(0))) &amp;&amp;( !cascade(ba, &amp;ba-&gt;tv3, INDEX(1))) &amp;&amp; (!cascade(ba, &amp;ba-&gt;tv4, INDEX(2))) ) cascade(ba, &amp;ba-&gt;tv5, INDEX(3)); ba-&gt;current_index ++; list_replace_init(ba-&gt;tv1.vec + index, &amp;work_list); while(!list_empty(head)) { void (*fn)(unsigned long); unsigned long data; timer = list_first_entry(head, struct timer_list, entry); fn = timer-&gt;function; data = timer-&gt;data; detach_timer(timer); (*fn)(data); } } } } static void init_tvr_list(struct tvec_root * tvr) { int i; for( i = 0; i&lt;TVR_SIZE; i++ ) INIT_LIST_HEAD(&amp;tvr-&gt;vec[i]); } static void init_tvn_list(struct tvec * tvn) { int i; for( i = 0; i&lt;TVN_SIZE; i++ ) INIT_LIST_HEAD(&amp;tvn-&gt;vec[i]); } //创建时间轮 外部接口 void *ti_timewheel_create(void ) { struct tvec_base *base; int ret = 0; struct timeval tv; base = (struct tvec_base *) malloc( sizeof(struct tvec_base) ); if( NULL==base ) return NULL; bzero( base,sizeof(struct tvec_base) ); init_tvr_list(&amp;base-&gt;tv1); init_tvn_list(&amp;base-&gt;tv2); init_tvn_list(&amp;base-&gt;tv3); init_tvn_list(&amp;base-&gt;tv4); init_tvn_list(&amp;base-&gt;tv5); gettimeofday(&amp;tv, NULL); base-&gt;current_index = tv.tv_sec*1000 + tv.tv_usec/1000;/*当前时间毫秒数*/ if( 0 != pthread_create(&amp;base-&gt;threadID,NULL,deal_function_timeout,base) ) { free(base); return NULL; } return base; } static void ti_release_tvr(struct tvec_root *pvr) { int i; struct list_head *pos,*tmp; struct timer_list *pen; for(i = 0; i &lt; TVR_SIZE; i++) { list_for_each_safe(pos,tmp,&amp;pvr-&gt;vec[i]) { pen = list_entry(pos,struct timer_list, entry); list_del(pos); free(pen); } } } static void ti_release_tvn(struct tvec *pvn) { int i; struct list_head *pos,*tmp; struct timer_list *pen; for(i = 0; i &lt; TVN_SIZE; i++) { list_for_each_safe(pos,tmp,&amp;pvn-&gt;vec[i]) { pen = list_entry(pos,struct timer_list, entry); list_del(pos); free(pen); } } } /* *释放时间轮 外部接口 * */ void ti_timewheel_release(void * pwheel) { struct tvec_base *base = (struct tvec_base *)pwheel; if(NULL == base) return; ti_release_tvr(&amp;base-&gt;tv1); ti_release_tvn(&amp;base-&gt;tv2); ti_release_tvn(&amp;base-&gt;tv3); ti_release_tvn(&amp;base-&gt;tv4); ti_release_tvn(&amp;base-&gt;tv5); free(pwheel); } /************demo****************/ struct request_para{ void *timer; int val; }; void mytimer(unsigned long arg) { struct request_para *para = (struct request_para *)arg; log(&#34;%d\n&#34;,para-&gt;val); mod_timer(para-&gt;timer,3000); //进行再次启动定时器  sleep(10);/*定时器依然被阻塞*/ //定时器资源的释放是在这里完成的  //ti_del_timer(para-&gt;timer); } int main(int argc,char *argv[]) { void *pwheel = NULL; void *timer = NULL; struct request_para *para; para = (struct request_para *)malloc( sizeof(struct request_para) ); if(NULL == para) return 0; bzero(para,sizeof(struct request_para)); //创建一个时间轮  pwheel = ti_timewheel_create(); if(NULL == pwheel) return -1; //添加一个定时器  para-&gt;val = 100; para-&gt;timer = ti_add_timer(pwheel, 3000, &amp;mytimer, (unsigned long)para); while(1) { sleep(2); } //释放时间轮  ti_timewheel_release(pwheel); return 0; } 编译运行 peng@ubuntu:/mnt/hgfs/timer/4. timerwheel/2. 多级时间轮$ ls a.out list.h log.h mutiTimeWheel.c toney@ubantu:/mnt/hgfs/timer录/4. timerwheel/2. 多级时间轮$ gcc mutiTimeWheel.c -lpthread toney@ubantu:/mnt/hgfs/timer/4. timerwheel/2. 多级时间轮$ ./a.out [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 [#DEBUG: Toeny Sun: mytimer:370]:100 从结果可以看出：如果添加的定时任务是比较耗时的操作，那么后续的任务也会被阻塞，可能一直到超时，甚至一直阻塞下去，这个取决于当前任务是否耗时。
这个理论上是绝不能接受的：一个任务不应该也不能去影响其他的任务吧。但是目前没有对此问题进行改进和完善，以后有机会再继续完善吧。
]]></content>
  </entry>
  
  <entry>
    <title>Linux mmap内存映射详解</title>
    <url>/post/linux/linux-mmap-explanation.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>device driver</tag>
    </tags>
    <content type="html"><![CDATA[mmap用于把文件映射到内存空间中，简单说mmap就是把一个文件的内容在内存里面做一个映像。
mmap基础概念 mmap是一种内存映射的方法，这一功能可以用在文件的处理上，即将一个文件或者其它对象映射到进程的地址空间，实现文件磁盘地址和进程虚拟地址空间中一段虚拟地址的一一对映关系。在编程时可以使某个磁盘文件的内容看起来像是内存中的一个数组。如果文件由记录组成，而这些记录又能够用结构体来描述的话，可以通过访问结构体来更新文件的内容。
实现这样的映射关系后，进程就可以采用指针的方式读写操作这一段内存，而系统会自动回写到页面到对应的文件磁盘上，即完成了对文件的操作而不必再调用read,write等系统调用函数。内核空间对这段区域的修改也直接反映用户空间，从而可以实现不同进程间的文件共享。如图所示：
进程的虚拟地址空间，由多个虚拟内存区域构成。虚拟内存区域是进程的虚拟地址空间中的一个同质区间，即具有同样特性的连续地址范围。上图中所示的text数据段（代码段）、初始数据段、BSS数据段、堆、栈和内存映射，都是一个独立的虚拟内存区域。而为内存映射服务的地址空间处在堆栈之间的空余部分。
内核为系统中的每个进程维护一个单独的任务结构（task_struct）。任务结构中的元素包含或者指向内核运行该进程所需的所有信息(PID、指向用户栈的指针、可执行目标文件的名字、程序计数器等)。Linux内核使用vm_area_struct结构来表示一个独立的虚拟内存区域，由于每个不同质的虚拟内存区域功能和内部机制都不同，因此一个进程使用多个vm_area_struct结构来分别表示不同类型的虚拟内存区域。各个vm_area_struct结构使用链表或者树形结构链接，方便进程快速访问，如下图所示：
vm_area_struct结构中包含区域起始和终止地址以及其他相关信息，同时也包含一个vm_ops指针，其内部可引出所有针对这个区域可以使用的系统调用函数。这样，进程对某一虚拟内存区域的任何操作需要用要的信息，都可以从vm_area_struct中获得。mmap函数就是要创建一个新的vm_area_struct结构，并将其与文件的物理磁盘地址相连。
mm_struct：描述了虚拟内存的当前状态。pgd指向一级页表的基址（当内核运行这个进程时， pgd会被存放在CR3控制寄存器，也就是页表基址寄存器中），mmap指向一个vm_area_structs 的链表，其中每个vm_area_structs都描述了当前虚拟地址空间的一个区域。 vm_starts 指向这个区域的起始处。 vm_end 指向这个区域的结束处。 vm_prot 描述这个区域内包含的所有页的读写许可权限。 vm_flags 描述这个区域内的页面是与其他进程共享的，还是这个进程私有的以及一些其他信息。 vm_next 指向链表的下一个区域结构。  mmap内存映射原理 mmap内存映射的实现过程，总的来说可以分为三个阶段：
(一)启动映射过程，并在虚拟地址空间中为映射创建虚拟映射区域    进程在用户空间调用库函数mmap，原型：void *mmap(void *start, size_t length, int prot, int flags, int fd, off_t offset);
  在当前进程的虚拟地址空间中，寻找一段空闲的满足要求的连续的虚拟地址。
  为此虚拟区分配一个vm_area_struct结构，接着对这个结构的各个域进行了初始化。
  将新建的虚拟区结构（vm_area_struct）插入进程的虚拟地址区域链表或树中。
  (二)调用内核空间的系统调用函数mmap（不同于用户空间函数），实现文件物理地址和进程虚拟地址的一一映射关系   为映射分配了新的虚拟地址区域后，通过待映射的文件指针，在文件描述符表中找到对应的文件描述符，通过文件描述符，链接到内核“已打开文件集”中该文件的文件结构体（struct file），每个文件结构体维护者和这个已打开文件相关的各项信息。
  通过该文件的文件结构体，链接到file_operations模块，调用内核函数mmap，其原型为：int mmap(struct file *filp, struct vm_area_struct *vma)，不同于用户空间库函数。
  内核mmap函数通过虚拟文件系统inode模块定位到文件磁盘物理地址。
  通过remap_pfn_range函数建立页表，即实现了文件地址和虚拟地址区域的映射关系。此时，这片虚拟地址并没有任何数据关联到主存中。
  (三)进程发起对这片映射空间的访问，引发缺页异常，实现文件内容到物理内存（主存）的拷贝  注：前两个阶段仅在于创建虚拟区间并完成地址映射，但是并没有将任何文件数据的拷贝至主存。真正的文件读取是当进程发起读写操作时。
 进程的读或写操作访问虚拟地址空间这一段映射地址，通过查询页表，发现这一段地址并不在物理页面上。因为目前只建立了地址映射，真正的硬盘数据还没有拷贝到内存中，因此引发缺页异常。
  缺页异常进行一系列判断，确定无非法操作后，内核发起请求调页过程。
  调页过程先在交换缓存空间（swap cache）中寻找需要访问的内存页，如果没有则调用nopage函数把所缺的页从磁盘装入到主存中。
  之后进程即可对这片主存进行读或者写的操作，如果写操作改变了其内容，一定时间后系统会自动回写脏页面到对应磁盘地址，也即完成了写入到文件的过程。
  注意：修改过的脏页面并不会立即更新回文件中，而是有一段时间的延迟，可以调用msync()来强制同步, 这样所写的内容就能立即保存到文件里了。
mmap 示例代码 mmap (内存映射)函数的作用是建立一段可以被两个或更多个程序读写的内存。一个程序对它所做出的修改可以被其他程序看见。这要通过使用带有特殊权限集的虚拟内存段来实现。对这类虚拟内存段的读写会使操作系统去读写磁盘文件中与之对应的部分。mmap 函数创建一个指向一段内存区域的指针，该内存区域与可以通过一个打开的文件描述符访问的文件的内容相关联。mmap 函数原型如下：
#include &lt;sys/mman.h&gt;void *mmap(void *addr, size_t length, int prot, int flags, int fd, off_t offset); 可以通过传递 off 参数来改变共享内存段访问的文件中数据的起始偏移值。打开的文件描述符由 fildes 参数给出。可以访问的数据量(即内存段的长度)由 len 参数设置。
可以通过 addr 参数来请求使用某个特定的内存地址。如果它的取值是零，结果指针就将自动分配。这是推荐的做法，否则会降低程序的可移植性，因为不同系统上的可用地址范围是不一样的。
prot 参数用于设置内存段的访问权限。它是下列常数值的按位或的结果：
PROT_READ 内存段可读。 PROT_WRITE 内存段可写。 PROT_EXEC 内存段可执行。 PROT_NONE 内存段不能被访问。 flags 参数控制程序对该内存段的改变所造成的影响：
msync 函数的作用是：把在该内存段的某个部分或整段中的修改写回到被映射的文件中(或者从被映射文件里读出)。
#include &lt;sys/mman.h&gt;int msync(void *addr, size_t len, int flags); 内存段需要修改的部分由作为参数传递过来的起始地址 addr 和长度 len 确定。flags 参数控制着执行修改的具体方式，可以使用的选项如下：
MS_ASYNC 采用异步写方式 MS_SYNC 采用同步写方式 MS_INVALIDATE 从文件中读回数据 munmap 函数的作用是释放内存段：
#include &lt;sys/mman.h&gt;int munmap(void *addr, size_t length); 示例代码：
(1) 定义一个 RECORD 数据结构，然后创建出 NRECORDS 每个记录，每个记录中保存着它们各自的编号。然后把这些记录都追加到文件 records.dat 里去。
(2) 接着，把第 43 记录中的整数值由 43 修改为 143，并把它写入第 43 条记录中的字符串。
(3) 把这些记录映射到内存中，然后访问第 43 条记录，把它的整数值修改为 243 (同时更新该记录中的字符串)，使用的还是内存映射的方法。
可以将上述 (2) (3) 分别编写程序验证结果。
#include &lt;unistd.h&gt;#include &lt;stdio.h&gt;#include &lt;sys/mman.h&gt;#include &lt;fcntl.h&gt;#include &lt;stdlib.h&gt;typedef struct{ int integer; char string[24]; }RECORD; #define NRECORDS (100) int main() { RECORD record, *mapped; int i, f; FILE *fp; fp = fopen(&#34;records.dat&#34;, &#34;w+&#34;); for( i = 0; i &lt; NRECORDS; i++) { record.integer = i; sprintf(record.string, &#34;[RECORD-%d]&#34;, i); fwrite(&amp;record, sizeof(record), 1, fp); } fclose(fp); fp = fopen(&#34;records.dat&#34;, &#34;r+&#34;); fseek(fp, 43 * sizeof(record), SEEK_SET); fread(&amp;record, sizeof(record), 1, fp); record.integer = 143; sprintf(record.string, &#34;[RECORD-%d]&#34;, record.integer); fseek(fp, 43 * sizeof(record), SEEK_SET); fwrite(&amp;record, sizeof(record), 1, fp); fclose(fp); f = open(&#34;records.dat&#34;, O_RDWR); mapped = (RECORD*)mmap(0, NRECORDS * sizeof(record), PROT_READ | PROT_WRITE, MAP_SHARED, f, 0); printf(&#34;f:[%d]\n&#34;, f); //open是系统调用，返回文件描述符。fopen是库函数，返回指针。 	mapped[43].integer = 243; sprintf(mapped[43].string, &#34;[RECORD-%d]&#34;, mapped[43].integer); msync((void *) mapped, NRECORDS * sizeof(record), MS_ASYNC); munmap((void *)mapped, NRECORDS * sizeof(record)); close(f); return 0;	} mmap 和常规文件操作的区别 使用系统调用，函数的调用过程：
  进程发起读文件请求。
  内核通过查找进程文件描述符表，定位到内核已打开文件集上的文件信息，从而找到此文件的inode。
  inode在address_space上查找要请求的文件页是否已经缓存在页缓存中。如果存在，则直接返回这片文件页的内容。
  如果不存在，则通过inode定位到文件磁盘地址，将数据从磁盘复制到页缓存。之后再次发起读页面过程，进而将页缓存中的数据发给用户进程。
  总结来说，常规文件操作为了提高读写效率和保护磁盘，使用了页缓存机制。这样造成读文件时需要先将文件页从磁盘拷贝到页缓存中，由于页缓存处在内核空间，不能被用户进程直接寻址，所以还需要将页缓存中数据页再次拷贝到内存对应的用户空间中。这样，通过了两次数据拷贝过程，才能完成进程对文件内容的获取任务。写操作也是一样，待写入的buffer在内核空间不能直接访问，必须要先拷贝至内核空间对应的主存，再写回磁盘中（延迟写回），也是需要两次数据拷贝。
而使用mmap操作文件中，创建新的虚拟内存区域和建立文件磁盘地址和虚拟内存区域映射这两步，没有任何文件拷贝操作。而之后访问数据时发现内存中并无数据而发起的缺页异常过程，可以通过已经建立好的映射关系，只使用一次数据拷贝，就从磁盘中将数据传入内存的用户空间中，供进程使用。
总而言之，常规文件操作需要从磁盘到页缓存再到用户主存的两次数据拷贝。而mmap操控文件，只需要从磁盘到用户主存的一次数据拷贝过程。说白了，mmap的关键点是实现了用户空间和内核空间的数据直接交互而省去了空间不同、数据不通的繁琐过程。因此mmap效率更高。
由上文讨论可知，mmap优点共有一下几点：
  对文件的读取操作跨过了页缓存，减少了数据的拷贝次数，用内存读写取代I/O读写，提高了文件读取效率。
  实现了用户空间和内核空间的高效交互方式。两空间的各自修改操作可以直接反映在映射的区域内，从而被对方空间及时捕捉。
  提供进程间共享内存及相互通信的方式。不管是父子进程还是无亲缘关系的进程，都可以将自身用户空间映射到同一个文件或匿名映射到同一片区域。从而通过各自对映射区域的改动，达到进程间通信和进程间共享的目的。
  同时，如果进程A和进程B都映射了区域C，当A第一次读取C时通过缺页从磁盘复制文件页到内存中；但当B再读C的相同页面时，虽然也会产生缺页异常，但是不再需要从磁盘中复制文件过来，而可直接使用已经保存在内存中的文件数据。
可用于实现高效的大规模数据传输。内存空间不足，是制约大数据操作的一个方面，解决方案往往是借助硬盘空间协助操作，补充内存的不足。但是进一步会造成大量的文件I/O操作，极大影响效率。这个问题可以通过mmap映射很好的解决。换句话说，但凡是需要用磁盘空间代替内存的时候，mmap都可以发挥其功效。  mmap 使用的细节   使用mmap需要注意的一个关键点是，mmap映射区域大小必须是物理页大小(page_size)的整倍数（32位系统中通常是4k字节）。原因是，内存的最小粒度是页，而进程虚拟地址空间和内存的映射也是以页为单位。为了匹配内存的操作，mmap从磁盘到虚拟地址空间的映射也必须是页。
  内核可以跟踪被内存映射的底层对象（文件）的大小，进程可以合法的访问在当前文件大小以内又在内存映射区以内的那些字节。也就是说，如果文件的大小一直在扩张，只要在映射区域范围内的数据，进程都可以合法得到，这和映射建立时文件的大小无关。
  映射建立之后，即使文件关闭，映射依然存在。因为映射的是磁盘的地址，不是文件本身，和文件句柄无关。同时可用于进程间通信的有效地址空间不完全受限于被映射文件的大小，因为是按页映射。
 ]]></content>
  </entry>
  
  <entry>
    <title>几道简单的Linux驱动相关面试题</title>
    <url>/post/linux/linux-device-driver-questions-and-answers.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>linux</tag>
      <tag>device driver</tag>
    </tags>
    <content type="html"><![CDATA[今天给大家分享几道Linux设备驱动相关的面试题，希望能对需要的网友一些帮助！
Linux基础 任意3种网络操作的Linux命令,并说明他们的含义 ifconfig 命令 ifconfig 用于查看和配置 Linux 系统的网络接口。 查看所有网络接口及其状态：ifconfig -a 。 使用 up 和 down 命令启动或停止某个接口：ifconfig eth0 up 和 ifconfig eth0 down 。
iptables 命令 iptables ，是一个配置 Linux 内核防火墙的命令行工具。功能非常强大，对于我们开发来说，主要掌握如何开放端口即可。
netstat 命令 Linux netstat命令用于显示网络状态。
利用netstat指令可让你得知整个Linux系统的网络情况。
ping 命令 Linux ping命令用于检测主机。
执行ping指令会使用ICMP传输协议，发出要求回应的信息，若远端主机的网络功能没有问题，就会回应该信息，因而得知该主机运作正常。
telnet 命令 Linux telnet命令用于远端登入。
执行telnet指令开启终端机阶段作业，并登入远端主机。
Linux支持的文件类型  普通文件类型 - 目录文件类型 d 块设备文件类型 b 字符设备类型 c 套接字文件类型 s FIFO管道文件类型 p 链接文件类型 l  Linux系统编程 嵌入式操作系统进程间有哪些同步通信服务？ Linux进程间通信方式主要有  信号(signal) 信号量 管道(pipe)、流管道(s_pipe)、有名管道(FIFO)。 消息队列 共享内存 套接字（本地的还有域套接字）  ARM 请问ARM支持哪几种异常类型？ 异常源分类
要进入异常模式，一定要有异常源，ARM规定有7种异常源：
   异常源 描述     Reset 上电时执行   Undef 当流水线中的某个非法指令到达执行状态时执行   SWI 当一个软中断指令被执行完的时候执行   Prefetch 当一个指令被从内存中预取时，由于某种原因而失败，如果它能到达执行状态这个异常才会产生   Data 如果一个预取指令试图存取一个非法的内存单元，这时异常产生   IRQ 通常的中断   FIQ 快速中断    请简述什么是中断？中断发生后，CPU做了哪些操作 中断：是指CPU在执行程序的过程中，出现了某些突发事件时CPU必须暂停执行当前的程序，转去处理突发事件，处理完毕后CPU又返回源程序被中断的位置并继续执行。
中断发生后，ARM核的操作步骤可以总结为4大步3小步。
4大步3小步  保存执行状态：将CPSR复制到发生的异常模式下SPSR中； 模式切换：   CPSR模式位强制设置为与异常类型相对应的值， 处理器进入到ARM执行模式， 禁止所有IRQ中断，当进入FIQ快速中断模式时禁止FIQ中断；   保存返回地址：将下一条指令的地址（被打断程序）保存在LR(异常模式下LR_excep)中。 跳入异常向量表：强制设置PC的值为相应异常向量地址，跳转到异常处理程序中。  什么是GPIO？ general purpose input/output GPIO是相对于芯片本身而言的，如某个管脚是芯片的GPIO脚，则该脚可作为输入或输出高或低电平使用，当然某个脚具有复用的功能，即可做GPIO也可做其他用途。
也就是说你可以把这些引脚拿来用作任何一般用途的输入输出，例如用一根引脚连到led的一极来控制它的亮灭，也可以用一根（一些）引脚连到一个传感器上以获得该传感器的状态，这给cpu提供了一个方便的控制周边设备的途经。如果没有足够多的gpio管脚，在控制一些外围设备时就会力有不逮，这时可采取的方案是使用CPLD来帮助管理。
IIC引脚名称及功能？  SDA 数据线，用于传输数据 SCL 时钟线，用于同步数据  IIC的S、P信号如何发出？ 每次通信都必须由主设备发起，当主设备决定开始通讯时，需要发送开始（S）信号，需要执行以下动作；
 空闲时SCL默认是高电平； 将SDA线从高压电平切换到低压电平； 然后将SCL从高电平切换到低电平。 在主设备发送开始条件信号之后，所有从机即使处于睡眠模式也将变为活动状态，并等待接收地址位。 当双方决定结束通讯时，需要发送停止（P）信号，需要执行以下动作； 先将SDA、SCL设置为低电平； 然后将SCL从低电平切换到高电平； 将SDA从低电平切换到高电平。 在停止条件信号之后，I2C总线即处于空闲状态。  SPI引脚名称及功能？ 串行时钟线（SCK）、 主机输入/从机输出数据线MISO、 主机输出/从机输入数据线MOSI 从机选择线SS
(有的SPI接口芯片带有中断信号线INT或INT、有的SPI接口芯片没有主机输出/从机输入数据线MOSI)
驱动  查看驱动模块中打印信息应该使用什么命令？如何查看内核中已有的字符设备的信息？如何查看正在使用的有哪些中断号？
 查看驱动模块中打印信息的命令： dmesg 查看加载模块信息可以用 lsmod 已经分配的字符设备块设备号信息可以查看下面文件 cat /proc/devices 内核会为每一个驱动模块建立一个文件夹，如下： ls /sys/module/ 显示当前使用的中断号 cat /proc/interrupts  如何手动创建字符设备？并简述主设备号和次设备号的用途。
 创建字符设备命令如下:
mknod chartest c 4 64， mknod : 创建设备节点 chartest ：设备节点名字 c ： 字符设备， 4 ： 主设备号 64： 次设备号 主设备号：主设备号标识设备对应的驱动程序。虽然现代的linux内核允许多个驱动程序共享主设备号，但我们看待的大多数设备仍然按照“一个主设备对应一个驱动程序”的原则组织。
次设备号：次设备号由内核使用，用于正确确定设备文件所指的设备。依赖于驱动程序的编写方式，我们可以通过次设备号获得一个指向内核设备的直接指针，也可将此设备号当作设备本地数组的索引。
比如：
硬件平台可能又4个串口，他们驱动非常类似，区别仅仅是个字对应的SFR基地址不同， 那么我们可以让着几个串口共用同一个串口设备驱动 通过次设备号来区别具体是哪一个串口  内核中使用共享资源时，为了使之满足互斥条件，通常有哪些方法？
 原子操作，自旋锁，信号量，互斥锁
 Linux内核包括那几个子系统？
 Linux内核主要由进程调度（SCHED）、内存管理（MM）、虚拟文件系统（VFS）、网络接口（NET）和进程间通信（IPC）5个子系统组成
]]></content>
  </entry>
  
  <entry>
    <title>10个Python脚本来自动化你的日常任务</title>
    <url>/post/python/ten-python-script-to-automatically-execute-your-daily-task.html</url>
    <categories><category>Python</category>
    </categories>
    <tags>
      <tag>python</tag>
    </tags>
    <content type="html"><![CDATA[ 在这个自动化时代，我们有很多重复无聊的工作要做。 想想这些你不再需要一次又一次地做的无聊的事情，让它自动化，让你的生活更轻松。 那么在本文中，我将向您介绍 10 个 Python 自动化脚本，以使你的工作更加自动化，生活更加轻松。 因此，没有更多的重复任务将这篇文章放在您的列表中，让我们开始吧。
 解析和提取 HTML  此自动化脚本将帮助你从网页 URL 中提取 HTML，然后还为你提供可用于解析 HTML 以获取数据的功能。这个很棒的脚本对于网络爬虫和那些想要解析 HTML 以获取重要数据的人来说是一种很好的享受。
 # Parse and Extract HTML # pip install gazpacho import gazpacho # Extract HTML from URL url = &#39;https://www.example.com/&#39; html = gazpacho.get(url) print(html) # Extract HTML with Headers headers = {&#39;User-Agent&#39;: &#39;Mozilla/5.0&#39;} html = gazpacho.get(url, headers=headers) print(html) # Parse HTML parse = gazpacho.Soup(html) # Find single tags tag1 = parse.find(&#39;h1&#39;) tag2 = parse.find(&#39;span&#39;) # Find multiple tags tags1 = parse.find_all(&#39;p&#39;) tags2 = parse.find_all(&#39;a&#39;) # Find tags by class tag = parse.find(&#39;.class&#39;) # Find tags by Attribute tag = parse.find(&#34;div&#34;, attrs={&#34;class&#34;: &#34;test&#34;}) # Extract text from tags text = parse.find(&#39;h1&#39;).text text = parse.find_all(&#39;p&#39;)[0].text 二维码扫描仪  拥有大量二维码图像或只想扫描二维码图像，那么此自动化脚本将帮助你。该脚本使用 Qrtools 模块，使你能够以编程方式扫描 QR 图像。
 # Qrcode Scanner # pip install qrtools from qrtools import Qr def Scan_Qr(qr_img): qr = Qr() qr.decode(qr_img) print(qr.data) return qr.data print(&#34;Your Qr Code is: &#34;, Scan_Qr(&#34;qr.png&#34;)) 截图  现在，你可以使用下面这个很棒的脚本以编程方式截取屏幕截图。使用此脚本，你可以直接截屏或截取特定区域的屏幕截图。
 # Grab Screenshot # pip install pyautogui # pip install Pillow from pyautogui import screenshot import time from PIL import ImageGrab # Grab Screenshot of Screen def grab_screenshot(): shot = screenshot() shot.save(&#39;my_screenshot.png&#39;) # Grab Screenshot of Specific Area def grab_screenshot_area(): area = (0, 0, 500, 500) shot = ImageGrab.grab(area) shot.save(&#39;my_screenshot_area.png&#39;) # Grab Screenshot with Delay def grab_screenshot_delay(): time.sleep(5) shot = screenshot() shot.save(&#39;my_screenshot_delay.png&#39;) 创建有声读物  厌倦了手动将您的 PDF 书籍转换为有声读物，那么这是你的自动化脚本，它使用 GTTS 模块将你的 PDF 文本转换为音频。
 # Create Audiobooks # pip install gTTS # pip install PyPDF2 from PyPDF2 import PdfFileReader as reader from gtts import gTTS def create_audio(pdf_file): read_Pdf = reader(open(pdf_file, &#39;rb&#39;)) for page in range(read_Pdf.numPages): text = read_Pdf.getPage(page).extractText() tts = gTTS(text, lang=&#39;en&#39;) tts.save(&#39;page&#39; + str(page) + &#39;.mp3&#39;) create_audio(&#39;book.pdf&#39;) PDF 编辑器  使用以下自动化脚本使用 Python 编辑 PDF 文件。该脚本使用 PyPDF4 模块，它是 PyPDF2 的升级版本，下面我编写了 Parse Text、Remove pages 等常用功能。当你有大量 PDF 文件要编辑或需要以编程方式在 Python 项目中使用脚本时，这是一个方便的脚本。
 # PDF Editor # pip install PyPDf4 import PyPDF4 # Parse the Text from PDF def parse_text(pdf_file): reader = PyPDF4.PdfFileReader(pdf_file) for page in reader.pages: print(page.extractText()) # Remove Page from PDF def remove_page(pdf_file, page_numbers): filer = PyPDF4.PdfReader(&#39;source.pdf&#39;, &#39;rb&#39;) out = PyPDF4.PdfWriter() for index in page_numbers: page = filer.pages[index] out.add_page(page) with open(&#39;rm.pdf&#39;, &#39;wb&#39;) as f: out.write(f) # Add Blank Page to PDF def add_page(pdf_file, page_number): reader = PyPDF4.PdfFileReader(pdf_file) writer = PyPDF4.PdfWriter() writer.addPage() with open(&#39;add.pdf&#39;, &#39;wb&#39;) as f: writer.write(f) # Rotate Pages def rotate_page(pdf_file): reader = PyPDF4.PdfFileReader(pdf_file) writer = PyPDF4.PdfWriter() for page in reader.pages: page.rotateClockwise(90) writer.addPage(page) with open(&#39;rotate.pdf&#39;, &#39;wb&#39;) as f: writer.write(f) # Merge PDFs def merge_pdfs(pdf_file1, pdf_file2): pdf1 = PyPDF4.PdfFileReader(pdf_file1) pdf2 = PyPDF4.PdfFileReader(pdf_file2) writer = PyPDF4.PdfWriter() for page in pdf1.pages: writer.addPage(page) for page in pdf2.pages: writer.addPage(page) with open(&#39;merge.pdf&#39;, &#39;wb&#39;) as f: writer.write(f) 迷你 Stackoverflow  作为一名程序员，我知道我们每天都需要 StackOverflow，但你不再需要在 Google 上搜索它。现在，在您继续处理项目的同时，在你的 CMD 中获得直接解决方案。通过使用 Howdoi 模块，你可以在命令提示符或终端中获得 StackOverflow 解决方案。你可以在下面找到一些可以尝试的示例。
 # Automate Stackoverflow # pip install howdoi # Get Answers in CMD #example 1 &gt; howdoi how do i install python3 # example 2 &gt; howdoi selenium Enter keys # example 3 &gt; howdoi how to install modules # example 4 &gt; howdoi Parse html with python # example 5 &gt; howdoi int not iterable error # example 6 &gt; howdoi how to parse pdf with python # example 7 &gt; howdoi Sort list in python # example 8 &gt; howdoi merge two lists in python # example 9 &gt;howdoi get last element in list python # example 10 &gt; howdoi fast way to sort list 自动化手机  此自动化脚本将帮助你使用 Python 中的 Android 调试桥 (ADB) 自动化你的智能手机。下面我将展示如何自动执行常见任务，例如滑动手势、呼叫、发送短信等等。您可以了解有关 ADB 的更多信息，并探索更多令人兴奋的方法来实现手机自动化，让您的生活更轻松。
 # Automate Mobile Phones # pip install opencv-python import subprocess def main_adb(cm): p = subprocess.Popen(cm.split(&#39; &#39;), stdout=subprocess.PIPE, shell=True) (output, _) = p.communicate() return output.decode(&#39;utf-8&#39;) # Swipe  def swipe(x1, y1, x2, y2, duration): cmd = &#39;adb shell input swipe {}{}{}{}{}&#39;.format(x1, y1, x2, y2, duration) return main_adb(cmd) # Tap or Clicking def tap(x, y): cmd = &#39;adb shell input tap {}{}&#39;.format(x, y) return main_adb(cmd) # Make a Call def make_call(number): cmd = f&#34;adb shell am start -a android.intent.action.CALL -d tel:{number}&#34; return main_adb(cmd) # Send SMS def send_sms(number, message): cmd = &#39;adb shell am start -a android.intent.action.SENDTO -d sms:{}--es sms_body &#34;{}&#34;&#39;.format(number, message) return main_adb(cmd) # Download File From Mobile to PC def download_file(file_name): cmd = &#39;adb pull /sdcard/{}&#39;.format(file_name) return main_adb(cmd) # Take a screenshot def screenshot(): cmd = &#39;adb shell screencap -p&#39; return main_adb(cmd) # Power On and Off def power_off(): cmd = &#39;&#34;adb shell input keyevent 26&#34;&#39; return main_adb(cmd) 监控 CPU/GPU 温度  你可能使用 CPU-Z 或任何规格监控软件来捕获你的 Cpu 和 Gpu 温度，但你也可以通过编程方式进行。好吧，这个脚本使用 Pythonnet 和 OpenhardwareMonitor 来帮助你监控当前的 Cpu 和 Gpu 温度。你可以使用它在达到一定温度时通知自己，也可以在 Python 项目中使用它来简化日常生活。
 # Get CPU/GPU Temperature # pip install pythonnet import clr clr.AddReference(&#34;OpenHardwareMonitorLib&#34;) from OpenHardwareMonitorLib import * spec = Computer() spec.GPUEnabled = True spec.CPUEnabled = True spec.Open() # Get CPU Temp def Cpu_Temp(): while True: for cpu in range(0, len(spec.Hardware[0].Sensors)): if &#34;/temperature&#34; in str(spec.Hardware[0].Sensors[cpu].Identifier): print(str(spec.Hardware[0].Sensors[cpu].Value)) # Get GPU Temp def Gpu_Temp() while True: for gpu in range(0, len(spec.Hardware[0].Sensors)): if &#34;/temperature&#34; in str(spec.Hardware[0].Sensors[gpu].Identifier): print(str(spec.Hardware[0].Sensors[gpu].Value)) Instagram 上传机器人  Instagram 是一个著名的社交媒体平台，你现在不需要通过智能手机上传照片或视频。你可以使用以下脚本以编程方式执行此操作。
 # Upload Photos and Video on Insta # pip install instabot from instabot import Bot def Upload_Photo(img): robot = Bot() robot.login(user) robot.upload_photo(img, caption=&#34;Medium Article&#34;) print(&#34;Photo Uploaded&#34;) def Upload_Video(video): robot = Bot() robot.login(user) robot.upload_video(video, caption=&#34;Medium Article&#34;) print(&#34;Video Uploaded&#34;) def Upload_Story(img): robot = Bot() robot.login(user) robot.upload_story(img, caption=&#34;Medium Article&#34;) print(&#34;Story Photos Uploaded&#34;) Upload_Photo(&#34;img.jpg&#34;) Upload_Video(&#34;video.mp4&#34;) 视频水印  使用此自动化脚本为你的视频添加水印，该脚本使用 Moviepy，这是一个方便的视频编辑模块。在下面的脚本中，你可以看到如何添加水印并且可以自由使用它。
 # Video Watermark with Python # pip install moviepy from moviepy.editor import * clip = VideoFileClip(&#34;myvideo.mp4&#34;, audio=True) width,height = clip.size text = TextClip(&#34;WaterMark&#34;, font=&#39;Arial&#39;, color=&#39;white&#39;, fontsize=28) set_color = text.on_color(size=(clip.w + text.w, text.h-10), color=(0,0,0), pos=(6,&#39;center&#39;), col_opacity=0.6) set_textPos = set_color.set_pos( lambda pos: (max(width/30,int(width-0.5* width* pos)),max(5*height/6,int(100* pos))) ) Output = CompositeVideoClip([clip, set_textPos]) Output.duration = clip.duration Output.write_videofile(&#34;output.mp4&#34;, fps=30, codec=&#39;libx264&#39;) ]]></content>
  </entry>
  
  <entry>
    <title>FPGA硬核和软核处理器的区别</title>
    <url>/post/fpga/difference-between-hard-core-processor-and-soft-core-processor-of-fpga.html</url>
    <categories><category>FPGA</category>
    </categories>
    <tags>
      <tag>CPU</tag>
      <tag>fpga</tag>
      <tag>processor</tag>
      <tag>Altera</tag>
      <tag>Xilinx</tag>
    </tags>
    <content type="html"><![CDATA[ 从架构的角度来说，SOPC和SoC FPGA是统一的，都是由FPGA部分和处理器部分组成。在SoC FPGA 中，嵌入的是纯硬件基础的硬核处理器，简称HPS(Hardware Processor System)，而SOPC技术中，嵌入的是使用FPGA逻辑资源实现的软核处理器，两者指令集不一样，处理器性能也不一样。
 软核处理器 SOPC技术，即软核处理器，最早是由Altera公司提出来的，它是基于 FPGA  的SOC片上系统设计技术。是使用FPGA的逻辑和资源搭建的一个软核CPU系统，由于是使用FPGA的通用逻辑搭建的CPU，因此具有一定的灵活性，用户可以根据自己的需求对CPU进行定制裁剪，增加一些专用功能，例如除法或浮点运算单元，用于提升CPU在某些专用运算方面的性能，或者删除一些在系统里面使用不到的功能，以节约逻辑资源。
另外也可以根据用户的实际需求，为CPU添加各种标准或定制的外设，例如UART，SPI，IIC等标准接口外设，同时，用户也可以自己使用FPGA的逻辑资源，编写各种专用的外设，然后连接到CPU总线上，由CPU进行控制，以实现软硬件的协同工作，在保证系统性能的同时，增加了系统的灵活性。
而且，如果单个的软核CPU无法满足用户需求，可以添加多个CPU软核，搭建多核系统，通过多核CPU协同工作，让系统拥有更加灵活便捷的控制能力。
由于是使用FPGA资源实现的，所以具有很大的灵活性，可以实现根据需要实现多种处理器，如8051，RISC-V，Xilinx的 MicroBlaze ，Altera的Nios-II等等。
硬核处理器 由于软核CPU是使用FPGA的通用逻辑资源搭建的，相较使用经过布局布线优化的硬核处理器来说，软核处理器够运行的最高实时钟主频要低一些，而且也会相应的消耗较多的FPGA逻辑资源以及片上存储器资源，因此SOPC方案仅适用于对于数处理器整体性能要求不高的应用，例如整个系统的初始化配置，人机交互，多个功能模块间的协调控制等功能。
所以，各大FPGA厂家推出了SoC FPGA技术，是在芯片设计之初，就在内部的硬件电路上添加了硬核处理器，是纯硬件实现的，不会消耗FPGA的逻辑资源，硬核处理器和FPGA逻辑在一定程度上是相互独立的，简单的说，就是SoC FPGA就是把一块ARM处理器和一块FPGA芯片封装成了一个芯片。
例如比较有名的Xilinx的ZYNQ/PYNQ系列集成ARM Cortex-A9处理器，同时具有ARM软件的可编程性和FPGA 的硬件可编程性，不仅可实现重要分析与硬件加速，同时还在单个器件上高度集成 CPU、DSP、ASSP 以及混合信号功能。
ZYNQ开发板 Intel的Cyclone V系列，集成双核Cortex-A9，于2013年发布，在单一芯片上集成了双核的ARM Cortex-A9处理器和FPGA逻辑资源的新型SoC芯片，相较于传统的单一ARM处理器或FPGA芯片，它既拥有了ARM处理器灵活高效的数据运算和事务处理能力，同时又集成了FPGA的高速并行处理优势，同时，基于两者独特的片上互联结构，使用时可以将FPGA上的通用逻辑资源经过配置，映射为ARM处理器的一个或多个具有特定功能的外设，通过高达128位宽的AXI高速总线进行通信，完成数据和控制命令的交互。由于片上的ARM处理器是经过布局布线的硬线逻辑，因此其能工作的时钟主频较高，因此单位时间内能够执行的指令也更多。
区别和联系 从架构的角度来说，SOPC和SoC FPGA是统一的，都是由FPGA部分和处理器部分组成。在SoC FPGA 中，嵌入的是纯硬件基础的硬核处理器，简称HPS(Hardware Processor System)，而SOPC技术中，嵌入的是使用FPGA逻辑资源实现的软核处理器，两者指令集不一样，处理器性能也不一样。
一般来说，硬核处理器的性能要远远高于软核处理器。另外，硬核处理器除了CPU部分，还集成了各种高性能外设，如MMU、DDR3控制器、Nand FLASH控制器等，可以运行成熟的Linux操作系统和应用程序，提供统一的系统API，降低开发者的软件开发难度。而软核CPU虽然可以通过配置，用逻辑资源来搭建相应的控制器以支持相应功能，但是从性能和开发难度上来说，基于SoC FPGA架构进行设计开发是比较好的选择。
ZYNQ内部框图 另外，虽然SoC FPGA芯片上既包含了有ARM，又包含了有FPGA，但是两者一定程度上是相互独立的，SoC芯片上的ARM处理器核并非是包含于FPGA逻辑单元内部的，FPGA和ARM（HPS）处理器只是封装到同一个芯片中，JTAG接口、电源引脚和外设的接口引脚都是独立的，因此，如果使用SoC FPGA芯片进行设计，即使不使用到片上的ARM处理器，ARM处理器部分占用的芯片资源也无法释放出来，不能用作通用的FPGA资源。
而SOPC则是使用FPGA通用逻辑和存储器资源搭建的CPU，当不使用CPU时，CPU部分占用的资源可以被释放，重新用作通用FPGA资源。
]]></content>
  </entry>
  
  <entry>
    <title>详解嵌入式LCD的接口类型</title>
    <url>/post/fpga/embedded-lcd-interface-model.html</url>
    <categories><category>FPGA</category>
    </categories>
    <tags>
      <tag>LCD</tag>
      <tag>RGB</tag>
    </tags>
    <content type="html"><![CDATA[ 从架构的角度来说，SOPC和SoC FPGA是统一的，都是由FPGA部分和处理器部分组成。在SoC FPGA 中，嵌入的是纯硬件基础的硬核处理器，简称HPS(Hardware Processor System)，而SOPC技术中，嵌入的是使用FPGA逻辑资源实现的软核处理器，两者指令集不一样，处理器性能也不一样。
 LCD的接口有多种，分类很细。主要看LCD的驱动方式和控制方式，目前手机上的彩色LCD的连接方式一般有这么几种：MCU模式，RGB模式，SPI模式，VSYNC模式，MDDI模式，DSI模式。MCU模式(也写成MPU模式的)。只有TFT模块才有RGB接口。
但应用比较多的就是MUC模式和RGB模式，区别有以下几点：
MCU接口: 会解码命令，由timing generator产生时序信号，驱动COM和SEG驱器。
RGB接口: 在写LCD register setting时，和MCU接口没有区别。区别只在于图像的写入方式。
用MCU模式时由于数据可以先存到IC内部GRAM后再往屏上写，所以这种模式LCD可以直接接在MEMORY的总线上。
用RGB模式时就不同了，它没有内部RAM，HSYNC，VSYNC，ENABLE，CS，RESET，RS可以直接接在MEMORY的GPIO口上，用GPIO口来模拟波形.
MPU接口方式: 显示数据写入DDRAM，常用于静止图片显示。
RGB接口方式: 显示数据不写入DDRAM，直接写屏，速度快，常用于显示视频或动画用。
主要的区别是: MCU接口方式: 显示数据写入DDRAM，常用于静止图片显示。 RGB接口方式: 显示数据不写入DDRAM，直接写屏，速度快，常用于显示视频或动画用。
MCU模式 因为主要针对单片机的领域在使用,因此得名.后在中低端手机大量使用,其主要特点是价格便宜的。MCU-LCD接口的标准术语是Intel提出的8080总线标准，因此在很多文档中用I80 来指MCU-LCD屏。主要又可以分为8080模式和6800模式，这两者之间主要是时序的区别。数据位传输有8位，9位，16位，18位，24位。连线分为：CS/，RS(寄存器选择)，RD/，WR/，再就是数据线了。优点是：控制简单方便，无需时钟和同步信号。缺点是：要耗费GRAM，所以难以做到大屏(3.8以上)。对于MCU接口的LCM，其内部的芯片就叫LCD驱动器。主要功能是对主机发过的数据/命令，进行变换，变成每个象素的RGB数据，使之在屏上显示出来。这个过程不需要点、行、帧时钟。
MCU接口的LCD的DriverIC都带GRAM，Driver IC作为MCU的一片协处理器，接受MCU发过来的Command/Data，可以相对独立的工作。对于MCU接口的LCM(LCD Module)，其内部的芯片就叫LCD驱动器。主要功能是对主机发过的数据/命令，进行变换，变成每个象素的RGB数据，使之在屏上显示出来。这个过程不需要点、行、帧时钟。
M6800模式 M6800模式支持可选择的总线宽度8/9/16/18-bit(默认为8位)，其实际设计思想是与I80的思想是一样的，主要区别就是该模式的总线控制读写信号组合在一个引脚上(/WR)，而增加了一个锁存信号(E)数据位传输有8位，9位，16位和18位。
I8080模式 I80模式连线分为：CS/，RS(寄存器选择)，RD/，WR/，再就是数据线了。优点是：控制简单方便，无需时钟和同步信号。缺点是：要耗费GRAM，所以难以做到大屏(QVGA以上)。
 MCU接口标准名称是I80，管脚的控制脚有5个： CS 片选信号 RS (置1为写数据,置0为写命令) /WR (为0表示写数据) 数据命令区分信号 /RD (为0表示读数据) RESET 复位LCD( 用固定命令系列 0 1 0来复位)  VSYNC模式 该模式其实就是就是在MCU模式上加了一个VSYNC信号，应用于运动画面更新，这样就与上述两个接口有很大的区别。该模式支持直接进行动画显示的功能，它提供了一个对MCU接口最小的改动，实现动画显示的解决方案。在这种模式下，内部的显示操作与外部VSYNC信号同步。可以实现比内部操作更高的速率的动画显示。但由于其操作方式的不同，该模式对速率有一个限制，那就是对内部SRAM的写速率一定要大于显示读内部SRAM的速率。
RGB模式 大屏采用较多的模式，数据位传输也有6位，16位和18位，24位之分。连线一般有：VSYNC，HSYNC，DOTCLK，CS，RESET，有的也需要RS，剩下就是数据线。它的优缺点正好和MCU模式相反。
MCU-LCD屏它与RGB-LCD屏主要区别在于显存的位置。RGB-LCD的显存是由系统内存充当的，因此其大小只受限于系统内存的大小，这样RGB-LCD可以做出较大尺寸，象现在4.3&quot;只能算入门级，而MID中7&quot;,10&quot;的屏都开始大量使用。而MCU-LCD的设计之初只要考虑单片机的内存较小，因此都是把显存内置在LCD模块内部.然后软件通过专门显示命令来更新显存，因此MCU屏往往不能做得很大。同时显示更新速度也比RGB-LCD慢。显示数据传输模式也有差别。RGB屏只需显存组织好数据。启动显示后，LCD-DMA会自动把显存中的数据通过RGB接口送到LCM。而MCU屏则需要发送画点的命令来修改MCU内部的RAM(即不能直接写MCU屏的RAM)。所以RGB显示速度明显比MCU快，而且播放视频方面，MCU-LCD也比较慢。
对于RGB接口的LCM，主机输出的直接是每个象素的RGB数据，不需要进行变换(GAMMA校正等除外)，对于这种接口，需要在主机部分有个LCD控制器，以产生RGB数据和点、行、帧同步信号。
彩色TFT液晶屏主要有2种接口：TTL接口(RGB颜色接口)， LVDS接口(将RGB颜色打包成差分信号传输)。TTL接口主要用于12.1寸一下的小尺寸TFT屏，LVDS接口主要用于8寸以上的大尺寸TFT屏。TTL接口线多，传输距离短;LVDS接口传输距离长，线的数量少。大屏采用较多的模式，控制脚是VSYNC，HSYNC，VDEN，VCLK， S3C2440最高支持24个数据脚，数据脚是VD[23-0]。
CPU或显卡发出的图像数据是TTL信号(0-5V、0-3.3V、0-2.5V、或0-1.8V)，LCD本身接收的也是TTL信号，由于TTL信号在高速率的长距离传输时性能不佳，抗干扰能力比较差，后来又提出了多种传输模式，比如LVDS、TDMS、GVIF、P&amp;D、DVI和DFP等。他们实际上只是将CPU或显卡发出的TTL信号编码成各种信号以传输，在LCD那边将接收到的信号进行解码得到TTL信号。
但是不管采用何种传输模式，本质的TTL信号是一样的。
注意: TTL/LVDS分别是两种信号的传输模式，TTL是高电平表示1，低电平表示0的模式，LVDS是正负两个对应波形，用两个波形的差值来表示当前是1还是0
SPI模式 采用较少，有3线和4线的，连线为CS/，SLK，SDI，SDO四根线，连线少但是软件控制比较复杂。
MDDI模式(MobileDisplayDigitalInterface) 高通公司于2004年提出的接口MDDI，通过减少连线可提高移动电话的可靠性并降低功耗，这将取代SPI模式而成为移动领域的高速串行接口。 连线主要是host_data,host_strobe,client_data,client_strobe,power,GND几根线。
DSI模式 该模式串行的双向高速命令传输模式，连线有D0P，D0N，D1P，D1N，CLKP，CLKN。
]]></content>
  </entry>
  
  <entry>
    <title>带你走进Linux内核源码中最常见的数据结构之「mutex」</title>
    <url>/post/linux/linux-kernel-source-code-data-structure-mutex.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>kernel</tag>
      <tag>mutex</tag>
    </tags>
    <content type="html"><![CDATA[定义 互斥锁（英语：Mutual exclusion，缩写 Mutex）是一种用于多线程编程中，防止两条线程同时对同一公共资源（比如全域变量）进行读写的机制。
该目的通过将代码切片成一个一个的**临界区域（critical section）**达成。临界区域指的是一块对公共资源进行存取的代码，并非一种机制或是算法。一个程序、进程、线程可以拥有多个临界区域，但是并不一定会应用互斥锁。
例如：一段代码（甲）正在分步修改一块数据。这时，另一条线程（乙）由于一些原因被唤醒。如果乙此时去读取甲正在修改的数据，而甲碰巧还没有完成整个修改过程，这个时候这块数据的状态就处在极大的不确定状态中，读取到的数据当然也是有问题的。更严重的情况是乙也往这块地方写数据，这样的一来，后果将变得不可收拾。因此，多个线程间共享的数据必须被保护。达到这个目的的方法，就是确保同一时间只有一个临界区域处于运行状态，而其他的临界区域，无论是读是写，都必须被挂起并且不能获得运行机会。
互斥锁实现多线程同步的核心思想是：有线程访问进程空间中的公共资源时，该线程执行“加锁”操作（将资源“锁”起来），阻止其它线程访问。访问完成后，该线程负责完成“解锁”操作，将资源让给其它线程。当有多个线程想访问资源时，谁最先完成“加锁”操作，谁就最先访问资源。
当有多个线程想访问“加锁”状态下的公共资源时，它们只能等待资源“解锁”，所有线程会排成一个等待（阻塞）队列。资源解锁后，操作系统会唤醒等待队列中的所有线程，第一个访问资源的线程会率先将资源“锁”起来，其它线程则继续等待。当有多个线程想访问“加锁”状态下的公共资源时，它们只能等待资源“解锁”，所有线程会排成一个等待（阻塞）队列。资源解锁后，操作系统会唤醒等待队列中的所有线程，第一个访问资源的线程会率先将资源“锁”起来，其它线程则继续等待。
mutex有什么缺点？ 不同于mutex最初的设计与目的，现在的struct mutex是内核中最大的锁之一，比如在x86-64上，它差不多有32bytes的大小，而struct samaphore是24bytes，rw_semaphore为40bytes，更大的数据结构意味着占用更多的CPU缓存和更多的内存占用。
什么时候应该使用mutex？ 除非mutex的严格语义要求不合适或者临界区域阻止锁的共享，否则相较于其他锁原语来说更倾向于使用mutex
mutex与spinlock的区别？ spinlock是让一个尝试获取它的线程在一个循环中等待的锁，线程在等待时会一直查看锁的状态。而mutex是一个可以让多个进程轮流分享相同资源的机制
spinlock通常短时间持有，mutex可以长时间持有
spinlock任务在等待锁释放时不可以睡眠，mutex可以
看到一个非常有意思的解释：
spinlock就像是坐在车后座的熊孩子，一直问“到了吗？到了吗？到了吗？…”
mutex就像一个司机返回的信号，说“我们到了！”
实现 看一下Linux kernel-5.8是如何实现mutex的2 实现
struct mutex { atomic_long_t owner; spinlock_t wait_lock; #ifdef CONFIG_MUTEX_SPIN_ON_OWNER  struct optimistic_spin_queue osq; /* Spinner MCS lock */ #endif  struct list_head wait_list; #ifdef CONFIG_DEBUG_MUTEXES  void *magic; #endif #ifdef CONFIG_DEBUG_LOCK_ALLOC  struct lockdep_map dep_map; #endif }; 可以看到，mutex使用了原子变量owner来追踪锁的状态，owner实际上是指向当前mutex锁拥有者的struct task_struct *指针，所以当锁没有被持有时，owner为NULL。
/* * This is the control structure for tasks blocked on mutex, * which resides on the blocked task&#39;s kernel stack: * 表示等待队列wait_list中进程的结构体 */ struct mutex_waiter { struct list_head list; struct task_struct *task; struct ww_acquire_ctx *ww_ctx; #ifdef CONFIG_DEBUG_MUTEXES  void *magic; #endif }; 上锁 当要获取mutex时，通常有三种路径方式
fastpath: 通过 cmpxchg() 当前任务与所有者来尝试原子性的获取锁。这仅适用于无竞争的情况（cmpxchg() 检查 0UL，因此上面的所有 3 个状态位都必须为 0）。如果锁被争用，它会转到下一个可能的路径。
midpath: 又名乐观旋转（optimistic spinning）—在锁的持有者正在运行并且没有其他具有更高优先级（need_resched）的任务准备运行时，通过旋转来获取锁。理由是如果锁的所有者正在运行，它很可能很快就会释放锁。mutex spinner使用 MCS 锁排队，因此只有一个spinner可以竞争mutex。
MCS 锁（由 Mellor-Crummey 和 Scott 提出）是一个简单的自旋锁，具有公平的理想属性，每个 cpu 都试图获取在本地变量上旋转的锁，排队采用的是链表实现的FIFO。它避免了常见的test-and-set自旋锁实现引起的昂贵的cacheline bouncing。类似MCS的锁是专门为睡眠锁的乐观旋转而量身定制的（毕竟如果只是短暂的自旋比休眠效率要高）。自定义 MCS 锁的一个重要特性是它具有额外的属性，即当spinner需要重新调度时，它们能够直接退出 MCS 自旋锁队列。这有助于避免需要重新调度的 MCS spinner持续在mutex持有者上自旋，而仅需直接进入慢速路径获取MCS锁。
slowpath: 最后的手段，如果仍然无法获得锁，则将任务添加到等待队列并休眠，直到被解锁路径唤醒。在正常情况下它阻塞为 TASK_UNINTERRUPTIBLE。 虽然正式的内核互斥锁是可休眠的锁，但midpath路径 (ii) 使它们更实际地成为混合类型。通过简单地不中断任务并忙于等待几个周期而不是立即休眠，此锁的性能已被视为显着改善了许多工作负载。请注意，此技术也用于 rw 信号量。
具体代码调用链很长…
/*不可中断的获取锁*/ void __sched mutex_lock(struct mutex *lock) { might_sleep(); /*fastpath*/ if (!__mutex_trylock_fast(lock)) /*midpath and slowpath*/ __mutex_lock_slowpath(lock); } __mutex_trylock_fast(lock) -&gt; atomic_long_try_cmpxchg_acquire(&amp;lock-&gt;owner, &amp;zero, curr) -&gt; atomic64_try_cmpxchg_acquire(v, (s64 *)old, new); __mutex_lock_slowpath(lock)-&gt;__mutex_lock(lock, TASK_UNINTERRUPTIBLE, 0, NULL, _RET_IP_) -&gt; __mutex_lock_common(lock, state, subclass, nest_lock, ip, NULL, false) /*可中断的获取锁*/ int mutex_lock_interruptible(struct mutex *lock); 尝试上锁 int __sched mutex_trylock(struct mutex *lock) { bool locked; #ifdef CONFIG_DEBUG_MUTEXES  DEBUG_LOCKS_WARN_ON(lock-&gt;magic != lock); #endif  locked = __mutex_trylock(lock); if (locked) mutex_acquire(&amp;lock-&gt;dep_map, 0, 1, _RET_IP_); return locked; } static inline bool __mutex_trylock(struct mutex *lock) { return !__mutex_trylock_or_owner(lock); } 释放锁 void __sched mutex_unlock(struct mutex *lock) { #ifndef CONFIG_DEBUG_LOCK_ALLOC  if (__mutex_unlock_fast(lock)) return; #endif  __mutex_unlock_slowpath(lock, _RET_IP_); } 跟加锁对称，也有fastpath, midpath, slowpath三条路径。 判断锁状态
bool mutex_is_locked(struct mutex *lock) { return __mutex_owner(lock) != NULL; } 很显而易见，mutex持有者不为NULL即表示锁定状态。
实际案例 实验：
#include &lt;pthread.h&gt;#include &lt;stdio.h&gt; #define LOOP 1000000  int cnt = 0; int cs1 = 0, cs2 = 0; void* task(void* args) { while(1) { if(cnt &gt;= LOOP) { break; } cnt++; if((int)args == 1) cs1 ++; else cs2++; } return NULL; } int main() { pthread_t tid1; pthread_t tid2; /* create the thread */ pthread_create(&amp;tid1, NULL, task, (void*)1); pthread_create(&amp;tid2, NULL, task, (void*)2); /* wait for thread to exit */ pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(&#34;cnt = %d cs1=%d cs2=%d total=%d\n&#34;, cnt,cs1,cs2,cs1+cs2); return 0; } 输出：
cnt = 1000000 cs1=958560 cs2=1520226 total=2478786 正确结果不应该是1000000吗？为什么会出错呢，我们可以从汇编角度来分析一下。
$&gt; g++ -E test.c -o test.i $&gt; g++ -S test.i -o test.s $&gt; vim test.s .file &#34;test.c&#34; .globl _cnt .bss .align 4 _cnt: .space 4 .text .globl __Z5task1Pv .def __Z5task1Pv; .scl 2; .type 32; .endef __Z5task1Pv: ... 我们可以看到一个简单的cnt++，对应
movl _cnt, %eax addl $1, %eax movl %eax, _cnt CPU先将cnt的值读到寄存器eax中，然后将[eax] + 1，最后将eax的值返回到cnt中，这些操作不是**原子性质(atomic)**的，这就导致cnt被多个线程操作时，+1过程会被打断。
加入mutex保护临界资源
#include &lt;pthread.h&gt;#include &lt;stdio.h&gt; #define LOOP 1000000  pthread_mutex_t mutex; int cnt = 0; int cs1 = 0, cs2 = 0; void* task(void* args) { while(1) { pthread_mutex_lock(&amp;mutex); if(cnt &gt;= LOOP) { pthread_mutex_unlock(&amp;mutex); break; } cnt++; pthread_mutex_unlock(&amp;mutex); if((int)args == 1) cs1 ++; else cs2++; } return NULL; } int main() { pthread_mutex_init(&amp;mutex , NULL); pthread_t tid1; pthread_t tid2; /* create the thread */ pthread_create(&amp;tid1, NULL, task, (void*)1); pthread_create(&amp;tid2, NULL, task, (void*)2); /* wait for thread to exit */ pthread_join(tid1, NULL); pthread_join(tid2, NULL); printf(&#34;cnt = %d cs1=%d cs2=%d total=%d\n&#34;, cnt,cs1,cs2,cs1+cs2); return 0; } 输出：
cnt = 1000000 cs1=517007 cs2=482993 total=1000000 ]]></content>
  </entry>
  
  <entry>
    <title>openssl命令</title>
    <url>/post/linux/openssl.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>openssl</tag>
      <tag>系统管理</tag>
      <tag>系统安全</tag>
    </tags>
    <content type="html"><![CDATA[ 强大的安全套接字层密码库
 OpenSSL是一个强大的安全套接字层密码库，囊括主要的密码算法、常用的密钥和证书封装管理功能及SSL协议，并提供丰富的应用程序供测试或其它目的使用。在OpenSSL被曝出现严重安全漏洞后，发现多数通过SSL协议加密的网站使用名为OpenSSL的开源软件包。由于这是互联网应用最广泛的安全传输方法，被网银、在线支付、电商网站、门户网站、电子邮件等重要网站广泛使用，所以该漏洞影响范围广大。
OpenSSL有两种运行模式：交互模式和批处理模式。
直接输入openssl回车进入交互模式，输入带命令选项的openssl进入批处理模式。
OpenSSL整个软件包大概可以分成三个主要的功能部分：密码算法库、SSL协议库以及应用程序。OpenSSL的目录结构自然也是围绕这三个功能部分进行规划的。 对称加密算法 OpenSSL一共提供了8种对称加密算法，其中7种是分组加密算法，仅有的一种流加密算法是RC4。这7种分组加密算法分别是AES、DES、Blowfish、CAST、IDEA、RC2、RC5，都支持电子密码本模式（ECB）、加密分组链接模式（CBC）、加密反馈模式（CFB）和输出反馈模式（OFB）四种常用的分组密码加密模式。其中，AES使用的加密反馈模式（CFB）和输出反馈模式（OFB）分组长度是128位，其它算法使用的则是64位。事实上，DES算法里面不仅仅是常用的DES算法，还支持三个密钥和两个密钥3DES算法。 非对称加密算法 OpenSSL一共实现了4种非对称加密算法，包括DH算法、RSA算法、DSA算法和椭圆曲线算法（EC）。DH算法一般用户密钥交换。RSA算法既可以用于密钥交换，也可以用于数字签名，当然，如果你能够忍受其缓慢的速度，那么也可以用于数据加密。DSA算法则一般只用于数字签名。 信息摘要算法 OpenSSL实现了5种信息摘要算法，分别是MD2、MD5、MDC2、SHA（SHA1）和RIPEMD。SHA算法事实上包括了SHA和SHA1两种信息摘要算法，此外，OpenSSL还实现了DSS标准中规定的两种信息摘要算法DSS和DSS1。 密钥和证书管理 密钥和证书管理是PKI的一个重要组成部分，OpenSSL为之提供了丰富的功能，支持多种标准。 首先，OpenSSL实现了ASN.1的证书和密钥相关标准，提供了对证书、公钥、私钥、证书请求以及CRL等数据对象的DER、PEM和BASE64的编解码功能。OpenSSL提供了产生各种公开密钥对和对称密钥的方法、函数和应用程序，同时提供了对公钥和私钥的DER编解码功能。并实现了私钥的PKCS#12和PKCS#8的编解码功能。OpenSSL在标准中提供了对私钥的加密保护功能，使得密钥可以安全地进行存储和分发。 在此基础上，OpenSSL实现了对证书的X.509标准编解码、PKCS#12格式的编解码以及PKCS#7的编解码功能。并提供了一种文本数据库，支持证书的管理功能，包括证书密钥产生、请求产生、证书签发、吊销和验证等功能。 事实上，OpenSSL提供的CA应用程序就是一个小型的证书管理中心（CA），实现了证书签发的整个流程和证书管理的大部分机制。
实例 1、消息摘要算法应用例子 用SHA1算法计算文件file.txt的哈西值，输出到stdout：
# openssl dgst -sha1 file.txt 用SHA1算法计算文件file.txt的哈西值，输出到文件digest.txt：
# openssl sha1 -out digest.txt file.txt 用DSS1(SHA1)算法为文件file.txt签名，输出到文件dsasign.bin。签名的private key必须为DSA算法产生的，保存在文件dsakey.pem中。
# openssl dgst -dss1 -sign dsakey.pem -out dsasign.bin file.txt 用dss1算法验证file.txt的数字签名dsasign.bin，验证的private key为DSA算法产生的文件dsakey.pem。
# openssl dgst -dss1 -prverify dsakey.pem -signature dsasign.bin file.txt 用sha1算法为文件file.txt签名,输出到文件rsasign.bin，签名的private key为RSA算法产生的文件rsaprivate.pem。
# openssl sha1 -sign rsaprivate.pem -out rsasign.bin file.txt # 用sha1算法验证file.txt的数字签名rsasign.bin，验证的public key为RSA算法生成的rsapublic.pem。 # openssl sha1 -verify rsapublic.pem -signature rsasign.bin file.txt 2、对称加密应用例子 对称加密应用例子，用DES3算法的CBC模式加密文件plaintext.doc，加密结果输出到文件ciphertext.bin。
# openssl enc -des3 -salt -in plaintext.doc -out ciphertext.bin 用DES3算法的OFB模式解密文件ciphertext.bin，提供的口令为trousers，输出到文件plaintext.doc。注意：因为模式不同，该命令不能对以上的文件进行解密。
# openssl enc -des-ede3-ofb -d -in ciphertext.bin -out plaintext.doc -pass pass:trousers 用Blowfish的CFB模式加密plaintext.doc，口令从环境变量PASSWORD中取，输出到文件ciphertext.bin。
# openssl bf-cfb -salt -in plaintext.doc -out ciphertext.bin -pass env:PASSWORD 给文件ciphertext.bin用base64编码，输出到文件base64.txt。
# openssl base64 -in ciphertext.bin -out base64.txt 用RC5算法的CBC模式加密文件plaintext.doc，输出到文件ciphertext.bin，salt、key和初始化向量(iv)在命令行指定。
# openssl rc5 -in plaintext.doc -out ciphertext.bin -S C62CB1D49F158ADC -iv E9EDACA1BD7090C6 -K 89D4B1678D604FAA3DBFFD030A314B29 3、Diffie-Hellman应用例子 使用生成因子2和随机的1024-bit的素数产生D0ffie-Hellman参数，输出保存到文件dhparam.pem
# openssl dhparam -out dhparam.pem -2 1024 从dhparam.pem中读取Diffie-Hell参数，以C代码的形式，输出到stdout。
# openssl dhparam -in dhparam.pem -noout -C 4、DSA应用例子应用例子 生成1024位DSA参数集，并输出到文件dsaparam.pem。
# openssl dsaparam -out dsaparam.pem 1024 使用参数文件dsaparam.pem生成DSA私钥匙，采用3DES加密后输出到文件dsaprivatekey.pem
# openssl gendsa -out dsaprivatekey.pem -des3 dsaparam.pem 使用私钥匙dsaprivatekey.pem生成公钥匙，输出到dsapublickey.pem
# openssl dsa -in dsaprivatekey.pem -pubout -out dsapublickey.pem 从dsaprivatekey.pem中读取私钥匙，解密并输入新口令进行加密，然后写回文件dsaprivatekey.pem
# openssl dsa -in dsaprivatekey.pem -out dsaprivatekey.pem -des3 -passin 5、RSA应用例子 产生1024位RSA私匙，用3DES加密它，口令为trousers，输出到文件rsaprivatekey.pem
# openssl genrsa -out rsaprivatekey.pem -passout pass:trousers -des3 1024 从文件rsaprivatekey.pem读取私匙，用口令trousers解密，生成的公钥匙输出到文件rsapublickey.pem
# openssl rsa -in rsaprivatekey.pem -passin pass:trousers -pubout -out rsapubckey.pem 用公钥匙rsapublickey.pem加密文件plain.txt，输出到文件cipher.txt
# openssl rsautl -encrypt -pubin -inkey rsapublickey.pem -in plain.txt -out cipher.txt 使用私钥匙rsaprivatekey.pem解密密文cipher.txt，输出到文件plain.txt
# openssl rsautl -decrypt -inkey rsaprivatekey.pem -in cipher.txt -out plain.txt 用私钥匙rsaprivatekey.pem给文件plain.txt签名，输出到文件signature.bin
# openssl rsautl -sign -inkey rsaprivatekey.pem -in plain.txt -out signature.bin 用公钥匙rsapublickey.pem验证签名signature.bin，输出到文件plain.txt
# openssl rsautl -verify -pubin -inkey rsapublickey.pem -in signature.bin -out plain 从X.509证书文件cert.pem中获取公钥匙，用3DES加密mail.txt，输出到文件mail.enc
# openssl smime -encrypt -in mail.txt -des3 -out mail.enc cert.pem 从X.509证书文件cert.pem中获取接收人的公钥匙，用私钥匙key.pem解密S/MIME消息mail.enc，结果输出到文件mail.txt
# openssl smime -decrypt -in mail.enc -recip cert.pem -inkey key.pem -out mail.txt cert.pem为X.509证书文件，用私匙key,pem为mail.txt签名，证书被包含在S/MIME消息中，输出到文件mail.sgn
# openssl smime -sign -in mail.txt -signer cert.pem -inkey key.pem -out mail.sgn 验证S/MIME消息mail.sgn，输出到文件mail.txt，签名者的证书应该作为S/MIME消息的一部分包含在mail.sgn中
# openssl smime -verify -in mail.sgn -out mail.txt ]]></content>
  </entry>
  
  <entry>
    <title>syslog命令</title>
    <url>/post/linux/syslog.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>syslog</tag>
      <tag>系统管理</tag>
      <tag>系统安全</tag>
    </tags>
    <content type="html"><![CDATA[ 系统默认的日志守护进程
 syslog是Linux系统默认的日志守护进程。
概述 默认的syslog配置文件是/etc/syslog.conf文件。程序，守护进程和内核提供了访问系统的日志信息。因此，任何希望生成日志信息的程序都可以向 syslog 接口呼叫生成该信息。
几乎所有的网络设备都可以通过syslog协议，将日志信息以用户数据报协议(UDP)方式传送到远端服务器，远端接收日志服务器必须通过syslogd监听UDP 端口514，并根据 syslog.conf配置文件中的配置处理本机，接收访问系统的日志信息，把指定的事件写入特定文件中，供后台数据库管理和响应之用。意味着可以让任何事件都登录到一台或多台服务器上，以备后台数据库用off-line(离线) 方法分析远端设备的事件。
通常，syslog 接受来自系统的各种功能的信息，每个信息都包括重要级。/etc/syslog.conf 文件通知 syslogd 如何根据设备和信息重要级别来报告信息。
使用方法 在/var/log中创建并写入日志信息是由syslog协议处理的，是由守护进程sylogd负责执行。每个标准的进程都可以用syslog记录日志。可以使用logger命令通过syslogd记录日志。
要向syslog文件/var/log/messages中记录日志信息：
logger this is a test log line 输出： tail -n 1 messages Jan 5 10:07:03 localhost root: this is a test log line 如果要记录特定的标记（tag）可以使用：
logger -t TAG this is a test log line 输出： tail -n 1 messages Jan 5 10:37:14 localhost TAG: this is a test log line ]]></content>
  </entry>
  
  <entry>
    <title>如何在Ubuntu Linux下将mp4转成mp3</title>
    <url>/post/linux/how-to-convert-mp4-to-mp3-in-ubuntu-linux.html</url>
    <categories><category>Linux</category>
    </categories>
    <tags>
      <tag>ubuntu</tag>
      <tag>ffmpeg</tag>
      <tag>mp4</tag>
      <tag>mp3</tag>
    </tags>
    <content type="html"><![CDATA[ FFmpeg是一款开源软件，用于生成处理多媒体数据的各类库和程序。FFmpeg可以转码、处理视频和图片（调整视频、图片大小，去噪等）、打包、传输及播放视频。
 本文描述了如何在Ubuntu Linux系统下，通过ffmpeg将mp4文件转成mp3文件。
为什么要将mp4转成mp3 因为这样可以节省空间，一些基本的设备是不支持mp4扩展名的文件，在这个例子里，我们将使用ffmpeg将mp4文件转成mp3文件。
FFmpeg是一个完整的跨平台的解决方案，用来录制，转化以及分流音视频，它包括业界领先的音视频编码库 labavcodec 。
在ubuntu上安装ffmpeg sudo apt-get install ffmpeg libavcodec-extra-53 将mp4转成mp3 基本的命令
ffmpeg -i filename.mp4 filename.mp3 可以用命令`man ffmpeg&rsquo;来查看更多选项
ffmpeg -i filename.mp4 -b:a 192K -vn filename.mp3 一个流的说明符可以匹配一些流，这些选项会适用于所有的流，比如，在-b:a 128k选项中的流说明符可以匹配所有的音频流。
通过脚本 下面这个脚本会将Music目录下的带有.mp4扩展名的文件转成.mp3扩展名的文件。
#!/bin/bash MP4FILE=$(ls ~/Music/ |grep .mp4) for filename in $MP4FILE do name=`echo &#34;$filename&#34; | sed -e &#34;s/.mp4$//g&#34;` ffmpeg -i ~/Music/$filename -b:a 192K -vn ~/Music/$name.mp3 done ]]></content>
  </entry>
  
  <entry>
    <title>风河携手TCS建构5G/Open RAN分布式移动网络基础设施生态系统</title>
    <url>/post/news/windriver-and-TCS-build-5G-Open-Ran-ecos.html</url>
    <categories><category>News</category>
    </categories>
    <tags>
      <tag>WindRiver</tag>
      <tag>vRan</tag>
      <tag>TCS</tag>
      <tag>5G</tag>
    </tags>
    <content type="html"><![CDATA[ 全球领先的关键任务智能系统软件提供商风河公司®宣布，正在与塔塔咨询服务公司（TCS）合作，在Wind River Studio上托管vRAN解决方案。这项战略合作将创建一个全栈移动基础设施解决方案，在4G-5G vRAN下一代网络中开展TCS部署和工程服务，并以Studio作为云平台。
 TCS网络解决方案与服务副总裁Vimal Kumar表示：“我们很高兴与风河合作，帮助我们的客户借助5G技术改善他们的业务。我们的Cognitive Network Operations平台运行在Wind River Studio之上，由此帮助电信网络运营商运用AI和ML技术来监测网络健康状况，预测可能发生的故障，提供以客户为中心的网络体验，并确保卓越的服务质量。”
风河公司首席产品官Avijit Sinha表示：“运营商正在致力于创造数字化、云原生的未来，他们正在寻求灵活、经济的解决方案，以便降低部署复杂度并进行持续性维护。风河公司提供了成熟的生产就绪产品，与领先运营商实现了实用化部署，其基础正是经过广泛验证的Wind River Studio技术。”
风河公司印度销售主管Rajeev Rawal表示：“与TCS携手，提供敏捷、安全、可靠和超低延迟解决方案，以支持新的应用场景，让云计算、边缘计算和智能化技术承担起更加重要的任务。”
作为5G市场的领导者，风河在世界首次成功5G数据会话和商业vRAN/O-RAN项目中发挥了关键作用，其中包括世界上最大的Open RAN网络。
Wind River Studio提供了一个完全基于云原生、Kubernetes和容器的体系结构，可用于大规模分布式边缘网络的开发、部署、运营和服务。这套平台为地理分布的管理解决方案提供了基础，能够为数千个节点提供单一窗口（SPoG）、零接触的自动化管理，从而简化Day 1和Day 2运营，而且与节点的物理位置无关。Studio解决了部署和管理物理地理分散云原生vRAN基础设施的复杂挑战，在vRAN部署中提供了传统的RAN性能。
 塔塔咨询服务 (TCS）简介
 塔塔咨询服务公司是一家IT服务、咨询和业务解决方案提供商，50多年来一直与许多全球最大企业合作，帮助他们实现转型。TCS提供以咨询为主导、以认知为动力的综合性商业、技术和工程服务以及解决方案。所有这些都通过独特的Location Independent Agile™ 模式来提供，被作为卓越软件开发的基准指标。
作为印度最大的跨国商业集团塔塔集团的一部分，TCS在55个国家拥有超过606,000名训练有素的咨询师。在截至2022年3月31日的财年中，TCS创造了257亿美元的合并营收，并在印度的BSE和NSE上市。
]]></content>
  </entry>
  
  <entry>
    <title>VxWorks 6.8下基于QT的串口编程</title>
    <url>/post/vxworks/vxworks-6.8-qt-uart-programming.html</url>
    <categories><category>VxWorks</category>
    </categories>
    <tags>
      <tag>VxWorks</tag>
      <tag>VxWorks 6.8</tag>
      <tag>UART</tag>
      <tag>QT</tag>
      <tag>串口</tag>
      <tag>编程</tag>
    </tags>
    <content type="html"><![CDATA[文章简要记录了VxWorks 6.8下基于Qt实现的串口编程。
相关的VxWorks 和 串口，请参阅 VxWorks下的串口测试程序设计和源码  。
VxWorks简介 VxWorks 操作系统是美国WindRiver公司于1983年设计开发的一种嵌入式实时操作系统（RTOS），是嵌入式开发环境的关键组成部分。良好的持续发展能力、高性能的内核以及友好的用户开发环境，在嵌入式实时操作系统领域占据一席之地。它以其良好的可靠性和卓越的实时性被广泛地应用在通信、军事、航空、航天等高精尖技术及实时性要求极高的领域中，如卫星通讯、军事演习、弹道制导、飞机导航等。在美国的 F-16、FA-18战斗机、B-2 隐形轰炸机和爱国者导弹上，甚至连1997年4月在火星表面登陆的火星探测器、2008年5月登陆的凤凰号，和2012年8月登陆的好奇号也都使用到了VxWorks。
串口简介 串行接口(Serial Interface) 简称串口，也称串行通信接口或串行通讯接口（通常指COM接口），是采用串行通信方式的扩展接口，指数据一位一位地顺序传送。
串行接口的特点是通信线路简单，只要一对传输线就可以实现双向通信（可以直接利用电话线作为传输线），从而大大降低了成本，特别适用于远距离通信，但传送速度较慢。常见的有一般计算机应用的RS-232（使用 25 针或 9 针连接器）和工业计算机应用的半双工RS-485与全双工RS-422。
我这里使用了232和422传输方式，在我本人理解这两种方式根据需求硬件已经做好的传输方式（也可以在BIOS设置），我们知道是什么传输方式，做到心中有数和如何搭建测试环境，今天在这里教大家个简单的232-9针连接器的接线方式，一般没接触过的拿过来一脸懵逼，好家伙9跟针都不知道是干嘛的，那么我告诉你如果是 232-9针，什么也别管直接找到第2针和第3针用杜邦线回连，这时你就具备环境自己检测板卡串口模块是否好用，如果测试程序一定记得把第5跟针要连接上，否则会出现数据不精准的情况（文章底部有贴图）。
在软件层面上只需要关注数据位、停止位、奇偶效验、读取方式和效率即可；
232串口接线说明 RS232串口接线方法：直连和交叉接法
一般情况下，设备和电脑的连接通讯，需用到RS232串口线直连线；而设备和设备的连接通讯，就会用到RS232串口线的交叉线。用户在选择的时候，应根据两个设备之间连接的实际情况，选择不同接法的RS232串口线。
代码实例 VxWorks串口所需要包含的头文件 #include &#34;vxWorks.h&#34;#include &#34;stdIo.h&#34;#include &#34;ioLib.h&#34;#include &#34;sysLib.h&#34;#include &#34;string.h&#34;#include &#34;taskLib.h&#34;VxWorks串口配置函数 ioctl(m_SeriPort,SIO_HW_OPTS_SET, CLOCAL | CS8 | PARODD | PARENB);	//8位数据位|1位停止位|偶效验 ioctl(m_SeriPort,FIOBAUDRATE,9600);	//波特率9600 ioctl(m_SeriPort,FIOSETOPTIONS,OPT_RAW);	//设置串口raw模式 ioctl(m_SeriPort,FIOFLUSH,0);	//清空输入输出的缓冲区 open函数 #define SERI_NAME &#34;/tyCo/0&#34; int m_SeriPort = open(SERI_NAME ,O_RDWR,0); int m_SeriPort = open(SERI_NAME ,O_WRONLY,0); write函数 char* sendData; int writeCom = write(m_SeriPort, sendData,strlen(sendData)); read函数 char data; int readCom = read(m_SeriPort,&amp;data,1); Seri_Demo_Qt_Vx #ifndef THREAD_H #define THREAD_H #include &lt;QThread&gt;#include &lt;QDebug&gt;#include &#34;vxWorks.h&#34;#include &#34;stdIo.h&#34;#include &#34;ioLib.h&#34;#include &#34;sysLib.h&#34;#include &#34;string.h&#34;#include &#34;taskLib.h&#34;class Thread : public QThread { Q_OBJECT public: explicit Thread(QObject *parent = 0); ~Thread(); void run(); //重写run函数 public: bool openSeri(QString comPort,int baudRate); //打开串口  void closeSeri(); //关闭串口  void writeSeri(char* sendData); //发送数据  void setFlag(bool flag = true); //线程数据标志位 signals: void RecvData(char data); private: bool seriStop; //读取数据标志位 true读取数据 false退出循环  int m_SeriPort; //串口文件描述符  QString m_SeriName; //串口名  int m_baud; //波特率 }; #endif //THREAD_H #include &#34;thread.h&#34; Thread::Thread(QObject *parent) : QThread(parent) { } Thread::~Thread() { } void Thread::run() { sysClkRateSet(1000); char rData; while(1) { int readCom = read(m_SeriPort,&amp;rData,1); if(readCom &gt; 0) { printf(&#34;%c\n&#34;,rData); emit RecvData(rData); if(seriStop == false) { qDebug()&lt;&lt; &#34;isStop == false break&#34;; break; } } else { taskDelay(10); } } } bool Thread::openSeri(QString comPort, int baudRate) { this-&gt;m_SeriName = comPort; this-&gt;m_baud = baudRate; qDebug()&lt;&lt; &#34;Thread::openSeri&#34; &lt;&lt; comPort.toUtf8().data() &lt;&lt; baudRate; m_SeriPort = open(comPort.toUtf8().data(),O_RDWR,0); if(m_SeriPort == ERROR) { qDebug()&lt;&lt; &#34;open :&#34; &lt;&lt; comPort.toUtf8().data() &lt;&lt; &#34; = &#34; &lt;&lt;m_SeriPort &lt;&lt; &#34;failed !&#34;; return false; } ioctl(m_SeriPort,SIO_HW_OPTS_SET, CLOCAL | CS8 | PARODD | PARENB); ioctl(m_SeriPort,FIOBAUDRATE,baudRate); ioctl(m_SeriPort,FIOSETOPTIONS,OPT_RAW); ioctl(m_SeriPort,FIOFLUSH,0); qDebug()&lt;&lt; &#34;open :&#34; &lt;&lt; comPort.toUtf8().data() &lt;&lt; &#34; = &#34; &lt;&lt; m_SeriPort &lt;&lt; &#34;succeeded !&#34;; return true; } void Thread::closeSeri() { if(seriStop == false) { qDebug()&lt;&lt; &#34;Thread::closeSeri&#34;; close(m_SeriPort); } } void Thread::writeSeri(char* sendData) { if(m_SeriPort == ERROR) { openSeri(m_SeriName,m_baud); } int writeCom = write(m_SeriPort, sendData,strlen(sendData)); qDebug()&lt;&lt; sendData &lt;&lt; writeCom; } void Thread::setFlag(bool flag) { this-&gt;seriStop = flag; qDebug()&lt;&lt; &#34;Thread::setFlag&#34; &lt;&lt; flag; } TestSeri_Demo_Qt_Vx_Demo #ifndef SERI_H #define SERI_H  #include &lt;QObject&gt;#include &lt;QDebug&gt;#include &#34;thread.h&#34; class Seri : public QObject { Q_OBJECT public: explicit Seri(QObject *parent = 0); ~Seri(); public: /*	open_Seri	打开串口 * comName	串口名 * comBaud	串口波特率 *	return 成功 true 失败 false */ bool open_Seri(QString comName,int comBaud); /* write_Seri	发送数据 * comData	发送数据内容 */ void write_Seri(QByteArray comData); /*	* close_Seri	关闭串口 */ void close_Seri(); signals: send_Seri(char data); private: Thread* m_pThread; }; #endif // SERI_H #include &#34;Seri.h&#34; Seri::Seri(QObject *parent) : QObject(parent) { m_pThread = new Thread; } Seri::~Seri() { if(m_pThread){ delete m_pThread; m_pThread=NULL; } } bool Seri::open_Seri(QString comName,int comBaud) { if(m_pThread-&gt;openSeri(comName,comBaud))//如果打开成功 	{ m_pThread-&gt;setFlag(true); m_pThread-&gt;start(); } return false; } void Seri::write_Seri(QByteArray comData) { m_pThread-&gt;writeSeri(comData.data()); } void Seri::close_Seri() { if(m_pThread-&gt;isRunning())//如果线程还在运行 --&gt; 退出循环接收数据 --&gt; 关闭串口 --&gt; 退出线程 --&gt; 回收线程 	{ m_pThread-&gt;setFlag(false); m_pThread-&gt;closeSeri(); m_pThread-&gt;quit(); m_pThread-&gt;wait(); } } 程序代码说明：  thread类为配置串口类 seri类为外部使用类 接收到的数据是利用信号槽为接口把数据传输出去 ]]></content>
  </entry>
  
  <entry>
    <title>VxWorks操作系统下的串口读写程序</title>
    <url>/post/vxworks/vxworks-uart-read-write-programming.html</url>
    <categories><category>VxWorks</category>
    </categories>
    <tags>
      <tag>VxWorks</tag>
      <tag>UART</tag>
      <tag>串口</tag>
      <tag>编程</tag>
    </tags>
    <content type="html"><![CDATA[关于传统的串口编程，在各大操作系统下的流程基本是一致的，只是针对不同的操作系统，函数接口可能有所差异而已，下面讲述VxWorks操作系统下对于串口读写的编程步骤和代码
相关的VxWorks 和 串口，请参阅 VxWorks下的串口测试程序设计和源码  。
串口配置过程 打开串口 fd = open(&#34;/tyCo/0&#34;, O_RDWR, 0);  &ldquo;/tyCo/0&rdquo;: 串口1的设备名 O_RDWR: 按照读写方式打开串口  设置串口raw模式，清空输入输出的缓冲区 在VxWorks中配置串口可以直接通过ioctl的控制命令来实现
ioctl(fd,FIOSETOPTIONS,OPT_RAW); ioctl(fd,FIOFLUSH,0); ioctl(int fd,int function,int arg); function的参数如下：
   参数 说明     FIOBAUDRATE 设置波特率，arg为一整数，表示要设定的波特率   FIOGETOPTIONS 取得设备控制字，arg表示读出的内容存放的位置   FIOSETOPTIONS 设置设备控制字，arg表示要设置的选项   FIOGETNAME 取得文件描述符对应的文件名，arg存放文件名的缓冲区   FIOREAD 取得输入缓冲区内未读取的字符数，arg用于接收结果的整型指针   FIOWRITE 取得输出缓冲区内的字符个数，arg用于接收结果的整型指针   FIOFLUSH 清空输入输出缓冲区的字符   FIOCANCEL 取消读和写    设置波特率，数据位，停止位，校验方式 在 VxWorks 中设置串口也是用 &lsquo;ioctl&rsquo; 系统调用加控制命令实现，其控制命令为&rsquo;SIO_HW_OPTS_SET'，第三个参数跟配置参数，如：数据位为8，停止位为1，无奇偶校验位，无流控可以这样配置
ioctl(fd,SIO_HW_OPTS_SET,CS8|PARENB|CLOCAL|CREAD); 具体各项参数意义如下：
   参数 说明     CLOCAL 忽略modem控制信号   CREAD 启动接收器   CSIZE 指定数据位：CS5~CS8   HUPCL 最后关闭时挂断modem连接   STOP8 被设置时指定2位停止位，否则默认为1位停止位   PARENB 被设置时启用奇偶校验，否则默认为无奇偶校验   PARODD 被设置时启用奇校验，否则默认为偶校验(PARENB设置时才有效)    串口读写操作 在VxWorks系统中串口的读写操作非常简单，直接使用系统调用函数 read() 和 write() 就能实现串口的读写操作。
int read(int fd, char *buffer, size_t maxbytes) 参数说明：
 fd: 用open函数打开串口设备返回的文件描述符 buffer: 读取的内容将要存放的地址，为指针变量 maxbytes: 读取的最大字节数  int write(int fd, char *buffer, size_t nbytes) 参数说明：
 fd: 用open函数打开串口设备返回的文件描述符 buffer: 将要写的内容的地址，为指针变量，通常为字符串首地址 nbytes: 将要写入的字节数，通常为要写入的字符串的长度  实例代码 VxWorks系统下串口读写的实例代码，仅供参考。
#include &#34;vxWorks.h&#34;#include &#34;stdio.h&#34;#include &#34;ioLib.h&#34;#include &#34;taskLib.h&#34;#include &#34;sioLib.h&#34;#include &#34;sdLib.h&#34;#include &#34;semLib.h&#34;#include &#34;msgQLib.h&#34; char wbuf[] = &#34;hello&#34;; #define DEV_NAME &#34;/tyCo/2&#34; #define MAX_BUF_SIZE 20 #define SD_COMMDATA_NAME &#34;share_data&#34; #define SD_COMMDATA_MUTEX &#34;share_sem&#34; #define SHARE_DATA_LENGTH 20  typedef struct unix_clock_struct { UINT32 sec; /* ms */ UINT32 msec; /* s */ UINT8 quality; /* 时标质量 */ } UNIX_CLOCK_STRUCT; char *comdata; int set_serial(int fd); SEM_ID mutexComdata; void taskUart(void); int main(void) { int ret; int sdCommId; char r_buff[MAX_BUF_SIZE]; mutexComdata = semOpen(SD_COMMDATA_MUTEX, SEM_TYPE_MUTEX, SEM_FULL, SEM_Q_PRIORITY | SEM_DELETE_SAFE | \ SEM_INVERSION_SAFE, OM_CREATE | OM_DELETE_ON_LAST_CLOSE, NULL); if(mutexComdata == NULL) { /*致命错误，无法创建互斥锁*/ printf(&#34;ERROR TO OPEN SD_COMMDATA_MUTEX\n&#34;); taskExit(0); } /* 申请公共数据共享内存 */ sdCommId = sdOpen(SD_COMMDATA_NAME, SD_LINGER, OM_CREATE, SHARE_DATA_LENGTH, 0, SD_ATTR_RW|SD_CACHE_OFF, &amp;comdata); if(sdCommId == NULL) { /*致命错误，无法分配公共数据内存，报错退出*/ printf(&#34;ERROR TO OPEN SD_COMMDATA\n&#34;); taskExit(0); } if((ret = taskSpawn(&#34;taskUart&#34;,90,0x100, 20000, (FUNCPTR)taskUart,\ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)) &lt; 0) { printf(&#34;taskSpawn failed:ret = %s\n&#34;); } return 0; } void taskUart(void) { int ret; int fd = -1; UNIX_CLOCK_STRUCT w_buff; if((fd = open(DEV_NAME, O_RDWR,0)) &lt; 0) { printf(&#34;open %s failed.\n&#34;,DEV_NAME); } /*配置串口参数*/ if((ret = set_serial(fd)) &lt; 0) { printf(&#34;ret = %d\nset_serial failed.\n&#34;); } while(1) { semRTake(mutexComdata,WAIT_FOREVER); #if 0/*清空输入输出缓冲*/ if((ret = ioctl(fd, FIOFLUSH, 0))&lt;0) { printf(&#34; ret = %d\nset FIOFLUSH failed.\n&#34;,ret); } memset(r_buff,0,sizeof(r_buff)); /*读取串口中的值*/ if((ret = read(fd,r_buff,sizeof(r_buff)))&lt;0) { printf(&#34;ret = %d:read %s failed.\n&#34;,ret,DEV_NAME); } else printf(&#34;Received:%s\n&#34;,r_buff); #endif  #if 1  /*清空输入输出缓冲*/ if((ret = ioctl(fd, FIOFLUSH, 0))&lt;0) { printf(&#34; ret = %d\nset FIOFLUSH failed.\n&#34;,ret); } if(NULL == bzero(&amp;w_buff,sizeof(w_buff))) { printf(&#34;memset failed.\n&#34;); } if(NULL == memcpy(&amp;w_buff,comdata,sizeof(w_buff))) { printf(&#34;memset failed.\n&#34;); } if(&amp;w_buff != NULL) { /*往串口中写值*/ if((ret = write(fd, &amp;w_buff.sec, sizeof(ret)))&lt;0) // if((ret = write(fd, wbuf, sizeof(wbuf)))&lt;0)  { printf(&#34;ret = %d:write %s failed.\n&#34;,ret,DEV_NAME); } else { printf(&#34;write success:%d\n&#34;,w_buff.sec); } } semGive(mutexComdata); #endif  taskDelay(sysClkRateGet()*2); } } int set_serial(int fd) { int error = -1; int ok = 0; int ret; if(fd&lt;0) { printf(&#34;error:fd is %d\n&#34;,fd); } /*设定波特率为9600*/ if((ret = ioctl(fd, FIOBAUDRATE, 9600))&lt;0) { printf(&#34;ret = %d\nset baudrate failed\n&#34;,ret); return error; } /*设定：数据位为8，无奇偶校验，1位停止位*/ /*CLOCAL:忽略modem控制信号 * CREAD：启动接收器 * CS8:设定数据位为8*/ if((ret = ioctl(fd, SIO_HW_OPTS_SET,CREAD|CS8 |CLOCAL))&lt;0) { printf(&#34;ret = %d\nset SIO_HW_OPTS_SET failed.\n&#34;); return error; } return ok; } ]]></content>
  </entry>
  
  <entry>
    <title>针对VxWorks的QT 5.15.10发布了</title>
    <url>/post/vxworks/qt-5-15-10-for-vxworks-released.html</url>
    <categories><category>VxWorks</category>
    </categories>
    <tags>
      <tag>VxWorks</tag>
      <tag>QT</tag>
      <tag>图像</tag>
    </tags>
    <content type="html"><![CDATA[Qt是一个多平台的C++图形用户界面应用程序框架。它提供给应用程序开发者建立艺术级的图形用户界面所需的所用功能。Qt是完全面向对象的编程，所以具有易扩展和组件编程的优势。
相关的VxWorks 和 QT的文章，请参阅 VxWorks 6.8操作系统下QT的安装设置和运行方法  。
我们非常激动地发布了支持VxWorks的QT 5.15.10 支持VxWorks的Qt 5.15.10长期支持的商业发行是基于我们最新的QT 5.15.10(LTS)之上的源代码发布。这个发行从早期的QT 5的版本官方升级了针对VxWorks的QT支持，这是对诸如航空和国防以及医疗等行业的市场需求的积极回应。它提供了QT版本的升级同时也提供了VxWorks系统具体的问题解决，还有别的一些改进。
这次发行支持基于iMX6硬件的Ubuntu主机，我们也同时在准备基于x68和基于Windows主机的支持。此次的发行包开放给拥有QT账户的客户，也同时通过git仓库的形式开放给具有商业许可证的客户，请和我们联系以获取更多细节。
从这儿开始 这儿有关于安装和配置的独立的文章，要获取更多关于QT和支持VxWorks的QT的详细信息，请查看这儿关于QT 5.15的在线文档。
   https://doc.qt.io/qt-5/vxworks.html  
   https://doc.qt.io/qt-5/index.html  
   https://wiki.qt.io/Getting_Commercial_Qt_Sources  
 ]]></content>
  </entry>
  
  <entry>
    <title>北南南北</title>
    <url>/about.html</url>
    <categories>
    </categories>
    <tags>
    </tags>
    <content type="html"><![CDATA[北南南北 是众多使用 VxWorks 嵌入式实时操作系统的网友分享经验的平台，为的就是让 VxWorks 的学习和应用变得相对开放一些，在此也欢迎你的加入！
我们的愿景 技术创新是技术持续发展的生命力，紧跟技术的发展趋势，研究最新的技术，保持对新技术的热情和好奇心，让技术为生产和生活服务。
使用反馈  加入 VxWorks Club   或 Google AI TPU     欢迎你的加入
 ]]></content>
  </entry>
  
  <entry>
    <title>VxWorks实时性能探究</title>
    <url>/post/vxworks/vxworks-real-time-feature-explore.html</url>
    <categories><category>VxWorks</category>
    </categories>
    <tags>
      <tag>VxWorks</tag>
      <tag>实时性</tag>
    </tags>
    <content type="html"><![CDATA[ VxWorks操作系统是一款硬实时操作系统，一直听闻其实时性能非常优秀，但是一直没有一个直观地概念。
 笔者最近在使用 VxWorks  , 由大名鼎鼎的风河（WindRiver）开发。本篇文章就是将VxWorks操作系统和市面上几种其他实时操作系统的实时性能进行对比。
前期知识准备 实时性能和响应时间有关，为此，先对计算机操作系统中的时间概念和时间尺度进行一下介绍。
1 s = 1000 ms = 1000000 us = 1000000000 ns，看不出来1 s时间还是很长的嘛
  时钟周期：主频为4 GHz的CPU的时钟周期为1/4G = 0.25 ns，时钟周期是计算机中最基本的、最小的[时间单位。在一个时钟周期内，CPU仅完成一个最基本的动作。
  CPU周期：CPU周期亦称机器周期，一条指令执行过程被划分为若干阶段，每一阶段完成所需时间。完成一个基本操作所需要的时间称为机器周期。通常用内存中读取一个指令字的最短时间来规定CPU周期。
  指令周期：取出并执行一条指令的时间。想要详细了解可以看这篇文章【浅析】CPU中的指令周期、CPU周期和时钟周期
  内存时钟周期：相比CPU，一般的DDR内存芯片速率仅为400 MHz，时钟周期达2.5 ns, 再加上总线延时，导致内存访问时间达到几十纳秒。CPU运行速率与内存访问速率比大致为100：1。
  硬盘读取时间：硬盘的读写速度就更慢了，一般的机械硬盘的完成一次读写所需要的时间，主要取决寻道时间+旋转时间，完成一次读或者写的时间量级大致为ms级别，因此内存访问速率与磁盘存取速度比大致为1000:1。
  上面是有关硬件方面的时间周期情况，对于操作系统或者应用程序来说，我们一般关注的是算法的时间复杂度和空间复杂度，这是从整理理想的情况来衡量一个算法的优劣。如果想要详细了解每条代码的执行所耗时间，我们需要更深入了解代码是怎么在计算机上执行的。
C语言代码都是经过预处理、编译，产生汇编代码（汇编代码几乎已经接近机器码了），一句高级语言代码相当于汇编语言的几行甚至几十行。而学过汇编语言的都应该知道，不同的汇编代码指令执行所耗费的时间也是不同的。一般来说,移位,加法,取反这种指令只需要一个时钟周期,而乘法,除法等指令需要几个乃至几十个时钟周期执行。
实时操作系统（RTOS）的实时性能评价指标 实时操作系统的实时性能评价指标一般有两个：
 任务切换时间  当多任务应用程序运行在操作系统上时，它把正在运行的任务的状态保存到任务自己的栈区之中，然后把下一个将要运行的任务的当前状态从该任务的栈区装入CPU的寄存器，并开始这个任务的执行，这个过程就叫做任务切换。
 中断响应时间  计算机接收到中断信号到操作系统做出响应，并完成切换转入中断服务程序的时间。
下图是几种实时操作系统的实时性能对比：
可以看出不管是任务切换时间还是中断响应，VxWorks都是最好的，当然VxWorks也是最贵的。
此外我们还可以看出不管是任务切换还是中断响应，时间尺度都是在几个us，根据CPU主频的不同，大概是几千个时钟周期的样子。 下面代码是测试执行100万次简单循环语句所耗费的时间:
int i = 1000000; int j = 0; while(i){ j += 0; i--; } timer = 2033 us //执行100万次该循环所耗时间，可以将执行每次的时间和任务切换的时间进行对比 ]]></content>
  </entry>
  
  <entry>
    <title>风河公司的资本交易历史</title>
    <url>/post/vxworks/windriver-capital-transaction.html</url>
    <categories><category>VxWorks</category>
    </categories>
    <tags>
      <tag>WindRiver</tag>
    </tags>
    <content type="html"><![CDATA[日前，安波福宣布同意以43亿美元现金从私募股权公司TPG Capital收购风河公司（ Wind River  ），以帮助其在多个行业的关键软件领域建立独特地位，继续其智能转型，向边缘支持、软件定义的未来迈进。
该交易预计将于2022年年中完成，在被收购之后，风河将隶属于安波福主动安全与用户体验事业部，继续在公司总裁兼首席执行官Kevin Dallas的领导下作为独立业务单位运营。
实时操作系统 作为实时操作系统领域，全球最优秀的选手，它值得我们所有的溢美之词，无论怎么夸它，都不过分。
VxWorks是风河公司推出的实时多任务操作系统（RTOS）。过去40年间，风河和VxWorks在嵌入式OS领域一直处于领先地位，在航空航天、通信、工业控制等行业有着广泛的应用，在业内被称为嵌入式OS的常青树。
风河公司目前有2个嵌入式OS平台：Linux和VxWorks。
VxWorks是由支持多核、32/64位嵌入式处理器、内存包含和内存管理的VxWorks 6.x和VxWorks5.x，Workbench开发工具（包括多种C/C++编译器和调试器），连接组件（USB、IPv4/v6、多种文件系统等），先进的网络协议和图像多媒体等模块组成。除了通用平台外，VxWorks还包括支持工业、网络、医疗和消费电子等的特定平台产品。
老当益壮 风河成立于1981年，2021年收入大约4亿美元，毛利率超过80%。
1987年风河基于VRTX推出VxWorks，1993年IPO上市，1995年VxWorks在NASA Clementine月球探测器上，被发射入太空。
1997年NASA火星探险者号飞船的实时操作系统，登陆火星。
风河是全球第一大嵌入式RTOS厂家，也是全球第一大嵌入式Linux厂家，硬实时操作系统长达30年的霸主，市场占有率超30%。
它的主要收入来自4个领域：
 宇航与国防 工业与医疗 电信 汽车  宇航与国防所占比例最高，接近50%，各种飞船或者说航天飞行器基本都是风河VxWorks的市场，SpaceX也是它的忠实用户，中国神舟系列的SpaceOS也有借鉴VxWorks653。
除了航天飞行器，AH-64阿帕奇武装直升机、F-16V（全球空军主力机型）、F-18大黄蜂，B-2战略轰炸机，X-47A，波音787都是VxWorks。
美国的F-22猛禽、F-35、B-52轰炸机、B-1B轰炸机、C-17运输机和F-16改进型，以及欧洲的A-400M运输机，X-47B无人机，还有民航空客的A380，爱国者防空导弹，都是Vxworks的忠实用户。
把竞争对手买下来，然后干掉！
1999年风河收购一个主要竞争对手，pSOS的发明者，一家集成系统公司。从那以后风河公司不再支持pSOS产品线，并推荐现存的pSOS客户转向VxWorks。
2004年针对网络和通信市场，推出便携的Linux平台，正式进军嵌入式Linux市场。
VxWorks通过了汽车领域最高的ASIL-D级认证，以及远超汽车标准的DO-178C A级认证，它也通过了，已经准备好了对汽车行业进行降维打击。  卖来卖去 2009年英特尔以8.84亿美元收购风河；
2018年4月英特尔出售风河给投资公司TPG。
英特尔刚刚收购4年不到，就卖给了TPG，英特尔也是颇具渣男属性了。
不过，风河公司貌似还不是最后一个被卖来卖去的此类企业，另外一个汽车级嵌入式系统的大牛供应商，Green Hills也在被卖的路上了，我们接下来的文章会保持对它的追踪，及时报道相关信息。
戳穿实时操作系统 在日常的HIL测试工作中，几乎没有哪个测试任务是因为“实时仿真机的实时性不够高”而导致出问题。
HIL工作最容易出问题的地方，往往是功能定义不明确、工具链不完整、协同自动化测试做不起来、线束掉链子以及项目上各种瞎搞等等。
换句话说，在汽车HIL测试领域，哪怕是最low逼的实时操作系统，也足够了，人家Vector公司用wince做实时机，照样玩得飞起，不耽误事。
HIL实时机诞生的历史环境，已经不复存在了，当年的PC机真是太鸡肋了。
而且，在近些年大火的自动驾驶测试领域，我见过太多实时性差得一批的测试系统，响应滞后得跟PID调节似的，却闭口不谈实时性问题，忽忽悠悠就验收通过了……
资本市场 通过这些收购案例，我们也能看到资本唯利是图的本性，什么来钱快干什么，脑子一热就买了，兴奋劲儿过了之后又卖了，不符合自己的产品路线，也照样卖掉。
]]></content>
  </entry>
  
  <entry>
    <title>Mermaid支持流程图</title>
    <url>/post/mermaid-charts.html</url>
    <categories><category>示例</category>
    </categories>
    <tags>
      <tag>流程图</tag>
      <tag>时序图</tag>
    </tags>
    <content type="html"><![CDATA[本主题已支持 Mermaid 实现以纯文本的方式绘制流程图、序列图、甘特图、状态图、关系图行等等，随着 Mermaid 也在逐步发展，后续还会有各种各样的图被引入进来，更多的类型及使用方式可关注其官方网站： https://mermaid-js.github.io/  。
使用说明  通过 hugo new 命令创建一篇新的文章 在文章头部配置 mermaid: true 使用短代码书写各种类型的图，自带2个参数： align（对齐） 和 bc（背景色），可参考如下使用示例   流程图 {{&lt; mermaid align=&#34;left&#34; &gt;}} graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D; {{&lt; /mermaid &gt;}} graph TD; A--B; A--C; B--D; C--D;  时序图 {{&lt; mermaid bc=&#34;#eee&#34; &gt;}} sequenceDiagram participant Alice participant Bob Alice-&gt;&gt;John: Hello John, how are you? loop Healthcheck John-&gt;&gt;John: Fight against hypochondria end Note right of John: Rational thoughts &lt;br/&gt;prevail! John--&gt;&gt;Alice: Great! John-&gt;&gt;Bob: How about you? Bob--&gt;&gt;John: Jolly good! {{&lt; /mermaid &gt;}} sequenceDiagram participant Alice participant Bob Alice-John: Hello John, how are you? loop Healthcheck John-John: Fight against hypochondria end Note right of John: Rational thoughts prevail! John--Alice: Great! John-Bob: How about you? Bob--John: Jolly good!  类图 {{&lt; mermaid &gt;}} classDiagram Class01 &lt;|-- AveryLongClass : Cool Class03 *-- Class04 Class05 o-- Class06 Class07 .. Class08 Class09 --&gt; C2 : Where am i? Class09 --* C3 Class09 --|&gt; Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08 &lt;--&gt; C2: Cool label {{&lt; /mermaid &gt;}} classDiagram Class01 C2 : Where am i? Class09 --* C3 Class09 --| Class07 Class07 : equals() Class07 : Object[] elementData Class01 : size() Class01 : int chimp Class01 : int gorilla Class08  C2: Cool label  甘特图 {{&lt; mermaid &gt;}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d {{&lt; /mermaid &gt;}} gantt dateFormat YYYY-MM-DD title Adding GANTT diagram to mermaid excludes weekdays 2014-01-10 section A section Completed task :done, des1, 2014-01-06,2014-01-08 Active task :active, des2, 2014-01-09, 3d Future task : des3, after des2, 5d Future task2 : des4, after des3, 5d  实体关系图 {{&lt; mermaid &gt;}} erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses {{&lt; /mermaid &gt;}} erDiagram CUSTOMER ||--o{ ORDER : places ORDER ||--|{ LINE-ITEM : contains CUSTOMER }|..|{ DELIVERY-ADDRESS : uses  用户旅程 {{&lt; mermaid &gt;}} journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me {{&lt; /mermaid &gt;}} journey title My working day section Go to work Make tea: 5: Me Go upstairs: 3: Me Do work: 1: Me, Cat section Go home Go downstairs: 5: Me Sit down: 5: Me ]]></content>
  </entry>
  
  <entry>
    <title>数学公式渲染</title>
    <url>/post/math-formula.html</url>
    <categories><category>示例</category>
    </categories>
    <tags>
      <tag>数学公式</tag>
      <tag>mathjax</tag>
      <tag>katex</tag>
    </tags>
    <content type="html"><![CDATA[本主题支持 mathjax 和 katex 两种不的方案支持数学公式的渲染，可根据自已的需求进行选择。
接下的示例中，将使用 MathJax   方案来展示渲染效果。
 使用 hugo new 命令创建一篇新的文章 可以全局启用数据公式渲染，请在项目配置参数 math: katex 或 math: mathjax 或是将该参数配置到需要显示数学公式的页面头部（减少不必要的加载消耗）   注意： 使用 支持的TeX功能  的联机参考资料。
例子 重复的分数 $$ \frac{1}{\Bigl(\sqrt{\phi \sqrt{5}}-\phi\Bigr) e^{\frac25 \pi}} \equiv 1+\frac{e^{-2\pi}} {1+\frac{e^{-4\pi}} {1+\frac{e^{-6\pi}} {1+\frac{e^{-8\pi}} {1+\cdots} } } } $$
总和记号 $$ \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) $$
几何级数之和 我把接下来的两个例子分成了几行，这样它在手机上表现得更好。这就是为什么它们包含 \displaystyle。
$$ \displaystyle\sum_{i=1}^{k+1}i $$
$$ \displaystyle= \left(\sum_{i=1}^{k}i\right) +(k+1) $$
$$ \displaystyle= \frac{k(k+1)}{2}+k+1 $$
$$ \displaystyle= \frac{k(k+1)+2(k+1)}{2} $$
$$ \displaystyle= \frac{(k+1)(k+2)}{2} $$
$$ \displaystyle= \frac{(k+1)((k+1)+1)}{2} $$
乘记号 $$ \displaystyle 1 + \frac{q^2}{(1-q)}+\frac{q^6}{(1-q)(1-q^2)}+\cdots = \displaystyle \prod_{j=0}^{\infty}\frac{1}{(1-q^{5j+2})(1-q^{5j+3})}, \displaystyle\text{ for }\lvert q\rvert &lt; 1. $$
随文数式 这是一些线性数学: $$ k_{n+1} = n^2 + k_n^2 - k_{n-1} $$ ， 然后是更多的文本。
希腊字母 $$ \Gamma\ \Delta\ \Theta\ \Lambda\ \Xi\ \Pi\ \Sigma\ \Upsilon\ \Phi\ \Psi\ \Omega \alpha\ \beta\ \gamma\ \delta\ \epsilon\ \zeta\ \eta\ \theta\ \iota\ \kappa\ \lambda\ \mu\ \nu\ \xi \ \omicron\ \pi\ \rho\ \sigma\ \tau\ \upsilon\ \phi\ \chi\ \psi\ \omega\ \varepsilon\ \vartheta\ \varpi\ \varrho\ \varsigma\ \varphi $$
箭头 $$ \gets\ \to\ \leftarrow\ \rightarrow\ \uparrow\ \Uparrow\ \downarrow\ \Downarrow\ \updownarrow\ \Updownarrow $$
$$ \Leftarrow\ \Rightarrow\ \leftrightarrow\ \Leftrightarrow\ \mapsto\ \hookleftarrow \leftharpoonup\ \leftharpoondown\ \rightleftharpoons\ \longleftarrow\ \Longleftarrow\ \longrightarrow $$
$$ \Longrightarrow\ \longleftrightarrow\ \Longleftrightarrow\ \longmapsto\ \hookrightarrow\ \rightharpoonup $$
$$ \rightharpoondown\ \leadsto\ \nearrow\ \searrow\ \swarrow\ \nwarrow $$
符号 $$ \surd\ \barwedge\ \veebar\ \odot\ \oplus\ \otimes\ \oslash\ \circledcirc\ \boxdot\ \bigtriangleup $$
$$ \bigtriangledown\ \dagger\ \diamond\ \star\ \triangleleft\ \triangleright\ \angle\ \infty\ \prime\ \triangle $$
微积分学 $$ \int u \frac{dv}{dx},dx=uv-\int \frac{du}{dx}v,dx $$
$$ f(x) = \int_{-\infty}^\infty \hat f(\xi),e^{2 \pi i \xi x} $$
$$ \oint \vec{F} \cdot d\vec{s}=0 $$
洛伦茨方程 $$ \begin{aligned} \dot{x} &amp; = \sigma(y-x) \\ \dot{y} &amp; = \rho x - y - xz \\ \dot{z} &amp; = -\beta z + xy \end{aligned} $$
交叉乘积 这在KaTeX中是可行的，但在这种环境中馏分的分离不是很好。
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \\ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \\ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
这里有一个解决方案:使用“mfrac”类(在MathJax情况下没有区别)的额外类使分数更小:
$$ \mathbf{V}_1 \times \mathbf{V}_2 = \begin{vmatrix} \mathbf{i} &amp; \mathbf{j} &amp; \mathbf{k} \\ \frac{\partial X}{\partial u} &amp; \frac{\partial Y}{\partial u} &amp; 0 \\ \frac{\partial X}{\partial v} &amp; \frac{\partial Y}{\partial v} &amp; 0 \end{vmatrix} $$
强调 $$ \hat{x}\ \vec{x}\ \ddot{x} $$
有弹性的括号 $$ \left(\frac{x^2}{y^3}\right) $$
评估范围 $$ \left.\frac{x^3}{3}\right|_0^1 $$
诊断标准 $$ f(n) = \begin{cases} \frac{n}{2}, &amp; \text{if } n\text{ is even} \\ 3n+1, &amp; \text{if } n\text{ is odd} \end{cases} $$
麦克斯韦方程组 $$ \begin{aligned} \nabla \times \vec{\mathbf{B}} -, \frac1c, \frac{\partial\vec{\mathbf{E}}}{\partial t} &amp; = \frac{4\pi}{c}\vec{\mathbf{j}} \\ \nabla \cdot \vec{\mathbf{E}} &amp; = 4 \pi \rho \\ \nabla \times \vec{\mathbf{E}}, +, \frac1c, \frac{\partial\vec{\mathbf{B}}}{\partial t} &amp; = \vec{\mathbf{0}} \\ \nabla \cdot \vec{\mathbf{B}} &amp; = 0 \end{aligned} $$
统计学 固定词组：
$$ \frac{n!}{k!(n-k)!} = {^n}C_k {n \choose k} $$
分数在分数 $$ \frac{\frac{1}{x}+\frac{1}{y}}{y-z} $$
ｎ次方根 $$ \sqrt[n]{1+x+x^2+x^3+\ldots} $$
矩阵 $$ \begin{pmatrix} a_{11} &amp; a_{12} &amp; a_{13}\\ a_{21} &amp; a_{22} &amp; a_{23}\\ a_{31} &amp; a_{32} &amp; a_{33} \end{pmatrix} \begin{bmatrix} 0 &amp; \cdots &amp; 0 \\ \vdots &amp; \ddots &amp; \vdots \\ 0 &amp; \cdots &amp; 0 \end{bmatrix} $$
标点符号 $$ f(x) = \sqrt{1+x} \quad (x \ge -1) f(x) \sim x^2 \quad (x\to\infty) $$
现在用标点符号:
$$ f(x) = \sqrt{1+x}, \quad x \ge -1 f(x) \sim x^2, \quad x\to\infty $$
]]></content>
  </entry>
  
  <entry>
    <title>支持用户自定义设计</title>
    <url>/post/custom-files.html</url>
    <categories><category>示例</category>
    </categories>
    <tags>
      <tag>自定义</tag>
      <tag>个性化</tag>
      <tag>布局</tag>
    </tags>
    <content type="html"><![CDATA[对于熟悉前端开发的用户来说，可以通过自定义文件配置，实现对站点的样式和布局进行个性化的调整。其中布局方面主要是支持左侧边栏的站点概览部分，以及站点底部2个位置，但样式的重置可以是整个站点的任意位置。
打开配置参数 首先要明确在配置文件的 params 区域中有配置如下参数：
customFilePath: sidebar: custom_sidebar.html footer: custom_footer.html style: /css/custom_style.css 注意： sidebar 和 footer 的文件命名不可以与它们的参数名称相同，不然会影响系统默认的布局设计，切记！！！ 😄  然后在站点的根目录下创建 layouts/partials 2个目录，用于存放自定布局设计文件，另外在站点根目录下创建 statics/css 2个目录，用于存放自定义 CSS 样式文件。一切就绪后，就可以参考如下的步骤，完成自己的设计想法。
侧边栏设计 在前面创建 partials 目录中新一个后缀名为 html 的文件，可以在里面书写你所想表达的设计或内容，比如引入一些第三方组件内容。示例如下：
&lt;div class=&#34;mydefined animated&#34; itemprop=&#34;custom&#34;&gt; &lt;span&gt;支持自定义CSS和Sidebar布局啦💄💄💄&lt;/span&gt; &lt;/div&gt; 再把该文件的路径配置到相应的参数中，效果请查看左侧边栏底部的效果。
底部设计 在前面创建 partials 目录中新一个后缀名为 html 的文件，可以在里面书写你所想表达的设计或内容，比如引入一些第三方组件内容。示例如下：
&lt;div class=&#34;custom-footer&#34;&gt; Website source code &lt;a href=&#34;https://github.com/hugo-next/hugo-theme-next/tree/develop/exampleSite/layouts/partials/custom-footer.html&#34; target=&#34;_blank&#34;&gt;here&lt;/a&gt; &lt;/div&gt; 再把该文件的路径配置到相应的参数中，效果请查看站点底部的效果。
自定义样式 在前面创建 css 目录中新一个后缀名为 css 的文件，然后可以在里面把站点的样式进行重定义，或是增加一些自己定义的样式设计，在写文章时进行引用，示例如下：
.custom-head5 { font-size: 1.2em; color: #ed6c24; font-weight: bold; } 再把该文件的路径配置到相应的参数中，效果参考如下：
我是自定义的标题样式效果!!!
]]></content>
  </entry>
  
  <entry>
    <title>自定义短语示例</title>
    <url>/post/shortcodes.html</url>
    <categories><category>示例</category>
    </categories>
    <tags>
      <tag>短代码</tag>
      <tag>语法</tag>
    </tags>
    <content type="html"><![CDATA[虽然 Markdown 语法已经非常丰富能够满足我们写文章的绝大部分需求，但是为更好的对文章内容进行更友好的排版，为引设计一套自定义的短语，便于在使用时能够快速引用。
块引用 在引用一些经典名言名句时，可以采用此短语，语法参考如下：
{{&lt; quote &gt;}} ### block quote 写下你想表达的话语！ {{&lt; /quote &gt;}} 实际效果：
希望是无所谓有，无所谓无的，这正如地上的路。
其实地上本没有路，走的人多了，也便成了路。
鲁迅
 信息块 支持 default，info，success，warning，danger 等五种不同效果的展示，语法参考如下：
{{&lt; note [class] [no-icon] &gt;}} 书写表达的信息 支持 Markdown 语法 {{&lt; /note &gt;}} 实际效果：
Default Header without icon Welcome to Hugo NexT!  Default Header Welcome to Hugo NexT!  Info Header Welcome to Hugo NexT!  Success Header Welcome to Hugo NexT!  Warning Header Welcome to Hugo NexT!  Danger Header Welcome to Hugo NexT! ]]></content>
  </entry>
  
  <entry>
    <title>文章目录导航</title>
    <url>/post/table-of-content.html</url>
    <categories><category>示例</category>
    </categories>
    <tags>
      <tag>目录</tag>
      <tag>导航</tag>
      <tag>博客</tag>
    </tags>
    <content type="html"><![CDATA[巴顿将军说过：“衡量一个人是否成功，不是看他站到顶峰，而是从顶峰跌落之后的反弹力”，褚时健的人生便是如此，中年发家致富，名利双收，之后又跌落到谷底，等到74岁再创业，10年后带着褚橙归来，东山再起收获亿万财富，他的发展轨迹就是反弹的过程。
早年的故事 起始 2014年的春天，在云南省华宁县和宜良县的交界处，一座名叫矣则的小山村里，一处已经有上百年历史的古旧四合院宅子被拆掉。村委会正带领村民们进行“美丽乡村”的建设，一年以后，旧有村居将再也看不到，代之而起的是钢筋混凝土的新式民居。就像10年、20年前中国大小城市的改造一样，这个群山围绕的小村子也开始陷入“工地模式”。
童年浪花 在江河边长大的孩子几乎都有一个当仁不让的特长：善水。褚时健也不例外，他不仅从小就在南盘江和花鱼塘里扑腾出了上佳的游泳技术，五六岁已经可以一个猛子扎出老远，而且从七八岁就可以在南盘江和河滩上的鱼塘里捉鱼了。
少年故事 褚时健在乡村自由自在生活的十多年，其实正是中国社会风雨飘摇的十多年。特别是1937年卢沟桥事变后，日本人发动全面侵华战争，短短两三年间，中国的大部分国土相继沦陷
激情的青春十年 当上了游击队员 1948年夏天，褚时健回乡，在禄丰车站小学做了一名老师，同时也和褚时仁、褚时杰一起继续保持与共产党组织的联系，做一些传递情报的工作
战火纷飞 因为战斗力相较悬殊，所以游击队只能是靠打一枪换一个地方的办法，专找敌人薄弱的地方攻击，但更多时候，都是在防御和转移阵地。
迎来解放 1949年12月，国民党云南省主席卢汉在昆明宣布起义，云南正式拉开解放的序幕。1950年2月20日，陈赓、宋任穷、周保中率解放军第二野战军第四兵团进入昆明，24日，陈赓宣布云南全境解放。
生活的断层 跌入生活底层 “反右”运动中被打倒的人在“右派”身份确定后，只有一条路可走：下放到农场。农场名副其实，就是干农活儿的地方，必须过和农民一样的生活。
尾声 岁月像一条河 2015年，是褚时健和马静芬结婚60周年，被称为“钻石婚”的纪念年份。这简直是一份人生的奖赏,在中国离婚率愈益升高的当下，60年的婚姻，几乎就像一个前世之梦。一个甲子的相伴相随，褚时健和马静芬共同经历了国家和个人的各种风浪，共同面对过生死。他们两人已经不仅是夫妻，更是一对战友。尽管马静芬偶尔会对褚时健年轻时候的粗心抱怨上两句，但说到最后，她会说一句：“没有我就没有他，没有他也就没有我。”
作者致谢 这本书从2014年初夏开始采访，到今天完稿，历时18个月。封面上“作者”只能是我一个人的名字，但也只有我自己知道，这本书，包含了太多人的心力和体力。我当然首先要致谢王石先生，没有他就没有这本书。我自己细想下来，没有王石先生一直的鞭策和鼓励，也没有我写作工作的今天。从2006年我开始从事专业写作工作以来，他给我创造了很多写作的机会，并且不吝自己诸多人生和学习的体会和感悟，一一传递予我。知遇之恩，感谢非常。
最后，我当然要把最大的感谢致予褚时健先生。不仅是因为他慷慨、坦率面对我的各种提问，更重要的是，在倾听他的故事的过程里，他繁盛的人生经历，他的强大生命力，他对生活、对事业的一片赤子之心，也丰富了我对自己人生的思考。
]]></content>
  </entry>
  
  <entry>
    <title>Hugo 内置的 Chroma 语法高亮</title>
    <url>/post/syntax-highlighting.html</url>
    <categories><category>示例</category>
    </categories>
    <tags>
      <tag>语法</tag>
      <tag>高亮</tag>
      <tag>Chroma</tag>
    </tags>
    <content type="html"><![CDATA[Hugo 通过 Chroma 提供非常快速的语法高亮显示，现 Hugo 中使用 Chroma 作为代码块高亮支持，它内置在 Go 语言当中，速度是真的非常、非常快，而且最为重要的是它也兼容之前我们使用的 Pygments 方式。
以下通过 Hugo 内置短代码 highlight 和 Markdown 代码块方式分别验证不同语言的代码块渲染效果并能正确高亮显示，有关优化语法突出显示的更多信息，请参阅 Hugo 文档  。
编程语言 GO 199 200 201 202 203 204 205 206 207 208  func GetTitleFunc(style string) func(s string) string { switch strings.ToLower(style) { case &#34;go&#34;: return strings.Title case &#34;chicago&#34;: return transform.NewTitleConverter(transform.ChicagoStyle) default: return transform.NewTitleConverter(transform.APStyle)  } }   Java import javax.swing.JFrame; //Importing class JFrame import javax.swing.JLabel; //Importing class JLabel public class HelloWorld { public static void main(String[] args) { JFrame frame = new JFrame(); //Creating frame  frame.setTitle(&#34;Hi!&#34;); //Setting title frame  frame.add(new JLabel(&#34;Hello, world!&#34;));//Adding text to frame  frame.pack(); //Setting size to smallest  frame.setLocationRelativeTo(null); //Centering frame  frame.setVisible(true); //Showing frame  } } Python print &#34;Hello, world!&#34; Git 对比 *** /path/to/original &#39;&#39;timestamp&#39;&#39; --- /path/to/new &#39;&#39;timestamp&#39;&#39; *************** *** 1 **** ! This is a line. --- 1 --- ! This is a replacement line. It is important to spell -removed line +new line *** /path/to/original &#39;&#39;timestamp&#39;&#39; --- /path/to/new &#39;&#39;timestamp&#39;&#39; *************** *** 1 **** ! This is a line. --- 1 --- ! This is a replacement line. It is important to spell -removed line +new line 文件 Make 文件 CC=gcc CFLAGS=-I. hellomake: hellomake.o hellofunc.o $(CC) -o hellomake hellomake.o hellofunc.o -I. Markdown 文档 **bold** *italics* [link](www.example.com) 数据内容 JSON 数据 {&#34;employees&#34;:[ {&#34;firstName&#34;:&#34;John&#34;, &#34;lastName&#34;:&#34;Doe&#34;}, ]} XML 内容 &lt;employees&gt; &lt;employee&gt; &lt;firstName&gt;John&lt;/firstName&gt; &lt;lastName&gt;Doe&lt;/lastName&gt; &lt;/employee&gt; &lt;/employees&gt; SQL 查询 SELECT column_name,column_name FROM Table WHERE column_name = &#34;condition&#34; 除以上列举的代码高亮显示外，还支持诸如：C 语言、C++、HTML、CSS、Shell脚本等各主流的代码语言高亮显示，可自行测试效果。
]]></content>
  </entry>
  
  <entry>
    <title>支持 Emoji 表情</title>
    <url>/post/emoji-support.html</url>
    <categories><category>示例</category>
    </categories>
    <tags>
      <tag>表情</tag>
      <tag>emoji</tag>
    </tags>
    <content type="html"><![CDATA[Emoji 可以通过多种方式在 Hugo 项目中启用。
 emojify   方法可以直接在模板中调用, 或者使用 行内 Shortcodes  .
要全局使用 emoji, 需要在你的 网站配置  中设置 enableEmoji 为 true， 然后你就可以直接在文章中输入 emoji 的代码。
它们以冒号开头和结尾，并且包含 emoji 的 代码：
去露营啦! {:}tent: 很快就回来. 真开心! {:}joy: 呈现的输出效果如下:
去露营啦! ⛺ 很快就回来。
真开心! 😂
以下符号清单是 emoji 代码的非常有用的参考。
表情与情感 笑脸表情    图标 代码 图标 代码     😀 grinning 😃 smiley   😄 smile 😁 grin   😆 laughing satisfied 😅 sweat_smile   🤣 rofl 😂 joy   🙂 slightly_smiling_face 🙃 upside_down_face   😉 wink 😊 blush   😇 innocent      爱意表情    图标 代码 图标 代码     😍 heart_eyes 😘 kissing_heart   😗 kissing ☺️ relaxed   😚 kissing_closed_eyes 😙 kissing_smiling_eyes    吐舌头表情    图标 代码 图标 代码     😋 yum 😛 stuck_out_tongue   😜 stuck_out_tongue_winking_eye 😝 stuck_out_tongue_closed_eyes   🤑 money_mouth_face      国家和地区旗帜    图标 代码 图标 代码     🇦🇩 andorra 🇦🇪 united_arab_emirates   🇦🇫 afghanistan 🇦🇬 antigua_barbuda   🇦🇮 anguilla 🇦🇱 albania   🇦🇲 armenia 🇦🇴 angola   🇦🇶 antarctica 🇦🇷 argentina   🇦🇸 american_samoa 🇦🇹 austria   🇦🇺 australia 🇦🇼 aruba   🇦🇽 aland_islands 🇦🇿 azerbaijan   🇧🇦 bosnia_herzegovina 🇧🇧 barbados   🇧🇩 bangladesh 🇧🇪 belgium   🇧🇫 burkina_faso 🇧🇬 bulgaria   🇧🇭 bahrain 🇧🇮 burundi   🇧🇯 benin 🇧🇱 st_barthelemy   🇧🇲 bermuda 🇧🇳 brunei   🇧🇴 bolivia 🇧🇶 caribbean_netherlands   🇧🇷 brazil 🇧🇸 bahamas   🇧🇹 bhutan 🇧🇼 botswana   🇧🇾 belarus 🇧🇿 belize   🇨🇦 canada 🇨🇨 cocos_islands   🇨🇩 congo_kinshasa 🇨🇫 central_african_republic   🇨🇬 congo_brazzaville 🇨🇭 switzerland   🇨🇮 cote_divoire 🇨🇰 cook_islands   🇨🇱 chile 🇨🇲 cameroon   🇨🇳 cn 🇨🇴 colombia   🇨🇷 costa_rica 🇨🇺 cuba   🇨🇻 cape_verde 🇨🇼 curacao   🇨🇽 christmas_island 🇨🇾 cyprus   🇨🇿 czech_republic 🇩🇪 de   🇩🇯 djibouti 🇩🇰 denmark   🇩🇲 dominica 🇩🇴 dominican_republic   🇩🇿 algeria 🇪🇨 ecuador   🇪🇪 estonia 🇪🇬 egypt   🇪🇭 western_sahara 🇪🇷 eritrea   🇪🇸 es 🇪🇹 ethiopia   🇪🇺 eu european_union 🇫🇮 finland   🇫🇯 fiji 🇫🇰 falkland_islands   🇫🇲 micronesia 🇫🇴 faroe_islands   🇫🇷 fr 🇬🇦 gabon   🇬🇧 gb uk 🇬🇩 grenada   🇬🇪 georgia 🇬🇫 french_guiana   🇬🇬 guernsey 🇬🇭 ghana   🇬🇮 gibraltar 🇬🇱 greenland   🇬🇲 gambia 🇬🇳 guinea   🇬🇵 guadeloupe 🇬🇶 equatorial_guinea   🇬🇷 greece 🇬🇸 south_georgia_south_sandwich_islands   🇬🇹 guatemala 🇬🇺 guam   🇬🇼 guinea_bissau 🇬🇾 guyana   🇭🇰 hong_kong 🇭🇳 honduras   🇭🇷 croatia 🇭🇹 haiti   🇭🇺 hungary 🇮🇨 canary_islands   🇮🇩 indonesia 🇮🇪 ireland   🇮🇱 israel 🇮🇲 isle_of_man   🇮🇳 india 🇮🇴 british_indian_ocean_territory   🇮🇶 iraq 🇮🇷 iran   🇮🇸 iceland 🇮🇹 it   🇯🇪 jersey 🇯🇲 jamaica   🇯🇴 jordan 🇯🇵 jp   🇰🇪 kenya 🇰🇬 kyrgyzstan   🇰🇭 cambodia 🇰🇮 kiribati   🇰🇲 comoros 🇰🇳 st_kitts_nevis   🇰🇵 north_korea 🇰🇷 kr   🇰🇼 kuwait 🇰🇾 cayman_islands   🇰🇿 kazakhstan 🇱🇦 laos   🇱🇧 lebanon 🇱🇨 st_lucia   🇱🇮 liechtenstein 🇱🇰 sri_lanka   🇱🇷 liberia 🇱🇸 lesotho   🇱🇹 lithuania 🇱🇺 luxembourg   🇱🇻 latvia 🇱🇾 libya   🇲🇦 morocco 🇲🇨 monaco   🇲🇩 moldova 🇲🇪 montenegro   🇲🇬 madagascar 🇲🇭 marshall_islands   🇲🇰 macedonia 🇲🇱 mali   🇲🇲 myanmar 🇲🇳 mongolia   🇲🇴 macau 🇲🇵 northern_mariana_islands   🇲🇶 martinique 🇲🇷 mauritania   🇲🇸 montserrat 🇲🇹 malta   🇲🇺 mauritius 🇲🇻 maldives   🇲🇼 malawi 🇲🇽 mexico   🇲🇾 malaysia 🇲🇿 mozambique   🇳🇦 namibia 🇳🇨 new_caledonia   🇳🇪 niger 🇳🇫 norfolk_island   🇳🇬 nigeria 🇳🇮 nicaragua   🇳🇱 netherlands 🇳🇴 norway   🇳🇵 nepal 🇳🇷 nauru   🇳🇺 niue 🇳🇿 new_zealand   🇴🇲 oman 🇵🇦 panama   🇵🇪 peru 🇵🇫 french_polynesia   🇵🇬 papua_new_guinea 🇵🇭 philippines   🇵🇰 pakistan 🇵🇱 poland   🇵🇲 st_pierre_miquelon 🇵🇳 pitcairn_islands   🇵🇷 puerto_rico 🇵🇸 palestinian_territories   🇵🇹 portugal 🇵🇼 palau   🇵🇾 paraguay 🇶🇦 qatar   🇷🇪 reunion 🇷🇴 romania   🇷🇸 serbia 🇷🇺 ru   🇷🇼 rwanda 🇸🇦 saudi_arabia   🇸🇧 solomon_islands 🇸🇨 seychelles   🇸🇩 sudan 🇸🇪 sweden   🇸🇬 singapore 🇸🇭 st_helena   🇸🇮 slovenia 🇸🇰 slovakia   🇸🇱 sierra_leone 🇸🇲 san_marino   🇸🇳 senegal 🇸🇴 somalia   🇸🇷 suriname 🇸🇸 south_sudan   🇸🇹 sao_tome_principe 🇸🇻 el_salvador   🇸🇽 sint_maarten 🇸🇾 syria   🇸🇿 swaziland 🇹🇨 turks_caicos_islands   🇹🇩 chad 🇹🇫 french_southern_territories   🇹🇬 togo 🇹🇭 thailand   🇹🇯 tajikistan 🇹🇰 tokelau   🇹🇱 timor_leste 🇹🇲 turkmenistan   🇹🇳 tunisia 🇹🇴 tonga   🇹🇷 tr 🇹🇹 trinidad_tobago   🇹🇻 tuvalu 🇹🇼 taiwan   🇹🇿 tanzania 🇺🇦 ukraine   🇺🇬 uganda 🇺🇸 us   🇺🇾 uruguay 🇺🇿 uzbekistan   🇻🇦 vatican_city 🇻🇨 st_vincent_grenadines   🇻🇪 venezuela 🇻🇬 british_virgin_islands   🇻🇮 us_virgin_islands 🇻🇳 vietnam   🇻🇺 vanuatu 🇼🇫 wallis_futuna   🇼🇸 samoa 🇽🇰 kosovo   🇾🇪 yemen 🇾🇹 mayotte   🇿🇦 south_africa 🇿🇲 zambia   🇿🇼 zimbabwe     ]]></content>
  </entry>
  
  <entry>
    <title>Markdown 语法支持</title>
    <url>/post/markdown-syntax.html</url>
    <categories><category>示例</category>
    </categories>
    <tags>
      <tag>Markdown</tag>
      <tag>语法</tag>
    </tags>
    <content type="html"><![CDATA[仅以此篇文章来测试下在 NexT 主题中在通过 Hugo 引擎来建站时，是否支持 Markdown 文件内容中所写的各种语法，并展示下实际的效果。
标题样式 让我们从所有可能的标题开始，在 HTML 中 &lt;h1&gt;-&lt;h6&gt;元素分别表示六个不同级别的标题样式，其中 &lt;h1&gt; 为最大标题，&lt;h6&gt;为最小标题，效果如下：
标题 1 标题 2 标题 3 标题 4 标题 5 标题 6 段落格式 根据 W3C  定义的 HTML5 规范  ，HTML 文档由元素和文本组成。每个元素的组成都由一个 开始标记  表示，例如： &lt;body&gt; ，和 结束标记  表示，例如： &lt;/body&gt; 。（某些开始标记和结束标记在某些情况下可以省略，并由其他标记暗示。） 元素可以具有属性，这些属性控制元素的工作方式。例如：超链接是使用 a 元素及其 href 属性形成的。
Markdown 语法 ![图像说明](图像地址) HTML IMG 标签 &lt;img src=&#34;图像地址&#34; width=&#34;宽度&#34; height=&#34;高度&#34; /&gt; SVG 格式 &lt;svg&gt;xxxxxx&lt;/svg&gt; 
列表类型 有序列表  第一个元素 第二个元素 第三个元素  无序列表  列表元素 另一个元素 和其它元素  嵌套列表 借助 HTML 的 ul 元素来实现。
 第一项 第二项  第二项第一个子项目 第二项第二个子项目  第二项第二分项第一分项 第二项第二分项第二分项 第二项第二分项第三分项   第二项第三个子项目  第二项第三分项第一分项 第二项第三分项第二分项 第二项第三分项第三分项    第三项  自定义列表 通过 HTML 的 dl 元素还支持自定义列表（表格列表）。
 Hugo 目录结构 assets config.toml content data theme static Hugo 模板 基础模板 列表模板 单页模板  块引用 blockquote 元素表示从另一个源引用的内容，可以选择引用必须在 footer 或 cite 元素中，也可以选择使用注释和缩写等行内更改。
 引用文本 这一行也是同样的引用 同样你也在 blockquote 中使用 Markdown 语法书写
 带有引文的 Blockquote 元素效果。
 我的目标不是赚大钱,是为了制造好的电脑。当我意识到我可以永远当工程师时，我才创办了这家公司。
— 史蒂夫·沃兹尼亚克  根据 Mozilla 的网站记录，Firefox 1.0 于 2004 年发布，并取得了巨大成功。
表格 表格并不算是 Markdown 的核心要素，但 Hugo 同样支持它。
   ID 创建者 模型 年份     1 Honda Accord 2009   2 Toyota Camry 2012   3 Hyundai Elantra 2010    可以使用 : （英文格式冒号）来对表格内容进行对齐。
   表格 可以是 很酷     左对齐 居中 右对齐   左对齐 居中 右对齐   左对齐 居中 右对齐    同样也可以在表格中使用 Markdown 语法。
   表格 中 使用 Markdown 语法     斜体 粗体 中划线 代码块    Code &lt;!DOCTYPE html&gt; &lt;html lang=&#34;en&#34;&gt; &lt;head&gt; &lt;meta charset=&#34;UTF-8&#34;&gt; &lt;title&gt;Example HTML5 Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;Test&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; &lt;!DOCTYPE html&gt; &lt;html lang=&#34;en&#34;&gt; &lt;head&gt; &lt;meta charset=&#34;UTF-8&#34;&gt; &lt;title&gt;Example HTML5 Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;Test&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; 其它元素： abbr、sub、sup、kbd等等 GIF 是位图图像格式。
H2O
C6H12O6
Xn + Yn = Zn
按X获胜。或按CTRL+ALT+F显示 FPS 计数器。
比特作为信息论中的信息单位，也被称为 shannon ，以信息论领域的创始人 Claude shannon 的名字命名。
参考：
 来自 Mainroad 主题的 Basic Elements   内容 ]]></content>
  </entry>
  
  <entry>
    <title>友情链接</title>
    <url>/flinks.html</url>
    <categories>
    </categories>
    <tags>
    </tags>
    <content type="html"><![CDATA[如想交换本站友情链接，请在评论区留下你的站点信息，格式参考如下：
- name: VxWorks俱乐部 desc: VxWorks实时操作系统 avatar: https://www.vxworks.net/images/vxworks-club-logo.png link: https://www.vxworks.net ]]></content>
  </entry>
  
</search>